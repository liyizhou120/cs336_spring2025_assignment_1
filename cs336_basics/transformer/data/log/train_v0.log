2025-11-23 16:20:27.874 | INFO     | __main__:<module>:67 - Start initializing model
2025-11-23 16:22:09.465 | INFO     | __main__:<module>:68 - Start initializing model
2025-11-23 16:22:10.114 | INFO     | __main__:<module>:79 - Initialization completed
2025-11-23 16:22:10.114 | INFO     | __main__:<module>:82 - Start initializing optimizer
2025-11-23 16:22:10.115 | INFO     | __main__:<module>:89 - Optimizer initialization completed
2025-11-23 16:22:10.115 | INFO     | __main__:<module>:103 - Not providing checkpoint. Begin from start
2025-11-23 16:22:10.115 | INFO     | __main__:<module>:105 - Start loading training dataset: ./data/token/TinyStories_train_10000_token_ids.npy, validation set: ./data/token/TinyStories_valid_10000_token_ids.npy
2025-11-23 16:46:03.473 | INFO     | __main__:<module>:68 - Start initializing model
2025-11-23 16:46:04.129 | INFO     | __main__:<module>:79 - Initialization completed
2025-11-23 16:46:04.129 | INFO     | __main__:<module>:82 - Start initializing optimizer
2025-11-23 16:46:04.130 | INFO     | __main__:<module>:89 - Optimizer initialization completed
2025-11-23 16:46:04.130 | INFO     | __main__:<module>:103 - Not providing checkpoint. Begin from start
2025-11-23 16:46:04.130 | INFO     | __main__:<module>:105 - Start loading training dataset: ./data/token/TinyStories_train_10000_token_ids.npy, validation set: ./data/token/TinyStories_valid_10000_token_ids.npy
2025-11-23 20:11:17.745 | INFO     | __main__:<module>:68 - Start initializing model
2025-11-23 20:31:42.395 | INFO     | __main__:<module>:68 - Start initializing model
2025-11-23 20:31:47.132 | INFO     | __main__:<module>:79 - Initialization completed
2025-11-23 20:31:47.133 | INFO     | __main__:<module>:82 - Start initializing optimizer
2025-11-23 20:31:47.133 | INFO     | __main__:<module>:89 - Optimizer initialization completed
2025-11-23 20:31:47.133 | INFO     | __main__:<module>:103 - Not providing checkpoint. Begin from start
2025-11-23 20:31:47.134 | INFO     | __main__:<module>:105 - Start loading training dataset: ./data/token/TinyStories_train_10000_token_ids.npy, validation set: ./data/token/TinyStories_valid_10000_token_ids.npy
2025-11-23 22:08:02.146 | INFO     | __main__:<module>:68 - Start initializing model
2025-11-23 22:08:04.076 | INFO     | __main__:<module>:79 - Initialization completed
2025-11-23 22:08:04.076 | INFO     | __main__:<module>:82 - Start initializing optimizer
2025-11-23 22:08:04.077 | INFO     | __main__:<module>:89 - Optimizer initialization completed
2025-11-23 22:08:04.077 | INFO     | __main__:<module>:103 - Not providing checkpoint. Begin from start
2025-11-23 22:08:04.077 | INFO     | __main__:<module>:105 - Start loading training dataset: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/token/TinyStories_train_10000_token_ids.npy, validation set: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/token/TinyStories_valid_10000_token_ids.npy
2025-11-23 22:08:04.078 | INFO     | __main__:<module>:110 - Dataset loaded successfully
2025-11-23 22:08:04.078 | INFO     | __main__:<module>:115 - 总token数: 541204140, 训练轮数: 0.5, batch大小: 16, 上下文长度: 256
2025-11-23 22:08:04.078 | INFO     | __main__:<module>:116 - 总训练步数: 66064
2025-11-23 22:08:04.078 | INFO     | __main__:<module>:119 - Start training models...
2025-11-23 22:08:05.894 | INFO     | __main__:<module>:160 - Step10, Loss: 9.20979118347168, Grad L2 Norm: 8.613034879090264e-06
2025-11-23 22:08:07.263 | INFO     | __main__:<module>:160 - Step20, Loss: 9.207963943481445, Grad L2 Norm: 3.7948622775729746e-05
2025-11-23 22:08:08.634 | INFO     | __main__:<module>:160 - Step30, Loss: 9.205224990844727, Grad L2 Norm: 7.83634022809565e-05
2025-11-23 22:08:10.010 | INFO     | __main__:<module>:160 - Step40, Loss: 9.201213836669922, Grad L2 Norm: 0.00013600407692138106
2025-11-23 22:08:11.384 | INFO     | __main__:<module>:160 - Step50, Loss: 9.195821762084961, Grad L2 Norm: 0.00020786176901310682
2025-11-23 22:08:12.762 | INFO     | __main__:<module>:160 - Step60, Loss: 9.18879508972168, Grad L2 Norm: 0.0003040149749722332
2025-11-23 22:08:14.144 | INFO     | __main__:<module>:160 - Step70, Loss: 9.182096481323242, Grad L2 Norm: 0.0003900013689417392
2025-11-23 22:08:15.520 | INFO     | __main__:<module>:160 - Step80, Loss: 9.170950889587402, Grad L2 Norm: 0.0005499281105585396
2025-11-23 22:08:16.899 | INFO     | __main__:<module>:160 - Step90, Loss: 9.164247512817383, Grad L2 Norm: 0.0006322706467472017
2025-11-23 22:08:18.276 | INFO     | __main__:<module>:160 - Step100, Loss: 9.151863098144531, Grad L2 Norm: 0.0008226896752603352
2025-11-23 22:08:19.655 | INFO     | __main__:<module>:160 - Step110, Loss: 9.140024185180664, Grad L2 Norm: 0.0009512893157079816
2025-11-23 22:08:21.037 | INFO     | __main__:<module>:160 - Step120, Loss: 9.124418258666992, Grad L2 Norm: 0.0011491298209875822
2025-11-23 22:08:22.418 | INFO     | __main__:<module>:160 - Step130, Loss: 9.110442161560059, Grad L2 Norm: 0.0013218886451795697
2025-11-23 22:08:23.800 | INFO     | __main__:<module>:160 - Step140, Loss: 9.097908020019531, Grad L2 Norm: 0.0014793087029829621
2025-11-23 22:08:25.187 | INFO     | __main__:<module>:160 - Step150, Loss: 9.082786560058594, Grad L2 Norm: 0.0017077361699193716
2025-11-23 22:08:26.574 | INFO     | __main__:<module>:160 - Step160, Loss: 9.063281059265137, Grad L2 Norm: 0.001978877931833267
2025-11-23 22:08:27.965 | INFO     | __main__:<module>:160 - Step170, Loss: 9.043066024780273, Grad L2 Norm: 0.002172979526221752
2025-11-23 22:08:29.352 | INFO     | __main__:<module>:160 - Step180, Loss: 9.02453899383545, Grad L2 Norm: 0.0023777892347425222
2025-11-23 22:08:30.741 | INFO     | __main__:<module>:160 - Step190, Loss: 8.998929977416992, Grad L2 Norm: 0.0026182059664279222
2025-11-23 22:08:32.131 | INFO     | __main__:<module>:160 - Step200, Loss: 8.985431671142578, Grad L2 Norm: 0.002869672840461135
2025-11-23 22:08:33.526 | INFO     | __main__:<module>:160 - Step210, Loss: 8.946361541748047, Grad L2 Norm: 0.0032172631472349167
2025-11-23 22:08:34.924 | INFO     | __main__:<module>:160 - Step220, Loss: 8.939452171325684, Grad L2 Norm: 0.0034773109946399927
2025-11-23 22:08:36.324 | INFO     | __main__:<module>:160 - Step230, Loss: 8.897878646850586, Grad L2 Norm: 0.0038213469088077545
2025-11-23 22:08:37.725 | INFO     | __main__:<module>:160 - Step240, Loss: 8.864505767822266, Grad L2 Norm: 0.004136681091040373
2025-11-23 22:08:39.126 | INFO     | __main__:<module>:160 - Step250, Loss: 8.858259201049805, Grad L2 Norm: 0.004366779234260321
2025-11-23 22:08:40.524 | INFO     | __main__:<module>:160 - Step260, Loss: 8.812429428100586, Grad L2 Norm: 0.004804691299796104
2025-11-23 22:08:41.924 | INFO     | __main__:<module>:160 - Step270, Loss: 8.779300689697266, Grad L2 Norm: 0.005116619635373354
2025-11-23 22:08:43.323 | INFO     | __main__:<module>:160 - Step280, Loss: 8.764276504516602, Grad L2 Norm: 0.005464381538331509
2025-11-23 22:08:44.723 | INFO     | __main__:<module>:160 - Step290, Loss: 8.73833179473877, Grad L2 Norm: 0.00587110361084342
2025-11-23 22:08:46.123 | INFO     | __main__:<module>:160 - Step300, Loss: 8.687100410461426, Grad L2 Norm: 0.006109099835157394
2025-11-23 22:08:47.523 | INFO     | __main__:<module>:160 - Step310, Loss: 8.68061637878418, Grad L2 Norm: 0.00607073912397027
2025-11-23 22:08:48.921 | INFO     | __main__:<module>:160 - Step320, Loss: 8.61333179473877, Grad L2 Norm: 0.006907383445650339
2025-11-23 22:08:50.324 | INFO     | __main__:<module>:160 - Step330, Loss: 8.588451385498047, Grad L2 Norm: 0.007057230919599533
2025-11-23 22:08:51.724 | INFO     | __main__:<module>:160 - Step340, Loss: 8.568437576293945, Grad L2 Norm: 0.007436973042786121
2025-11-23 22:08:53.125 | INFO     | __main__:<module>:160 - Step350, Loss: 8.513898849487305, Grad L2 Norm: 0.007698944769799709
2025-11-23 22:08:54.525 | INFO     | __main__:<module>:160 - Step360, Loss: 8.47126579284668, Grad L2 Norm: 0.008253189735114574
2025-11-23 22:08:55.928 | INFO     | __main__:<module>:160 - Step370, Loss: 8.458541870117188, Grad L2 Norm: 0.008609969168901443
2025-11-23 22:08:57.330 | INFO     | __main__:<module>:160 - Step380, Loss: 8.427852630615234, Grad L2 Norm: 0.008840566501021385
2025-11-23 22:08:58.741 | INFO     | __main__:<module>:160 - Step390, Loss: 8.33700180053711, Grad L2 Norm: 0.009705384261906147
2025-11-23 22:09:00.143 | INFO     | __main__:<module>:160 - Step400, Loss: 8.330716133117676, Grad L2 Norm: 0.009469338692724705
2025-11-23 22:09:00.144 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:09:00.969 | INFO     | __main__:<module>:181 - validation loss: 8.291158628463744
2025-11-23 22:09:02.382 | INFO     | __main__:<module>:160 - Step410, Loss: 8.252317428588867, Grad L2 Norm: 0.010375400073826313
2025-11-23 22:09:03.786 | INFO     | __main__:<module>:160 - Step420, Loss: 8.25655460357666, Grad L2 Norm: 0.010142910294234753
2025-11-23 22:09:05.190 | INFO     | __main__:<module>:160 - Step430, Loss: 8.129941940307617, Grad L2 Norm: 0.011373201385140419
2025-11-23 22:09:06.598 | INFO     | __main__:<module>:160 - Step440, Loss: 8.077526092529297, Grad L2 Norm: 0.01170758344233036
2025-11-23 22:09:08.004 | INFO     | __main__:<module>:160 - Step450, Loss: 8.128122329711914, Grad L2 Norm: 0.01107051596045494
2025-11-23 22:09:09.408 | INFO     | __main__:<module>:160 - Step460, Loss: 8.017446517944336, Grad L2 Norm: 0.011997206136584282
2025-11-23 22:09:10.816 | INFO     | __main__:<module>:160 - Step470, Loss: 8.030324935913086, Grad L2 Norm: 0.01211419515311718
2025-11-23 22:09:12.224 | INFO     | __main__:<module>:160 - Step480, Loss: 7.882019996643066, Grad L2 Norm: 0.012771950103342533
2025-11-23 22:09:13.632 | INFO     | __main__:<module>:160 - Step490, Loss: 7.921996116638184, Grad L2 Norm: 0.01257432159036398
2025-11-23 22:09:15.042 | INFO     | __main__:<module>:160 - Step500, Loss: 7.8684797286987305, Grad L2 Norm: 0.012998860329389572
2025-11-23 22:09:16.464 | INFO     | __main__:<module>:160 - Step510, Loss: 7.865888595581055, Grad L2 Norm: 0.013083968311548233
2025-11-23 22:09:17.875 | INFO     | __main__:<module>:160 - Step520, Loss: 7.728871822357178, Grad L2 Norm: 0.01360368449240923
2025-11-23 22:09:19.292 | INFO     | __main__:<module>:160 - Step530, Loss: 7.669918060302734, Grad L2 Norm: 0.014071933925151825
2025-11-23 22:09:20.702 | INFO     | __main__:<module>:160 - Step540, Loss: 7.551612377166748, Grad L2 Norm: 0.01440142560750246
2025-11-23 22:09:22.111 | INFO     | __main__:<module>:160 - Step550, Loss: 7.570810794830322, Grad L2 Norm: 0.013825196772813797
2025-11-23 22:09:23.520 | INFO     | __main__:<module>:160 - Step560, Loss: 7.590404510498047, Grad L2 Norm: 0.01349845714867115
2025-11-23 22:09:24.929 | INFO     | __main__:<module>:160 - Step570, Loss: 7.5325422286987305, Grad L2 Norm: 0.013869483955204487
2025-11-23 22:09:26.341 | INFO     | __main__:<module>:160 - Step580, Loss: 7.399576663970947, Grad L2 Norm: 0.014528746716678143
2025-11-23 22:09:27.750 | INFO     | __main__:<module>:160 - Step590, Loss: 7.395676612854004, Grad L2 Norm: 0.014200332574546337
2025-11-23 22:09:29.159 | INFO     | __main__:<module>:160 - Step600, Loss: 7.460811614990234, Grad L2 Norm: 0.013758535496890545
2025-11-23 22:09:30.570 | INFO     | __main__:<module>:160 - Step610, Loss: 7.226396560668945, Grad L2 Norm: 0.014715678989887238
2025-11-23 22:09:31.980 | INFO     | __main__:<module>:160 - Step620, Loss: 7.233590126037598, Grad L2 Norm: 0.01462587434798479
2025-11-23 22:09:33.389 | INFO     | __main__:<module>:160 - Step630, Loss: 7.205862522125244, Grad L2 Norm: 0.014615502208471298
2025-11-23 22:09:34.799 | INFO     | __main__:<module>:160 - Step640, Loss: 7.184593677520752, Grad L2 Norm: 0.0147969676181674
2025-11-23 22:09:36.210 | INFO     | __main__:<module>:160 - Step650, Loss: 7.213248252868652, Grad L2 Norm: 0.014411147683858871
2025-11-23 22:09:37.620 | INFO     | __main__:<module>:160 - Step660, Loss: 7.298121452331543, Grad L2 Norm: 0.013452920131385326
2025-11-23 22:09:39.031 | INFO     | __main__:<module>:160 - Step670, Loss: 7.153923511505127, Grad L2 Norm: 0.01446028333157301
2025-11-23 22:09:40.441 | INFO     | __main__:<module>:160 - Step680, Loss: 7.154692649841309, Grad L2 Norm: 0.014325691387057304
2025-11-23 22:09:41.850 | INFO     | __main__:<module>:160 - Step690, Loss: 6.996152877807617, Grad L2 Norm: 0.015292086638510227
2025-11-23 22:09:43.348 | INFO     | __main__:<module>:160 - Step700, Loss: 6.9152984619140625, Grad L2 Norm: 0.01591295190155506
2025-11-23 22:09:44.786 | INFO     | __main__:<module>:160 - Step710, Loss: 6.886429786682129, Grad L2 Norm: 0.015958089381456375
2025-11-23 22:09:46.226 | INFO     | __main__:<module>:160 - Step720, Loss: 6.867367744445801, Grad L2 Norm: 0.01575903408229351
2025-11-23 22:09:47.666 | INFO     | __main__:<module>:160 - Step730, Loss: 6.930410861968994, Grad L2 Norm: 0.0146373575553298
2025-11-23 22:09:49.106 | INFO     | __main__:<module>:160 - Step740, Loss: 6.900088310241699, Grad L2 Norm: 0.016200602054595947
2025-11-23 22:09:50.545 | INFO     | __main__:<module>:160 - Step750, Loss: 6.686041831970215, Grad L2 Norm: 0.016729488968849182
2025-11-23 22:09:51.981 | INFO     | __main__:<module>:160 - Step760, Loss: 6.603221893310547, Grad L2 Norm: 0.01685546338558197
2025-11-23 22:09:53.491 | INFO     | __main__:<module>:160 - Step770, Loss: 6.6638994216918945, Grad L2 Norm: 0.016028262674808502
2025-11-23 22:09:54.958 | INFO     | __main__:<module>:160 - Step780, Loss: 6.6243791580200195, Grad L2 Norm: 0.01639237441122532
2025-11-23 22:09:56.425 | INFO     | __main__:<module>:160 - Step790, Loss: 6.501008987426758, Grad L2 Norm: 0.017158187925815582
2025-11-23 22:09:57.895 | INFO     | __main__:<module>:160 - Step800, Loss: 6.597904205322266, Grad L2 Norm: 0.016938766464591026
2025-11-23 22:09:57.895 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:09:58.773 | INFO     | __main__:<module>:181 - validation loss: 6.60306408405304
2025-11-23 22:10:00.248 | INFO     | __main__:<module>:160 - Step810, Loss: 6.584214687347412, Grad L2 Norm: 0.016889767721295357
2025-11-23 22:10:01.716 | INFO     | __main__:<module>:160 - Step820, Loss: 6.609352111816406, Grad L2 Norm: 0.015954535454511642
2025-11-23 22:10:03.185 | INFO     | __main__:<module>:160 - Step830, Loss: 6.535594940185547, Grad L2 Norm: 0.016184626147150993
2025-11-23 22:10:04.654 | INFO     | __main__:<module>:160 - Step840, Loss: 6.5148210525512695, Grad L2 Norm: 0.01620279997587204
2025-11-23 22:10:06.121 | INFO     | __main__:<module>:160 - Step850, Loss: 6.429577350616455, Grad L2 Norm: 0.017271870747208595
2025-11-23 22:10:07.589 | INFO     | __main__:<module>:160 - Step860, Loss: 6.319930076599121, Grad L2 Norm: 0.01731451041996479
2025-11-23 22:10:09.059 | INFO     | __main__:<module>:160 - Step870, Loss: 6.230771541595459, Grad L2 Norm: 0.017015133053064346
2025-11-23 22:10:10.528 | INFO     | __main__:<module>:160 - Step880, Loss: 6.130980491638184, Grad L2 Norm: 0.018163667991757393
2025-11-23 22:10:11.998 | INFO     | __main__:<module>:160 - Step890, Loss: 6.367230415344238, Grad L2 Norm: 0.017158934846520424
2025-11-23 22:10:13.581 | INFO     | __main__:<module>:160 - Step900, Loss: 6.40322208404541, Grad L2 Norm: 0.016689663752913475
2025-11-23 22:10:15.133 | INFO     | __main__:<module>:160 - Step910, Loss: 6.255740165710449, Grad L2 Norm: 0.017548421397805214
2025-11-23 22:10:16.684 | INFO     | __main__:<module>:160 - Step920, Loss: 6.2027740478515625, Grad L2 Norm: 0.017647532746195793
2025-11-23 22:10:18.235 | INFO     | __main__:<module>:160 - Step930, Loss: 5.998293876647949, Grad L2 Norm: 0.01825454644858837
2025-11-23 22:10:19.788 | INFO     | __main__:<module>:160 - Step940, Loss: 5.956838607788086, Grad L2 Norm: 0.018222307786345482
2025-11-23 22:10:21.338 | INFO     | __main__:<module>:160 - Step950, Loss: 6.055420398712158, Grad L2 Norm: 0.017596552148461342
2025-11-23 22:10:22.888 | INFO     | __main__:<module>:160 - Step960, Loss: 5.990391254425049, Grad L2 Norm: 0.01861802488565445
2025-11-23 22:10:24.369 | INFO     | __main__:<module>:160 - Step970, Loss: 6.000202178955078, Grad L2 Norm: 0.018135594204068184
2025-11-23 22:10:25.848 | INFO     | __main__:<module>:160 - Step980, Loss: 6.145618438720703, Grad L2 Norm: 0.017535170540213585
2025-11-23 22:10:27.325 | INFO     | __main__:<module>:160 - Step990, Loss: 6.006123065948486, Grad L2 Norm: 0.018377048894762993
2025-11-23 22:10:28.796 | INFO     | __main__:<module>:160 - Step1000, Loss: 5.967182636260986, Grad L2 Norm: 0.01803908497095108
2025-11-23 22:10:30.383 | INFO     | __main__:<module>:160 - Step1010, Loss: 5.940817832946777, Grad L2 Norm: 0.01781567558646202
2025-11-23 22:10:31.916 | INFO     | __main__:<module>:160 - Step1020, Loss: 5.947004318237305, Grad L2 Norm: 0.01772211119532585
2025-11-23 22:10:33.455 | INFO     | __main__:<module>:160 - Step1030, Loss: 5.8015923500061035, Grad L2 Norm: 0.018324904143810272
2025-11-23 22:10:34.994 | INFO     | __main__:<module>:160 - Step1040, Loss: 5.721333980560303, Grad L2 Norm: 0.01982606202363968
2025-11-23 22:10:36.528 | INFO     | __main__:<module>:160 - Step1050, Loss: 5.83493709564209, Grad L2 Norm: 0.017950590699911118
2025-11-23 22:10:38.061 | INFO     | __main__:<module>:160 - Step1060, Loss: 5.865653991699219, Grad L2 Norm: 0.01870294101536274
2025-11-23 22:10:39.600 | INFO     | __main__:<module>:160 - Step1070, Loss: 5.558197498321533, Grad L2 Norm: 0.019884677603840828
2025-11-23 22:10:41.136 | INFO     | __main__:<module>:160 - Step1080, Loss: 5.770704746246338, Grad L2 Norm: 0.019589537754654884
2025-11-23 22:10:42.674 | INFO     | __main__:<module>:160 - Step1090, Loss: 5.730786323547363, Grad L2 Norm: 0.018250297755002975
2025-11-23 22:10:44.211 | INFO     | __main__:<module>:160 - Step1100, Loss: 5.551591873168945, Grad L2 Norm: 0.019364511594176292
2025-11-23 22:10:45.746 | INFO     | __main__:<module>:160 - Step1110, Loss: 5.739746570587158, Grad L2 Norm: 0.018017146736383438
2025-11-23 22:10:47.280 | INFO     | __main__:<module>:160 - Step1120, Loss: 5.448972702026367, Grad L2 Norm: 0.019605183973908424
2025-11-23 22:10:48.818 | INFO     | __main__:<module>:160 - Step1130, Loss: 5.537448883056641, Grad L2 Norm: 0.018559500575065613
2025-11-23 22:10:50.356 | INFO     | __main__:<module>:160 - Step1140, Loss: 5.582064628601074, Grad L2 Norm: 0.0190818440169096
2025-11-23 22:10:51.891 | INFO     | __main__:<module>:160 - Step1150, Loss: 5.48896598815918, Grad L2 Norm: 0.019801724702119827
2025-11-23 22:10:53.429 | INFO     | __main__:<module>:160 - Step1160, Loss: 5.507075309753418, Grad L2 Norm: 0.01972116529941559
2025-11-23 22:10:54.967 | INFO     | __main__:<module>:160 - Step1170, Loss: 5.463001251220703, Grad L2 Norm: 0.01864127814769745
2025-11-23 22:10:56.505 | INFO     | __main__:<module>:160 - Step1180, Loss: 5.532278060913086, Grad L2 Norm: 0.01921708881855011
2025-11-23 22:10:58.043 | INFO     | __main__:<module>:160 - Step1190, Loss: 5.226081371307373, Grad L2 Norm: 0.02037947066128254
2025-11-23 22:10:59.582 | INFO     | __main__:<module>:160 - Step1200, Loss: 5.384078502655029, Grad L2 Norm: 0.0200234092772007
2025-11-23 22:10:59.583 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:11:00.519 | INFO     | __main__:<module>:181 - validation loss: 5.409865164756775
2025-11-23 22:11:02.062 | INFO     | __main__:<module>:160 - Step1210, Loss: 5.394220352172852, Grad L2 Norm: 0.01896176114678383
2025-11-23 22:11:03.600 | INFO     | __main__:<module>:160 - Step1220, Loss: 5.425590991973877, Grad L2 Norm: 0.01880406029522419
2025-11-23 22:11:05.136 | INFO     | __main__:<module>:160 - Step1230, Loss: 5.371268272399902, Grad L2 Norm: 0.019215336069464684
2025-11-23 22:11:06.671 | INFO     | __main__:<module>:160 - Step1240, Loss: 5.367341995239258, Grad L2 Norm: 0.020149314776062965
2025-11-23 22:11:08.205 | INFO     | __main__:<module>:160 - Step1250, Loss: 5.311835289001465, Grad L2 Norm: 0.018798738718032837
2025-11-23 22:11:09.739 | INFO     | __main__:<module>:160 - Step1260, Loss: 5.29746150970459, Grad L2 Norm: 0.019237158820033073
2025-11-23 22:11:11.272 | INFO     | __main__:<module>:160 - Step1270, Loss: 5.196084976196289, Grad L2 Norm: 0.019432779401540756
2025-11-23 22:11:12.808 | INFO     | __main__:<module>:160 - Step1280, Loss: 5.046473503112793, Grad L2 Norm: 0.019618472084403038
2025-11-23 22:11:14.343 | INFO     | __main__:<module>:160 - Step1290, Loss: 5.134256362915039, Grad L2 Norm: 0.02038080245256424
2025-11-23 22:11:15.876 | INFO     | __main__:<module>:160 - Step1300, Loss: 5.065421104431152, Grad L2 Norm: 0.02030504122376442
2025-11-23 22:11:17.411 | INFO     | __main__:<module>:160 - Step1310, Loss: 5.2237653732299805, Grad L2 Norm: 0.020876318216323853
2025-11-23 22:11:18.947 | INFO     | __main__:<module>:160 - Step1320, Loss: 4.985612869262695, Grad L2 Norm: 0.02016281709074974
2025-11-23 22:11:20.481 | INFO     | __main__:<module>:160 - Step1330, Loss: 5.073693752288818, Grad L2 Norm: 0.020071087405085564
2025-11-23 22:11:22.016 | INFO     | __main__:<module>:160 - Step1340, Loss: 4.798768043518066, Grad L2 Norm: 0.019883429631590843
2025-11-23 22:11:23.549 | INFO     | __main__:<module>:160 - Step1350, Loss: 5.232178688049316, Grad L2 Norm: 0.019697576761245728
2025-11-23 22:11:25.087 | INFO     | __main__:<module>:160 - Step1360, Loss: 4.99631929397583, Grad L2 Norm: 0.02073606662452221
2025-11-23 22:11:26.619 | INFO     | __main__:<module>:160 - Step1370, Loss: 4.945767402648926, Grad L2 Norm: 0.021064726635813713
2025-11-23 22:11:28.153 | INFO     | __main__:<module>:160 - Step1380, Loss: 4.755239486694336, Grad L2 Norm: 0.01974414847791195
2025-11-23 22:11:29.690 | INFO     | __main__:<module>:160 - Step1390, Loss: 4.919817924499512, Grad L2 Norm: 0.019548173993825912
2025-11-23 22:11:31.225 | INFO     | __main__:<module>:160 - Step1400, Loss: 4.960236072540283, Grad L2 Norm: 0.019058873876929283
2025-11-23 22:11:32.765 | INFO     | __main__:<module>:160 - Step1410, Loss: 5.055672645568848, Grad L2 Norm: 0.01988619938492775
2025-11-23 22:11:34.302 | INFO     | __main__:<module>:160 - Step1420, Loss: 4.996687889099121, Grad L2 Norm: 0.019732831045985222
2025-11-23 22:11:35.840 | INFO     | __main__:<module>:160 - Step1430, Loss: 4.844852447509766, Grad L2 Norm: 0.019585244357585907
2025-11-23 22:11:37.376 | INFO     | __main__:<module>:160 - Step1440, Loss: 4.518801689147949, Grad L2 Norm: 0.021074166521430016
2025-11-23 22:11:38.911 | INFO     | __main__:<module>:160 - Step1450, Loss: 5.017363548278809, Grad L2 Norm: 0.019298646599054337
2025-11-23 22:11:40.449 | INFO     | __main__:<module>:160 - Step1460, Loss: 4.918619155883789, Grad L2 Norm: 0.019997665658593178
2025-11-23 22:11:41.983 | INFO     | __main__:<module>:160 - Step1470, Loss: 4.766716003417969, Grad L2 Norm: 0.019666913896799088
2025-11-23 22:11:43.527 | INFO     | __main__:<module>:160 - Step1480, Loss: 4.750659465789795, Grad L2 Norm: 0.019372599199414253
2025-11-23 22:11:45.083 | INFO     | __main__:<module>:160 - Step1490, Loss: 4.898016929626465, Grad L2 Norm: 0.019736183807253838
2025-11-23 22:11:46.638 | INFO     | __main__:<module>:160 - Step1500, Loss: 5.037012100219727, Grad L2 Norm: 0.019916227087378502
2025-11-23 22:11:48.197 | INFO     | __main__:<module>:160 - Step1510, Loss: 4.674685001373291, Grad L2 Norm: 0.019310621544718742
2025-11-23 22:11:49.751 | INFO     | __main__:<module>:160 - Step1520, Loss: 4.759929656982422, Grad L2 Norm: 0.019002733752131462
2025-11-23 22:11:51.296 | INFO     | __main__:<module>:160 - Step1530, Loss: 4.592165946960449, Grad L2 Norm: 0.019201237708330154
2025-11-23 22:11:52.846 | INFO     | __main__:<module>:160 - Step1540, Loss: 4.832496166229248, Grad L2 Norm: 0.019341370090842247
2025-11-23 22:11:54.395 | INFO     | __main__:<module>:160 - Step1550, Loss: 4.875303268432617, Grad L2 Norm: 0.020680930465459824
2025-11-23 22:11:55.946 | INFO     | __main__:<module>:160 - Step1560, Loss: 4.672051906585693, Grad L2 Norm: 0.020076416432857513
2025-11-23 22:11:57.500 | INFO     | __main__:<module>:160 - Step1570, Loss: 4.574896812438965, Grad L2 Norm: 0.020058125257492065
2025-11-23 22:11:59.050 | INFO     | __main__:<module>:160 - Step1580, Loss: 4.577981472015381, Grad L2 Norm: 0.020562604069709778
2025-11-23 22:12:00.603 | INFO     | __main__:<module>:160 - Step1590, Loss: 4.472053527832031, Grad L2 Norm: 0.019539467990398407
2025-11-23 22:12:02.152 | INFO     | __main__:<module>:160 - Step1600, Loss: 4.512904644012451, Grad L2 Norm: 0.019003495573997498
2025-11-23 22:12:02.152 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:12:03.096 | INFO     | __main__:<module>:181 - validation loss: 4.659734153747559
2025-11-23 22:12:04.657 | INFO     | __main__:<module>:160 - Step1610, Loss: 4.621757507324219, Grad L2 Norm: 0.01884894259274006
2025-11-23 22:12:06.210 | INFO     | __main__:<module>:160 - Step1620, Loss: 4.389774322509766, Grad L2 Norm: 0.019157297909259796
2025-11-23 22:12:07.758 | INFO     | __main__:<module>:160 - Step1630, Loss: 4.530258655548096, Grad L2 Norm: 0.02007463201880455
2025-11-23 22:12:09.309 | INFO     | __main__:<module>:160 - Step1640, Loss: 4.702676296234131, Grad L2 Norm: 0.01998496614396572
2025-11-23 22:12:10.860 | INFO     | __main__:<module>:160 - Step1650, Loss: 4.358044147491455, Grad L2 Norm: 0.019308660179376602
2025-11-23 22:12:12.414 | INFO     | __main__:<module>:160 - Step1660, Loss: 4.5616984367370605, Grad L2 Norm: 0.019378092139959335
2025-11-23 22:12:13.967 | INFO     | __main__:<module>:160 - Step1670, Loss: 4.389799118041992, Grad L2 Norm: 0.02061847411096096
2025-11-23 22:12:15.521 | INFO     | __main__:<module>:160 - Step1680, Loss: 4.440783977508545, Grad L2 Norm: 0.019240470603108406
2025-11-23 22:12:17.074 | INFO     | __main__:<module>:160 - Step1690, Loss: 4.723398685455322, Grad L2 Norm: 0.02078324742615223
2025-11-23 22:12:18.630 | INFO     | __main__:<module>:160 - Step1700, Loss: 4.519366264343262, Grad L2 Norm: 0.01984628289937973
2025-11-23 22:12:20.185 | INFO     | __main__:<module>:160 - Step1710, Loss: 4.361743927001953, Grad L2 Norm: 0.01992402970790863
2025-11-23 22:12:21.741 | INFO     | __main__:<module>:160 - Step1720, Loss: 4.382747650146484, Grad L2 Norm: 0.0185361597687006
2025-11-23 22:12:23.296 | INFO     | __main__:<module>:160 - Step1730, Loss: 4.478480339050293, Grad L2 Norm: 0.01896543800830841
2025-11-23 22:12:24.922 | INFO     | __main__:<module>:160 - Step1740, Loss: 4.561649322509766, Grad L2 Norm: 0.019976671785116196
2025-11-23 22:12:26.608 | INFO     | __main__:<module>:160 - Step1750, Loss: 4.73425817489624, Grad L2 Norm: 0.020597031340003014
2025-11-23 22:12:28.239 | INFO     | __main__:<module>:160 - Step1760, Loss: 4.666637420654297, Grad L2 Norm: 0.02046695165336132
2025-11-23 22:12:29.872 | INFO     | __main__:<module>:160 - Step1770, Loss: 4.506333351135254, Grad L2 Norm: 0.01956174522638321
2025-11-23 22:12:31.504 | INFO     | __main__:<module>:160 - Step1780, Loss: 4.235993385314941, Grad L2 Norm: 0.019324088469147682
2025-11-23 22:12:33.134 | INFO     | __main__:<module>:160 - Step1790, Loss: 4.4900712966918945, Grad L2 Norm: 0.019901486113667488
2025-11-23 22:12:34.674 | INFO     | __main__:<module>:160 - Step1800, Loss: 4.410625457763672, Grad L2 Norm: 0.020534364506602287
2025-11-23 22:12:36.212 | INFO     | __main__:<module>:160 - Step1810, Loss: 4.403542995452881, Grad L2 Norm: 0.019681600853800774
2025-11-23 22:12:37.745 | INFO     | __main__:<module>:160 - Step1820, Loss: 4.2101874351501465, Grad L2 Norm: 0.01884583756327629
2025-11-23 22:12:39.277 | INFO     | __main__:<module>:160 - Step1830, Loss: 4.239317417144775, Grad L2 Norm: 0.019664257764816284
2025-11-23 22:12:40.812 | INFO     | __main__:<module>:160 - Step1840, Loss: 4.463479518890381, Grad L2 Norm: 0.018688730895519257
2025-11-23 22:12:42.350 | INFO     | __main__:<module>:160 - Step1850, Loss: 4.247347831726074, Grad L2 Norm: 0.019151536747813225
2025-11-23 22:12:43.885 | INFO     | __main__:<module>:160 - Step1860, Loss: 4.26900053024292, Grad L2 Norm: 0.020791662856936455
2025-11-23 22:12:45.495 | INFO     | __main__:<module>:160 - Step1870, Loss: 4.5868425369262695, Grad L2 Norm: 0.0207282155752182
2025-11-23 22:12:47.108 | INFO     | __main__:<module>:160 - Step1880, Loss: 4.221034526824951, Grad L2 Norm: 0.018929528072476387
2025-11-23 22:12:48.722 | INFO     | __main__:<module>:160 - Step1890, Loss: 4.397975921630859, Grad L2 Norm: 0.019467312842607498
2025-11-23 22:12:50.331 | INFO     | __main__:<module>:160 - Step1900, Loss: 4.091516971588135, Grad L2 Norm: 0.018753349781036377
2025-11-23 22:12:51.943 | INFO     | __main__:<module>:160 - Step1910, Loss: 4.256387710571289, Grad L2 Norm: 0.01987726055085659
2025-11-23 22:12:53.545 | INFO     | __main__:<module>:160 - Step1920, Loss: 4.17405891418457, Grad L2 Norm: 0.020161397755146027
2025-11-23 22:12:55.095 | INFO     | __main__:<module>:160 - Step1930, Loss: 4.3601484298706055, Grad L2 Norm: 0.01822264865040779
2025-11-23 22:12:56.613 | INFO     | __main__:<module>:160 - Step1940, Loss: 4.283420562744141, Grad L2 Norm: 0.01900850422680378
2025-11-23 22:12:58.130 | INFO     | __main__:<module>:160 - Step1950, Loss: 4.126243591308594, Grad L2 Norm: 0.018979836255311966
2025-11-23 22:12:59.649 | INFO     | __main__:<module>:160 - Step1960, Loss: 4.001683235168457, Grad L2 Norm: 0.01695210114121437
2025-11-23 22:13:01.167 | INFO     | __main__:<module>:160 - Step1970, Loss: 4.089091777801514, Grad L2 Norm: 0.0184823889285326
2025-11-23 22:13:02.685 | INFO     | __main__:<module>:160 - Step1980, Loss: 4.094104766845703, Grad L2 Norm: 0.019028525799512863
2025-11-23 22:13:04.201 | INFO     | __main__:<module>:160 - Step1990, Loss: 4.056234359741211, Grad L2 Norm: 0.01849009282886982
2025-11-23 22:13:05.719 | INFO     | __main__:<module>:160 - Step2000, Loss: 4.227909088134766, Grad L2 Norm: 0.019769910722970963
2025-11-23 22:13:05.719 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:13:06.630 | INFO     | __main__:<module>:181 - validation loss: 4.215569257736206
2025-11-23 22:13:06.631 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_2000.pt
2025-11-23 22:16:08.989 | INFO     | __main__:<module>:68 - Start initializing model
2025-11-23 22:16:10.901 | INFO     | __main__:<module>:79 - Initialization completed
2025-11-23 22:16:10.901 | INFO     | __main__:<module>:82 - Start initializing optimizer
2025-11-23 22:16:10.902 | INFO     | __main__:<module>:89 - Optimizer initialization completed
2025-11-23 22:16:10.902 | INFO     | __main__:<module>:103 - Not providing checkpoint. Begin from start
2025-11-23 22:16:10.902 | INFO     | __main__:<module>:105 - Start loading training dataset: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/token/TinyStories_train_10000_token_ids.npy, validation set: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/token/TinyStories_valid_10000_token_ids.npy
2025-11-23 22:16:10.903 | INFO     | __main__:<module>:110 - Dataset loaded successfully
2025-11-23 22:16:10.903 | INFO     | __main__:<module>:115 - 总token数: 541204140, 训练轮数: 0.5, batch大小: 16, 上下文长度: 256
2025-11-23 22:16:10.903 | INFO     | __main__:<module>:116 - 总训练步数: 66064
2025-11-23 22:16:10.903 | INFO     | __main__:<module>:119 - Start training models...
2025-11-23 22:16:12.638 | INFO     | __main__:<module>:160 - Step10, Loss: 9.209803581237793, Grad L2 Norm: 8.62547767610522e-06
2025-11-23 22:16:14.008 | INFO     | __main__:<module>:160 - Step20, Loss: 9.207986831665039, Grad L2 Norm: 3.556328374543227e-05
2025-11-23 22:16:15.385 | INFO     | __main__:<module>:160 - Step30, Loss: 9.20506477355957, Grad L2 Norm: 7.93630606494844e-05
2025-11-23 22:16:16.760 | INFO     | __main__:<module>:160 - Step40, Loss: 9.200887680053711, Grad L2 Norm: 0.00014080018445383757
2025-11-23 22:16:18.132 | INFO     | __main__:<module>:160 - Step50, Loss: 9.196313858032227, Grad L2 Norm: 0.00020762858912348747
2025-11-23 22:16:19.506 | INFO     | __main__:<module>:160 - Step60, Loss: 9.189677238464355, Grad L2 Norm: 0.0003041519084945321
2025-11-23 22:16:20.881 | INFO     | __main__:<module>:160 - Step70, Loss: 9.181716918945312, Grad L2 Norm: 0.00039823047700338066
2025-11-23 22:16:22.256 | INFO     | __main__:<module>:160 - Step80, Loss: 9.172545433044434, Grad L2 Norm: 0.0005292954738251865
2025-11-23 22:16:23.633 | INFO     | __main__:<module>:160 - Step90, Loss: 9.164823532104492, Grad L2 Norm: 0.0006446702755056322
2025-11-23 22:16:25.013 | INFO     | __main__:<module>:160 - Step100, Loss: 9.151355743408203, Grad L2 Norm: 0.0008112387149594724
2025-11-23 22:16:26.391 | INFO     | __main__:<module>:160 - Step110, Loss: 9.14076042175293, Grad L2 Norm: 0.0009652217850089073
2025-11-23 22:16:27.772 | INFO     | __main__:<module>:160 - Step120, Loss: 9.122756004333496, Grad L2 Norm: 0.0011415579356253147
2025-11-23 22:16:29.152 | INFO     | __main__:<module>:160 - Step130, Loss: 9.115364074707031, Grad L2 Norm: 0.0013170402962714434
2025-11-23 22:16:30.536 | INFO     | __main__:<module>:160 - Step140, Loss: 9.092475891113281, Grad L2 Norm: 0.0015577217563986778
2025-11-23 22:16:31.919 | INFO     | __main__:<module>:160 - Step150, Loss: 9.077873229980469, Grad L2 Norm: 0.0017909255111590028
2025-11-23 22:16:33.308 | INFO     | __main__:<module>:160 - Step160, Loss: 9.057707786560059, Grad L2 Norm: 0.002007890958338976
2025-11-23 22:16:34.697 | INFO     | __main__:<module>:160 - Step170, Loss: 9.044593811035156, Grad L2 Norm: 0.002135071437805891
2025-11-23 22:16:36.084 | INFO     | __main__:<module>:160 - Step180, Loss: 9.02470588684082, Grad L2 Norm: 0.0024436155799776316
2025-11-23 22:16:37.475 | INFO     | __main__:<module>:160 - Step190, Loss: 9.001538276672363, Grad L2 Norm: 0.002836275612935424
2025-11-23 22:16:38.861 | INFO     | __main__:<module>:160 - Step200, Loss: 8.970943450927734, Grad L2 Norm: 0.003045713761821389
2025-11-23 22:16:40.253 | INFO     | __main__:<module>:160 - Step210, Loss: 8.949604034423828, Grad L2 Norm: 0.003217337653040886
2025-11-23 22:16:41.642 | INFO     | __main__:<module>:160 - Step220, Loss: 8.940359115600586, Grad L2 Norm: 0.0035302378237247467
2025-11-23 22:16:43.037 | INFO     | __main__:<module>:160 - Step230, Loss: 8.917292594909668, Grad L2 Norm: 0.003763011656701565
2025-11-23 22:16:44.432 | INFO     | __main__:<module>:160 - Step240, Loss: 8.883468627929688, Grad L2 Norm: 0.004138236399739981
2025-11-23 22:16:45.824 | INFO     | __main__:<module>:160 - Step250, Loss: 8.842264175415039, Grad L2 Norm: 0.004456255119293928
2025-11-23 22:16:47.218 | INFO     | __main__:<module>:160 - Step260, Loss: 8.812955856323242, Grad L2 Norm: 0.004824500065296888
2025-11-23 22:16:48.616 | INFO     | __main__:<module>:160 - Step270, Loss: 8.811859130859375, Grad L2 Norm: 0.0049451501108706
2025-11-23 22:16:50.017 | INFO     | __main__:<module>:160 - Step280, Loss: 8.760550498962402, Grad L2 Norm: 0.00553301302716136
2025-11-23 22:16:51.416 | INFO     | __main__:<module>:160 - Step290, Loss: 8.739948272705078, Grad L2 Norm: 0.005660037975758314
2025-11-23 22:16:52.817 | INFO     | __main__:<module>:160 - Step300, Loss: 8.674092292785645, Grad L2 Norm: 0.006255283951759338
2025-11-23 22:16:54.217 | INFO     | __main__:<module>:160 - Step310, Loss: 8.665857315063477, Grad L2 Norm: 0.006445565260946751
2025-11-23 22:16:55.618 | INFO     | __main__:<module>:160 - Step320, Loss: 8.629508972167969, Grad L2 Norm: 0.006935640703886747
2025-11-23 22:16:57.017 | INFO     | __main__:<module>:160 - Step330, Loss: 8.605253219604492, Grad L2 Norm: 0.0071674371138215065
2025-11-23 22:16:58.416 | INFO     | __main__:<module>:160 - Step340, Loss: 8.525476455688477, Grad L2 Norm: 0.007886696606874466
2025-11-23 22:16:59.817 | INFO     | __main__:<module>:160 - Step350, Loss: 8.497206687927246, Grad L2 Norm: 0.008296845480799675
2025-11-23 22:17:01.216 | INFO     | __main__:<module>:160 - Step360, Loss: 8.459419250488281, Grad L2 Norm: 0.008568975143134594
2025-11-23 22:17:02.621 | INFO     | __main__:<module>:160 - Step370, Loss: 8.398563385009766, Grad L2 Norm: 0.009111834689974785
2025-11-23 22:17:04.021 | INFO     | __main__:<module>:160 - Step380, Loss: 8.427452087402344, Grad L2 Norm: 0.008926416747272015
2025-11-23 22:17:05.420 | INFO     | __main__:<module>:160 - Step390, Loss: 8.365569114685059, Grad L2 Norm: 0.009485846385359764
2025-11-23 22:17:06.822 | INFO     | __main__:<module>:160 - Step400, Loss: 8.33452033996582, Grad L2 Norm: 0.009683026000857353
2025-11-23 22:17:06.823 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:17:07.641 | INFO     | __main__:<module>:181 - validation loss: 8.29613037109375
2025-11-23 22:17:09.046 | INFO     | __main__:<module>:160 - Step410, Loss: 8.278935432434082, Grad L2 Norm: 0.010242335498332977
2025-11-23 22:17:10.448 | INFO     | __main__:<module>:160 - Step420, Loss: 8.233816146850586, Grad L2 Norm: 0.010604816488921642
2025-11-23 22:17:11.852 | INFO     | __main__:<module>:160 - Step430, Loss: 8.167132377624512, Grad L2 Norm: 0.011052999645471573
2025-11-23 22:17:13.254 | INFO     | __main__:<module>:160 - Step440, Loss: 8.113436698913574, Grad L2 Norm: 0.011801530607044697
2025-11-23 22:17:14.654 | INFO     | __main__:<module>:160 - Step450, Loss: 8.112957000732422, Grad L2 Norm: 0.011555574834346771
2025-11-23 22:17:16.053 | INFO     | __main__:<module>:160 - Step460, Loss: 8.024089813232422, Grad L2 Norm: 0.012156682088971138
2025-11-23 22:17:17.456 | INFO     | __main__:<module>:160 - Step470, Loss: 7.935576915740967, Grad L2 Norm: 0.012648134492337704
2025-11-23 22:17:18.858 | INFO     | __main__:<module>:160 - Step480, Loss: 7.850423812866211, Grad L2 Norm: 0.013171201571822166
2025-11-23 22:17:20.260 | INFO     | __main__:<module>:160 - Step490, Loss: 7.761736869812012, Grad L2 Norm: 0.013932496309280396
2025-11-23 22:17:21.662 | INFO     | __main__:<module>:160 - Step500, Loss: 7.8383283615112305, Grad L2 Norm: 0.013154199346899986
2025-11-23 22:17:23.067 | INFO     | __main__:<module>:160 - Step510, Loss: 7.815059185028076, Grad L2 Norm: 0.013418217189610004
2025-11-23 22:17:24.471 | INFO     | __main__:<module>:160 - Step520, Loss: 7.661991119384766, Grad L2 Norm: 0.014153462834656239
2025-11-23 22:17:25.876 | INFO     | __main__:<module>:160 - Step530, Loss: 7.669291019439697, Grad L2 Norm: 0.013948803767561913
2025-11-23 22:17:27.278 | INFO     | __main__:<module>:160 - Step540, Loss: 7.633122444152832, Grad L2 Norm: 0.013975475914776325
2025-11-23 22:17:28.681 | INFO     | __main__:<module>:160 - Step550, Loss: 7.656569957733154, Grad L2 Norm: 0.01405635941773653
2025-11-23 22:17:30.087 | INFO     | __main__:<module>:160 - Step560, Loss: 7.512359619140625, Grad L2 Norm: 0.01445204671472311
2025-11-23 22:17:31.490 | INFO     | __main__:<module>:160 - Step570, Loss: 7.5099945068359375, Grad L2 Norm: 0.01431326288729906
2025-11-23 22:17:32.895 | INFO     | __main__:<module>:160 - Step580, Loss: 7.479631423950195, Grad L2 Norm: 0.014079305343329906
2025-11-23 22:17:34.304 | INFO     | __main__:<module>:160 - Step590, Loss: 7.360076904296875, Grad L2 Norm: 0.01472575031220913
2025-11-23 22:17:35.709 | INFO     | __main__:<module>:160 - Step600, Loss: 7.397632598876953, Grad L2 Norm: 0.014203022234141827
2025-11-23 22:17:37.115 | INFO     | __main__:<module>:160 - Step610, Loss: 7.295788288116455, Grad L2 Norm: 0.014715198427438736
2025-11-23 22:17:38.523 | INFO     | __main__:<module>:160 - Step620, Loss: 7.218235015869141, Grad L2 Norm: 0.014916370622813702
2025-11-23 22:17:39.930 | INFO     | __main__:<module>:160 - Step630, Loss: 7.249755859375, Grad L2 Norm: 0.014830470085144043
2025-11-23 22:17:41.337 | INFO     | __main__:<module>:160 - Step640, Loss: 7.186058044433594, Grad L2 Norm: 0.014501279219985008
2025-11-23 22:17:42.745 | INFO     | __main__:<module>:160 - Step650, Loss: 7.185916900634766, Grad L2 Norm: 0.014631634578108788
2025-11-23 22:17:44.152 | INFO     | __main__:<module>:160 - Step660, Loss: 7.04356575012207, Grad L2 Norm: 0.015001925639808178
2025-11-23 22:17:45.639 | INFO     | __main__:<module>:160 - Step670, Loss: 7.032851696014404, Grad L2 Norm: 0.015905393287539482
2025-11-23 22:17:47.070 | INFO     | __main__:<module>:160 - Step680, Loss: 7.119967460632324, Grad L2 Norm: 0.014806170016527176
2025-11-23 22:17:48.502 | INFO     | __main__:<module>:160 - Step690, Loss: 6.854164123535156, Grad L2 Norm: 0.01649046689271927
2025-11-23 22:17:49.933 | INFO     | __main__:<module>:160 - Step700, Loss: 6.91649866104126, Grad L2 Norm: 0.015431196428835392
2025-11-23 22:17:51.365 | INFO     | __main__:<module>:160 - Step710, Loss: 6.937314987182617, Grad L2 Norm: 0.016031522303819656
2025-11-23 22:17:52.800 | INFO     | __main__:<module>:160 - Step720, Loss: 6.910196781158447, Grad L2 Norm: 0.015691570937633514
2025-11-23 22:17:54.233 | INFO     | __main__:<module>:160 - Step730, Loss: 6.920992851257324, Grad L2 Norm: 0.015992222353816032
2025-11-23 22:17:55.706 | INFO     | __main__:<module>:160 - Step740, Loss: 6.674025535583496, Grad L2 Norm: 0.017292063683271408
2025-11-23 22:17:57.185 | INFO     | __main__:<module>:160 - Step750, Loss: 6.799824237823486, Grad L2 Norm: 0.016838619485497475
2025-11-23 22:17:58.644 | INFO     | __main__:<module>:160 - Step760, Loss: 6.74433708190918, Grad L2 Norm: 0.01652105152606964
2025-11-23 22:18:00.100 | INFO     | __main__:<module>:160 - Step770, Loss: 6.717835903167725, Grad L2 Norm: 0.01655290089547634
2025-11-23 22:18:01.556 | INFO     | __main__:<module>:160 - Step780, Loss: 6.621787071228027, Grad L2 Norm: 0.01756499707698822
2025-11-23 22:18:03.012 | INFO     | __main__:<module>:160 - Step790, Loss: 6.543461799621582, Grad L2 Norm: 0.017336716875433922
2025-11-23 22:18:04.468 | INFO     | __main__:<module>:160 - Step800, Loss: 6.6161603927612305, Grad L2 Norm: 0.01706073433160782
2025-11-23 22:18:04.469 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:18:05.335 | INFO     | __main__:<module>:181 - validation loss: 6.572024917602539
2025-11-23 22:18:06.796 | INFO     | __main__:<module>:160 - Step810, Loss: 6.548113822937012, Grad L2 Norm: 0.01694483868777752
2025-11-23 22:18:08.252 | INFO     | __main__:<module>:160 - Step820, Loss: 6.4501214027404785, Grad L2 Norm: 0.017567317932844162
2025-11-23 22:18:09.710 | INFO     | __main__:<module>:160 - Step830, Loss: 6.422268390655518, Grad L2 Norm: 0.0180190559476614
2025-11-23 22:18:11.167 | INFO     | __main__:<module>:160 - Step840, Loss: 6.406659126281738, Grad L2 Norm: 0.017359944060444832
2025-11-23 22:18:12.619 | INFO     | __main__:<module>:160 - Step850, Loss: 6.314949989318848, Grad L2 Norm: 0.01769772171974182
2025-11-23 22:18:14.098 | INFO     | __main__:<module>:160 - Step860, Loss: 6.3513712882995605, Grad L2 Norm: 0.017440997064113617
2025-11-23 22:18:15.595 | INFO     | __main__:<module>:160 - Step870, Loss: 6.336597442626953, Grad L2 Norm: 0.0183773934841156
2025-11-23 22:18:17.091 | INFO     | __main__:<module>:160 - Step880, Loss: 6.377798080444336, Grad L2 Norm: 0.01648835465312004
2025-11-23 22:18:18.586 | INFO     | __main__:<module>:160 - Step890, Loss: 6.283125400543213, Grad L2 Norm: 0.01792037859559059
2025-11-23 22:18:20.081 | INFO     | __main__:<module>:160 - Step900, Loss: 5.973493576049805, Grad L2 Norm: 0.019343651831150055
2025-11-23 22:18:21.577 | INFO     | __main__:<module>:160 - Step910, Loss: 6.2299089431762695, Grad L2 Norm: 0.017761467024683952
2025-11-23 22:18:23.072 | INFO     | __main__:<module>:160 - Step920, Loss: 6.23223352432251, Grad L2 Norm: 0.018036367371678352
2025-11-23 22:18:24.568 | INFO     | __main__:<module>:160 - Step930, Loss: 6.008172988891602, Grad L2 Norm: 0.01875956356525421
2025-11-23 22:18:26.063 | INFO     | __main__:<module>:160 - Step940, Loss: 5.905867099761963, Grad L2 Norm: 0.018658623099327087
2025-11-23 22:18:27.557 | INFO     | __main__:<module>:160 - Step950, Loss: 6.126131057739258, Grad L2 Norm: 0.017523448914289474
2025-11-23 22:18:29.051 | INFO     | __main__:<module>:160 - Step960, Loss: 5.813496112823486, Grad L2 Norm: 0.019089240580797195
2025-11-23 22:18:30.546 | INFO     | __main__:<module>:160 - Step970, Loss: 6.063729286193848, Grad L2 Norm: 0.018284492194652557
2025-11-23 22:18:32.040 | INFO     | __main__:<module>:160 - Step980, Loss: 6.002397060394287, Grad L2 Norm: 0.01781487837433815
2025-11-23 22:18:33.534 | INFO     | __main__:<module>:160 - Step990, Loss: 5.834772109985352, Grad L2 Norm: 0.01824425347149372
2025-11-23 22:18:35.027 | INFO     | __main__:<module>:160 - Step1000, Loss: 6.017510890960693, Grad L2 Norm: 0.01763283833861351
2025-11-23 22:18:36.521 | INFO     | __main__:<module>:160 - Step1010, Loss: 5.687501430511475, Grad L2 Norm: 0.018920041620731354
2025-11-23 22:18:38.014 | INFO     | __main__:<module>:160 - Step1020, Loss: 5.687082767486572, Grad L2 Norm: 0.019043192267417908
2025-11-23 22:18:39.508 | INFO     | __main__:<module>:160 - Step1030, Loss: 5.901472091674805, Grad L2 Norm: 0.018332889303565025
2025-11-23 22:18:41.005 | INFO     | __main__:<module>:160 - Step1040, Loss: 5.619102954864502, Grad L2 Norm: 0.019418304786086082
2025-11-23 22:18:42.502 | INFO     | __main__:<module>:160 - Step1050, Loss: 5.832822799682617, Grad L2 Norm: 0.018237067386507988
2025-11-23 22:18:43.997 | INFO     | __main__:<module>:160 - Step1060, Loss: 5.767000675201416, Grad L2 Norm: 0.019114932045340538
2025-11-23 22:18:45.490 | INFO     | __main__:<module>:160 - Step1070, Loss: 5.651910781860352, Grad L2 Norm: 0.019106410443782806
2025-11-23 22:18:46.987 | INFO     | __main__:<module>:160 - Step1080, Loss: 5.669715404510498, Grad L2 Norm: 0.018035223707556725
2025-11-23 22:18:48.483 | INFO     | __main__:<module>:160 - Step1090, Loss: 5.869351387023926, Grad L2 Norm: 0.018680766224861145
2025-11-23 22:18:49.980 | INFO     | __main__:<module>:160 - Step1100, Loss: 5.668544769287109, Grad L2 Norm: 0.018279043957591057
2025-11-23 22:18:51.475 | INFO     | __main__:<module>:160 - Step1110, Loss: 5.695423126220703, Grad L2 Norm: 0.018088774755597115
2025-11-23 22:18:52.970 | INFO     | __main__:<module>:160 - Step1120, Loss: 5.5963640213012695, Grad L2 Norm: 0.019382579252123833
2025-11-23 22:18:54.464 | INFO     | __main__:<module>:160 - Step1130, Loss: 5.538288593292236, Grad L2 Norm: 0.019704055041074753
2025-11-23 22:18:55.961 | INFO     | __main__:<module>:160 - Step1140, Loss: 5.517614364624023, Grad L2 Norm: 0.019126705825328827
2025-11-23 22:18:57.456 | INFO     | __main__:<module>:160 - Step1150, Loss: 5.520965576171875, Grad L2 Norm: 0.0182237196713686
2025-11-23 22:18:58.950 | INFO     | __main__:<module>:160 - Step1160, Loss: 5.542363166809082, Grad L2 Norm: 0.018030401319265366
2025-11-23 22:19:00.445 | INFO     | __main__:<module>:160 - Step1170, Loss: 5.41080379486084, Grad L2 Norm: 0.019343210384249687
2025-11-23 22:19:01.941 | INFO     | __main__:<module>:160 - Step1180, Loss: 5.334625244140625, Grad L2 Norm: 0.01873413473367691
2025-11-23 22:19:03.437 | INFO     | __main__:<module>:160 - Step1190, Loss: 5.067763328552246, Grad L2 Norm: 0.01919187232851982
2025-11-23 22:19:04.934 | INFO     | __main__:<module>:160 - Step1200, Loss: 5.3689165115356445, Grad L2 Norm: 0.019016925245523453
2025-11-23 22:19:04.935 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:19:05.831 | INFO     | __main__:<module>:181 - validation loss: 5.339997863769531
2025-11-23 22:19:07.348 | INFO     | __main__:<module>:160 - Step1210, Loss: 5.356457710266113, Grad L2 Norm: 0.01929781772196293
2025-11-23 22:19:08.972 | INFO     | __main__:<module>:160 - Step1220, Loss: 5.282937049865723, Grad L2 Norm: 0.01912328042089939
2025-11-23 22:19:10.571 | INFO     | __main__:<module>:160 - Step1230, Loss: 5.321696758270264, Grad L2 Norm: 0.019345181062817574
2025-11-23 22:19:12.100 | INFO     | __main__:<module>:160 - Step1240, Loss: 5.169407844543457, Grad L2 Norm: 0.018924938514828682
2025-11-23 22:19:13.631 | INFO     | __main__:<module>:160 - Step1250, Loss: 5.1475629806518555, Grad L2 Norm: 0.018829332664608955
2025-11-23 22:19:15.162 | INFO     | __main__:<module>:160 - Step1260, Loss: 5.103330135345459, Grad L2 Norm: 0.01902688480913639
2025-11-23 22:19:16.691 | INFO     | __main__:<module>:160 - Step1270, Loss: 5.205447196960449, Grad L2 Norm: 0.019427824765443802
2025-11-23 22:19:18.218 | INFO     | __main__:<module>:160 - Step1280, Loss: 5.282739639282227, Grad L2 Norm: 0.01948261819779873
2025-11-23 22:19:19.746 | INFO     | __main__:<module>:160 - Step1290, Loss: 5.07997989654541, Grad L2 Norm: 0.019324226304888725
2025-11-23 22:19:21.274 | INFO     | __main__:<module>:160 - Step1300, Loss: 5.22629451751709, Grad L2 Norm: 0.019422108307480812
2025-11-23 22:19:22.806 | INFO     | __main__:<module>:160 - Step1310, Loss: 5.176119804382324, Grad L2 Norm: 0.01900194212794304
2025-11-23 22:19:24.337 | INFO     | __main__:<module>:160 - Step1320, Loss: 4.945765018463135, Grad L2 Norm: 0.019423726946115494
2025-11-23 22:19:25.868 | INFO     | __main__:<module>:160 - Step1330, Loss: 4.870938301086426, Grad L2 Norm: 0.019904538989067078
2025-11-23 22:19:27.399 | INFO     | __main__:<module>:160 - Step1340, Loss: 5.065268516540527, Grad L2 Norm: 0.020444823428988457
2025-11-23 22:19:28.931 | INFO     | __main__:<module>:160 - Step1350, Loss: 5.342545509338379, Grad L2 Norm: 0.018979951739311218
2025-11-23 22:19:30.461 | INFO     | __main__:<module>:160 - Step1360, Loss: 5.0052170753479, Grad L2 Norm: 0.01979728229343891
2025-11-23 22:19:31.990 | INFO     | __main__:<module>:160 - Step1370, Loss: 5.114636421203613, Grad L2 Norm: 0.01904226839542389
2025-11-23 22:19:33.521 | INFO     | __main__:<module>:160 - Step1380, Loss: 4.86584997177124, Grad L2 Norm: 0.019109264016151428
2025-11-23 22:19:35.051 | INFO     | __main__:<module>:160 - Step1390, Loss: 4.988102912902832, Grad L2 Norm: 0.01973629556596279
2025-11-23 22:19:36.583 | INFO     | __main__:<module>:160 - Step1400, Loss: 4.80360221862793, Grad L2 Norm: 0.019693011417984962
2025-11-23 22:19:38.115 | INFO     | __main__:<module>:160 - Step1410, Loss: 4.882840156555176, Grad L2 Norm: 0.019950542598962784
2025-11-23 22:19:39.644 | INFO     | __main__:<module>:160 - Step1420, Loss: 4.9714460372924805, Grad L2 Norm: 0.018894052132964134
2025-11-23 22:19:41.176 | INFO     | __main__:<module>:160 - Step1430, Loss: 4.83234977722168, Grad L2 Norm: 0.019095633178949356
2025-11-23 22:19:42.707 | INFO     | __main__:<module>:160 - Step1440, Loss: 4.982690334320068, Grad L2 Norm: 0.021301932632923126
2025-11-23 22:19:44.240 | INFO     | __main__:<module>:160 - Step1450, Loss: 4.811084747314453, Grad L2 Norm: 0.01995343342423439
2025-11-23 22:19:45.773 | INFO     | __main__:<module>:160 - Step1460, Loss: 5.011358261108398, Grad L2 Norm: 0.020807817578315735
2025-11-23 22:19:47.305 | INFO     | __main__:<module>:160 - Step1470, Loss: 4.906806468963623, Grad L2 Norm: 0.01858869008719921
2025-11-23 22:19:48.835 | INFO     | __main__:<module>:160 - Step1480, Loss: 4.6537885665893555, Grad L2 Norm: 0.019171157851815224
2025-11-23 22:19:50.367 | INFO     | __main__:<module>:160 - Step1490, Loss: 4.813607692718506, Grad L2 Norm: 0.01975276879966259
2025-11-23 22:19:51.899 | INFO     | __main__:<module>:160 - Step1500, Loss: 4.824610710144043, Grad L2 Norm: 0.019501985982060432
2025-11-23 22:19:53.432 | INFO     | __main__:<module>:160 - Step1510, Loss: 4.675531387329102, Grad L2 Norm: 0.020070912316441536
2025-11-23 22:19:54.962 | INFO     | __main__:<module>:160 - Step1520, Loss: 4.789589881896973, Grad L2 Norm: 0.020210159942507744
2025-11-23 22:19:56.493 | INFO     | __main__:<module>:160 - Step1530, Loss: 4.695986747741699, Grad L2 Norm: 0.019481182098388672
2025-11-23 22:19:58.023 | INFO     | __main__:<module>:160 - Step1540, Loss: 4.560999870300293, Grad L2 Norm: 0.018360525369644165
2025-11-23 22:19:59.557 | INFO     | __main__:<module>:160 - Step1550, Loss: 4.7497406005859375, Grad L2 Norm: 0.019324785098433495
2025-11-23 22:20:01.089 | INFO     | __main__:<module>:160 - Step1560, Loss: 4.535262584686279, Grad L2 Norm: 0.019392933696508408
2025-11-23 22:20:02.621 | INFO     | __main__:<module>:160 - Step1570, Loss: 4.65479040145874, Grad L2 Norm: 0.019642019644379616
2025-11-23 22:20:04.151 | INFO     | __main__:<module>:160 - Step1580, Loss: 4.714990139007568, Grad L2 Norm: 0.01933438889682293
2025-11-23 22:20:05.683 | INFO     | __main__:<module>:160 - Step1590, Loss: 4.645751476287842, Grad L2 Norm: 0.020346112549304962
2025-11-23 22:20:07.216 | INFO     | __main__:<module>:160 - Step1600, Loss: 4.384624481201172, Grad L2 Norm: 0.019632339477539062
2025-11-23 22:20:07.216 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:20:08.145 | INFO     | __main__:<module>:181 - validation loss: 4.611269283294678
2025-11-23 22:20:09.681 | INFO     | __main__:<module>:160 - Step1610, Loss: 4.68853759765625, Grad L2 Norm: 0.018952203914523125
2025-11-23 22:20:11.213 | INFO     | __main__:<module>:160 - Step1620, Loss: 4.654073238372803, Grad L2 Norm: 0.021544916555285454
2025-11-23 22:20:12.744 | INFO     | __main__:<module>:160 - Step1630, Loss: 4.576998710632324, Grad L2 Norm: 0.020473595708608627
2025-11-23 22:20:14.276 | INFO     | __main__:<module>:160 - Step1640, Loss: 4.513591766357422, Grad L2 Norm: 0.019272230565547943
2025-11-23 22:20:15.807 | INFO     | __main__:<module>:160 - Step1650, Loss: 4.763808250427246, Grad L2 Norm: 0.020828939974308014
2025-11-23 22:20:17.337 | INFO     | __main__:<module>:160 - Step1660, Loss: 4.640735149383545, Grad L2 Norm: 0.02103457972407341
2025-11-23 22:20:18.871 | INFO     | __main__:<module>:160 - Step1670, Loss: 4.521790504455566, Grad L2 Norm: 0.019434655085206032
2025-11-23 22:20:20.400 | INFO     | __main__:<module>:160 - Step1680, Loss: 4.615412712097168, Grad L2 Norm: 0.019031444564461708
2025-11-23 22:20:21.931 | INFO     | __main__:<module>:160 - Step1690, Loss: 4.695716381072998, Grad L2 Norm: 0.020678333938121796
2025-11-23 22:20:23.463 | INFO     | __main__:<module>:160 - Step1700, Loss: 4.537703514099121, Grad L2 Norm: 0.019687872380018234
2025-11-23 22:20:24.994 | INFO     | __main__:<module>:160 - Step1710, Loss: 4.365735054016113, Grad L2 Norm: 0.01949429139494896
2025-11-23 22:20:26.528 | INFO     | __main__:<module>:160 - Step1720, Loss: 4.415037155151367, Grad L2 Norm: 0.019396664574742317
2025-11-23 22:20:28.057 | INFO     | __main__:<module>:160 - Step1730, Loss: 4.362281799316406, Grad L2 Norm: 0.019262507557868958
2025-11-23 22:20:29.587 | INFO     | __main__:<module>:160 - Step1740, Loss: 4.436842918395996, Grad L2 Norm: 0.01906011439859867
2025-11-23 22:20:31.120 | INFO     | __main__:<module>:160 - Step1750, Loss: 4.389595985412598, Grad L2 Norm: 0.02102162316441536
2025-11-23 22:20:32.651 | INFO     | __main__:<module>:160 - Step1760, Loss: 4.330726623535156, Grad L2 Norm: 0.018884433433413506
2025-11-23 22:20:34.182 | INFO     | __main__:<module>:160 - Step1770, Loss: 4.478085994720459, Grad L2 Norm: 0.019546864554286003
2025-11-23 22:20:35.715 | INFO     | __main__:<module>:160 - Step1780, Loss: 4.411892414093018, Grad L2 Norm: 0.01771232858300209
2025-11-23 22:20:37.243 | INFO     | __main__:<module>:160 - Step1790, Loss: 4.411647796630859, Grad L2 Norm: 0.018285952508449554
2025-11-23 22:20:38.773 | INFO     | __main__:<module>:160 - Step1800, Loss: 4.217533588409424, Grad L2 Norm: 0.018868744373321533
2025-11-23 22:20:40.304 | INFO     | __main__:<module>:160 - Step1810, Loss: 4.383111000061035, Grad L2 Norm: 0.018898382782936096
2025-11-23 22:20:41.839 | INFO     | __main__:<module>:160 - Step1820, Loss: 4.145570278167725, Grad L2 Norm: 0.01873847097158432
2025-11-23 22:20:43.369 | INFO     | __main__:<module>:160 - Step1830, Loss: 4.268182754516602, Grad L2 Norm: 0.018983282148838043
2025-11-23 22:20:44.899 | INFO     | __main__:<module>:160 - Step1840, Loss: 4.271030426025391, Grad L2 Norm: 0.019625499844551086
2025-11-23 22:20:46.429 | INFO     | __main__:<module>:160 - Step1850, Loss: 4.324288368225098, Grad L2 Norm: 0.019269736483693123
2025-11-23 22:20:47.961 | INFO     | __main__:<module>:160 - Step1860, Loss: 4.224676132202148, Grad L2 Norm: 0.019911717623472214
2025-11-23 22:20:49.491 | INFO     | __main__:<module>:160 - Step1870, Loss: 4.387971878051758, Grad L2 Norm: 0.02042471617460251
2025-11-23 22:20:51.022 | INFO     | __main__:<module>:160 - Step1880, Loss: 4.331315994262695, Grad L2 Norm: 0.01945306546986103
2025-11-23 22:20:52.555 | INFO     | __main__:<module>:160 - Step1890, Loss: 4.394775867462158, Grad L2 Norm: 0.01924653723835945
2025-11-23 22:20:54.084 | INFO     | __main__:<module>:160 - Step1900, Loss: 4.204057693481445, Grad L2 Norm: 0.019047001376748085
2025-11-23 22:20:55.615 | INFO     | __main__:<module>:160 - Step1910, Loss: 4.415889739990234, Grad L2 Norm: 0.021149052307009697
2025-11-23 22:20:57.146 | INFO     | __main__:<module>:160 - Step1920, Loss: 4.50070858001709, Grad L2 Norm: 0.021604061126708984
2025-11-23 22:20:58.677 | INFO     | __main__:<module>:160 - Step1930, Loss: 4.422843933105469, Grad L2 Norm: 0.019083207473158836
2025-11-23 22:21:00.209 | INFO     | __main__:<module>:160 - Step1940, Loss: 4.267376899719238, Grad L2 Norm: 0.019804224371910095
2025-11-23 22:21:01.741 | INFO     | __main__:<module>:160 - Step1950, Loss: 4.376322269439697, Grad L2 Norm: 0.01866392232477665
2025-11-23 22:21:03.271 | INFO     | __main__:<module>:160 - Step1960, Loss: 4.222129821777344, Grad L2 Norm: 0.018976228311657906
2025-11-23 22:21:04.803 | INFO     | __main__:<module>:160 - Step1970, Loss: 4.240509033203125, Grad L2 Norm: 0.019006170332431793
2025-11-23 22:21:06.335 | INFO     | __main__:<module>:160 - Step1980, Loss: 4.207616806030273, Grad L2 Norm: 0.019041234627366066
2025-11-23 22:21:07.865 | INFO     | __main__:<module>:160 - Step1990, Loss: 4.229115009307861, Grad L2 Norm: 0.019560793414711952
2025-11-23 22:21:09.397 | INFO     | __main__:<module>:160 - Step2000, Loss: 4.276479721069336, Grad L2 Norm: 0.019755642861127853
2025-11-23 22:21:09.398 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:21:10.326 | INFO     | __main__:<module>:181 - validation loss: 4.23154194355011
2025-11-23 22:21:10.327 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_2000.pt
2025-11-23 22:29:33.178 | INFO     | __main__:<module>:68 - Start initializing model
2025-11-23 22:29:35.436 | INFO     | __main__:<module>:79 - Initialization completed
2025-11-23 22:29:35.436 | INFO     | __main__:<module>:82 - Start initializing optimizer
2025-11-23 22:29:35.437 | INFO     | __main__:<module>:89 - Optimizer initialization completed
2025-11-23 22:29:35.437 | INFO     | __main__:<module>:103 - Not providing checkpoint. Begin from start
2025-11-23 22:29:35.437 | INFO     | __main__:<module>:105 - Start loading training dataset: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/token/TinyStories_train_10000_token_ids.npy, validation set: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/token/TinyStories_valid_10000_token_ids.npy
2025-11-23 22:29:35.438 | INFO     | __main__:<module>:110 - Dataset loaded successfully
2025-11-23 22:29:35.439 | INFO     | __main__:<module>:115 - 总token数: 541204140, 训练轮数: 0.5, batch大小: 16, 上下文长度: 256
2025-11-23 22:29:35.439 | INFO     | __main__:<module>:116 - 总训练步数: 66064
2025-11-23 22:29:35.439 | INFO     | __main__:<module>:119 - Start training models...
2025-11-23 22:29:37.303 | INFO     | __main__:<module>:160 - Step10, Loss: 9.209765434265137, Grad L2 Norm: 9.059691365109757e-06
2025-11-23 22:29:38.718 | INFO     | __main__:<module>:160 - Step20, Loss: 9.208112716674805, Grad L2 Norm: 3.336426743771881e-05
2025-11-23 22:29:40.153 | INFO     | __main__:<module>:160 - Step30, Loss: 9.204983711242676, Grad L2 Norm: 7.789245864842087e-05
2025-11-23 22:29:41.590 | INFO     | __main__:<module>:160 - Step40, Loss: 9.20078182220459, Grad L2 Norm: 0.00013425103679765016
2025-11-23 22:29:43.020 | INFO     | __main__:<module>:160 - Step50, Loss: 9.195513725280762, Grad L2 Norm: 0.00021071235823910683
2025-11-23 22:29:44.460 | INFO     | __main__:<module>:160 - Step60, Loss: 9.188976287841797, Grad L2 Norm: 0.00030726747354492545
2025-11-23 22:29:45.897 | INFO     | __main__:<module>:160 - Step70, Loss: 9.180770874023438, Grad L2 Norm: 0.00041062376112677157
2025-11-23 22:29:47.335 | INFO     | __main__:<module>:160 - Step80, Loss: 9.170051574707031, Grad L2 Norm: 0.0005395628977566957
2025-11-23 22:29:48.772 | INFO     | __main__:<module>:160 - Step90, Loss: 9.163610458374023, Grad L2 Norm: 0.0006283199181780219
2025-11-23 22:29:50.210 | INFO     | __main__:<module>:160 - Step100, Loss: 9.152965545654297, Grad L2 Norm: 0.0007613972411490977
2025-11-23 22:29:51.653 | INFO     | __main__:<module>:160 - Step110, Loss: 9.13900375366211, Grad L2 Norm: 0.0009564422070980072
2025-11-23 22:29:53.096 | INFO     | __main__:<module>:160 - Step120, Loss: 9.121773719787598, Grad L2 Norm: 0.0011639692820608616
2025-11-23 22:29:54.533 | INFO     | __main__:<module>:160 - Step130, Loss: 9.112861633300781, Grad L2 Norm: 0.0013076674658805132
2025-11-23 22:29:55.978 | INFO     | __main__:<module>:160 - Step140, Loss: 9.091854095458984, Grad L2 Norm: 0.0015398756368085742
2025-11-23 22:29:57.426 | INFO     | __main__:<module>:160 - Step150, Loss: 9.074792861938477, Grad L2 Norm: 0.0017597464611753821
2025-11-23 22:29:58.874 | INFO     | __main__:<module>:160 - Step160, Loss: 9.057397842407227, Grad L2 Norm: 0.0020009358413517475
2025-11-23 22:30:00.322 | INFO     | __main__:<module>:160 - Step170, Loss: 9.043268203735352, Grad L2 Norm: 0.002220242051407695
2025-11-23 22:30:01.772 | INFO     | __main__:<module>:160 - Step180, Loss: 9.01995849609375, Grad L2 Norm: 0.002465248806402087
2025-11-23 22:30:03.221 | INFO     | __main__:<module>:160 - Step190, Loss: 8.997154235839844, Grad L2 Norm: 0.0026919683441519737
2025-11-23 22:30:04.664 | INFO     | __main__:<module>:160 - Step200, Loss: 8.987981796264648, Grad L2 Norm: 0.0027843189891427755
2025-11-23 22:30:06.116 | INFO     | __main__:<module>:160 - Step210, Loss: 8.958454132080078, Grad L2 Norm: 0.003210563212633133
2025-11-23 22:30:07.566 | INFO     | __main__:<module>:160 - Step220, Loss: 8.926736831665039, Grad L2 Norm: 0.0034378403797745705
2025-11-23 22:30:09.015 | INFO     | __main__:<module>:160 - Step230, Loss: 8.904451370239258, Grad L2 Norm: 0.0038252254016697407
2025-11-23 22:30:10.463 | INFO     | __main__:<module>:160 - Step240, Loss: 8.87098503112793, Grad L2 Norm: 0.004068094305694103
2025-11-23 22:30:11.920 | INFO     | __main__:<module>:160 - Step250, Loss: 8.841583251953125, Grad L2 Norm: 0.004436727613210678
2025-11-23 22:30:13.368 | INFO     | __main__:<module>:160 - Step260, Loss: 8.806167602539062, Grad L2 Norm: 0.004812248516827822
2025-11-23 22:30:14.813 | INFO     | __main__:<module>:160 - Step270, Loss: 8.77507209777832, Grad L2 Norm: 0.005121355410665274
2025-11-23 22:30:16.265 | INFO     | __main__:<module>:160 - Step280, Loss: 8.769807815551758, Grad L2 Norm: 0.00530362781137228
2025-11-23 22:30:17.719 | INFO     | __main__:<module>:160 - Step290, Loss: 8.689188003540039, Grad L2 Norm: 0.006002467125654221
2025-11-23 22:30:19.171 | INFO     | __main__:<module>:160 - Step300, Loss: 8.66543960571289, Grad L2 Norm: 0.006407257169485092
2025-11-23 22:30:20.618 | INFO     | __main__:<module>:160 - Step310, Loss: 8.661808013916016, Grad L2 Norm: 0.006370739545673132
2025-11-23 22:30:22.077 | INFO     | __main__:<module>:160 - Step320, Loss: 8.626543045043945, Grad L2 Norm: 0.006719870958477259
2025-11-23 22:30:23.534 | INFO     | __main__:<module>:160 - Step330, Loss: 8.59704303741455, Grad L2 Norm: 0.006891189608722925
2025-11-23 22:30:24.992 | INFO     | __main__:<module>:160 - Step340, Loss: 8.530303955078125, Grad L2 Norm: 0.007725279312580824
2025-11-23 22:30:26.450 | INFO     | __main__:<module>:160 - Step350, Loss: 8.51086139678955, Grad L2 Norm: 0.008356504142284393
2025-11-23 22:30:27.906 | INFO     | __main__:<module>:160 - Step360, Loss: 8.460034370422363, Grad L2 Norm: 0.008417434990406036
2025-11-23 22:30:29.366 | INFO     | __main__:<module>:160 - Step370, Loss: 8.411674499511719, Grad L2 Norm: 0.008389497175812721
2025-11-23 22:30:30.822 | INFO     | __main__:<module>:160 - Step380, Loss: 8.365316390991211, Grad L2 Norm: 0.009114441461861134
2025-11-23 22:30:32.281 | INFO     | __main__:<module>:160 - Step390, Loss: 8.313440322875977, Grad L2 Norm: 0.009976537898182869
2025-11-23 22:30:33.741 | INFO     | __main__:<module>:160 - Step400, Loss: 8.285158157348633, Grad L2 Norm: 0.00978962890803814
2025-11-23 22:30:33.741 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:30:34.593 | INFO     | __main__:<module>:181 - validation loss: 8.286060762405395
2025-11-23 22:30:36.045 | INFO     | __main__:<module>:160 - Step410, Loss: 8.242939949035645, Grad L2 Norm: 0.01030630711466074
2025-11-23 22:30:37.507 | INFO     | __main__:<module>:160 - Step420, Loss: 8.168853759765625, Grad L2 Norm: 0.010827694088220596
2025-11-23 22:30:38.974 | INFO     | __main__:<module>:160 - Step430, Loss: 8.141742706298828, Grad L2 Norm: 0.010964260436594486
2025-11-23 22:30:40.432 | INFO     | __main__:<module>:160 - Step440, Loss: 8.128555297851562, Grad L2 Norm: 0.011378618888556957
2025-11-23 22:30:41.897 | INFO     | __main__:<module>:160 - Step450, Loss: 8.013065338134766, Grad L2 Norm: 0.011830314062535763
2025-11-23 22:30:43.358 | INFO     | __main__:<module>:160 - Step460, Loss: 8.025965690612793, Grad L2 Norm: 0.011879227124154568
2025-11-23 22:30:44.821 | INFO     | __main__:<module>:160 - Step470, Loss: 7.939427375793457, Grad L2 Norm: 0.012313295155763626
2025-11-23 22:30:46.276 | INFO     | __main__:<module>:160 - Step480, Loss: 7.901860237121582, Grad L2 Norm: 0.012676184065639973
2025-11-23 22:30:47.733 | INFO     | __main__:<module>:160 - Step490, Loss: 7.7667999267578125, Grad L2 Norm: 0.013591228052973747
2025-11-23 22:30:49.195 | INFO     | __main__:<module>:160 - Step500, Loss: 7.78950834274292, Grad L2 Norm: 0.01364370808005333
2025-11-23 22:30:50.659 | INFO     | __main__:<module>:160 - Step510, Loss: 7.769193172454834, Grad L2 Norm: 0.013457849621772766
2025-11-23 22:30:52.120 | INFO     | __main__:<module>:160 - Step520, Loss: 7.676057815551758, Grad L2 Norm: 0.013797137886285782
2025-11-23 22:30:53.582 | INFO     | __main__:<module>:160 - Step530, Loss: 7.616467475891113, Grad L2 Norm: 0.013915365561842918
2025-11-23 22:30:55.045 | INFO     | __main__:<module>:160 - Step540, Loss: 7.700695037841797, Grad L2 Norm: 0.013414948247373104
2025-11-23 22:30:56.508 | INFO     | __main__:<module>:160 - Step550, Loss: 7.524726867675781, Grad L2 Norm: 0.014596134424209595
2025-11-23 22:30:57.966 | INFO     | __main__:<module>:160 - Step560, Loss: 7.51072359085083, Grad L2 Norm: 0.014371128752827644
2025-11-23 22:30:59.431 | INFO     | __main__:<module>:160 - Step570, Loss: 7.372890472412109, Grad L2 Norm: 0.015122874639928341
2025-11-23 22:31:00.892 | INFO     | __main__:<module>:160 - Step580, Loss: 7.4580888748168945, Grad L2 Norm: 0.014441963285207748
2025-11-23 22:31:02.354 | INFO     | __main__:<module>:160 - Step590, Loss: 7.349374771118164, Grad L2 Norm: 0.01435012649744749
2025-11-23 22:31:03.893 | INFO     | __main__:<module>:160 - Step600, Loss: 7.309937477111816, Grad L2 Norm: 0.01489436998963356
2025-11-23 22:31:05.376 | INFO     | __main__:<module>:160 - Step610, Loss: 7.327692985534668, Grad L2 Norm: 0.014058512635529041
2025-11-23 22:31:06.858 | INFO     | __main__:<module>:160 - Step620, Loss: 7.156206130981445, Grad L2 Norm: 0.014851552434265614
2025-11-23 22:31:08.408 | INFO     | __main__:<module>:160 - Step630, Loss: 7.18390417098999, Grad L2 Norm: 0.015002178959548473
2025-11-23 22:31:09.948 | INFO     | __main__:<module>:160 - Step640, Loss: 7.184182643890381, Grad L2 Norm: 0.01419540774077177
2025-11-23 22:31:11.465 | INFO     | __main__:<module>:160 - Step650, Loss: 7.0465617179870605, Grad L2 Norm: 0.015423104166984558
2025-11-23 22:31:12.972 | INFO     | __main__:<module>:160 - Step660, Loss: 7.115293979644775, Grad L2 Norm: 0.014828091487288475
2025-11-23 22:31:14.488 | INFO     | __main__:<module>:160 - Step670, Loss: 7.073478698730469, Grad L2 Norm: 0.01521262526512146
2025-11-23 22:31:16.006 | INFO     | __main__:<module>:160 - Step680, Loss: 7.076024055480957, Grad L2 Norm: 0.01476605236530304
2025-11-23 22:31:17.523 | INFO     | __main__:<module>:160 - Step690, Loss: 6.948189735412598, Grad L2 Norm: 0.01545759104192257
2025-11-23 22:31:19.040 | INFO     | __main__:<module>:160 - Step700, Loss: 6.981762409210205, Grad L2 Norm: 0.015075726434588432
2025-11-23 22:31:20.559 | INFO     | __main__:<module>:160 - Step710, Loss: 6.999898910522461, Grad L2 Norm: 0.015081653371453285
2025-11-23 22:31:22.073 | INFO     | __main__:<module>:160 - Step720, Loss: 6.913574695587158, Grad L2 Norm: 0.014999249018728733
2025-11-23 22:31:23.682 | INFO     | __main__:<module>:160 - Step730, Loss: 6.770933151245117, Grad L2 Norm: 0.015978403389453888
2025-11-23 22:31:25.278 | INFO     | __main__:<module>:160 - Step740, Loss: 6.800073623657227, Grad L2 Norm: 0.015756307169795036
2025-11-23 22:31:26.828 | INFO     | __main__:<module>:160 - Step750, Loss: 6.699621200561523, Grad L2 Norm: 0.016298072412610054
2025-11-23 22:31:28.373 | INFO     | __main__:<module>:160 - Step760, Loss: 6.690589904785156, Grad L2 Norm: 0.015987439081072807
2025-11-23 22:31:29.923 | INFO     | __main__:<module>:160 - Step770, Loss: 6.608452796936035, Grad L2 Norm: 0.01670113392174244
2025-11-23 22:31:31.468 | INFO     | __main__:<module>:160 - Step780, Loss: 6.657474517822266, Grad L2 Norm: 0.016415061429142952
2025-11-23 22:31:33.012 | INFO     | __main__:<module>:160 - Step790, Loss: 6.602731704711914, Grad L2 Norm: 0.016681931912899017
2025-11-23 22:31:34.567 | INFO     | __main__:<module>:160 - Step800, Loss: 6.640399932861328, Grad L2 Norm: 0.016613250598311424
2025-11-23 22:31:34.568 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:31:35.478 | INFO     | __main__:<module>:181 - validation loss: 6.526479578018188
2025-11-23 22:31:37.041 | INFO     | __main__:<module>:160 - Step810, Loss: 6.560371398925781, Grad L2 Norm: 0.017069270834326744
2025-11-23 22:31:38.727 | INFO     | __main__:<module>:160 - Step820, Loss: 6.5263495445251465, Grad L2 Norm: 0.017163386568427086
2025-11-23 22:31:40.353 | INFO     | __main__:<module>:160 - Step830, Loss: 6.546180725097656, Grad L2 Norm: 0.01668102853000164
2025-11-23 22:31:41.983 | INFO     | __main__:<module>:160 - Step840, Loss: 6.473430633544922, Grad L2 Norm: 0.017247777432203293
2025-11-23 22:31:43.605 | INFO     | __main__:<module>:160 - Step850, Loss: 6.315671920776367, Grad L2 Norm: 0.017817340791225433
2025-11-23 22:31:45.167 | INFO     | __main__:<module>:160 - Step860, Loss: 6.258042812347412, Grad L2 Norm: 0.018458202481269836
2025-11-23 22:31:46.707 | INFO     | __main__:<module>:160 - Step870, Loss: 6.168112754821777, Grad L2 Norm: 0.01919403299689293
2025-11-23 22:31:48.306 | INFO     | __main__:<module>:160 - Step880, Loss: 6.210412979125977, Grad L2 Norm: 0.018188107758760452
2025-11-23 22:31:49.929 | INFO     | __main__:<module>:160 - Step890, Loss: 6.3421759605407715, Grad L2 Norm: 0.017589423805475235
2025-11-23 22:31:51.551 | INFO     | __main__:<module>:160 - Step900, Loss: 6.1210479736328125, Grad L2 Norm: 0.018475642427802086
2025-11-23 22:31:53.172 | INFO     | __main__:<module>:160 - Step910, Loss: 6.164512634277344, Grad L2 Norm: 0.01789373904466629
2025-11-23 22:31:54.797 | INFO     | __main__:<module>:160 - Step920, Loss: 6.323402404785156, Grad L2 Norm: 0.01754753850400448
2025-11-23 22:31:56.340 | INFO     | __main__:<module>:160 - Step930, Loss: 6.374524116516113, Grad L2 Norm: 0.016325119882822037
2025-11-23 22:31:57.879 | INFO     | __main__:<module>:160 - Step940, Loss: 6.1756062507629395, Grad L2 Norm: 0.018238240852952003
2025-11-23 22:31:59.448 | INFO     | __main__:<module>:160 - Step950, Loss: 6.176192283630371, Grad L2 Norm: 0.01735229417681694
2025-11-23 22:32:01.146 | INFO     | __main__:<module>:160 - Step960, Loss: 5.887031555175781, Grad L2 Norm: 0.018592435866594315
2025-11-23 22:32:02.756 | INFO     | __main__:<module>:160 - Step970, Loss: 5.8059515953063965, Grad L2 Norm: 0.019929686561226845
2025-11-23 22:32:04.358 | INFO     | __main__:<module>:160 - Step980, Loss: 5.984370231628418, Grad L2 Norm: 0.01807844638824463
2025-11-23 22:32:05.957 | INFO     | __main__:<module>:160 - Step990, Loss: 5.892041206359863, Grad L2 Norm: 0.01782137155532837
2025-11-23 22:32:07.555 | INFO     | __main__:<module>:160 - Step1000, Loss: 5.891985893249512, Grad L2 Norm: 0.017812954261898994
2025-11-23 22:32:09.157 | INFO     | __main__:<module>:160 - Step1010, Loss: 5.742631912231445, Grad L2 Norm: 0.019090427085757256
2025-11-23 22:32:10.753 | INFO     | __main__:<module>:160 - Step1020, Loss: 5.923686504364014, Grad L2 Norm: 0.0184275284409523
2025-11-23 22:32:12.355 | INFO     | __main__:<module>:160 - Step1030, Loss: 5.742944240570068, Grad L2 Norm: 0.017696723341941833
2025-11-23 22:32:13.953 | INFO     | __main__:<module>:160 - Step1040, Loss: 5.848492622375488, Grad L2 Norm: 0.01888645999133587
2025-11-23 22:32:15.553 | INFO     | __main__:<module>:160 - Step1050, Loss: 5.884477615356445, Grad L2 Norm: 0.018483933061361313
2025-11-23 22:32:17.149 | INFO     | __main__:<module>:160 - Step1060, Loss: 5.70277214050293, Grad L2 Norm: 0.01954404078423977
2025-11-23 22:32:18.737 | INFO     | __main__:<module>:160 - Step1070, Loss: 5.4590020179748535, Grad L2 Norm: 0.019679661840200424
2025-11-23 22:32:20.417 | INFO     | __main__:<module>:160 - Step1080, Loss: 5.914699554443359, Grad L2 Norm: 0.018353041261434555
2025-11-23 22:32:22.102 | INFO     | __main__:<module>:160 - Step1090, Loss: 5.798346519470215, Grad L2 Norm: 0.018581386655569077
2025-11-23 22:32:23.785 | INFO     | __main__:<module>:160 - Step1100, Loss: 5.621962547302246, Grad L2 Norm: 0.01898345910012722
2025-11-23 22:32:25.463 | INFO     | __main__:<module>:160 - Step1110, Loss: 5.682621002197266, Grad L2 Norm: 0.019612371921539307
2025-11-23 22:32:27.144 | INFO     | __main__:<module>:160 - Step1120, Loss: 5.589721202850342, Grad L2 Norm: 0.01885884441435337
2025-11-23 22:32:28.825 | INFO     | __main__:<module>:160 - Step1130, Loss: 5.585757255554199, Grad L2 Norm: 0.019432414323091507
2025-11-23 22:32:30.502 | INFO     | __main__:<module>:160 - Step1140, Loss: 5.443121910095215, Grad L2 Norm: 0.018653636798262596
2025-11-23 22:32:32.182 | INFO     | __main__:<module>:160 - Step1150, Loss: 5.5396952629089355, Grad L2 Norm: 0.01976572535932064
2025-11-23 22:32:33.861 | INFO     | __main__:<module>:160 - Step1160, Loss: 5.325300693511963, Grad L2 Norm: 0.019891472533345222
2025-11-23 22:32:35.537 | INFO     | __main__:<module>:160 - Step1170, Loss: 5.569526672363281, Grad L2 Norm: 0.020170442759990692
2025-11-23 22:32:37.131 | INFO     | __main__:<module>:160 - Step1180, Loss: 5.2956061363220215, Grad L2 Norm: 0.019323602318763733
2025-11-23 22:32:38.723 | INFO     | __main__:<module>:160 - Step1190, Loss: 5.44915771484375, Grad L2 Norm: 0.019605914130806923
2025-11-23 22:32:40.309 | INFO     | __main__:<module>:160 - Step1200, Loss: 5.405875205993652, Grad L2 Norm: 0.01971418596804142
2025-11-23 22:32:40.310 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:32:41.253 | INFO     | __main__:<module>:181 - validation loss: 5.390503311157227
2025-11-23 22:32:42.848 | INFO     | __main__:<module>:160 - Step1210, Loss: 5.261401176452637, Grad L2 Norm: 0.019336730241775513
2025-11-23 22:32:44.492 | INFO     | __main__:<module>:160 - Step1220, Loss: 5.214573860168457, Grad L2 Norm: 0.01893788017332554
2025-11-23 22:32:46.134 | INFO     | __main__:<module>:160 - Step1230, Loss: 5.31307315826416, Grad L2 Norm: 0.017842231318354607
2025-11-23 22:32:47.774 | INFO     | __main__:<module>:160 - Step1240, Loss: 5.0766191482543945, Grad L2 Norm: 0.01948791742324829
2025-11-23 22:32:49.417 | INFO     | __main__:<module>:160 - Step1250, Loss: 5.287082672119141, Grad L2 Norm: 0.019124599173665047
2025-11-23 22:32:51.057 | INFO     | __main__:<module>:160 - Step1260, Loss: 5.234350204467773, Grad L2 Norm: 0.019289342686533928
2025-11-23 22:32:52.700 | INFO     | __main__:<module>:160 - Step1270, Loss: 5.139272689819336, Grad L2 Norm: 0.01849704422056675
2025-11-23 22:32:54.340 | INFO     | __main__:<module>:160 - Step1280, Loss: 5.30418586730957, Grad L2 Norm: 0.01952199637889862
2025-11-23 22:32:55.978 | INFO     | __main__:<module>:160 - Step1290, Loss: 5.098446369171143, Grad L2 Norm: 0.019741201773285866
2025-11-23 22:32:57.617 | INFO     | __main__:<module>:160 - Step1300, Loss: 5.027775287628174, Grad L2 Norm: 0.019022243097424507
2025-11-23 22:32:59.258 | INFO     | __main__:<module>:160 - Step1310, Loss: 5.120759963989258, Grad L2 Norm: 0.01912863925099373
2025-11-23 22:33:00.903 | INFO     | __main__:<module>:160 - Step1320, Loss: 4.8248491287231445, Grad L2 Norm: 0.019115565344691277
2025-11-23 22:33:02.543 | INFO     | __main__:<module>:160 - Step1330, Loss: 4.954372882843018, Grad L2 Norm: 0.020127680152654648
2025-11-23 22:33:04.182 | INFO     | __main__:<module>:160 - Step1340, Loss: 5.105541229248047, Grad L2 Norm: 0.02017327956855297
2025-11-23 22:33:05.823 | INFO     | __main__:<module>:160 - Step1350, Loss: 4.732531547546387, Grad L2 Norm: 0.01901092939078808
2025-11-23 22:33:07.460 | INFO     | __main__:<module>:160 - Step1360, Loss: 5.083396911621094, Grad L2 Norm: 0.019027791917324066
2025-11-23 22:33:09.102 | INFO     | __main__:<module>:160 - Step1370, Loss: 4.929401397705078, Grad L2 Norm: 0.019358312711119652
2025-11-23 22:33:10.743 | INFO     | __main__:<module>:160 - Step1380, Loss: 4.805095672607422, Grad L2 Norm: 0.018591567873954773
2025-11-23 22:33:12.384 | INFO     | __main__:<module>:160 - Step1390, Loss: 5.197446823120117, Grad L2 Norm: 0.019310712814331055
2025-11-23 22:33:14.028 | INFO     | __main__:<module>:160 - Step1400, Loss: 4.927089214324951, Grad L2 Norm: 0.020659299567341805
2025-11-23 22:33:15.672 | INFO     | __main__:<module>:160 - Step1410, Loss: 5.051732540130615, Grad L2 Norm: 0.019970666617155075
2025-11-23 22:33:17.311 | INFO     | __main__:<module>:160 - Step1420, Loss: 4.922530174255371, Grad L2 Norm: 0.020750554278492928
2025-11-23 22:33:18.957 | INFO     | __main__:<module>:160 - Step1430, Loss: 4.782718658447266, Grad L2 Norm: 0.020213991403579712
2025-11-23 22:33:20.598 | INFO     | __main__:<module>:160 - Step1440, Loss: 4.809699535369873, Grad L2 Norm: 0.02039836347103119
2025-11-23 22:33:22.235 | INFO     | __main__:<module>:160 - Step1450, Loss: 4.761037826538086, Grad L2 Norm: 0.019965743646025658
2025-11-23 22:33:23.872 | INFO     | __main__:<module>:160 - Step1460, Loss: 4.848738193511963, Grad L2 Norm: 0.018902290612459183
2025-11-23 22:33:25.511 | INFO     | __main__:<module>:160 - Step1470, Loss: 4.789196491241455, Grad L2 Norm: 0.020239217206835747
2025-11-23 22:33:27.152 | INFO     | __main__:<module>:160 - Step1480, Loss: 4.82314395904541, Grad L2 Norm: 0.019610797986388206
2025-11-23 22:33:28.788 | INFO     | __main__:<module>:160 - Step1490, Loss: 4.871351718902588, Grad L2 Norm: 0.02056143619120121
2025-11-23 22:33:30.430 | INFO     | __main__:<module>:160 - Step1500, Loss: 4.6597394943237305, Grad L2 Norm: 0.019252175465226173
2025-11-23 22:33:32.072 | INFO     | __main__:<module>:160 - Step1510, Loss: 4.743075847625732, Grad L2 Norm: 0.019554482772946358
2025-11-23 22:33:33.712 | INFO     | __main__:<module>:160 - Step1520, Loss: 4.61619758605957, Grad L2 Norm: 0.018833797425031662
2025-11-23 22:33:35.354 | INFO     | __main__:<module>:160 - Step1530, Loss: 4.881736755371094, Grad L2 Norm: 0.020305385813117027
2025-11-23 22:33:37.055 | INFO     | __main__:<module>:160 - Step1540, Loss: 4.723972320556641, Grad L2 Norm: 0.020579276606440544
2025-11-23 22:33:38.808 | INFO     | __main__:<module>:160 - Step1550, Loss: 4.567373275756836, Grad L2 Norm: 0.01998755894601345
2025-11-23 22:33:40.559 | INFO     | __main__:<module>:160 - Step1560, Loss: 4.685219764709473, Grad L2 Norm: 0.018875686451792717
2025-11-23 22:33:42.309 | INFO     | __main__:<module>:160 - Step1570, Loss: 4.672567367553711, Grad L2 Norm: 0.01877705194056034
2025-11-23 22:33:44.054 | INFO     | __main__:<module>:160 - Step1580, Loss: 4.473250389099121, Grad L2 Norm: 0.019241904839873314
2025-11-23 22:33:45.801 | INFO     | __main__:<module>:160 - Step1590, Loss: 4.452605724334717, Grad L2 Norm: 0.019850997254252434
2025-11-23 22:33:47.463 | INFO     | __main__:<module>:160 - Step1600, Loss: 4.666243553161621, Grad L2 Norm: 0.02074275352060795
2025-11-23 22:33:47.464 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:33:48.485 | INFO     | __main__:<module>:181 - validation loss: 4.601436281204224
2025-11-23 22:33:50.145 | INFO     | __main__:<module>:160 - Step1610, Loss: 4.589836120605469, Grad L2 Norm: 0.0193884689360857
2025-11-23 22:33:51.807 | INFO     | __main__:<module>:160 - Step1620, Loss: 4.880596160888672, Grad L2 Norm: 0.018968481570482254
2025-11-23 22:33:53.467 | INFO     | __main__:<module>:160 - Step1630, Loss: 4.641751766204834, Grad L2 Norm: 0.019861772656440735
2025-11-23 22:33:55.132 | INFO     | __main__:<module>:160 - Step1640, Loss: 4.5881829261779785, Grad L2 Norm: 0.01930425874888897
2025-11-23 22:33:56.795 | INFO     | __main__:<module>:160 - Step1650, Loss: 4.485329627990723, Grad L2 Norm: 0.019979745149612427
2025-11-23 22:33:58.460 | INFO     | __main__:<module>:160 - Step1660, Loss: 4.617006301879883, Grad L2 Norm: 0.02017880603671074
2025-11-23 22:34:00.121 | INFO     | __main__:<module>:160 - Step1670, Loss: 4.482025146484375, Grad L2 Norm: 0.018912848085165024
2025-11-23 22:34:01.779 | INFO     | __main__:<module>:160 - Step1680, Loss: 4.692325592041016, Grad L2 Norm: 0.01989549584686756
2025-11-23 22:34:03.440 | INFO     | __main__:<module>:160 - Step1690, Loss: 4.440150260925293, Grad L2 Norm: 0.019287895411252975
2025-11-23 22:34:05.098 | INFO     | __main__:<module>:160 - Step1700, Loss: 4.284208297729492, Grad L2 Norm: 0.01968129724264145
2025-11-23 22:34:06.756 | INFO     | __main__:<module>:160 - Step1710, Loss: 4.519570350646973, Grad L2 Norm: 0.01999402791261673
2025-11-23 22:34:08.417 | INFO     | __main__:<module>:160 - Step1720, Loss: 4.5338826179504395, Grad L2 Norm: 0.019150085747241974
2025-11-23 22:34:10.071 | INFO     | __main__:<module>:160 - Step1730, Loss: 4.20919132232666, Grad L2 Norm: 0.017972318455576897
2025-11-23 22:34:11.725 | INFO     | __main__:<module>:160 - Step1740, Loss: 4.28098726272583, Grad L2 Norm: 0.020543109625577927
2025-11-23 22:34:13.393 | INFO     | __main__:<module>:160 - Step1750, Loss: 4.4191179275512695, Grad L2 Norm: 0.019176265224814415
2025-11-23 22:34:15.047 | INFO     | __main__:<module>:160 - Step1760, Loss: 4.2869462966918945, Grad L2 Norm: 0.018465882167220116
2025-11-23 22:34:16.699 | INFO     | __main__:<module>:160 - Step1770, Loss: 4.38131046295166, Grad L2 Norm: 0.018456710502505302
2025-11-23 22:34:18.360 | INFO     | __main__:<module>:160 - Step1780, Loss: 4.381028175354004, Grad L2 Norm: 0.020427415147423744
2025-11-23 22:34:20.022 | INFO     | __main__:<module>:160 - Step1790, Loss: 4.3634257316589355, Grad L2 Norm: 0.019275683909654617
2025-11-23 22:34:21.680 | INFO     | __main__:<module>:160 - Step1800, Loss: 4.298110485076904, Grad L2 Norm: 0.019008489325642586
2025-11-23 22:34:23.340 | INFO     | __main__:<module>:160 - Step1810, Loss: 4.464783668518066, Grad L2 Norm: 0.019651491194963455
2025-11-23 22:34:25.001 | INFO     | __main__:<module>:160 - Step1820, Loss: 4.242298126220703, Grad L2 Norm: 0.019184228032827377
2025-11-23 22:34:26.659 | INFO     | __main__:<module>:160 - Step1830, Loss: 4.377277374267578, Grad L2 Norm: 0.019732389599084854
2025-11-23 22:34:28.321 | INFO     | __main__:<module>:160 - Step1840, Loss: 4.422000408172607, Grad L2 Norm: 0.01993303932249546
2025-11-23 22:34:29.981 | INFO     | __main__:<module>:160 - Step1850, Loss: 4.289669036865234, Grad L2 Norm: 0.018369635567069054
2025-11-23 22:34:31.639 | INFO     | __main__:<module>:160 - Step1860, Loss: 4.244077682495117, Grad L2 Norm: 0.018603652715682983
2025-11-23 22:34:33.298 | INFO     | __main__:<module>:160 - Step1870, Loss: 4.415347099304199, Grad L2 Norm: 0.019683144986629486
2025-11-23 22:34:34.965 | INFO     | __main__:<module>:160 - Step1880, Loss: 4.351294040679932, Grad L2 Norm: 0.021159900352358818
2025-11-23 22:34:36.698 | INFO     | __main__:<module>:160 - Step1890, Loss: 4.249848365783691, Grad L2 Norm: 0.018531417474150658
2025-11-23 22:34:38.457 | INFO     | __main__:<module>:160 - Step1900, Loss: 4.3823137283325195, Grad L2 Norm: 0.02011341229081154
2025-11-23 22:34:40.219 | INFO     | __main__:<module>:160 - Step1910, Loss: 4.241338729858398, Grad L2 Norm: 0.019511165097355843
2025-11-23 22:34:41.975 | INFO     | __main__:<module>:160 - Step1920, Loss: 4.4927778244018555, Grad L2 Norm: 0.020762842148542404
2025-11-23 22:34:43.736 | INFO     | __main__:<module>:160 - Step1930, Loss: 4.360781669616699, Grad L2 Norm: 0.018931487575173378
2025-11-23 22:34:45.499 | INFO     | __main__:<module>:160 - Step1940, Loss: 4.375536918640137, Grad L2 Norm: 0.02002088539302349
2025-11-23 22:34:47.260 | INFO     | __main__:<module>:160 - Step1950, Loss: 4.338232040405273, Grad L2 Norm: 0.019918616861104965
2025-11-23 22:34:49.023 | INFO     | __main__:<module>:160 - Step1960, Loss: 4.449782371520996, Grad L2 Norm: 0.01985931396484375
2025-11-23 22:34:50.779 | INFO     | __main__:<module>:160 - Step1970, Loss: 4.175508975982666, Grad L2 Norm: 0.019896820187568665
2025-11-23 22:34:52.542 | INFO     | __main__:<module>:160 - Step1980, Loss: 4.212817668914795, Grad L2 Norm: 0.01881513185799122
2025-11-23 22:34:54.298 | INFO     | __main__:<module>:160 - Step1990, Loss: 4.309930801391602, Grad L2 Norm: 0.01906719245016575
2025-11-23 22:34:56.059 | INFO     | __main__:<module>:160 - Step2000, Loss: 4.317638397216797, Grad L2 Norm: 0.018530530855059624
2025-11-23 22:34:56.060 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:34:57.086 | INFO     | __main__:<module>:181 - validation loss: 4.2328368663787845
2025-11-23 22:34:57.087 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_2000.pt
2025-11-23 22:34:58.667 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-23 22:35:00.238 | INFO     | __main__:<module>:160 - Step2010, Loss: 4.249747276306152, Grad L2 Norm: 0.019245587289333344
2025-11-23 22:35:01.939 | INFO     | __main__:<module>:160 - Step2020, Loss: 4.02531623840332, Grad L2 Norm: 0.018123652786016464
2025-11-23 22:35:03.636 | INFO     | __main__:<module>:160 - Step2030, Loss: 4.1712236404418945, Grad L2 Norm: 0.01906253956258297
2025-11-23 22:35:05.344 | INFO     | __main__:<module>:160 - Step2040, Loss: 4.250028610229492, Grad L2 Norm: 0.018711840733885765
2025-11-23 22:35:07.053 | INFO     | __main__:<module>:160 - Step2050, Loss: 4.343011856079102, Grad L2 Norm: 0.021295981481671333
2025-11-23 22:35:08.759 | INFO     | __main__:<module>:160 - Step2060, Loss: 4.258843421936035, Grad L2 Norm: 0.019485807046294212
2025-11-23 22:35:10.462 | INFO     | __main__:<module>:160 - Step2070, Loss: 4.166051387786865, Grad L2 Norm: 0.01805608533322811
2025-11-23 22:35:12.169 | INFO     | __main__:<module>:160 - Step2080, Loss: 4.065123081207275, Grad L2 Norm: 0.017494771629571915
2025-11-23 22:35:13.873 | INFO     | __main__:<module>:160 - Step2090, Loss: 4.184247970581055, Grad L2 Norm: 0.018289344385266304
2025-11-23 22:35:15.579 | INFO     | __main__:<module>:160 - Step2100, Loss: 4.123456001281738, Grad L2 Norm: 0.019000813364982605
2025-11-23 22:35:17.283 | INFO     | __main__:<module>:160 - Step2110, Loss: 3.9955453872680664, Grad L2 Norm: 0.019241515547037125
2025-11-23 22:35:18.988 | INFO     | __main__:<module>:160 - Step2120, Loss: 4.253148555755615, Grad L2 Norm: 0.019631531089544296
2025-11-23 22:35:20.688 | INFO     | __main__:<module>:160 - Step2130, Loss: 4.248310565948486, Grad L2 Norm: 0.01845318078994751
2025-11-23 22:35:22.394 | INFO     | __main__:<module>:160 - Step2140, Loss: 4.078906536102295, Grad L2 Norm: 0.018982766196131706
2025-11-23 22:35:24.096 | INFO     | __main__:<module>:160 - Step2150, Loss: 4.372901916503906, Grad L2 Norm: 0.02039974182844162
2025-11-23 22:35:25.796 | INFO     | __main__:<module>:160 - Step2160, Loss: 3.9835987091064453, Grad L2 Norm: 0.01929716020822525
2025-11-23 22:35:27.499 | INFO     | __main__:<module>:160 - Step2170, Loss: 4.2763214111328125, Grad L2 Norm: 0.01884029246866703
2025-11-23 22:35:29.200 | INFO     | __main__:<module>:160 - Step2180, Loss: 4.192663669586182, Grad L2 Norm: 0.019669311121106148
2025-11-23 22:35:30.905 | INFO     | __main__:<module>:160 - Step2190, Loss: 4.30548095703125, Grad L2 Norm: 0.01920950971543789
2025-11-23 22:35:32.608 | INFO     | __main__:<module>:160 - Step2200, Loss: 4.078832626342773, Grad L2 Norm: 0.021233858540654182
2025-11-23 22:35:34.305 | INFO     | __main__:<module>:160 - Step2210, Loss: 4.081887245178223, Grad L2 Norm: 0.019397275522351265
2025-11-23 22:35:36.007 | INFO     | __main__:<module>:160 - Step2220, Loss: 3.906689405441284, Grad L2 Norm: 0.01848510466516018
2025-11-23 22:35:37.713 | INFO     | __main__:<module>:160 - Step2230, Loss: 3.9784626960754395, Grad L2 Norm: 0.019107835367321968
2025-11-23 22:35:39.417 | INFO     | __main__:<module>:160 - Step2240, Loss: 4.220252990722656, Grad L2 Norm: 0.01946520060300827
2025-11-23 22:35:41.122 | INFO     | __main__:<module>:160 - Step2250, Loss: 3.954453468322754, Grad L2 Norm: 0.019910581409931183
2025-11-23 22:35:42.820 | INFO     | __main__:<module>:160 - Step2260, Loss: 3.9705848693847656, Grad L2 Norm: 0.020156124606728554
2025-11-23 22:35:44.525 | INFO     | __main__:<module>:160 - Step2270, Loss: 4.108133316040039, Grad L2 Norm: 0.020292097702622414
2025-11-23 22:35:46.225 | INFO     | __main__:<module>:160 - Step2280, Loss: 4.123989582061768, Grad L2 Norm: 0.019534721970558167
2025-11-23 22:35:47.930 | INFO     | __main__:<module>:160 - Step2290, Loss: 3.8555283546447754, Grad L2 Norm: 0.017957355827093124
2025-11-23 22:35:49.635 | INFO     | __main__:<module>:160 - Step2300, Loss: 4.13295841217041, Grad L2 Norm: 0.01985001005232334
2025-11-23 22:35:51.334 | INFO     | __main__:<module>:160 - Step2310, Loss: 4.0743255615234375, Grad L2 Norm: 0.02040429227054119
2025-11-23 22:35:53.035 | INFO     | __main__:<module>:160 - Step2320, Loss: 4.055704116821289, Grad L2 Norm: 0.02092299424111843
2025-11-23 22:35:54.769 | INFO     | __main__:<module>:160 - Step2330, Loss: 4.167590618133545, Grad L2 Norm: 0.01984221674501896
2025-11-23 22:35:56.544 | INFO     | __main__:<module>:160 - Step2340, Loss: 4.040239334106445, Grad L2 Norm: 0.0173379834741354
2025-11-23 22:35:58.320 | INFO     | __main__:<module>:160 - Step2350, Loss: 3.8883137702941895, Grad L2 Norm: 0.01990203745663166
2025-11-23 22:36:00.095 | INFO     | __main__:<module>:160 - Step2360, Loss: 4.007669925689697, Grad L2 Norm: 0.017724480479955673
2025-11-23 22:36:01.870 | INFO     | __main__:<module>:160 - Step2370, Loss: 4.051077842712402, Grad L2 Norm: 0.018991990014910698
2025-11-23 22:36:03.644 | INFO     | __main__:<module>:160 - Step2380, Loss: 4.114849090576172, Grad L2 Norm: 0.01931108720600605
2025-11-23 22:36:05.416 | INFO     | __main__:<module>:160 - Step2390, Loss: 4.0156731605529785, Grad L2 Norm: 0.01804601401090622
2025-11-23 22:36:07.187 | INFO     | __main__:<module>:160 - Step2400, Loss: 4.00206184387207, Grad L2 Norm: 0.019196897745132446
2025-11-23 22:36:07.188 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:36:08.207 | INFO     | __main__:<module>:181 - validation loss: 4.0077344417572025
2025-11-23 22:36:09.921 | INFO     | __main__:<module>:160 - Step2410, Loss: 4.081906318664551, Grad L2 Norm: 0.019314192235469818
2025-11-23 22:36:11.697 | INFO     | __main__:<module>:160 - Step2420, Loss: 4.022821426391602, Grad L2 Norm: 0.017577627673745155
2025-11-23 22:36:13.472 | INFO     | __main__:<module>:160 - Step2430, Loss: 3.8897275924682617, Grad L2 Norm: 0.018094679340720177
2025-11-23 22:36:15.242 | INFO     | __main__:<module>:160 - Step2440, Loss: 3.925302028656006, Grad L2 Norm: 0.018496384844183922
2025-11-23 22:36:17.013 | INFO     | __main__:<module>:160 - Step2450, Loss: 4.113376140594482, Grad L2 Norm: 0.021101318299770355
2025-11-23 22:36:18.788 | INFO     | __main__:<module>:160 - Step2460, Loss: 4.038381576538086, Grad L2 Norm: 0.019530395045876503
2025-11-23 22:36:20.547 | INFO     | __main__:<module>:160 - Step2470, Loss: 3.9426872730255127, Grad L2 Norm: 0.02071494422852993
2025-11-23 22:36:22.320 | INFO     | __main__:<module>:160 - Step2480, Loss: 4.017112731933594, Grad L2 Norm: 0.019228452816605568
2025-11-23 22:36:24.084 | INFO     | __main__:<module>:160 - Step2490, Loss: 4.131810188293457, Grad L2 Norm: 0.020019380375742912
2025-11-23 22:36:25.855 | INFO     | __main__:<module>:160 - Step2500, Loss: 3.977578639984131, Grad L2 Norm: 0.019890323281288147
2025-11-23 22:36:27.632 | INFO     | __main__:<module>:160 - Step2510, Loss: 4.145482063293457, Grad L2 Norm: 0.021167825907468796
2025-11-23 22:36:29.402 | INFO     | __main__:<module>:160 - Step2520, Loss: 3.806471347808838, Grad L2 Norm: 0.018889933824539185
2025-11-23 22:36:31.178 | INFO     | __main__:<module>:160 - Step2530, Loss: 3.9768600463867188, Grad L2 Norm: 0.020816372707486153
2025-11-23 22:36:32.954 | INFO     | __main__:<module>:160 - Step2540, Loss: 4.049586296081543, Grad L2 Norm: 0.018571674823760986
2025-11-23 22:36:34.722 | INFO     | __main__:<module>:160 - Step2550, Loss: 4.1302385330200195, Grad L2 Norm: 0.019725648686289787
2025-11-23 22:36:36.492 | INFO     | __main__:<module>:160 - Step2560, Loss: 4.07958459854126, Grad L2 Norm: 0.02004069834947586
2025-11-23 22:36:38.250 | INFO     | __main__:<module>:160 - Step2570, Loss: 3.722024917602539, Grad L2 Norm: 0.01889006793498993
2025-11-23 22:36:40.020 | INFO     | __main__:<module>:160 - Step2580, Loss: 3.891369104385376, Grad L2 Norm: 0.018703320994973183
2025-11-23 22:36:41.799 | INFO     | __main__:<module>:160 - Step2590, Loss: 4.080117702484131, Grad L2 Norm: 0.020868176594376564
2025-11-23 22:36:43.567 | INFO     | __main__:<module>:160 - Step2600, Loss: 4.021095275878906, Grad L2 Norm: 0.019071435555815697
2025-11-23 22:36:45.344 | INFO     | __main__:<module>:160 - Step2610, Loss: 4.4003682136535645, Grad L2 Norm: 0.0208368469029665
2025-11-23 22:36:47.120 | INFO     | __main__:<module>:160 - Step2620, Loss: 4.059088706970215, Grad L2 Norm: 0.01941055990755558
2025-11-23 22:36:48.879 | INFO     | __main__:<module>:160 - Step2630, Loss: 3.9709205627441406, Grad L2 Norm: 0.020209046080708504
2025-11-23 22:36:50.651 | INFO     | __main__:<module>:160 - Step2640, Loss: 3.975928783416748, Grad L2 Norm: 0.01841174252331257
2025-11-23 22:36:52.422 | INFO     | __main__:<module>:160 - Step2650, Loss: 3.856640338897705, Grad L2 Norm: 0.01908040978014469
2025-11-23 22:36:54.193 | INFO     | __main__:<module>:160 - Step2660, Loss: 4.189944267272949, Grad L2 Norm: 0.01995040662586689
2025-11-23 22:36:55.965 | INFO     | __main__:<module>:160 - Step2670, Loss: 4.048933029174805, Grad L2 Norm: 0.020895887166261673
2025-11-23 22:36:57.722 | INFO     | __main__:<module>:160 - Step2680, Loss: 4.019035339355469, Grad L2 Norm: 0.02007988654077053
2025-11-23 22:36:59.500 | INFO     | __main__:<module>:160 - Step2690, Loss: 3.925194025039673, Grad L2 Norm: 0.019925599917769432
2025-11-23 22:37:01.255 | INFO     | __main__:<module>:160 - Step2700, Loss: 3.740016222000122, Grad L2 Norm: 0.018393786624073982
2025-11-23 22:37:03.017 | INFO     | __main__:<module>:160 - Step2710, Loss: 4.001072406768799, Grad L2 Norm: 0.021885700523853302
2025-11-23 22:37:04.769 | INFO     | __main__:<module>:160 - Step2720, Loss: 3.988269805908203, Grad L2 Norm: 0.020629681646823883
2025-11-23 22:37:06.534 | INFO     | __main__:<module>:160 - Step2730, Loss: 3.891911029815674, Grad L2 Norm: 0.020285900682210922
2025-11-23 22:37:08.307 | INFO     | __main__:<module>:160 - Step2740, Loss: 3.856576442718506, Grad L2 Norm: 0.020148398354649544
2025-11-23 22:37:10.049 | INFO     | __main__:<module>:160 - Step2750, Loss: 3.901486873626709, Grad L2 Norm: 0.019110895693302155
2025-11-23 22:37:11.814 | INFO     | __main__:<module>:160 - Step2760, Loss: 3.798097610473633, Grad L2 Norm: 0.018095532432198524
2025-11-23 22:37:13.579 | INFO     | __main__:<module>:160 - Step2770, Loss: 4.0121307373046875, Grad L2 Norm: 0.019591614603996277
2025-11-23 22:37:15.334 | INFO     | __main__:<module>:160 - Step2780, Loss: 3.9110283851623535, Grad L2 Norm: 0.019120344892144203
2025-11-23 22:37:17.103 | INFO     | __main__:<module>:160 - Step2790, Loss: 3.81186580657959, Grad L2 Norm: 0.019287273287773132
2025-11-23 22:37:18.854 | INFO     | __main__:<module>:160 - Step2800, Loss: 3.7729525566101074, Grad L2 Norm: 0.018421856686472893
2025-11-23 22:37:18.855 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:37:19.872 | INFO     | __main__:<module>:181 - validation loss: 3.8960211873054504
2025-11-23 22:37:21.616 | INFO     | __main__:<module>:160 - Step2810, Loss: 3.8077468872070312, Grad L2 Norm: 0.017615068703889847
2025-11-23 22:37:23.350 | INFO     | __main__:<module>:160 - Step2820, Loss: 3.9031896591186523, Grad L2 Norm: 0.01956837996840477
2025-11-23 22:37:25.106 | INFO     | __main__:<module>:160 - Step2830, Loss: 3.760921001434326, Grad L2 Norm: 0.01771884225308895
2025-11-23 22:37:26.857 | INFO     | __main__:<module>:160 - Step2840, Loss: 4.017115592956543, Grad L2 Norm: 0.019642243161797523
2025-11-23 22:37:28.623 | INFO     | __main__:<module>:160 - Step2850, Loss: 3.9175384044647217, Grad L2 Norm: 0.018214378505945206
2025-11-23 22:37:30.359 | INFO     | __main__:<module>:160 - Step2860, Loss: 3.8318257331848145, Grad L2 Norm: 0.01850413717329502
2025-11-23 22:37:32.101 | INFO     | __main__:<module>:160 - Step2870, Loss: 4.064908027648926, Grad L2 Norm: 0.019108090549707413
2025-11-23 22:37:33.837 | INFO     | __main__:<module>:160 - Step2880, Loss: 3.9726672172546387, Grad L2 Norm: 0.019336175173521042
2025-11-23 22:37:35.594 | INFO     | __main__:<module>:160 - Step2890, Loss: 3.882054328918457, Grad L2 Norm: 0.0199373047798872
2025-11-23 22:37:37.341 | INFO     | __main__:<module>:160 - Step2900, Loss: 3.894350051879883, Grad L2 Norm: 0.020053980872035027
2025-11-23 22:37:39.101 | INFO     | __main__:<module>:160 - Step2910, Loss: 3.7829642295837402, Grad L2 Norm: 0.01769980601966381
2025-11-23 22:37:40.866 | INFO     | __main__:<module>:160 - Step2920, Loss: 3.8168630599975586, Grad L2 Norm: 0.0182045865803957
2025-11-23 22:37:42.615 | INFO     | __main__:<module>:160 - Step2930, Loss: 4.007318496704102, Grad L2 Norm: 0.020011600106954575
2025-11-23 22:37:44.374 | INFO     | __main__:<module>:160 - Step2940, Loss: 3.8406457901000977, Grad L2 Norm: 0.018027659505605698
2025-11-23 22:37:46.124 | INFO     | __main__:<module>:160 - Step2950, Loss: 3.952421188354492, Grad L2 Norm: 0.019925806671380997
2025-11-23 22:37:47.887 | INFO     | __main__:<module>:160 - Step2960, Loss: 3.840075969696045, Grad L2 Norm: 0.018582917749881744
2025-11-23 22:37:49.616 | INFO     | __main__:<module>:160 - Step2970, Loss: 3.8802709579467773, Grad L2 Norm: 0.01905108615756035
2025-11-23 22:37:51.359 | INFO     | __main__:<module>:160 - Step2980, Loss: 3.8555848598480225, Grad L2 Norm: 0.018157202750444412
2025-11-23 22:37:53.093 | INFO     | __main__:<module>:160 - Step2990, Loss: 3.801234245300293, Grad L2 Norm: 0.019729958847165108
2025-11-23 22:37:54.850 | INFO     | __main__:<module>:160 - Step3000, Loss: 3.8973779678344727, Grad L2 Norm: 0.018335646018385887
2025-11-23 22:37:56.600 | INFO     | __main__:<module>:160 - Step3010, Loss: 3.8139827251434326, Grad L2 Norm: 0.018240926787257195
2025-11-23 22:37:58.355 | INFO     | __main__:<module>:160 - Step3020, Loss: 3.8889479637145996, Grad L2 Norm: 0.017890146002173424
2025-11-23 22:38:00.107 | INFO     | __main__:<module>:160 - Step3030, Loss: 3.8409817218780518, Grad L2 Norm: 0.022275138646364212
2025-11-23 22:38:01.838 | INFO     | __main__:<module>:160 - Step3040, Loss: 3.868985176086426, Grad L2 Norm: 0.019571011886000633
2025-11-23 22:38:03.598 | INFO     | __main__:<module>:160 - Step3050, Loss: 3.9369707107543945, Grad L2 Norm: 0.020369810983538628
2025-11-23 22:38:05.346 | INFO     | __main__:<module>:160 - Step3060, Loss: 3.8044371604919434, Grad L2 Norm: 0.01845281571149826
2025-11-23 22:38:07.086 | INFO     | __main__:<module>:160 - Step3070, Loss: 3.8711581230163574, Grad L2 Norm: 0.01898079551756382
2025-11-23 22:38:08.827 | INFO     | __main__:<module>:160 - Step3080, Loss: 3.8896121978759766, Grad L2 Norm: 0.020416971296072006
2025-11-23 22:38:10.575 | INFO     | __main__:<module>:160 - Step3090, Loss: 3.873337984085083, Grad L2 Norm: 0.018830446526408195
2025-11-23 22:38:12.323 | INFO     | __main__:<module>:160 - Step3100, Loss: 3.784735679626465, Grad L2 Norm: 0.019512569531798363
2025-11-23 22:38:14.095 | INFO     | __main__:<module>:160 - Step3110, Loss: 3.801898717880249, Grad L2 Norm: 0.018892521038651466
2025-11-23 22:38:15.848 | INFO     | __main__:<module>:160 - Step3120, Loss: 3.8154239654541016, Grad L2 Norm: 0.018322551622986794
2025-11-23 22:38:17.599 | INFO     | __main__:<module>:160 - Step3130, Loss: 3.8663206100463867, Grad L2 Norm: 0.019202688708901405
2025-11-23 22:38:19.346 | INFO     | __main__:<module>:160 - Step3140, Loss: 3.6812291145324707, Grad L2 Norm: 0.01892959512770176
2025-11-23 22:38:21.100 | INFO     | __main__:<module>:160 - Step3150, Loss: 3.8721814155578613, Grad L2 Norm: 0.02136143110692501
2025-11-23 22:38:22.858 | INFO     | __main__:<module>:160 - Step3160, Loss: 3.822418689727783, Grad L2 Norm: 0.020075419917702675
2025-11-23 22:38:24.599 | INFO     | __main__:<module>:160 - Step3170, Loss: 3.768812417984009, Grad L2 Norm: 0.019367549568414688
2025-11-23 22:38:26.336 | INFO     | __main__:<module>:160 - Step3180, Loss: 3.852015495300293, Grad L2 Norm: 0.019929010421037674
2025-11-23 22:38:28.079 | INFO     | __main__:<module>:160 - Step3190, Loss: 3.9189133644104004, Grad L2 Norm: 0.01959436759352684
2025-11-23 22:38:29.819 | INFO     | __main__:<module>:160 - Step3200, Loss: 3.8256399631500244, Grad L2 Norm: 0.018963705748319626
2025-11-23 22:38:29.820 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:38:30.837 | INFO     | __main__:<module>:181 - validation loss: 3.8215078949928283
2025-11-23 22:38:32.584 | INFO     | __main__:<module>:160 - Step3210, Loss: 3.9024691581726074, Grad L2 Norm: 0.019870225340127945
2025-11-23 22:38:34.340 | INFO     | __main__:<module>:160 - Step3220, Loss: 3.769590377807617, Grad L2 Norm: 0.019050240516662598
2025-11-23 22:38:36.085 | INFO     | __main__:<module>:160 - Step3230, Loss: 3.897395610809326, Grad L2 Norm: 0.020723437890410423
2025-11-23 22:38:37.826 | INFO     | __main__:<module>:160 - Step3240, Loss: 3.7514266967773438, Grad L2 Norm: 0.019544225186109543
2025-11-23 22:38:39.573 | INFO     | __main__:<module>:160 - Step3250, Loss: 3.6794686317443848, Grad L2 Norm: 0.01854722760617733
2025-11-23 22:38:41.316 | INFO     | __main__:<module>:160 - Step3260, Loss: 3.746617078781128, Grad L2 Norm: 0.019170193001627922
2025-11-23 22:38:43.054 | INFO     | __main__:<module>:160 - Step3270, Loss: 3.8598055839538574, Grad L2 Norm: 0.018672384321689606
2025-11-23 22:38:44.804 | INFO     | __main__:<module>:160 - Step3280, Loss: 3.889254570007324, Grad L2 Norm: 0.018921444192528725
2025-11-23 22:38:46.530 | INFO     | __main__:<module>:160 - Step3290, Loss: 3.7322440147399902, Grad L2 Norm: 0.017446644604206085
2025-11-23 22:38:48.270 | INFO     | __main__:<module>:160 - Step3300, Loss: 3.797630786895752, Grad L2 Norm: 0.021123213693499565
2025-11-23 22:38:50.010 | INFO     | __main__:<module>:160 - Step3310, Loss: 3.680576801300049, Grad L2 Norm: 0.017803117632865906
2025-11-23 22:38:51.769 | INFO     | __main__:<module>:160 - Step3320, Loss: 3.8618595600128174, Grad L2 Norm: 0.017889896407723427
2025-11-23 22:38:53.514 | INFO     | __main__:<module>:160 - Step3330, Loss: 3.6489202976226807, Grad L2 Norm: 0.020970802754163742
2025-11-23 22:38:55.266 | INFO     | __main__:<module>:160 - Step3340, Loss: 3.7673704624176025, Grad L2 Norm: 0.018939893692731857
2025-11-23 22:38:56.996 | INFO     | __main__:<module>:160 - Step3350, Loss: 3.681779384613037, Grad L2 Norm: 0.01895306073129177
2025-11-23 22:38:58.742 | INFO     | __main__:<module>:160 - Step3360, Loss: 3.808990955352783, Grad L2 Norm: 0.02118963561952114
2025-11-23 22:39:00.481 | INFO     | __main__:<module>:160 - Step3370, Loss: 3.702979803085327, Grad L2 Norm: 0.018473979085683823
2025-11-23 22:39:02.231 | INFO     | __main__:<module>:160 - Step3380, Loss: 3.8467001914978027, Grad L2 Norm: 0.019734641537070274
2025-11-23 22:39:03.985 | INFO     | __main__:<module>:160 - Step3390, Loss: 3.9087157249450684, Grad L2 Norm: 0.019421767443418503
2025-11-23 22:39:05.734 | INFO     | __main__:<module>:160 - Step3400, Loss: 3.891193151473999, Grad L2 Norm: 0.02093547023832798
2025-11-23 22:39:07.486 | INFO     | __main__:<module>:160 - Step3410, Loss: 3.7861363887786865, Grad L2 Norm: 0.01836301200091839
2025-11-23 22:39:09.245 | INFO     | __main__:<module>:160 - Step3420, Loss: 3.889763832092285, Grad L2 Norm: 0.020528050139546394
2025-11-23 22:39:11.001 | INFO     | __main__:<module>:160 - Step3430, Loss: 3.7356786727905273, Grad L2 Norm: 0.018612511456012726
2025-11-23 22:39:12.747 | INFO     | __main__:<module>:160 - Step3440, Loss: 3.8182497024536133, Grad L2 Norm: 0.022369880229234695
2025-11-23 22:39:14.491 | INFO     | __main__:<module>:160 - Step3450, Loss: 3.9118778705596924, Grad L2 Norm: 0.01832342892885208
2025-11-23 22:39:16.223 | INFO     | __main__:<module>:160 - Step3460, Loss: 4.0246195793151855, Grad L2 Norm: 0.019449511542916298
2025-11-23 22:39:17.964 | INFO     | __main__:<module>:160 - Step3470, Loss: 3.715846061706543, Grad L2 Norm: 0.020841695368289948
2025-11-23 22:39:19.704 | INFO     | __main__:<module>:160 - Step3480, Loss: 3.6779112815856934, Grad L2 Norm: 0.019282378256320953
2025-11-23 22:39:21.476 | INFO     | __main__:<module>:160 - Step3490, Loss: 3.8127238750457764, Grad L2 Norm: 0.018407050520181656
2025-11-23 22:39:23.228 | INFO     | __main__:<module>:160 - Step3500, Loss: 3.9076404571533203, Grad L2 Norm: 0.01995910331606865
2025-11-23 22:39:24.973 | INFO     | __main__:<module>:160 - Step3510, Loss: 3.697166919708252, Grad L2 Norm: 0.020185021683573723
2025-11-23 22:39:26.716 | INFO     | __main__:<module>:160 - Step3520, Loss: 3.771961212158203, Grad L2 Norm: 0.018428228795528412
2025-11-23 22:39:28.453 | INFO     | __main__:<module>:160 - Step3530, Loss: 3.734907627105713, Grad L2 Norm: 0.022567661479115486
2025-11-23 22:39:30.501 | INFO     | __main__:<module>:160 - Step3540, Loss: 3.8442625999450684, Grad L2 Norm: 0.01998257450759411
2025-11-23 22:39:32.555 | INFO     | __main__:<module>:160 - Step3550, Loss: 3.7423861026763916, Grad L2 Norm: 0.019156603142619133
2025-11-23 22:39:34.607 | INFO     | __main__:<module>:160 - Step3560, Loss: 3.742888927459717, Grad L2 Norm: 0.01880025491118431
2025-11-23 22:39:36.662 | INFO     | __main__:<module>:160 - Step3570, Loss: 3.713494062423706, Grad L2 Norm: 0.017483241856098175
2025-11-23 22:39:38.708 | INFO     | __main__:<module>:160 - Step3580, Loss: 4.046412467956543, Grad L2 Norm: 0.023537972941994667
2025-11-23 22:39:40.759 | INFO     | __main__:<module>:160 - Step3590, Loss: 3.931513786315918, Grad L2 Norm: 0.0218561589717865
2025-11-23 22:39:42.804 | INFO     | __main__:<module>:160 - Step3600, Loss: 3.813258647918701, Grad L2 Norm: 0.01877150498330593
2025-11-23 22:39:42.805 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:39:44.100 | INFO     | __main__:<module>:181 - validation loss: 3.7916802644729612
2025-11-23 22:39:46.155 | INFO     | __main__:<module>:160 - Step3610, Loss: 3.5838189125061035, Grad L2 Norm: 0.017589829862117767
2025-11-23 22:39:48.201 | INFO     | __main__:<module>:160 - Step3620, Loss: 3.6925835609436035, Grad L2 Norm: 0.019392523914575577
2025-11-23 22:39:50.239 | INFO     | __main__:<module>:160 - Step3630, Loss: 3.8140361309051514, Grad L2 Norm: 0.01936350390315056
2025-11-23 22:39:52.275 | INFO     | __main__:<module>:160 - Step3640, Loss: 3.9101691246032715, Grad L2 Norm: 0.018994931131601334
2025-11-23 22:39:54.306 | INFO     | __main__:<module>:160 - Step3650, Loss: 3.6503593921661377, Grad L2 Norm: 0.019149083644151688
2025-11-23 22:39:56.342 | INFO     | __main__:<module>:160 - Step3660, Loss: 3.7764124870300293, Grad L2 Norm: 0.01971769519150257
2025-11-23 22:39:58.379 | INFO     | __main__:<module>:160 - Step3670, Loss: 3.732140064239502, Grad L2 Norm: 0.019453367218375206
2025-11-23 22:40:00.414 | INFO     | __main__:<module>:160 - Step3680, Loss: 3.922504425048828, Grad L2 Norm: 0.018642762675881386
2025-11-23 22:40:02.443 | INFO     | __main__:<module>:160 - Step3690, Loss: 3.795426607131958, Grad L2 Norm: 0.020115578547120094
2025-11-23 22:40:04.476 | INFO     | __main__:<module>:160 - Step3700, Loss: 3.8963711261749268, Grad L2 Norm: 0.01913536712527275
2025-11-23 22:40:06.502 | INFO     | __main__:<module>:160 - Step3710, Loss: 3.926055908203125, Grad L2 Norm: 0.02186627686023712
2025-11-23 22:40:08.529 | INFO     | __main__:<module>:160 - Step3720, Loss: 3.779031276702881, Grad L2 Norm: 0.01966509036719799
2025-11-23 22:40:10.551 | INFO     | __main__:<module>:160 - Step3730, Loss: 3.695796489715576, Grad L2 Norm: 0.020916057750582695
2025-11-23 22:40:12.570 | INFO     | __main__:<module>:160 - Step3740, Loss: 3.7377002239227295, Grad L2 Norm: 0.019856004044413567
2025-11-23 22:40:14.595 | INFO     | __main__:<module>:160 - Step3750, Loss: 3.680056571960449, Grad L2 Norm: 0.018505029380321503
2025-11-23 22:40:16.610 | INFO     | __main__:<module>:160 - Step3760, Loss: 3.807408571243286, Grad L2 Norm: 0.01923532411456108
2025-11-23 22:40:18.627 | INFO     | __main__:<module>:160 - Step3770, Loss: 3.846489429473877, Grad L2 Norm: 0.02035561203956604
2025-11-23 22:40:20.649 | INFO     | __main__:<module>:160 - Step3780, Loss: 3.6473388671875, Grad L2 Norm: 0.018008098006248474
2025-11-23 22:40:22.672 | INFO     | __main__:<module>:160 - Step3790, Loss: 3.8663084506988525, Grad L2 Norm: 0.018810385838150978
2025-11-23 22:40:24.685 | INFO     | __main__:<module>:160 - Step3800, Loss: 3.9052014350891113, Grad L2 Norm: 0.02122371830046177
2025-11-23 22:40:26.694 | INFO     | __main__:<module>:160 - Step3810, Loss: 3.871005058288574, Grad L2 Norm: 0.020943064242601395
2025-11-23 22:40:28.720 | INFO     | __main__:<module>:160 - Step3820, Loss: 3.9375030994415283, Grad L2 Norm: 0.02011752687394619
2025-11-23 22:40:30.735 | INFO     | __main__:<module>:160 - Step3830, Loss: 3.7703449726104736, Grad L2 Norm: 0.02078767865896225
2025-11-23 22:40:32.752 | INFO     | __main__:<module>:160 - Step3840, Loss: 3.6414875984191895, Grad L2 Norm: 0.019411254674196243
2025-11-23 22:40:34.765 | INFO     | __main__:<module>:160 - Step3850, Loss: 3.7328007221221924, Grad L2 Norm: 0.019449416548013687
2025-11-23 22:40:36.776 | INFO     | __main__:<module>:160 - Step3860, Loss: 3.8726425170898438, Grad L2 Norm: 0.021172786131501198
2025-11-23 22:40:38.785 | INFO     | __main__:<module>:160 - Step3870, Loss: 4.041518211364746, Grad L2 Norm: 0.020166859030723572
2025-11-23 22:40:40.803 | INFO     | __main__:<module>:160 - Step3880, Loss: 3.7535624504089355, Grad L2 Norm: 0.020142950117588043
2025-11-23 22:40:42.807 | INFO     | __main__:<module>:160 - Step3890, Loss: 3.5516159534454346, Grad L2 Norm: 0.019018132239580154
2025-11-23 22:40:44.825 | INFO     | __main__:<module>:160 - Step3900, Loss: 3.7375147342681885, Grad L2 Norm: 0.01856756955385208
2025-11-23 22:40:46.841 | INFO     | __main__:<module>:160 - Step3910, Loss: 3.8095359802246094, Grad L2 Norm: 0.01950666308403015
2025-11-23 22:40:48.844 | INFO     | __main__:<module>:160 - Step3920, Loss: 3.759288787841797, Grad L2 Norm: 0.01892019249498844
2025-11-23 22:40:50.860 | INFO     | __main__:<module>:160 - Step3930, Loss: 3.7376112937927246, Grad L2 Norm: 0.019027218222618103
2025-11-23 22:40:52.866 | INFO     | __main__:<module>:160 - Step3940, Loss: 3.658735752105713, Grad L2 Norm: 0.01710435003042221
2025-11-23 22:40:54.880 | INFO     | __main__:<module>:160 - Step3950, Loss: 3.6529102325439453, Grad L2 Norm: 0.020016338676214218
2025-11-23 22:40:56.884 | INFO     | __main__:<module>:160 - Step3960, Loss: 3.5269577503204346, Grad L2 Norm: 0.02024085260927677
2025-11-23 22:40:58.898 | INFO     | __main__:<module>:160 - Step3970, Loss: 3.7252516746520996, Grad L2 Norm: 0.018224285915493965
2025-11-23 22:41:00.900 | INFO     | __main__:<module>:160 - Step3980, Loss: 3.639582395553589, Grad L2 Norm: 0.01951354555785656
2025-11-23 22:41:02.902 | INFO     | __main__:<module>:160 - Step3990, Loss: 3.7108354568481445, Grad L2 Norm: 0.019002147018909454
2025-11-23 22:41:04.916 | INFO     | __main__:<module>:160 - Step4000, Loss: 3.7571558952331543, Grad L2 Norm: 0.021229296922683716
2025-11-23 22:41:04.917 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:41:06.191 | INFO     | __main__:<module>:181 - validation loss: 3.7499349117279053
2025-11-23 22:41:06.192 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_4000.pt
2025-11-23 22:41:07.833 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-23 22:41:09.824 | INFO     | __main__:<module>:160 - Step4010, Loss: 3.850625514984131, Grad L2 Norm: 0.020077208057045937
2025-11-23 22:41:11.831 | INFO     | __main__:<module>:160 - Step4020, Loss: 3.667205810546875, Grad L2 Norm: 0.019391700625419617
2025-11-23 22:41:13.831 | INFO     | __main__:<module>:160 - Step4030, Loss: 3.7865090370178223, Grad L2 Norm: 0.020265653729438782
2025-11-23 22:41:15.833 | INFO     | __main__:<module>:160 - Step4040, Loss: 3.9094595909118652, Grad L2 Norm: 0.0198807530105114
2025-11-23 22:41:17.833 | INFO     | __main__:<module>:160 - Step4050, Loss: 3.886127471923828, Grad L2 Norm: 0.020071156322956085
2025-11-23 22:41:19.832 | INFO     | __main__:<module>:160 - Step4060, Loss: 3.732612133026123, Grad L2 Norm: 0.019748670980334282
2025-11-23 22:41:21.834 | INFO     | __main__:<module>:160 - Step4070, Loss: 3.7950479984283447, Grad L2 Norm: 0.018516086041927338
2025-11-23 22:41:23.829 | INFO     | __main__:<module>:160 - Step4080, Loss: 3.569967746734619, Grad L2 Norm: 0.01915241964161396
2025-11-23 22:41:25.833 | INFO     | __main__:<module>:160 - Step4090, Loss: 3.6878795623779297, Grad L2 Norm: 0.017907751724123955
2025-11-23 22:41:27.834 | INFO     | __main__:<module>:160 - Step4100, Loss: 3.725386142730713, Grad L2 Norm: 0.01948999986052513
2025-11-23 22:41:29.844 | INFO     | __main__:<module>:160 - Step4110, Loss: 3.754945993423462, Grad L2 Norm: 0.020385943353176117
2025-11-23 22:41:31.846 | INFO     | __main__:<module>:160 - Step4120, Loss: 3.7948575019836426, Grad L2 Norm: 0.020223453640937805
2025-11-23 22:41:33.844 | INFO     | __main__:<module>:160 - Step4130, Loss: 3.692405939102173, Grad L2 Norm: 0.01915210671722889
2025-11-23 22:41:35.848 | INFO     | __main__:<module>:160 - Step4140, Loss: 3.614079475402832, Grad L2 Norm: 0.01817626878619194
2025-11-23 22:41:37.845 | INFO     | __main__:<module>:160 - Step4150, Loss: 3.875462770462036, Grad L2 Norm: 0.019160017371177673
2025-11-23 22:41:39.843 | INFO     | __main__:<module>:160 - Step4160, Loss: 3.669774055480957, Grad L2 Norm: 0.018358344212174416
2025-11-23 22:41:41.842 | INFO     | __main__:<module>:160 - Step4170, Loss: 3.5410540103912354, Grad L2 Norm: 0.018471652641892433
2025-11-23 22:41:43.840 | INFO     | __main__:<module>:160 - Step4180, Loss: 3.737086772918701, Grad L2 Norm: 0.02076251432299614
2025-11-23 22:41:45.840 | INFO     | __main__:<module>:160 - Step4190, Loss: 3.8722033500671387, Grad L2 Norm: 0.020482352003455162
2025-11-23 22:41:47.842 | INFO     | __main__:<module>:160 - Step4200, Loss: 3.78440260887146, Grad L2 Norm: 0.01945546455681324
2025-11-23 22:41:49.839 | INFO     | __main__:<module>:160 - Step4210, Loss: 3.739356517791748, Grad L2 Norm: 0.021129800006747246
2025-11-23 22:41:51.839 | INFO     | __main__:<module>:160 - Step4220, Loss: 3.676966667175293, Grad L2 Norm: 0.019581031054258347
2025-11-23 22:41:53.836 | INFO     | __main__:<module>:160 - Step4230, Loss: 3.80025315284729, Grad L2 Norm: 0.01985349878668785
2025-11-23 22:41:55.837 | INFO     | __main__:<module>:160 - Step4240, Loss: 3.729177474975586, Grad L2 Norm: 0.020582739263772964
2025-11-23 22:41:57.834 | INFO     | __main__:<module>:160 - Step4250, Loss: 3.607046127319336, Grad L2 Norm: 0.01803669147193432
2025-11-23 22:41:59.837 | INFO     | __main__:<module>:160 - Step4260, Loss: 3.7119967937469482, Grad L2 Norm: 0.01878858357667923
2025-11-23 22:42:01.836 | INFO     | __main__:<module>:160 - Step4270, Loss: 3.7033791542053223, Grad L2 Norm: 0.01861458271741867
2025-11-23 22:42:03.835 | INFO     | __main__:<module>:160 - Step4280, Loss: 3.6058530807495117, Grad L2 Norm: 0.020626580342650414
2025-11-23 22:42:05.832 | INFO     | __main__:<module>:160 - Step4290, Loss: 3.7016873359680176, Grad L2 Norm: 0.018782207742333412
2025-11-23 22:42:07.835 | INFO     | __main__:<module>:160 - Step4300, Loss: 3.7970664501190186, Grad L2 Norm: 0.019118379801511765
2025-11-23 22:42:09.835 | INFO     | __main__:<module>:160 - Step4310, Loss: 3.855246067047119, Grad L2 Norm: 0.021858666092157364
2025-11-23 22:42:11.832 | INFO     | __main__:<module>:160 - Step4320, Loss: 3.7322020530700684, Grad L2 Norm: 0.01935657113790512
2025-11-23 22:42:13.831 | INFO     | __main__:<module>:160 - Step4330, Loss: 3.680230140686035, Grad L2 Norm: 0.020840343087911606
2025-11-23 22:42:15.830 | INFO     | __main__:<module>:160 - Step4340, Loss: 3.7188363075256348, Grad L2 Norm: 0.019253673031926155
2025-11-23 22:42:17.828 | INFO     | __main__:<module>:160 - Step4350, Loss: 3.812516689300537, Grad L2 Norm: 0.019493423402309418
2025-11-23 22:42:19.830 | INFO     | __main__:<module>:160 - Step4360, Loss: 3.6814804077148438, Grad L2 Norm: 0.02054440975189209
2025-11-23 22:42:21.829 | INFO     | __main__:<module>:160 - Step4370, Loss: 3.66696834564209, Grad L2 Norm: 0.019585933536291122
2025-11-23 22:42:23.830 | INFO     | __main__:<module>:160 - Step4380, Loss: 3.674013137817383, Grad L2 Norm: 0.019594192504882812
2025-11-23 22:42:25.830 | INFO     | __main__:<module>:160 - Step4390, Loss: 3.735546588897705, Grad L2 Norm: 0.02026081643998623
2025-11-23 22:42:27.827 | INFO     | __main__:<module>:160 - Step4400, Loss: 3.711686134338379, Grad L2 Norm: 0.01849776692688465
2025-11-23 22:42:27.828 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:42:29.100 | INFO     | __main__:<module>:181 - validation loss: 3.733397090435028
2025-11-23 22:42:31.104 | INFO     | __main__:<module>:160 - Step4410, Loss: 3.7433722019195557, Grad L2 Norm: 0.019776107743382454
2025-11-23 22:42:33.106 | INFO     | __main__:<module>:160 - Step4420, Loss: 3.6598868370056152, Grad L2 Norm: 0.019609272480010986
2025-11-23 22:42:35.107 | INFO     | __main__:<module>:160 - Step4430, Loss: 3.728513479232788, Grad L2 Norm: 0.020211191847920418
2025-11-23 22:42:37.105 | INFO     | __main__:<module>:160 - Step4440, Loss: 3.592005729675293, Grad L2 Norm: 0.021795112639665604
2025-11-23 22:42:39.105 | INFO     | __main__:<module>:160 - Step4450, Loss: 3.699240207672119, Grad L2 Norm: 0.020141329616308212
2025-11-23 22:42:41.105 | INFO     | __main__:<module>:160 - Step4460, Loss: 3.885560989379883, Grad L2 Norm: 0.021076956763863564
2025-11-23 22:42:43.102 | INFO     | __main__:<module>:160 - Step4470, Loss: 3.7976932525634766, Grad L2 Norm: 0.019988136366009712
2025-11-23 22:42:45.103 | INFO     | __main__:<module>:160 - Step4480, Loss: 3.748474597930908, Grad L2 Norm: 0.019662944599986076
2025-11-23 22:42:47.105 | INFO     | __main__:<module>:160 - Step4490, Loss: 3.8103206157684326, Grad L2 Norm: 0.019903605803847313
2025-11-23 22:42:49.106 | INFO     | __main__:<module>:160 - Step4500, Loss: 3.7552545070648193, Grad L2 Norm: 0.019253628328442574
2025-11-23 22:42:51.102 | INFO     | __main__:<module>:160 - Step4510, Loss: 3.6687698364257812, Grad L2 Norm: 0.01928577572107315
2025-11-23 22:42:53.099 | INFO     | __main__:<module>:160 - Step4520, Loss: 3.5586585998535156, Grad L2 Norm: 0.019946038722991943
2025-11-23 22:42:55.100 | INFO     | __main__:<module>:160 - Step4530, Loss: 3.7254319190979004, Grad L2 Norm: 0.021214492619037628
2025-11-23 22:42:57.100 | INFO     | __main__:<module>:160 - Step4540, Loss: 3.838291645050049, Grad L2 Norm: 0.019100669771432877
2025-11-23 22:42:59.097 | INFO     | __main__:<module>:160 - Step4550, Loss: 3.678483009338379, Grad L2 Norm: 0.018179049715399742
2025-11-23 22:43:01.099 | INFO     | __main__:<module>:160 - Step4560, Loss: 3.8525962829589844, Grad L2 Norm: 0.02032189443707466
2025-11-23 22:43:03.097 | INFO     | __main__:<module>:160 - Step4570, Loss: 3.6608710289001465, Grad L2 Norm: 0.02058420330286026
2025-11-23 22:43:05.097 | INFO     | __main__:<module>:160 - Step4580, Loss: 3.7326278686523438, Grad L2 Norm: 0.020633138716220856
2025-11-23 22:43:07.096 | INFO     | __main__:<module>:160 - Step4590, Loss: 3.8595218658447266, Grad L2 Norm: 0.021685972809791565
2025-11-23 22:43:09.098 | INFO     | __main__:<module>:160 - Step4600, Loss: 3.6216671466827393, Grad L2 Norm: 0.01918029598891735
2025-11-23 22:43:11.098 | INFO     | __main__:<module>:160 - Step4610, Loss: 3.7222208976745605, Grad L2 Norm: 0.01928594335913658
2025-11-23 22:43:13.099 | INFO     | __main__:<module>:160 - Step4620, Loss: 3.494117259979248, Grad L2 Norm: 0.01971195638179779
2025-11-23 22:43:15.100 | INFO     | __main__:<module>:160 - Step4630, Loss: 3.543165922164917, Grad L2 Norm: 0.01884699985384941
2025-11-23 22:43:17.094 | INFO     | __main__:<module>:160 - Step4640, Loss: 3.5277960300445557, Grad L2 Norm: 0.0186263807117939
2025-11-23 22:43:19.092 | INFO     | __main__:<module>:160 - Step4650, Loss: 3.803898334503174, Grad L2 Norm: 0.018926428630948067
2025-11-23 22:43:21.090 | INFO     | __main__:<module>:160 - Step4660, Loss: 3.8413844108581543, Grad L2 Norm: 0.019999468699097633
2025-11-23 22:43:23.092 | INFO     | __main__:<module>:160 - Step4670, Loss: 3.6564717292785645, Grad L2 Norm: 0.019747577607631683
2025-11-23 22:43:25.089 | INFO     | __main__:<module>:160 - Step4680, Loss: 3.7490122318267822, Grad L2 Norm: 0.02036065235733986
2025-11-23 22:43:27.090 | INFO     | __main__:<module>:160 - Step4690, Loss: 3.6454501152038574, Grad L2 Norm: 0.018783988431096077
2025-11-23 22:43:29.091 | INFO     | __main__:<module>:160 - Step4700, Loss: 3.8080291748046875, Grad L2 Norm: 0.021845322102308273
2025-11-23 22:43:31.090 | INFO     | __main__:<module>:160 - Step4710, Loss: 3.6112241744995117, Grad L2 Norm: 0.019499879330396652
2025-11-23 22:43:33.088 | INFO     | __main__:<module>:160 - Step4720, Loss: 3.760903835296631, Grad L2 Norm: 0.021123142912983894
2025-11-23 22:43:35.090 | INFO     | __main__:<module>:160 - Step4730, Loss: 3.683488130569458, Grad L2 Norm: 0.018757881596684456
2025-11-23 22:43:37.088 | INFO     | __main__:<module>:160 - Step4740, Loss: 3.8712713718414307, Grad L2 Norm: 0.021520305424928665
2025-11-23 22:43:39.086 | INFO     | __main__:<module>:160 - Step4750, Loss: 3.7922210693359375, Grad L2 Norm: 0.021286573261022568
2025-11-23 22:43:41.085 | INFO     | __main__:<module>:160 - Step4760, Loss: 3.7528529167175293, Grad L2 Norm: 0.018617400899529457
2025-11-23 22:43:43.087 | INFO     | __main__:<module>:160 - Step4770, Loss: 3.7257602214813232, Grad L2 Norm: 0.021051863208413124
2025-11-23 22:43:45.092 | INFO     | __main__:<module>:160 - Step4780, Loss: 3.729637622833252, Grad L2 Norm: 0.021867843344807625
2025-11-23 22:43:47.089 | INFO     | __main__:<module>:160 - Step4790, Loss: 3.7488813400268555, Grad L2 Norm: 0.018984584137797356
2025-11-23 22:43:49.086 | INFO     | __main__:<module>:160 - Step4800, Loss: 3.6512722969055176, Grad L2 Norm: 0.02001306787133217
2025-11-23 22:43:49.087 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:43:50.357 | INFO     | __main__:<module>:181 - validation loss: 3.7021297216415405
2025-11-23 22:43:52.364 | INFO     | __main__:<module>:160 - Step4810, Loss: 3.8591506481170654, Grad L2 Norm: 0.019139636307954788
2025-11-23 22:43:54.360 | INFO     | __main__:<module>:160 - Step4820, Loss: 3.708199977874756, Grad L2 Norm: 0.020396696403622627
2025-11-23 22:43:56.360 | INFO     | __main__:<module>:160 - Step4830, Loss: 3.818343162536621, Grad L2 Norm: 0.019584715366363525
2025-11-23 22:43:58.360 | INFO     | __main__:<module>:160 - Step4840, Loss: 3.6219310760498047, Grad L2 Norm: 0.020261116325855255
2025-11-23 22:44:00.359 | INFO     | __main__:<module>:160 - Step4850, Loss: 3.856053352355957, Grad L2 Norm: 0.020704839378595352
2025-11-23 22:44:02.359 | INFO     | __main__:<module>:160 - Step4860, Loss: 3.7818198204040527, Grad L2 Norm: 0.02163323201239109
2025-11-23 22:44:04.360 | INFO     | __main__:<module>:160 - Step4870, Loss: 3.7444794178009033, Grad L2 Norm: 0.01938106119632721
2025-11-23 22:44:06.356 | INFO     | __main__:<module>:160 - Step4880, Loss: 3.731583595275879, Grad L2 Norm: 0.021203402429819107
2025-11-23 22:44:08.356 | INFO     | __main__:<module>:160 - Step4890, Loss: 3.5550010204315186, Grad L2 Norm: 0.019508391618728638
2025-11-23 22:44:10.357 | INFO     | __main__:<module>:160 - Step4900, Loss: 3.550705671310425, Grad L2 Norm: 0.018180783838033676
2025-11-23 22:44:12.357 | INFO     | __main__:<module>:160 - Step4910, Loss: 3.695366859436035, Grad L2 Norm: 0.019227882847189903
2025-11-23 22:44:14.356 | INFO     | __main__:<module>:160 - Step4920, Loss: 3.6971514225006104, Grad L2 Norm: 0.019776539877057076
2025-11-23 22:44:16.355 | INFO     | __main__:<module>:160 - Step4930, Loss: 3.7858471870422363, Grad L2 Norm: 0.020034581422805786
2025-11-23 22:44:18.354 | INFO     | __main__:<module>:160 - Step4940, Loss: 3.5734615325927734, Grad L2 Norm: 0.020712850615382195
2025-11-23 22:44:20.353 | INFO     | __main__:<module>:160 - Step4950, Loss: 3.7213003635406494, Grad L2 Norm: 0.019518151879310608
2025-11-23 22:44:22.354 | INFO     | __main__:<module>:160 - Step4960, Loss: 3.6949548721313477, Grad L2 Norm: 0.0201069675385952
2025-11-23 22:44:24.351 | INFO     | __main__:<module>:160 - Step4970, Loss: 3.6004858016967773, Grad L2 Norm: 0.020572422072291374
2025-11-23 22:44:26.349 | INFO     | __main__:<module>:160 - Step4980, Loss: 3.6648874282836914, Grad L2 Norm: 0.019986066967248917
2025-11-23 22:44:28.349 | INFO     | __main__:<module>:160 - Step4990, Loss: 3.6385340690612793, Grad L2 Norm: 0.021289024502038956
2025-11-23 22:44:30.351 | INFO     | __main__:<module>:160 - Step5000, Loss: 3.688960552215576, Grad L2 Norm: 0.019657397642731667
2025-11-23 22:44:32.349 | INFO     | __main__:<module>:160 - Step5010, Loss: 3.7822234630584717, Grad L2 Norm: 0.020432282239198685
2025-11-23 22:44:34.349 | INFO     | __main__:<module>:160 - Step5020, Loss: 3.645937919616699, Grad L2 Norm: 0.020277494564652443
2025-11-23 22:44:36.349 | INFO     | __main__:<module>:160 - Step5030, Loss: 3.9185051918029785, Grad L2 Norm: 0.02308809384703636
2025-11-23 22:44:38.350 | INFO     | __main__:<module>:160 - Step5040, Loss: 3.7964110374450684, Grad L2 Norm: 0.020702620968222618
2025-11-23 22:44:40.349 | INFO     | __main__:<module>:160 - Step5050, Loss: 3.6654152870178223, Grad L2 Norm: 0.020224446430802345
2025-11-23 22:44:42.347 | INFO     | __main__:<module>:160 - Step5060, Loss: 3.587249517440796, Grad L2 Norm: 0.01856054551899433
2025-11-23 22:44:44.346 | INFO     | __main__:<module>:160 - Step5070, Loss: 3.8252806663513184, Grad L2 Norm: 0.021008001640439034
2025-11-23 22:44:46.344 | INFO     | __main__:<module>:160 - Step5080, Loss: 3.6835789680480957, Grad L2 Norm: 0.02203829400241375
2025-11-23 22:44:48.345 | INFO     | __main__:<module>:160 - Step5090, Loss: 3.589891195297241, Grad L2 Norm: 0.018600231036543846
2025-11-23 22:44:50.343 | INFO     | __main__:<module>:160 - Step5100, Loss: 3.771172046661377, Grad L2 Norm: 0.020389767363667488
2025-11-23 22:44:52.338 | INFO     | __main__:<module>:160 - Step5110, Loss: 3.6559085845947266, Grad L2 Norm: 0.018962670117616653
2025-11-23 22:44:54.341 | INFO     | __main__:<module>:160 - Step5120, Loss: 3.7253522872924805, Grad L2 Norm: 0.019718913361430168
2025-11-23 22:44:56.342 | INFO     | __main__:<module>:160 - Step5130, Loss: 3.5886571407318115, Grad L2 Norm: 0.019429827108979225
2025-11-23 22:44:58.344 | INFO     | __main__:<module>:160 - Step5140, Loss: 3.6653084754943848, Grad L2 Norm: 0.020229017361998558
2025-11-23 22:45:00.340 | INFO     | __main__:<module>:160 - Step5150, Loss: 3.671044111251831, Grad L2 Norm: 0.020871054381132126
2025-11-23 22:45:02.339 | INFO     | __main__:<module>:160 - Step5160, Loss: 3.6604080200195312, Grad L2 Norm: 0.019467167556285858
2025-11-23 22:45:04.338 | INFO     | __main__:<module>:160 - Step5170, Loss: 3.6272268295288086, Grad L2 Norm: 0.020473076030611992
2025-11-23 22:45:06.339 | INFO     | __main__:<module>:160 - Step5180, Loss: 3.638993740081787, Grad L2 Norm: 0.02131277695298195
2025-11-23 22:45:08.339 | INFO     | __main__:<module>:160 - Step5190, Loss: 3.5936222076416016, Grad L2 Norm: 0.020298531278967857
2025-11-23 22:45:10.336 | INFO     | __main__:<module>:160 - Step5200, Loss: 3.7349042892456055, Grad L2 Norm: 0.0203534122556448
2025-11-23 22:45:10.336 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:45:11.604 | INFO     | __main__:<module>:181 - validation loss: 3.705575704574585
2025-11-23 22:45:13.615 | INFO     | __main__:<module>:160 - Step5210, Loss: 3.742140054702759, Grad L2 Norm: 0.020490135997533798
2025-11-23 22:45:15.627 | INFO     | __main__:<module>:160 - Step5220, Loss: 3.7777047157287598, Grad L2 Norm: 0.0190614964812994
2025-11-23 22:45:17.620 | INFO     | __main__:<module>:160 - Step5230, Loss: 3.7181806564331055, Grad L2 Norm: 0.020890764892101288
2025-11-23 22:45:19.620 | INFO     | __main__:<module>:160 - Step5240, Loss: 3.6105411052703857, Grad L2 Norm: 0.0187990739941597
2025-11-23 22:45:21.615 | INFO     | __main__:<module>:160 - Step5250, Loss: 3.737302780151367, Grad L2 Norm: 0.01902487315237522
2025-11-23 22:45:23.617 | INFO     | __main__:<module>:160 - Step5260, Loss: 3.7847416400909424, Grad L2 Norm: 0.020888982340693474
2025-11-23 22:45:25.614 | INFO     | __main__:<module>:160 - Step5270, Loss: 3.6180310249328613, Grad L2 Norm: 0.020772816613316536
2025-11-23 22:45:27.617 | INFO     | __main__:<module>:160 - Step5280, Loss: 3.6769330501556396, Grad L2 Norm: 0.020920874550938606
2025-11-23 22:45:29.613 | INFO     | __main__:<module>:160 - Step5290, Loss: 3.6735284328460693, Grad L2 Norm: 0.02258290909230709
2025-11-23 22:45:31.610 | INFO     | __main__:<module>:160 - Step5300, Loss: 3.6214120388031006, Grad L2 Norm: 0.020609432831406593
2025-11-23 22:45:33.610 | INFO     | __main__:<module>:160 - Step5310, Loss: 3.7263782024383545, Grad L2 Norm: 0.019976666197180748
2025-11-23 22:45:35.610 | INFO     | __main__:<module>:160 - Step5320, Loss: 3.842930793762207, Grad L2 Norm: 0.020009947940707207
2025-11-23 22:45:37.609 | INFO     | __main__:<module>:160 - Step5330, Loss: 3.6565327644348145, Grad L2 Norm: 0.01936204917728901
2025-11-23 22:45:39.609 | INFO     | __main__:<module>:160 - Step5340, Loss: 3.7812113761901855, Grad L2 Norm: 0.025609824806451797
2025-11-23 22:45:41.612 | INFO     | __main__:<module>:160 - Step5350, Loss: 3.626063823699951, Grad L2 Norm: 0.01863679476082325
2025-11-23 22:45:43.608 | INFO     | __main__:<module>:160 - Step5360, Loss: 3.6628215312957764, Grad L2 Norm: 0.01961621083319187
2025-11-23 22:45:45.607 | INFO     | __main__:<module>:160 - Step5370, Loss: 3.5622639656066895, Grad L2 Norm: 0.021124277263879776
2025-11-23 22:45:47.607 | INFO     | __main__:<module>:160 - Step5380, Loss: 3.729728937149048, Grad L2 Norm: 0.022601023316383362
2025-11-23 22:45:49.605 | INFO     | __main__:<module>:160 - Step5390, Loss: 3.674586296081543, Grad L2 Norm: 0.020708143711090088
2025-11-23 22:45:51.606 | INFO     | __main__:<module>:160 - Step5400, Loss: 3.603785991668701, Grad L2 Norm: 0.01914992369711399
2025-11-23 22:45:53.605 | INFO     | __main__:<module>:160 - Step5410, Loss: 3.6846094131469727, Grad L2 Norm: 0.02227890118956566
2025-11-23 22:45:55.603 | INFO     | __main__:<module>:160 - Step5420, Loss: 3.8039188385009766, Grad L2 Norm: 0.02096591703593731
2025-11-23 22:45:57.603 | INFO     | __main__:<module>:160 - Step5430, Loss: 3.793388843536377, Grad L2 Norm: 0.02030288614332676
2025-11-23 22:45:59.602 | INFO     | __main__:<module>:160 - Step5440, Loss: 3.7346062660217285, Grad L2 Norm: 0.019846150651574135
2025-11-23 22:46:01.604 | INFO     | __main__:<module>:160 - Step5450, Loss: 3.686647891998291, Grad L2 Norm: 0.02145589143037796
2025-11-23 22:46:03.601 | INFO     | __main__:<module>:160 - Step5460, Loss: 3.6702864170074463, Grad L2 Norm: 0.02191297896206379
2025-11-23 22:46:05.600 | INFO     | __main__:<module>:160 - Step5470, Loss: 3.651313066482544, Grad L2 Norm: 0.020773887634277344
2025-11-23 22:46:07.592 | INFO     | __main__:<module>:160 - Step5480, Loss: 3.694744110107422, Grad L2 Norm: 0.019734924659132957
2025-11-23 22:46:09.583 | INFO     | __main__:<module>:160 - Step5490, Loss: 3.5773861408233643, Grad L2 Norm: 0.020051831379532814
2025-11-23 22:46:11.581 | INFO     | __main__:<module>:160 - Step5500, Loss: 3.6710493564605713, Grad L2 Norm: 0.020614732056856155
2025-11-23 22:46:13.577 | INFO     | __main__:<module>:160 - Step5510, Loss: 3.7676661014556885, Grad L2 Norm: 0.021161699667572975
2025-11-23 22:46:15.576 | INFO     | __main__:<module>:160 - Step5520, Loss: 3.7553484439849854, Grad L2 Norm: 0.01893058978021145
2025-11-23 22:46:17.577 | INFO     | __main__:<module>:160 - Step5530, Loss: 3.79190731048584, Grad L2 Norm: 0.021986132487654686
2025-11-23 22:46:19.575 | INFO     | __main__:<module>:160 - Step5540, Loss: 3.573935031890869, Grad L2 Norm: 0.020247256383299828
2025-11-23 22:46:21.564 | INFO     | __main__:<module>:160 - Step5550, Loss: 3.6132733821868896, Grad L2 Norm: 0.02081424742937088
2025-11-23 22:46:23.554 | INFO     | __main__:<module>:160 - Step5560, Loss: 3.5988831520080566, Grad L2 Norm: 0.018553903326392174
2025-11-23 22:46:25.552 | INFO     | __main__:<module>:160 - Step5570, Loss: 3.71756649017334, Grad L2 Norm: 0.020073385909199715
2025-11-23 22:46:27.554 | INFO     | __main__:<module>:160 - Step5580, Loss: 3.6711363792419434, Grad L2 Norm: 0.020231591537594795
2025-11-23 22:46:29.542 | INFO     | __main__:<module>:160 - Step5590, Loss: 3.597942352294922, Grad L2 Norm: 0.0183218102902174
2025-11-23 22:46:31.532 | INFO     | __main__:<module>:160 - Step5600, Loss: 3.6582794189453125, Grad L2 Norm: 0.018785586580634117
2025-11-23 22:46:31.533 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:46:32.797 | INFO     | __main__:<module>:181 - validation loss: 3.678037703037262
2025-11-23 22:46:34.793 | INFO     | __main__:<module>:160 - Step5610, Loss: 3.6617236137390137, Grad L2 Norm: 0.019770987331867218
2025-11-23 22:46:36.786 | INFO     | __main__:<module>:160 - Step5620, Loss: 3.6126017570495605, Grad L2 Norm: 0.020198872312903404
2025-11-23 22:46:38.771 | INFO     | __main__:<module>:160 - Step5630, Loss: 3.7650747299194336, Grad L2 Norm: 0.021285271272063255
2025-11-23 22:46:40.770 | INFO     | __main__:<module>:160 - Step5640, Loss: 3.5442044734954834, Grad L2 Norm: 0.02113468572497368
2025-11-23 22:46:42.768 | INFO     | __main__:<module>:160 - Step5650, Loss: 3.693014621734619, Grad L2 Norm: 0.0211794376373291
2025-11-23 22:46:44.763 | INFO     | __main__:<module>:160 - Step5660, Loss: 3.6386075019836426, Grad L2 Norm: 0.021545100957155228
2025-11-23 22:46:46.751 | INFO     | __main__:<module>:160 - Step5670, Loss: 3.751682758331299, Grad L2 Norm: 0.019955914467573166
2025-11-23 22:46:48.746 | INFO     | __main__:<module>:160 - Step5680, Loss: 3.6094226837158203, Grad L2 Norm: 0.019483419135212898
2025-11-23 22:46:50.743 | INFO     | __main__:<module>:160 - Step5690, Loss: 3.6230130195617676, Grad L2 Norm: 0.019078515470027924
2025-11-23 22:46:52.730 | INFO     | __main__:<module>:160 - Step5700, Loss: 3.650216817855835, Grad L2 Norm: 0.020623203366994858
2025-11-23 22:46:54.726 | INFO     | __main__:<module>:160 - Step5710, Loss: 3.8556294441223145, Grad L2 Norm: 0.02059365250170231
2025-11-23 22:46:56.726 | INFO     | __main__:<module>:160 - Step5720, Loss: 3.5730133056640625, Grad L2 Norm: 0.021401291713118553
2025-11-23 22:46:58.721 | INFO     | __main__:<module>:160 - Step5730, Loss: 3.6903598308563232, Grad L2 Norm: 0.021289413794875145
2025-11-23 22:47:00.717 | INFO     | __main__:<module>:160 - Step5740, Loss: 3.672861099243164, Grad L2 Norm: 0.020837578922510147
2025-11-23 22:47:02.708 | INFO     | __main__:<module>:160 - Step5750, Loss: 3.725498676300049, Grad L2 Norm: 0.01937502808868885
2025-11-23 22:47:04.703 | INFO     | __main__:<module>:160 - Step5760, Loss: 3.496084690093994, Grad L2 Norm: 0.019491270184516907
2025-11-23 22:47:06.703 | INFO     | __main__:<module>:160 - Step5770, Loss: 3.7486038208007812, Grad L2 Norm: 0.021282058209180832
2025-11-23 22:47:08.687 | INFO     | __main__:<module>:160 - Step5780, Loss: 3.7439773082733154, Grad L2 Norm: 0.020335335284471512
2025-11-23 22:47:10.684 | INFO     | __main__:<module>:160 - Step5790, Loss: 3.853834390640259, Grad L2 Norm: 0.021946096792817116
2025-11-23 22:47:12.680 | INFO     | __main__:<module>:160 - Step5800, Loss: 3.8061461448669434, Grad L2 Norm: 0.021850012242794037
2025-11-23 22:47:14.672 | INFO     | __main__:<module>:160 - Step5810, Loss: 3.804226875305176, Grad L2 Norm: 0.020514653995633125
2025-11-23 22:47:16.662 | INFO     | __main__:<module>:160 - Step5820, Loss: 3.711221694946289, Grad L2 Norm: 0.02108634263277054
2025-11-23 22:47:18.658 | INFO     | __main__:<module>:160 - Step5830, Loss: 3.6540582180023193, Grad L2 Norm: 0.024125611409544945
2025-11-23 22:47:20.643 | INFO     | __main__:<module>:160 - Step5840, Loss: 3.6336584091186523, Grad L2 Norm: 0.019631026312708855
2025-11-23 22:47:22.636 | INFO     | __main__:<module>:160 - Step5850, Loss: 3.5888633728027344, Grad L2 Norm: 0.019519314169883728
2025-11-23 22:47:24.639 | INFO     | __main__:<module>:160 - Step5860, Loss: 3.6633105278015137, Grad L2 Norm: 0.020928695797920227
2025-11-23 22:47:26.639 | INFO     | __main__:<module>:160 - Step5870, Loss: 3.776057004928589, Grad L2 Norm: 0.021816853433847427
2025-11-23 22:47:28.637 | INFO     | __main__:<module>:160 - Step5880, Loss: 3.6681432723999023, Grad L2 Norm: 0.01961416006088257
2025-11-23 22:47:30.637 | INFO     | __main__:<module>:160 - Step5890, Loss: 3.730135440826416, Grad L2 Norm: 0.020545996725559235
2025-11-23 22:47:32.635 | INFO     | __main__:<module>:160 - Step5900, Loss: 3.6335556507110596, Grad L2 Norm: 0.02009722962975502
2025-11-23 22:47:34.634 | INFO     | __main__:<module>:160 - Step5910, Loss: 3.6843366622924805, Grad L2 Norm: 0.019932487979531288
2025-11-23 22:47:36.635 | INFO     | __main__:<module>:160 - Step5920, Loss: 3.7934200763702393, Grad L2 Norm: 0.021895963698625565
2025-11-23 22:47:38.632 | INFO     | __main__:<module>:160 - Step5930, Loss: 3.675433874130249, Grad L2 Norm: 0.020211057737469673
2025-11-23 22:47:40.632 | INFO     | __main__:<module>:160 - Step5940, Loss: 3.6796178817749023, Grad L2 Norm: 0.019289536401629448
2025-11-23 22:47:42.632 | INFO     | __main__:<module>:160 - Step5950, Loss: 3.6466469764709473, Grad L2 Norm: 0.02042381651699543
2025-11-23 22:47:44.629 | INFO     | __main__:<module>:160 - Step5960, Loss: 3.704230308532715, Grad L2 Norm: 0.020084038376808167
2025-11-23 22:47:46.625 | INFO     | __main__:<module>:160 - Step5970, Loss: 3.741692066192627, Grad L2 Norm: 0.01974279247224331
2025-11-23 22:47:48.631 | INFO     | __main__:<module>:160 - Step5980, Loss: 3.519878387451172, Grad L2 Norm: 0.02015523985028267
2025-11-23 22:47:50.629 | INFO     | __main__:<module>:160 - Step5990, Loss: 3.706475019454956, Grad L2 Norm: 0.02048586495220661
2025-11-23 22:47:52.631 | INFO     | __main__:<module>:160 - Step6000, Loss: 3.71278715133667, Grad L2 Norm: 0.021902460604906082
2025-11-23 22:47:52.631 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:47:53.899 | INFO     | __main__:<module>:181 - validation loss: 3.6891743779182433
2025-11-23 22:47:53.900 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_6000.pt
2025-11-23 22:47:55.520 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-23 22:47:57.486 | INFO     | __main__:<module>:160 - Step6010, Loss: 3.6456193923950195, Grad L2 Norm: 0.019774433225393295
2025-11-23 22:47:59.472 | INFO     | __main__:<module>:160 - Step6020, Loss: 3.612769365310669, Grad L2 Norm: 0.020124470815062523
2025-11-23 22:48:01.464 | INFO     | __main__:<module>:160 - Step6030, Loss: 3.6413002014160156, Grad L2 Norm: 0.01967000402510166
2025-11-23 22:48:03.466 | INFO     | __main__:<module>:160 - Step6040, Loss: 3.8419055938720703, Grad L2 Norm: 0.01957954838871956
2025-11-23 22:48:05.464 | INFO     | __main__:<module>:160 - Step6050, Loss: 3.712897539138794, Grad L2 Norm: 0.01892833039164543
2025-11-23 22:48:07.462 | INFO     | __main__:<module>:160 - Step6060, Loss: 3.6884443759918213, Grad L2 Norm: 0.02076689712703228
2025-11-23 22:48:09.451 | INFO     | __main__:<module>:160 - Step6070, Loss: 3.720979690551758, Grad L2 Norm: 0.02111368626356125
2025-11-23 22:48:11.443 | INFO     | __main__:<module>:160 - Step6080, Loss: 3.6999049186706543, Grad L2 Norm: 0.019438957795500755
2025-11-23 22:48:13.443 | INFO     | __main__:<module>:160 - Step6090, Loss: 3.6333847045898438, Grad L2 Norm: 0.01938335783779621
2025-11-23 22:48:15.442 | INFO     | __main__:<module>:160 - Step6100, Loss: 3.738396406173706, Grad L2 Norm: 0.02019580826163292
2025-11-23 22:48:17.441 | INFO     | __main__:<module>:160 - Step6110, Loss: 3.705740451812744, Grad L2 Norm: 0.021040912717580795
2025-11-23 22:48:19.443 | INFO     | __main__:<module>:160 - Step6120, Loss: 3.525780439376831, Grad L2 Norm: 0.019600877538323402
2025-11-23 22:48:21.437 | INFO     | __main__:<module>:160 - Step6130, Loss: 3.5266165733337402, Grad L2 Norm: 0.01815888099372387
2025-11-23 22:48:23.431 | INFO     | __main__:<module>:160 - Step6140, Loss: 3.492457866668701, Grad L2 Norm: 0.01912909746170044
2025-11-23 22:48:25.422 | INFO     | __main__:<module>:160 - Step6150, Loss: 3.6972038745880127, Grad L2 Norm: 0.019877510145306587
2025-11-23 22:48:27.420 | INFO     | __main__:<module>:160 - Step6160, Loss: 3.6046345233917236, Grad L2 Norm: 0.02000613696873188
2025-11-23 22:48:29.419 | INFO     | __main__:<module>:160 - Step6170, Loss: 3.715965747833252, Grad L2 Norm: 0.01938551850616932
2025-11-23 22:48:31.418 | INFO     | __main__:<module>:160 - Step6180, Loss: 3.7768216133117676, Grad L2 Norm: 0.021655095741152763
2025-11-23 22:48:33.417 | INFO     | __main__:<module>:160 - Step6190, Loss: 3.8253657817840576, Grad L2 Norm: 0.021469570696353912
2025-11-23 22:48:35.415 | INFO     | __main__:<module>:160 - Step6200, Loss: 3.7093493938446045, Grad L2 Norm: 0.02007102034986019
2025-11-23 22:48:37.416 | INFO     | __main__:<module>:160 - Step6210, Loss: 3.626983165740967, Grad L2 Norm: 0.02080073580145836
2025-11-23 22:48:39.404 | INFO     | __main__:<module>:160 - Step6220, Loss: 3.614100933074951, Grad L2 Norm: 0.018954230472445488
2025-11-23 22:48:41.395 | INFO     | __main__:<module>:160 - Step6230, Loss: 3.541072368621826, Grad L2 Norm: 0.01956111192703247
2025-11-23 22:48:43.393 | INFO     | __main__:<module>:160 - Step6240, Loss: 3.787506103515625, Grad L2 Norm: 0.021628253161907196
2025-11-23 22:48:45.394 | INFO     | __main__:<module>:160 - Step6250, Loss: 3.6086626052856445, Grad L2 Norm: 0.019359514117240906
2025-11-23 22:48:47.381 | INFO     | __main__:<module>:160 - Step6260, Loss: 3.80117130279541, Grad L2 Norm: 0.02165674790740013
2025-11-23 22:48:49.375 | INFO     | __main__:<module>:160 - Step6270, Loss: 3.6781005859375, Grad L2 Norm: 0.020844584330916405
2025-11-23 22:48:51.371 | INFO     | __main__:<module>:160 - Step6280, Loss: 3.6333248615264893, Grad L2 Norm: 0.02125157229602337
2025-11-23 22:48:53.367 | INFO     | __main__:<module>:160 - Step6290, Loss: 3.5371837615966797, Grad L2 Norm: 0.020431725308299065
2025-11-23 22:48:55.360 | INFO     | __main__:<module>:160 - Step6300, Loss: 3.684359073638916, Grad L2 Norm: 0.019927971065044403
2025-11-23 22:48:57.351 | INFO     | __main__:<module>:160 - Step6310, Loss: 3.651867389678955, Grad L2 Norm: 0.019944604486227036
2025-11-23 22:48:59.345 | INFO     | __main__:<module>:160 - Step6320, Loss: 3.758375883102417, Grad L2 Norm: 0.02012203261256218
2025-11-23 22:49:01.332 | INFO     | __main__:<module>:160 - Step6330, Loss: 3.7417149543762207, Grad L2 Norm: 0.0200036633759737
2025-11-23 22:49:03.327 | INFO     | __main__:<module>:160 - Step6340, Loss: 3.627129316329956, Grad L2 Norm: 0.021970607340335846
2025-11-23 22:49:05.323 | INFO     | __main__:<module>:160 - Step6350, Loss: 3.8612990379333496, Grad L2 Norm: 0.021730570122599602
2025-11-23 22:49:07.311 | INFO     | __main__:<module>:160 - Step6360, Loss: 3.7106239795684814, Grad L2 Norm: 0.02103211171925068
2025-11-23 22:49:09.304 | INFO     | __main__:<module>:160 - Step6370, Loss: 3.663708448410034, Grad L2 Norm: 0.021237993612885475
2025-11-23 22:49:11.293 | INFO     | __main__:<module>:160 - Step6380, Loss: 3.550373077392578, Grad L2 Norm: 0.020073240622878075
2025-11-23 22:49:13.284 | INFO     | __main__:<module>:160 - Step6390, Loss: 3.645897388458252, Grad L2 Norm: 0.02030918374657631
2025-11-23 22:49:15.282 | INFO     | __main__:<module>:160 - Step6400, Loss: 3.784700393676758, Grad L2 Norm: 0.021357014775276184
2025-11-23 22:49:15.283 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:49:16.547 | INFO     | __main__:<module>:181 - validation loss: 3.6614510297775267
2025-11-23 22:49:18.545 | INFO     | __main__:<module>:160 - Step6410, Loss: 3.560979127883911, Grad L2 Norm: 0.020224090665578842
2025-11-23 22:49:20.534 | INFO     | __main__:<module>:160 - Step6420, Loss: 3.6717417240142822, Grad L2 Norm: 0.02433609403669834
2025-11-23 22:49:22.522 | INFO     | __main__:<module>:160 - Step6430, Loss: 3.7137322425842285, Grad L2 Norm: 0.0217579435557127
2025-11-23 22:49:24.523 | INFO     | __main__:<module>:160 - Step6440, Loss: 3.5547924041748047, Grad L2 Norm: 0.01965458132326603
2025-11-23 22:49:26.513 | INFO     | __main__:<module>:160 - Step6450, Loss: 3.6098551750183105, Grad L2 Norm: 0.02066376805305481
2025-11-23 22:49:28.502 | INFO     | __main__:<module>:160 - Step6460, Loss: 3.706076145172119, Grad L2 Norm: 0.01996290683746338
2025-11-23 22:49:30.491 | INFO     | __main__:<module>:160 - Step6470, Loss: 3.5824637413024902, Grad L2 Norm: 0.018736323341727257
2025-11-23 22:49:32.482 | INFO     | __main__:<module>:160 - Step6480, Loss: 3.743191719055176, Grad L2 Norm: 0.02072364278137684
2025-11-23 22:49:34.479 | INFO     | __main__:<module>:160 - Step6490, Loss: 3.7690398693084717, Grad L2 Norm: 0.02430768683552742
2025-11-23 22:49:36.477 | INFO     | __main__:<module>:160 - Step6500, Loss: 3.7412285804748535, Grad L2 Norm: 0.020744595676660538
2025-11-23 22:49:38.468 | INFO     | __main__:<module>:160 - Step6510, Loss: 3.6218466758728027, Grad L2 Norm: 0.021036421880126
2025-11-23 22:49:40.457 | INFO     | __main__:<module>:160 - Step6520, Loss: 3.6543235778808594, Grad L2 Norm: 0.02010803483426571
2025-11-23 22:49:42.456 | INFO     | __main__:<module>:160 - Step6530, Loss: 3.5865964889526367, Grad L2 Norm: 0.019748931750655174
2025-11-23 22:49:44.452 | INFO     | __main__:<module>:160 - Step6540, Loss: 3.5384433269500732, Grad L2 Norm: 0.020341163501143456
2025-11-23 22:49:46.452 | INFO     | __main__:<module>:160 - Step6550, Loss: 3.61139178276062, Grad L2 Norm: 0.020346317440271378
2025-11-23 22:49:48.442 | INFO     | __main__:<module>:160 - Step6560, Loss: 3.6903982162475586, Grad L2 Norm: 0.020134083926677704
2025-11-23 22:49:50.433 | INFO     | __main__:<module>:160 - Step6570, Loss: 3.589106559753418, Grad L2 Norm: 0.020779697224497795
2025-11-23 22:49:52.422 | INFO     | __main__:<module>:160 - Step6580, Loss: 3.6671524047851562, Grad L2 Norm: 0.01882481388747692
2025-11-23 22:49:54.408 | INFO     | __main__:<module>:160 - Step6590, Loss: 3.677049160003662, Grad L2 Norm: 0.01970207691192627
2025-11-23 22:49:56.395 | INFO     | __main__:<module>:160 - Step6600, Loss: 3.7723541259765625, Grad L2 Norm: 0.020457515493035316
2025-11-23 22:49:58.382 | INFO     | __main__:<module>:160 - Step6610, Loss: 3.734149932861328, Grad L2 Norm: 0.019221317023038864
2025-11-23 22:50:00.373 | INFO     | __main__:<module>:160 - Step6620, Loss: 3.7119204998016357, Grad L2 Norm: 0.02036166563630104
2025-11-23 22:50:02.366 | INFO     | __main__:<module>:160 - Step6630, Loss: 3.696394920349121, Grad L2 Norm: 0.01955741085112095
2025-11-23 22:50:04.372 | INFO     | __main__:<module>:160 - Step6640, Loss: 3.644338846206665, Grad L2 Norm: 0.019949041306972504
2025-11-23 22:50:06.369 | INFO     | __main__:<module>:160 - Step6650, Loss: 3.626274585723877, Grad L2 Norm: 0.020302273333072662
2025-11-23 22:50:08.367 | INFO     | __main__:<module>:160 - Step6660, Loss: 3.520806312561035, Grad L2 Norm: 0.021670963615179062
2025-11-23 22:50:10.354 | INFO     | __main__:<module>:160 - Step6670, Loss: 3.7693874835968018, Grad L2 Norm: 0.023051241412758827
2025-11-23 22:50:12.342 | INFO     | __main__:<module>:160 - Step6680, Loss: 3.6538233757019043, Grad L2 Norm: 0.01896701008081436
2025-11-23 22:50:14.331 | INFO     | __main__:<module>:160 - Step6690, Loss: 3.6476261615753174, Grad L2 Norm: 0.019762467592954636
2025-11-23 22:50:16.319 | INFO     | __main__:<module>:160 - Step6700, Loss: 3.7751119136810303, Grad L2 Norm: 0.020026078447699547
2025-11-23 22:50:18.306 | INFO     | __main__:<module>:160 - Step6710, Loss: 3.709228754043579, Grad L2 Norm: 0.02251727320253849
2025-11-23 22:50:20.303 | INFO     | __main__:<module>:160 - Step6720, Loss: 3.6531543731689453, Grad L2 Norm: 0.019756456837058067
2025-11-23 22:50:22.288 | INFO     | __main__:<module>:160 - Step6730, Loss: 3.6824169158935547, Grad L2 Norm: 0.020729245617985725
2025-11-23 22:50:24.278 | INFO     | __main__:<module>:160 - Step6740, Loss: 3.7413887977600098, Grad L2 Norm: 0.020798958837985992
2025-11-23 22:50:26.265 | INFO     | __main__:<module>:160 - Step6750, Loss: 3.623324155807495, Grad L2 Norm: 0.020375216379761696
2025-11-23 22:50:28.261 | INFO     | __main__:<module>:160 - Step6760, Loss: 3.6725592613220215, Grad L2 Norm: 0.020196162164211273
2025-11-23 22:50:30.264 | INFO     | __main__:<module>:160 - Step6770, Loss: 3.71474552154541, Grad L2 Norm: 0.02074349671602249
2025-11-23 22:50:32.262 | INFO     | __main__:<module>:160 - Step6780, Loss: 3.651553153991699, Grad L2 Norm: 0.021008716896176338
2025-11-23 22:50:34.265 | INFO     | __main__:<module>:160 - Step6790, Loss: 3.7040786743164062, Grad L2 Norm: 0.02027183026075363
2025-11-23 22:50:36.263 | INFO     | __main__:<module>:160 - Step6800, Loss: 3.665816307067871, Grad L2 Norm: 0.020740151405334473
2025-11-23 22:50:36.263 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:50:37.532 | INFO     | __main__:<module>:181 - validation loss: 3.6562719464302065
2025-11-23 22:50:39.542 | INFO     | __main__:<module>:160 - Step6810, Loss: 3.8751001358032227, Grad L2 Norm: 0.022115439176559448
2025-11-23 22:50:41.541 | INFO     | __main__:<module>:160 - Step6820, Loss: 3.47558856010437, Grad L2 Norm: 0.0194082111120224
2025-11-23 22:50:43.541 | INFO     | __main__:<module>:160 - Step6830, Loss: 3.757960319519043, Grad L2 Norm: 0.021374419331550598
2025-11-23 22:50:45.540 | INFO     | __main__:<module>:160 - Step6840, Loss: 3.558054208755493, Grad L2 Norm: 0.01975894905626774
2025-11-23 22:50:47.539 | INFO     | __main__:<module>:160 - Step6850, Loss: 3.5993118286132812, Grad L2 Norm: 0.02204289473593235
2025-11-23 22:50:49.539 | INFO     | __main__:<module>:160 - Step6860, Loss: 3.554605484008789, Grad L2 Norm: 0.02064352110028267
2025-11-23 22:50:51.540 | INFO     | __main__:<module>:160 - Step6870, Loss: 3.7900331020355225, Grad L2 Norm: 0.025579633191227913
2025-11-23 22:50:53.538 | INFO     | __main__:<module>:160 - Step6880, Loss: 3.586203098297119, Grad L2 Norm: 0.020564770326018333
2025-11-23 22:50:55.538 | INFO     | __main__:<module>:160 - Step6890, Loss: 3.581791877746582, Grad L2 Norm: 0.018720565363764763
2025-11-23 22:50:57.536 | INFO     | __main__:<module>:160 - Step6900, Loss: 3.708458185195923, Grad L2 Norm: 0.02145179733633995
2025-11-23 22:50:59.537 | INFO     | __main__:<module>:160 - Step6910, Loss: 3.658766269683838, Grad L2 Norm: 0.020857304334640503
2025-11-23 22:51:01.535 | INFO     | __main__:<module>:160 - Step6920, Loss: 3.682677984237671, Grad L2 Norm: 0.02052571438252926
2025-11-23 22:51:03.534 | INFO     | __main__:<module>:160 - Step6930, Loss: 3.643338203430176, Grad L2 Norm: 0.01993977651000023
2025-11-23 22:51:05.533 | INFO     | __main__:<module>:160 - Step6940, Loss: 3.7295119762420654, Grad L2 Norm: 0.02141578495502472
2025-11-23 22:51:07.532 | INFO     | __main__:<module>:160 - Step6950, Loss: 3.730797290802002, Grad L2 Norm: 0.021908817812800407
2025-11-23 22:51:09.531 | INFO     | __main__:<module>:160 - Step6960, Loss: 3.662442207336426, Grad L2 Norm: 0.02052893489599228
2025-11-23 22:51:11.534 | INFO     | __main__:<module>:160 - Step6970, Loss: 3.7002546787261963, Grad L2 Norm: 0.021737288683652878
2025-11-23 22:51:13.533 | INFO     | __main__:<module>:160 - Step6980, Loss: 3.684457778930664, Grad L2 Norm: 0.01975410059094429
2025-11-23 22:51:15.531 | INFO     | __main__:<module>:160 - Step6990, Loss: 3.6548192501068115, Grad L2 Norm: 0.021227193996310234
2025-11-23 22:51:17.531 | INFO     | __main__:<module>:160 - Step7000, Loss: 3.652311325073242, Grad L2 Norm: 0.02223960869014263
2025-11-23 22:51:19.531 | INFO     | __main__:<module>:160 - Step7010, Loss: 3.65582537651062, Grad L2 Norm: 0.020723294466733932
2025-11-23 22:51:21.529 | INFO     | __main__:<module>:160 - Step7020, Loss: 3.7145912647247314, Grad L2 Norm: 0.020950783044099808
2025-11-23 22:51:23.528 | INFO     | __main__:<module>:160 - Step7030, Loss: 3.6487605571746826, Grad L2 Norm: 0.020001908764243126
2025-11-23 22:51:25.529 | INFO     | __main__:<module>:160 - Step7040, Loss: 3.7191696166992188, Grad L2 Norm: 0.02130846306681633
2025-11-23 22:51:27.527 | INFO     | __main__:<module>:160 - Step7050, Loss: 3.7232394218444824, Grad L2 Norm: 0.02003910019993782
2025-11-23 22:51:29.530 | INFO     | __main__:<module>:160 - Step7060, Loss: 3.658303737640381, Grad L2 Norm: 0.022743459790945053
2025-11-23 22:51:31.529 | INFO     | __main__:<module>:160 - Step7070, Loss: 3.5799641609191895, Grad L2 Norm: 0.021340806037187576
2025-11-23 22:51:33.526 | INFO     | __main__:<module>:160 - Step7080, Loss: 3.755929946899414, Grad L2 Norm: 0.020901665091514587
2025-11-23 22:51:35.526 | INFO     | __main__:<module>:160 - Step7090, Loss: 3.6221137046813965, Grad L2 Norm: 0.019318221136927605
2025-11-23 22:51:37.526 | INFO     | __main__:<module>:160 - Step7100, Loss: 3.557497024536133, Grad L2 Norm: 0.019534947350621223
2025-11-23 22:51:39.525 | INFO     | __main__:<module>:160 - Step7110, Loss: 3.5648159980773926, Grad L2 Norm: 0.02068333700299263
2025-11-23 22:51:41.525 | INFO     | __main__:<module>:160 - Step7120, Loss: 3.5950307846069336, Grad L2 Norm: 0.01934422180056572
2025-11-23 22:51:43.524 | INFO     | __main__:<module>:160 - Step7130, Loss: 3.670571804046631, Grad L2 Norm: 0.019961774349212646
2025-11-23 22:51:45.522 | INFO     | __main__:<module>:160 - Step7140, Loss: 3.8457260131835938, Grad L2 Norm: 0.02118753455579281
2025-11-23 22:51:47.524 | INFO     | __main__:<module>:160 - Step7150, Loss: 3.534071445465088, Grad L2 Norm: 0.02034452185034752
2025-11-23 22:51:49.523 | INFO     | __main__:<module>:160 - Step7160, Loss: 3.598625659942627, Grad L2 Norm: 0.021449871361255646
2025-11-23 22:51:51.524 | INFO     | __main__:<module>:160 - Step7170, Loss: 3.6674766540527344, Grad L2 Norm: 0.02171161025762558
2025-11-23 22:51:53.521 | INFO     | __main__:<module>:160 - Step7180, Loss: 3.687699794769287, Grad L2 Norm: 0.01989266648888588
2025-11-23 22:51:55.520 | INFO     | __main__:<module>:160 - Step7190, Loss: 3.567507028579712, Grad L2 Norm: 0.019076725468039513
2025-11-23 22:51:57.520 | INFO     | __main__:<module>:160 - Step7200, Loss: 3.7060980796813965, Grad L2 Norm: 0.019235821440815926
2025-11-23 22:51:57.521 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:51:58.793 | INFO     | __main__:<module>:181 - validation loss: 3.642743980884552
2025-11-23 22:52:00.797 | INFO     | __main__:<module>:160 - Step7210, Loss: 3.635392904281616, Grad L2 Norm: 0.020158294588327408
2025-11-23 22:52:02.792 | INFO     | __main__:<module>:160 - Step7220, Loss: 3.6588048934936523, Grad L2 Norm: 0.02056666649878025
2025-11-23 22:52:04.781 | INFO     | __main__:<module>:160 - Step7230, Loss: 3.5948057174682617, Grad L2 Norm: 0.020629748702049255
2025-11-23 22:52:06.776 | INFO     | __main__:<module>:160 - Step7240, Loss: 3.7150323390960693, Grad L2 Norm: 0.02137650176882744
2025-11-23 22:52:08.773 | INFO     | __main__:<module>:160 - Step7250, Loss: 3.6896443367004395, Grad L2 Norm: 0.018716881051659584
2025-11-23 22:52:10.768 | INFO     | __main__:<module>:160 - Step7260, Loss: 3.6140644550323486, Grad L2 Norm: 0.020147090777754784
2025-11-23 22:52:12.759 | INFO     | __main__:<module>:160 - Step7270, Loss: 3.6455366611480713, Grad L2 Norm: 0.02038073167204857
2025-11-23 22:52:14.754 | INFO     | __main__:<module>:160 - Step7280, Loss: 3.638289451599121, Grad L2 Norm: 0.02056221105158329
2025-11-23 22:52:16.753 | INFO     | __main__:<module>:160 - Step7290, Loss: 3.6171958446502686, Grad L2 Norm: 0.02182254008948803
2025-11-23 22:52:18.752 | INFO     | __main__:<module>:160 - Step7300, Loss: 3.767892360687256, Grad L2 Norm: 0.020806221291422844
2025-11-23 22:52:20.755 | INFO     | __main__:<module>:160 - Step7310, Loss: 3.5409398078918457, Grad L2 Norm: 0.02086673304438591
2025-11-23 22:52:22.751 | INFO     | __main__:<module>:160 - Step7320, Loss: 3.709786891937256, Grad L2 Norm: 0.02079077810049057
2025-11-23 22:52:24.752 | INFO     | __main__:<module>:160 - Step7330, Loss: 3.4789812564849854, Grad L2 Norm: 0.020194627344608307
2025-11-23 22:52:26.752 | INFO     | __main__:<module>:160 - Step7340, Loss: 3.5842044353485107, Grad L2 Norm: 0.020177654922008514
2025-11-23 22:52:28.751 | INFO     | __main__:<module>:160 - Step7350, Loss: 3.6230154037475586, Grad L2 Norm: 0.02013077214360237
2025-11-23 22:52:30.751 | INFO     | __main__:<module>:160 - Step7360, Loss: 3.648756504058838, Grad L2 Norm: 0.020784970372915268
2025-11-23 22:52:32.754 | INFO     | __main__:<module>:160 - Step7370, Loss: 3.554141044616699, Grad L2 Norm: 0.020074153319001198
2025-11-23 22:52:34.750 | INFO     | __main__:<module>:160 - Step7380, Loss: 3.657160758972168, Grad L2 Norm: 0.02057301625609398
2025-11-23 22:52:36.750 | INFO     | __main__:<module>:160 - Step7390, Loss: 3.8850817680358887, Grad L2 Norm: 0.020995022729039192
2025-11-23 22:52:38.749 | INFO     | __main__:<module>:160 - Step7400, Loss: 3.7013449668884277, Grad L2 Norm: 0.02156110480427742
2025-11-23 22:52:40.749 | INFO     | __main__:<module>:160 - Step7410, Loss: 3.7508485317230225, Grad L2 Norm: 0.02072477713227272
2025-11-23 22:52:42.747 | INFO     | __main__:<module>:160 - Step7420, Loss: 3.5363399982452393, Grad L2 Norm: 0.019421817734837532
2025-11-23 22:52:44.746 | INFO     | __main__:<module>:160 - Step7430, Loss: 3.600559711456299, Grad L2 Norm: 0.022398047149181366
2025-11-23 22:52:46.749 | INFO     | __main__:<module>:160 - Step7440, Loss: 3.5526351928710938, Grad L2 Norm: 0.019886303693056107
2025-11-23 22:52:48.749 | INFO     | __main__:<module>:160 - Step7450, Loss: 3.692229747772217, Grad L2 Norm: 0.02036641165614128
2025-11-23 22:52:50.747 | INFO     | __main__:<module>:160 - Step7460, Loss: 3.6586813926696777, Grad L2 Norm: 0.021385014057159424
2025-11-23 22:52:52.746 | INFO     | __main__:<module>:160 - Step7470, Loss: 3.7328009605407715, Grad L2 Norm: 0.021989982575178146
2025-11-23 22:52:54.746 | INFO     | __main__:<module>:160 - Step7480, Loss: 3.426378011703491, Grad L2 Norm: 0.021781867370009422
2025-11-23 22:52:56.748 | INFO     | __main__:<module>:160 - Step7490, Loss: 3.748696804046631, Grad L2 Norm: 0.01997937075793743
2025-11-23 22:52:58.745 | INFO     | __main__:<module>:160 - Step7500, Loss: 3.7184078693389893, Grad L2 Norm: 0.020721683278679848
2025-11-23 22:53:00.743 | INFO     | __main__:<module>:160 - Step7510, Loss: 3.6030657291412354, Grad L2 Norm: 0.023104563355445862
2025-11-23 22:53:02.744 | INFO     | __main__:<module>:160 - Step7520, Loss: 3.5997517108917236, Grad L2 Norm: 0.019602708518505096
2025-11-23 22:53:04.742 | INFO     | __main__:<module>:160 - Step7530, Loss: 3.7315902709960938, Grad L2 Norm: 0.021940430626273155
2025-11-23 22:53:06.740 | INFO     | __main__:<module>:160 - Step7540, Loss: 3.4732160568237305, Grad L2 Norm: 0.019400523975491524
2025-11-23 22:53:08.740 | INFO     | __main__:<module>:160 - Step7550, Loss: 3.6125826835632324, Grad L2 Norm: 0.023221619427204132
2025-11-23 22:53:10.743 | INFO     | __main__:<module>:160 - Step7560, Loss: 3.6388845443725586, Grad L2 Norm: 0.020656587556004524
2025-11-23 22:53:12.742 | INFO     | __main__:<module>:160 - Step7570, Loss: 3.5677051544189453, Grad L2 Norm: 0.02157038450241089
2025-11-23 22:53:14.739 | INFO     | __main__:<module>:160 - Step7580, Loss: 3.7415590286254883, Grad L2 Norm: 0.020252946764230728
2025-11-23 22:53:16.737 | INFO     | __main__:<module>:160 - Step7590, Loss: 3.554724931716919, Grad L2 Norm: 0.019593410193920135
2025-11-23 22:53:18.736 | INFO     | __main__:<module>:160 - Step7600, Loss: 3.814633369445801, Grad L2 Norm: 0.023510105907917023
2025-11-23 22:53:18.737 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:53:20.007 | INFO     | __main__:<module>:181 - validation loss: 3.6517418384552003
2025-11-23 22:53:22.014 | INFO     | __main__:<module>:160 - Step7610, Loss: 3.5203728675842285, Grad L2 Norm: 0.019610105082392693
2025-11-23 22:53:24.015 | INFO     | __main__:<module>:160 - Step7620, Loss: 3.580472469329834, Grad L2 Norm: 0.02150869555771351
2025-11-23 22:53:26.013 | INFO     | __main__:<module>:160 - Step7630, Loss: 3.520045280456543, Grad L2 Norm: 0.019536206498742104
2025-11-23 22:53:28.013 | INFO     | __main__:<module>:160 - Step7640, Loss: 3.511889934539795, Grad L2 Norm: 0.02296041138470173
2025-11-23 22:53:30.012 | INFO     | __main__:<module>:160 - Step7650, Loss: 3.617154598236084, Grad L2 Norm: 0.020397312939167023
2025-11-23 22:53:32.014 | INFO     | __main__:<module>:160 - Step7660, Loss: 3.5836949348449707, Grad L2 Norm: 0.01977955736219883
2025-11-23 22:53:34.013 | INFO     | __main__:<module>:160 - Step7670, Loss: 3.6979289054870605, Grad L2 Norm: 0.02122475765645504
2025-11-23 22:53:36.013 | INFO     | __main__:<module>:160 - Step7680, Loss: 3.7029011249542236, Grad L2 Norm: 0.020899232476949692
2025-11-23 22:53:38.012 | INFO     | __main__:<module>:160 - Step7690, Loss: 3.53737211227417, Grad L2 Norm: 0.019149960950016975
2025-11-23 22:53:40.011 | INFO     | __main__:<module>:160 - Step7700, Loss: 3.567953109741211, Grad L2 Norm: 0.01988271251320839
2025-11-23 22:53:42.011 | INFO     | __main__:<module>:160 - Step7710, Loss: 3.784945487976074, Grad L2 Norm: 0.021482009440660477
2025-11-23 22:53:44.010 | INFO     | __main__:<module>:160 - Step7720, Loss: 3.752216339111328, Grad L2 Norm: 0.023288266733288765
2025-11-23 22:53:46.008 | INFO     | __main__:<module>:160 - Step7730, Loss: 3.7233071327209473, Grad L2 Norm: 0.02100876346230507
2025-11-23 22:53:48.011 | INFO     | __main__:<module>:160 - Step7740, Loss: 3.665980339050293, Grad L2 Norm: 0.02300860732793808
2025-11-23 22:53:50.010 | INFO     | __main__:<module>:160 - Step7750, Loss: 3.6887664794921875, Grad L2 Norm: 0.020422857254743576
2025-11-23 22:53:52.008 | INFO     | __main__:<module>:160 - Step7760, Loss: 3.503986358642578, Grad L2 Norm: 0.020755240693688393
2025-11-23 22:53:54.006 | INFO     | __main__:<module>:160 - Step7770, Loss: 3.620347499847412, Grad L2 Norm: 0.020632177591323853
2025-11-23 22:53:56.004 | INFO     | __main__:<module>:160 - Step7780, Loss: 3.4897212982177734, Grad L2 Norm: 0.019331859424710274
2025-11-23 22:53:58.001 | INFO     | __main__:<module>:160 - Step7790, Loss: 3.602353096008301, Grad L2 Norm: 0.022498201578855515
2025-11-23 22:54:00.000 | INFO     | __main__:<module>:160 - Step7800, Loss: 3.6165153980255127, Grad L2 Norm: 0.02073679305613041
2025-11-23 22:54:02.002 | INFO     | __main__:<module>:160 - Step7810, Loss: 3.686215877532959, Grad L2 Norm: 0.021675754338502884
2025-11-23 22:54:04.002 | INFO     | __main__:<module>:160 - Step7820, Loss: 3.5172483921051025, Grad L2 Norm: 0.021110765635967255
2025-11-23 22:54:06.005 | INFO     | __main__:<module>:160 - Step7830, Loss: 3.6785922050476074, Grad L2 Norm: 0.020694131031632423
2025-11-23 22:54:08.004 | INFO     | __main__:<module>:160 - Step7840, Loss: 3.5953798294067383, Grad L2 Norm: 0.02039932645857334
2025-11-23 22:54:10.006 | INFO     | __main__:<module>:160 - Step7850, Loss: 3.710514545440674, Grad L2 Norm: 0.021994927898049355
2025-11-23 22:54:12.003 | INFO     | __main__:<module>:160 - Step7860, Loss: 3.647976875305176, Grad L2 Norm: 0.021918967366218567
2025-11-23 22:54:13.999 | INFO     | __main__:<module>:160 - Step7870, Loss: 3.6813247203826904, Grad L2 Norm: 0.021601159125566483
2025-11-23 22:54:16.001 | INFO     | __main__:<module>:160 - Step7880, Loss: 3.5774550437927246, Grad L2 Norm: 0.022733613848686218
2025-11-23 22:54:18.003 | INFO     | __main__:<module>:160 - Step7890, Loss: 3.5597028732299805, Grad L2 Norm: 0.020652934908866882
2025-11-23 22:54:20.001 | INFO     | __main__:<module>:160 - Step7900, Loss: 3.5387237071990967, Grad L2 Norm: 0.02017914690077305
2025-11-23 22:54:21.999 | INFO     | __main__:<module>:160 - Step7910, Loss: 3.6163852214813232, Grad L2 Norm: 0.02005462534725666
2025-11-23 22:54:23.997 | INFO     | __main__:<module>:160 - Step7920, Loss: 3.7278075218200684, Grad L2 Norm: 0.022100629284977913
2025-11-23 22:54:25.996 | INFO     | __main__:<module>:160 - Step7930, Loss: 3.654268741607666, Grad L2 Norm: 0.020541109144687653
2025-11-23 22:54:27.997 | INFO     | __main__:<module>:160 - Step7940, Loss: 3.640678882598877, Grad L2 Norm: 0.02056334912776947
2025-11-23 22:54:29.994 | INFO     | __main__:<module>:160 - Step7950, Loss: 3.574716329574585, Grad L2 Norm: 0.023742709308862686
2025-11-23 22:54:31.995 | INFO     | __main__:<module>:160 - Step7960, Loss: 3.664149045944214, Grad L2 Norm: 0.021260106936097145
2025-11-23 22:54:33.994 | INFO     | __main__:<module>:160 - Step7970, Loss: 3.5955023765563965, Grad L2 Norm: 0.022544655948877335
2025-11-23 22:54:35.997 | INFO     | __main__:<module>:160 - Step7980, Loss: 3.534158229827881, Grad L2 Norm: 0.01996564120054245
2025-11-23 22:54:37.995 | INFO     | __main__:<module>:160 - Step7990, Loss: 3.668062925338745, Grad L2 Norm: 0.019929679110646248
2025-11-23 22:54:39.992 | INFO     | __main__:<module>:160 - Step8000, Loss: 3.6169116497039795, Grad L2 Norm: 0.019569791853427887
2025-11-23 22:54:39.993 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:54:41.260 | INFO     | __main__:<module>:181 - validation loss: 3.6328755378723145
2025-11-23 22:54:41.261 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_8000.pt
2025-11-23 22:54:42.926 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-23 22:54:44.899 | INFO     | __main__:<module>:160 - Step8010, Loss: 3.669800281524658, Grad L2 Norm: 0.021078089252114296
2025-11-23 22:54:46.889 | INFO     | __main__:<module>:160 - Step8020, Loss: 3.6449666023254395, Grad L2 Norm: 0.019843723624944687
2025-11-23 22:54:48.887 | INFO     | __main__:<module>:160 - Step8030, Loss: 3.763789176940918, Grad L2 Norm: 0.021003641188144684
2025-11-23 22:54:50.878 | INFO     | __main__:<module>:160 - Step8040, Loss: 3.5880002975463867, Grad L2 Norm: 0.0198587104678154
2025-11-23 22:54:52.867 | INFO     | __main__:<module>:160 - Step8050, Loss: 3.77236270904541, Grad L2 Norm: 0.02194562368094921
2025-11-23 22:54:54.859 | INFO     | __main__:<module>:160 - Step8060, Loss: 3.6486706733703613, Grad L2 Norm: 0.021386250853538513
2025-11-23 22:54:56.850 | INFO     | __main__:<module>:160 - Step8070, Loss: 3.5967001914978027, Grad L2 Norm: 0.020243441686034203
2025-11-23 22:54:58.845 | INFO     | __main__:<module>:160 - Step8080, Loss: 3.5539040565490723, Grad L2 Norm: 0.021832047030329704
2025-11-23 22:55:00.844 | INFO     | __main__:<module>:160 - Step8090, Loss: 3.6755099296569824, Grad L2 Norm: 0.02142624370753765
2025-11-23 22:55:02.833 | INFO     | __main__:<module>:160 - Step8100, Loss: 3.5749034881591797, Grad L2 Norm: 0.020405858755111694
2025-11-23 22:55:04.826 | INFO     | __main__:<module>:160 - Step8110, Loss: 3.755056858062744, Grad L2 Norm: 0.02100382000207901
2025-11-23 22:55:06.821 | INFO     | __main__:<module>:160 - Step8120, Loss: 3.5069220066070557, Grad L2 Norm: 0.019313933327794075
2025-11-23 22:55:08.807 | INFO     | __main__:<module>:160 - Step8130, Loss: 3.504887580871582, Grad L2 Norm: 0.020360799506306648
2025-11-23 22:55:10.802 | INFO     | __main__:<module>:160 - Step8140, Loss: 3.5843183994293213, Grad L2 Norm: 0.020313778892159462
2025-11-23 22:55:12.801 | INFO     | __main__:<module>:160 - Step8150, Loss: 3.673286199569702, Grad L2 Norm: 0.020925011485815048
2025-11-23 22:55:14.801 | INFO     | __main__:<module>:160 - Step8160, Loss: 3.6493277549743652, Grad L2 Norm: 0.020814429968595505
2025-11-23 22:55:16.792 | INFO     | __main__:<module>:160 - Step8170, Loss: 3.661996603012085, Grad L2 Norm: 0.02277260646224022
2025-11-23 22:55:18.783 | INFO     | __main__:<module>:160 - Step8180, Loss: 3.5648579597473145, Grad L2 Norm: 0.018525518476963043
2025-11-23 22:55:20.780 | INFO     | __main__:<module>:160 - Step8190, Loss: 3.4608302116394043, Grad L2 Norm: 0.019658323377370834
2025-11-23 22:55:22.781 | INFO     | __main__:<module>:160 - Step8200, Loss: 3.7724220752716064, Grad L2 Norm: 0.020648472011089325
2025-11-23 22:55:24.776 | INFO     | __main__:<module>:160 - Step8210, Loss: 3.768810272216797, Grad L2 Norm: 0.023921124637126923
2025-11-23 22:55:26.778 | INFO     | __main__:<module>:160 - Step8220, Loss: 3.465487480163574, Grad L2 Norm: 0.02087930217385292
2025-11-23 22:55:28.767 | INFO     | __main__:<module>:160 - Step8230, Loss: 3.9100818634033203, Grad L2 Norm: 0.02370969019830227
2025-11-23 22:55:30.758 | INFO     | __main__:<module>:160 - Step8240, Loss: 3.5879621505737305, Grad L2 Norm: 0.02280971221625805
2025-11-23 22:55:32.755 | INFO     | __main__:<module>:160 - Step8250, Loss: 3.563422918319702, Grad L2 Norm: 0.021923385560512543
2025-11-23 22:55:34.756 | INFO     | __main__:<module>:160 - Step8260, Loss: 3.6286861896514893, Grad L2 Norm: 0.02046087384223938
2025-11-23 22:55:36.753 | INFO     | __main__:<module>:160 - Step8270, Loss: 3.622166156768799, Grad L2 Norm: 0.02107207477092743
2025-11-23 22:55:38.747 | INFO     | __main__:<module>:160 - Step8280, Loss: 3.603037118911743, Grad L2 Norm: 0.02003166824579239
2025-11-23 22:55:40.735 | INFO     | __main__:<module>:160 - Step8290, Loss: 3.6944961547851562, Grad L2 Norm: 0.019593147560954094
2025-11-23 22:55:42.726 | INFO     | __main__:<module>:160 - Step8300, Loss: 3.5234475135803223, Grad L2 Norm: 0.022447191178798676
2025-11-23 22:55:44.734 | INFO     | __main__:<module>:160 - Step8310, Loss: 3.639080047607422, Grad L2 Norm: 0.01949356123805046
2025-11-23 22:55:46.727 | INFO     | __main__:<module>:160 - Step8320, Loss: 3.6609482765197754, Grad L2 Norm: 0.019275106489658356
2025-11-23 22:55:48.714 | INFO     | __main__:<module>:160 - Step8330, Loss: 3.7665610313415527, Grad L2 Norm: 0.022185083478689194
2025-11-23 22:55:50.709 | INFO     | __main__:<module>:160 - Step8340, Loss: 3.745893955230713, Grad L2 Norm: 0.020835600793361664
2025-11-23 22:55:52.704 | INFO     | __main__:<module>:160 - Step8350, Loss: 3.5918688774108887, Grad L2 Norm: 0.01986468955874443
2025-11-23 22:55:54.693 | INFO     | __main__:<module>:160 - Step8360, Loss: 3.5952088832855225, Grad L2 Norm: 0.021066443994641304
2025-11-23 22:55:56.688 | INFO     | __main__:<module>:160 - Step8370, Loss: 3.665438175201416, Grad L2 Norm: 0.02010198123753071
2025-11-23 22:55:58.676 | INFO     | __main__:<module>:160 - Step8380, Loss: 3.642573833465576, Grad L2 Norm: 0.021542638540267944
2025-11-23 22:56:00.666 | INFO     | __main__:<module>:160 - Step8390, Loss: 3.695816993713379, Grad L2 Norm: 0.021568870171904564
2025-11-23 22:56:02.653 | INFO     | __main__:<module>:160 - Step8400, Loss: 3.750894784927368, Grad L2 Norm: 0.02090146392583847
2025-11-23 22:56:02.654 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:56:03.918 | INFO     | __main__:<module>:181 - validation loss: 3.6302194118499758
2025-11-23 22:56:05.924 | INFO     | __main__:<module>:160 - Step8410, Loss: 3.641535758972168, Grad L2 Norm: 0.021819492802023888
2025-11-23 22:56:07.916 | INFO     | __main__:<module>:160 - Step8420, Loss: 3.561894178390503, Grad L2 Norm: 0.021021438762545586
2025-11-23 22:56:09.925 | INFO     | __main__:<module>:160 - Step8430, Loss: 3.582397699356079, Grad L2 Norm: 0.021766407415270805
2025-11-23 22:56:11.921 | INFO     | __main__:<module>:160 - Step8440, Loss: 3.62896466255188, Grad L2 Norm: 0.02070406824350357
2025-11-23 22:56:13.913 | INFO     | __main__:<module>:160 - Step8450, Loss: 3.653088331222534, Grad L2 Norm: 0.01924237236380577
2025-11-23 22:56:15.907 | INFO     | __main__:<module>:160 - Step8460, Loss: 3.65509295463562, Grad L2 Norm: 0.020327534526586533
2025-11-23 22:56:17.902 | INFO     | __main__:<module>:160 - Step8470, Loss: 3.5930168628692627, Grad L2 Norm: 0.020496312528848648
2025-11-23 22:56:19.901 | INFO     | __main__:<module>:160 - Step8480, Loss: 3.692744493484497, Grad L2 Norm: 0.021678421646356583
2025-11-23 22:56:21.894 | INFO     | __main__:<module>:160 - Step8490, Loss: 3.7287328243255615, Grad L2 Norm: 0.02018909528851509
2025-11-23 22:56:23.886 | INFO     | __main__:<module>:160 - Step8500, Loss: 3.5515825748443604, Grad L2 Norm: 0.019789444282650948
2025-11-23 22:56:25.882 | INFO     | __main__:<module>:160 - Step8510, Loss: 3.7104079723358154, Grad L2 Norm: 0.020749224349856377
2025-11-23 22:56:27.879 | INFO     | __main__:<module>:160 - Step8520, Loss: 3.6762540340423584, Grad L2 Norm: 0.020675694569945335
2025-11-23 22:56:29.880 | INFO     | __main__:<module>:160 - Step8530, Loss: 3.664933204650879, Grad L2 Norm: 0.02205055020749569
2025-11-23 22:56:31.877 | INFO     | __main__:<module>:160 - Step8540, Loss: 3.523139238357544, Grad L2 Norm: 0.02124941162765026
2025-11-23 22:56:33.878 | INFO     | __main__:<module>:160 - Step8550, Loss: 3.7761623859405518, Grad L2 Norm: 0.021756548434495926
2025-11-23 22:56:35.875 | INFO     | __main__:<module>:160 - Step8560, Loss: 3.5620830059051514, Grad L2 Norm: 0.02005668915808201
2025-11-23 22:56:37.876 | INFO     | __main__:<module>:160 - Step8570, Loss: 3.6142444610595703, Grad L2 Norm: 0.02195991948246956
2025-11-23 22:56:39.875 | INFO     | __main__:<module>:160 - Step8580, Loss: 3.635517120361328, Grad L2 Norm: 0.019892297685146332
2025-11-23 22:56:41.872 | INFO     | __main__:<module>:160 - Step8590, Loss: 3.576211929321289, Grad L2 Norm: 0.019746093079447746
2025-11-23 22:56:43.872 | INFO     | __main__:<module>:160 - Step8600, Loss: 3.5967578887939453, Grad L2 Norm: 0.020794417709112167
2025-11-23 22:56:45.872 | INFO     | __main__:<module>:160 - Step8610, Loss: 3.7217416763305664, Grad L2 Norm: 0.020756442099809647
2025-11-23 22:56:47.869 | INFO     | __main__:<module>:160 - Step8620, Loss: 3.6513619422912598, Grad L2 Norm: 0.022460948675870895
2025-11-23 22:56:49.862 | INFO     | __main__:<module>:160 - Step8630, Loss: 3.799271821975708, Grad L2 Norm: 0.021514026448130608
2025-11-23 22:56:51.851 | INFO     | __main__:<module>:160 - Step8640, Loss: 3.666947364807129, Grad L2 Norm: 0.021690919995307922
2025-11-23 22:56:53.850 | INFO     | __main__:<module>:160 - Step8650, Loss: 3.664923667907715, Grad L2 Norm: 0.020981041714549065
2025-11-23 22:56:55.846 | INFO     | __main__:<module>:160 - Step8660, Loss: 3.6166248321533203, Grad L2 Norm: 0.020344512537121773
2025-11-23 22:56:57.848 | INFO     | __main__:<module>:160 - Step8670, Loss: 3.697845935821533, Grad L2 Norm: 0.021642988547682762
2025-11-23 22:56:59.847 | INFO     | __main__:<module>:160 - Step8680, Loss: 3.9024100303649902, Grad L2 Norm: 0.025183919817209244
2025-11-23 22:57:01.847 | INFO     | __main__:<module>:160 - Step8690, Loss: 3.7742652893066406, Grad L2 Norm: 0.02157754637300968
2025-11-23 22:57:03.847 | INFO     | __main__:<module>:160 - Step8700, Loss: 3.5131072998046875, Grad L2 Norm: 0.02075226977467537
2025-11-23 22:57:05.846 | INFO     | __main__:<module>:160 - Step8710, Loss: 3.6164281368255615, Grad L2 Norm: 0.020776936784386635
2025-11-23 22:57:07.846 | INFO     | __main__:<module>:160 - Step8720, Loss: 3.5578436851501465, Grad L2 Norm: 0.02091139554977417
2025-11-23 22:57:09.844 | INFO     | __main__:<module>:160 - Step8730, Loss: 3.538747787475586, Grad L2 Norm: 0.02042492851614952
2025-11-23 22:57:11.844 | INFO     | __main__:<module>:160 - Step8740, Loss: 3.5790152549743652, Grad L2 Norm: 0.020595887675881386
2025-11-23 22:57:13.846 | INFO     | __main__:<module>:160 - Step8750, Loss: 3.7151479721069336, Grad L2 Norm: 0.02217310480773449
2025-11-23 22:57:15.842 | INFO     | __main__:<module>:160 - Step8760, Loss: 3.6132731437683105, Grad L2 Norm: 0.019834402948617935
2025-11-23 22:57:17.841 | INFO     | __main__:<module>:160 - Step8770, Loss: 3.6382932662963867, Grad L2 Norm: 0.022094154730439186
2025-11-23 22:57:19.841 | INFO     | __main__:<module>:160 - Step8780, Loss: 3.516660690307617, Grad L2 Norm: 0.020207110792398453
2025-11-23 22:57:21.842 | INFO     | __main__:<module>:160 - Step8790, Loss: 3.7111830711364746, Grad L2 Norm: 0.020833857357501984
2025-11-23 22:57:23.840 | INFO     | __main__:<module>:160 - Step8800, Loss: 3.8212695121765137, Grad L2 Norm: 0.024364056065678596
2025-11-23 22:57:23.841 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:57:25.109 | INFO     | __main__:<module>:181 - validation loss: 3.6363696336746214
2025-11-23 22:57:27.117 | INFO     | __main__:<module>:160 - Step8810, Loss: 3.557075262069702, Grad L2 Norm: 0.02014024183154106
2025-11-23 22:57:29.118 | INFO     | __main__:<module>:160 - Step8820, Loss: 3.685119390487671, Grad L2 Norm: 0.019007252529263496
2025-11-23 22:57:31.118 | INFO     | __main__:<module>:160 - Step8830, Loss: 3.6827030181884766, Grad L2 Norm: 0.02258988283574581
2025-11-23 22:57:33.116 | INFO     | __main__:<module>:160 - Step8840, Loss: 3.5588438510894775, Grad L2 Norm: 0.020982075482606888
2025-11-23 22:57:35.115 | INFO     | __main__:<module>:160 - Step8850, Loss: 3.604978561401367, Grad L2 Norm: 0.020204931497573853
2025-11-23 22:57:37.118 | INFO     | __main__:<module>:160 - Step8860, Loss: 3.577019691467285, Grad L2 Norm: 0.01964341662824154
2025-11-23 22:57:39.114 | INFO     | __main__:<module>:160 - Step8870, Loss: 3.6374268531799316, Grad L2 Norm: 0.021870259195566177
2025-11-23 22:57:41.112 | INFO     | __main__:<module>:160 - Step8880, Loss: 3.7400307655334473, Grad L2 Norm: 0.02337723597884178
2025-11-23 22:57:43.113 | INFO     | __main__:<module>:160 - Step8890, Loss: 3.5806498527526855, Grad L2 Norm: 0.019749222323298454
2025-11-23 22:57:45.115 | INFO     | __main__:<module>:160 - Step8900, Loss: 3.585660696029663, Grad L2 Norm: 0.021311383694410324
2025-11-23 22:57:47.113 | INFO     | __main__:<module>:160 - Step8910, Loss: 3.7475533485412598, Grad L2 Norm: 0.022435462102293968
2025-11-23 22:57:49.111 | INFO     | __main__:<module>:160 - Step8920, Loss: 3.633932113647461, Grad L2 Norm: 0.02011200785636902
2025-11-23 22:57:51.109 | INFO     | __main__:<module>:160 - Step8930, Loss: 3.693608283996582, Grad L2 Norm: 0.021027958020567894
2025-11-23 22:57:53.114 | INFO     | __main__:<module>:160 - Step8940, Loss: 3.649693489074707, Grad L2 Norm: 0.024163618683815002
2025-11-23 22:57:55.111 | INFO     | __main__:<module>:160 - Step8950, Loss: 3.6578872203826904, Grad L2 Norm: 0.020345991477370262
2025-11-23 22:57:57.108 | INFO     | __main__:<module>:160 - Step8960, Loss: 3.5110507011413574, Grad L2 Norm: 0.020473988726735115
2025-11-23 22:57:59.106 | INFO     | __main__:<module>:160 - Step8970, Loss: 3.714606761932373, Grad L2 Norm: 0.021714387461543083
2025-11-23 22:58:01.102 | INFO     | __main__:<module>:160 - Step8980, Loss: 3.6425368785858154, Grad L2 Norm: 0.020195594057440758
2025-11-23 22:58:03.091 | INFO     | __main__:<module>:160 - Step8990, Loss: 3.739539623260498, Grad L2 Norm: 0.021890908479690552
2025-11-23 22:58:05.084 | INFO     | __main__:<module>:160 - Step9000, Loss: 3.8154501914978027, Grad L2 Norm: 0.02219642698764801
2025-11-23 22:58:07.087 | INFO     | __main__:<module>:160 - Step9010, Loss: 3.7200827598571777, Grad L2 Norm: 0.0217188261449337
2025-11-23 22:58:09.087 | INFO     | __main__:<module>:160 - Step9020, Loss: 3.8919007778167725, Grad L2 Norm: 0.021681617945432663
2025-11-23 22:58:11.080 | INFO     | __main__:<module>:160 - Step9030, Loss: 3.8376598358154297, Grad L2 Norm: 0.02218416891992092
2025-11-23 22:58:13.068 | INFO     | __main__:<module>:160 - Step9040, Loss: 3.568905830383301, Grad L2 Norm: 0.022232649847865105
2025-11-23 22:58:15.062 | INFO     | __main__:<module>:160 - Step9050, Loss: 3.778245210647583, Grad L2 Norm: 0.021817894652485847
2025-11-23 22:58:17.059 | INFO     | __main__:<module>:160 - Step9060, Loss: 3.686063766479492, Grad L2 Norm: 0.01956738345324993
2025-11-23 22:58:19.058 | INFO     | __main__:<module>:160 - Step9070, Loss: 3.638546943664551, Grad L2 Norm: 0.020390834659337997
2025-11-23 22:58:21.048 | INFO     | __main__:<module>:160 - Step9080, Loss: 3.6692328453063965, Grad L2 Norm: 0.021083150058984756
2025-11-23 22:58:23.041 | INFO     | __main__:<module>:160 - Step9090, Loss: 3.584296226501465, Grad L2 Norm: 0.02035212516784668
2025-11-23 22:58:25.039 | INFO     | __main__:<module>:160 - Step9100, Loss: 3.620575428009033, Grad L2 Norm: 0.019357353448867798
2025-11-23 22:58:27.038 | INFO     | __main__:<module>:160 - Step9110, Loss: 3.651096820831299, Grad L2 Norm: 0.020990906283259392
2025-11-23 22:58:29.040 | INFO     | __main__:<module>:160 - Step9120, Loss: 3.5286760330200195, Grad L2 Norm: 0.02202322706580162
2025-11-23 22:58:31.042 | INFO     | __main__:<module>:160 - Step9130, Loss: 3.6553597450256348, Grad L2 Norm: 0.02155541442334652
2025-11-23 22:58:33.043 | INFO     | __main__:<module>:160 - Step9140, Loss: 3.6707658767700195, Grad L2 Norm: 0.020471926778554916
2025-11-23 22:58:35.040 | INFO     | __main__:<module>:160 - Step9150, Loss: 3.5630011558532715, Grad L2 Norm: 0.019466271623969078
2025-11-23 22:58:37.040 | INFO     | __main__:<module>:160 - Step9160, Loss: 3.651892900466919, Grad L2 Norm: 0.019634900614619255
2025-11-23 22:58:39.039 | INFO     | __main__:<module>:160 - Step9170, Loss: 3.493619680404663, Grad L2 Norm: 0.019821247085928917
2025-11-23 22:58:41.040 | INFO     | __main__:<module>:160 - Step9180, Loss: 3.4774394035339355, Grad L2 Norm: 0.02134096994996071
2025-11-23 22:58:43.037 | INFO     | __main__:<module>:160 - Step9190, Loss: 3.554527521133423, Grad L2 Norm: 0.0209308210760355
2025-11-23 22:58:45.042 | INFO     | __main__:<module>:160 - Step9200, Loss: 3.607372760772705, Grad L2 Norm: 0.02044128254055977
2025-11-23 22:58:45.042 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 22:58:46.318 | INFO     | __main__:<module>:181 - validation loss: 3.6391523480415344
2025-11-23 22:58:48.331 | INFO     | __main__:<module>:160 - Step9210, Loss: 3.592771530151367, Grad L2 Norm: 0.0203167162835598
2025-11-23 22:58:50.337 | INFO     | __main__:<module>:160 - Step9220, Loss: 3.6515116691589355, Grad L2 Norm: 0.02325836941599846
2025-11-23 22:58:52.350 | INFO     | __main__:<module>:160 - Step9230, Loss: 3.538905143737793, Grad L2 Norm: 0.020328396931290627
2025-11-23 22:58:54.359 | INFO     | __main__:<module>:160 - Step9240, Loss: 3.6342315673828125, Grad L2 Norm: 0.021420981734991074
2025-11-23 22:58:56.371 | INFO     | __main__:<module>:160 - Step9250, Loss: 3.6660799980163574, Grad L2 Norm: 0.020632321015000343
2025-11-23 22:58:58.384 | INFO     | __main__:<module>:160 - Step9260, Loss: 3.5707619190216064, Grad L2 Norm: 0.02144753746688366
2025-11-23 22:59:00.398 | INFO     | __main__:<module>:160 - Step9270, Loss: 3.6821603775024414, Grad L2 Norm: 0.02080564759671688
2025-11-23 22:59:02.418 | INFO     | __main__:<module>:160 - Step9280, Loss: 3.6432838439941406, Grad L2 Norm: 0.022695589810609818
2025-11-23 22:59:04.437 | INFO     | __main__:<module>:160 - Step9290, Loss: 3.7464582920074463, Grad L2 Norm: 0.02183559723198414
2025-11-23 22:59:06.453 | INFO     | __main__:<module>:160 - Step9300, Loss: 3.612443447113037, Grad L2 Norm: 0.021631717681884766
2025-11-23 22:59:08.465 | INFO     | __main__:<module>:160 - Step9310, Loss: 3.7033815383911133, Grad L2 Norm: 0.021677114069461823
2025-11-23 22:59:10.474 | INFO     | __main__:<module>:160 - Step9320, Loss: 3.5512161254882812, Grad L2 Norm: 0.019550690427422523
2025-11-23 22:59:12.481 | INFO     | __main__:<module>:160 - Step9330, Loss: 3.663341522216797, Grad L2 Norm: 0.020727545022964478
2025-11-23 22:59:14.489 | INFO     | __main__:<module>:160 - Step9340, Loss: 3.570653200149536, Grad L2 Norm: 0.024365434423089027
2025-11-23 22:59:16.501 | INFO     | __main__:<module>:160 - Step9350, Loss: 3.5169734954833984, Grad L2 Norm: 0.01904829777777195
2025-11-23 22:59:18.507 | INFO     | __main__:<module>:160 - Step9360, Loss: 3.6887569427490234, Grad L2 Norm: 0.021339714527130127
2025-11-23 22:59:20.516 | INFO     | __main__:<module>:160 - Step9370, Loss: 3.5605647563934326, Grad L2 Norm: 0.021245678886771202
2025-11-23 22:59:22.525 | INFO     | __main__:<module>:160 - Step9380, Loss: 3.7250537872314453, Grad L2 Norm: 0.02224225550889969
2025-11-23 22:59:24.529 | INFO     | __main__:<module>:160 - Step9390, Loss: 3.5615715980529785, Grad L2 Norm: 0.02036680094897747
2025-11-23 22:59:26.540 | INFO     | __main__:<module>:160 - Step9400, Loss: 3.642937660217285, Grad L2 Norm: 0.02061893418431282
2025-11-23 22:59:28.545 | INFO     | __main__:<module>:160 - Step9410, Loss: 3.4914708137512207, Grad L2 Norm: 0.020203882828354836
2025-11-23 22:59:30.559 | INFO     | __main__:<module>:160 - Step9420, Loss: 3.9363884925842285, Grad L2 Norm: 0.02432950958609581
2025-11-23 22:59:32.567 | INFO     | __main__:<module>:160 - Step9430, Loss: 3.597595691680908, Grad L2 Norm: 0.02307484857738018
2025-11-23 22:59:34.581 | INFO     | __main__:<module>:160 - Step9440, Loss: 3.7552008628845215, Grad L2 Norm: 0.02157406322658062
2025-11-23 22:59:36.594 | INFO     | __main__:<module>:160 - Step9450, Loss: 3.548778772354126, Grad L2 Norm: 0.02007058821618557
2025-11-23 22:59:38.602 | INFO     | __main__:<module>:160 - Step9460, Loss: 3.6090545654296875, Grad L2 Norm: 0.021090248599648476
2025-11-23 22:59:40.602 | INFO     | __main__:<module>:160 - Step9470, Loss: 3.520937919616699, Grad L2 Norm: 0.020857881754636765
2025-11-23 22:59:42.602 | INFO     | __main__:<module>:160 - Step9480, Loss: 3.504035234451294, Grad L2 Norm: 0.0204005166888237
2025-11-23 22:59:44.613 | INFO     | __main__:<module>:160 - Step9490, Loss: 3.705247163772583, Grad L2 Norm: 0.020277509465813637
2025-11-23 22:59:46.620 | INFO     | __main__:<module>:160 - Step9500, Loss: 3.6191513538360596, Grad L2 Norm: 0.020609863102436066
2025-11-23 22:59:48.632 | INFO     | __main__:<module>:160 - Step9510, Loss: 3.5662779808044434, Grad L2 Norm: 0.021243883296847343
2025-11-23 22:59:50.646 | INFO     | __main__:<module>:160 - Step9520, Loss: 3.631080389022827, Grad L2 Norm: 0.01904875412583351
2025-11-23 22:59:52.662 | INFO     | __main__:<module>:160 - Step9530, Loss: 3.7141480445861816, Grad L2 Norm: 0.022080563008785248
2025-11-23 22:59:54.680 | INFO     | __main__:<module>:160 - Step9540, Loss: 3.5152440071105957, Grad L2 Norm: 0.020484646782279015
2025-11-23 22:59:56.700 | INFO     | __main__:<module>:160 - Step9550, Loss: 3.8223392963409424, Grad L2 Norm: 0.023287566378712654
2025-11-23 22:59:58.720 | INFO     | __main__:<module>:160 - Step9560, Loss: 3.6020684242248535, Grad L2 Norm: 0.021604333072900772
2025-11-23 23:00:00.742 | INFO     | __main__:<module>:160 - Step9570, Loss: 3.7447400093078613, Grad L2 Norm: 0.02097318321466446
2025-11-23 23:00:02.763 | INFO     | __main__:<module>:160 - Step9580, Loss: 3.6965444087982178, Grad L2 Norm: 0.021653713658452034
2025-11-23 23:00:04.787 | INFO     | __main__:<module>:160 - Step9590, Loss: 3.6953787803649902, Grad L2 Norm: 0.02149219997227192
2025-11-23 23:00:06.807 | INFO     | __main__:<module>:160 - Step9600, Loss: 3.7004590034484863, Grad L2 Norm: 0.020117519423365593
2025-11-23 23:00:06.807 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:00:08.096 | INFO     | __main__:<module>:181 - validation loss: 3.6330952405929566
2025-11-23 23:00:10.124 | INFO     | __main__:<module>:160 - Step9610, Loss: 3.707578659057617, Grad L2 Norm: 0.02076147496700287
2025-11-23 23:00:12.144 | INFO     | __main__:<module>:160 - Step9620, Loss: 3.601604461669922, Grad L2 Norm: 0.022461770102381706
2025-11-23 23:00:14.164 | INFO     | __main__:<module>:160 - Step9630, Loss: 3.7847092151641846, Grad L2 Norm: 0.022440960630774498
2025-11-23 23:00:16.183 | INFO     | __main__:<module>:160 - Step9640, Loss: 3.6744134426116943, Grad L2 Norm: 0.0205399077385664
2025-11-23 23:00:18.199 | INFO     | __main__:<module>:160 - Step9650, Loss: 3.594226360321045, Grad L2 Norm: 0.02046363241970539
2025-11-23 23:00:20.213 | INFO     | __main__:<module>:160 - Step9660, Loss: 3.6578423976898193, Grad L2 Norm: 0.02003181166946888
2025-11-23 23:00:22.229 | INFO     | __main__:<module>:160 - Step9670, Loss: 3.633845806121826, Grad L2 Norm: 0.02212383970618248
2025-11-23 23:00:24.260 | INFO     | __main__:<module>:160 - Step9680, Loss: 3.6498475074768066, Grad L2 Norm: 0.0200437493622303
2025-11-23 23:00:26.280 | INFO     | __main__:<module>:160 - Step9690, Loss: 3.636453151702881, Grad L2 Norm: 0.021604683250188828
2025-11-23 23:00:28.296 | INFO     | __main__:<module>:160 - Step9700, Loss: 3.5451536178588867, Grad L2 Norm: 0.020464934408664703
2025-11-23 23:00:30.313 | INFO     | __main__:<module>:160 - Step9710, Loss: 3.528714179992676, Grad L2 Norm: 0.021573293954133987
2025-11-23 23:00:32.328 | INFO     | __main__:<module>:160 - Step9720, Loss: 3.4115591049194336, Grad L2 Norm: 0.02127023972570896
2025-11-23 23:00:34.344 | INFO     | __main__:<module>:160 - Step9730, Loss: 3.5868992805480957, Grad L2 Norm: 0.019020050764083862
2025-11-23 23:00:36.364 | INFO     | __main__:<module>:160 - Step9740, Loss: 3.577000141143799, Grad L2 Norm: 0.022269079461693764
2025-11-23 23:00:38.381 | INFO     | __main__:<module>:160 - Step9750, Loss: 3.660639762878418, Grad L2 Norm: 0.020415406674146652
2025-11-23 23:00:40.399 | INFO     | __main__:<module>:160 - Step9760, Loss: 3.4896740913391113, Grad L2 Norm: 0.0217338427901268
2025-11-23 23:00:42.414 | INFO     | __main__:<module>:160 - Step9770, Loss: 3.7090587615966797, Grad L2 Norm: 0.020984387025237083
2025-11-23 23:00:44.425 | INFO     | __main__:<module>:160 - Step9780, Loss: 3.652012348175049, Grad L2 Norm: 0.02098042331635952
2025-11-23 23:00:46.443 | INFO     | __main__:<module>:160 - Step9790, Loss: 3.582287311553955, Grad L2 Norm: 0.021399052813649178
2025-11-23 23:00:48.460 | INFO     | __main__:<module>:160 - Step9800, Loss: 3.6752281188964844, Grad L2 Norm: 0.020470887422561646
2025-11-23 23:00:50.478 | INFO     | __main__:<module>:160 - Step9810, Loss: 3.613523483276367, Grad L2 Norm: 0.021038208156824112
2025-11-23 23:00:52.502 | INFO     | __main__:<module>:160 - Step9820, Loss: 3.6003811359405518, Grad L2 Norm: 0.02193119376897812
2025-11-23 23:00:54.521 | INFO     | __main__:<module>:160 - Step9830, Loss: 3.762104034423828, Grad L2 Norm: 0.022652018815279007
2025-11-23 23:00:56.543 | INFO     | __main__:<module>:160 - Step9840, Loss: 3.4786152839660645, Grad L2 Norm: 0.02111690305173397
2025-11-23 23:00:58.561 | INFO     | __main__:<module>:160 - Step9850, Loss: 3.872462034225464, Grad L2 Norm: 0.024038348346948624
2025-11-23 23:01:00.580 | INFO     | __main__:<module>:160 - Step9860, Loss: 3.6503891944885254, Grad L2 Norm: 0.022079994902014732
2025-11-23 23:01:02.601 | INFO     | __main__:<module>:160 - Step9870, Loss: 3.52378511428833, Grad L2 Norm: 0.02019811049103737
2025-11-23 23:01:04.618 | INFO     | __main__:<module>:160 - Step9880, Loss: 3.6659469604492188, Grad L2 Norm: 0.02198142744600773
2025-11-23 23:01:06.639 | INFO     | __main__:<module>:160 - Step9890, Loss: 3.46120285987854, Grad L2 Norm: 0.02114677242934704
2025-11-23 23:01:08.657 | INFO     | __main__:<module>:160 - Step9900, Loss: 3.637115955352783, Grad L2 Norm: 0.020610854029655457
2025-11-23 23:01:10.672 | INFO     | __main__:<module>:160 - Step9910, Loss: 3.5504958629608154, Grad L2 Norm: 0.0206504687666893
2025-11-23 23:01:12.689 | INFO     | __main__:<module>:160 - Step9920, Loss: 3.6850767135620117, Grad L2 Norm: 0.020792143419384956
2025-11-23 23:01:14.706 | INFO     | __main__:<module>:160 - Step9930, Loss: 3.625311851501465, Grad L2 Norm: 0.020454606041312218
2025-11-23 23:01:16.719 | INFO     | __main__:<module>:160 - Step9940, Loss: 3.754312038421631, Grad L2 Norm: 0.020039787515997887
2025-11-23 23:01:18.732 | INFO     | __main__:<module>:160 - Step9950, Loss: 3.515052080154419, Grad L2 Norm: 0.020588070154190063
2025-11-23 23:01:20.749 | INFO     | __main__:<module>:160 - Step9960, Loss: 3.6007919311523438, Grad L2 Norm: 0.020079538226127625
2025-11-23 23:01:22.767 | INFO     | __main__:<module>:160 - Step9970, Loss: 3.6719894409179688, Grad L2 Norm: 0.02060602977871895
2025-11-23 23:01:24.785 | INFO     | __main__:<module>:160 - Step9980, Loss: 3.5825910568237305, Grad L2 Norm: 0.01981724053621292
2025-11-23 23:01:26.798 | INFO     | __main__:<module>:160 - Step9990, Loss: 3.599544048309326, Grad L2 Norm: 0.0236995629966259
2025-11-23 23:01:28.807 | INFO     | __main__:<module>:160 - Step10000, Loss: 3.63291597366333, Grad L2 Norm: 0.022034715861082077
2025-11-23 23:01:28.808 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:01:30.088 | INFO     | __main__:<module>:181 - validation loss: 3.6053222894668577
2025-11-23 23:01:30.088 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_10000.pt
2025-11-23 23:01:31.754 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-23 23:01:33.749 | INFO     | __main__:<module>:160 - Step10010, Loss: 3.791400194168091, Grad L2 Norm: 0.02278832159936428
2025-11-23 23:01:35.760 | INFO     | __main__:<module>:160 - Step10020, Loss: 3.5128519535064697, Grad L2 Norm: 0.021641697734594345
2025-11-23 23:01:37.761 | INFO     | __main__:<module>:160 - Step10030, Loss: 3.6991472244262695, Grad L2 Norm: 0.02001437544822693
2025-11-23 23:01:39.759 | INFO     | __main__:<module>:160 - Step10040, Loss: 3.6094794273376465, Grad L2 Norm: 0.021368341520428658
2025-11-23 23:01:41.760 | INFO     | __main__:<module>:160 - Step10050, Loss: 3.4126243591308594, Grad L2 Norm: 0.020991617813706398
2025-11-23 23:01:43.762 | INFO     | __main__:<module>:160 - Step10060, Loss: 3.66855525970459, Grad L2 Norm: 0.024516228586435318
2025-11-23 23:01:45.765 | INFO     | __main__:<module>:160 - Step10070, Loss: 3.747471809387207, Grad L2 Norm: 0.02136053889989853
2025-11-23 23:01:47.773 | INFO     | __main__:<module>:160 - Step10080, Loss: 3.577760696411133, Grad L2 Norm: 0.019716469570994377
2025-11-23 23:01:49.779 | INFO     | __main__:<module>:160 - Step10090, Loss: 3.6802010536193848, Grad L2 Norm: 0.020725075155496597
2025-11-23 23:01:51.780 | INFO     | __main__:<module>:160 - Step10100, Loss: 3.5772600173950195, Grad L2 Norm: 0.020997179672122
2025-11-23 23:01:53.781 | INFO     | __main__:<module>:160 - Step10110, Loss: 3.491941452026367, Grad L2 Norm: 0.01911746896803379
2025-11-23 23:01:55.791 | INFO     | __main__:<module>:160 - Step10120, Loss: 3.6075315475463867, Grad L2 Norm: 0.02006949856877327
2025-11-23 23:01:57.793 | INFO     | __main__:<module>:160 - Step10130, Loss: 3.6950442790985107, Grad L2 Norm: 0.02273700200021267
2025-11-23 23:01:59.793 | INFO     | __main__:<module>:160 - Step10140, Loss: 3.7061843872070312, Grad L2 Norm: 0.02120424434542656
2025-11-23 23:02:01.793 | INFO     | __main__:<module>:160 - Step10150, Loss: 3.555293083190918, Grad L2 Norm: 0.02108626812696457
2025-11-23 23:02:03.792 | INFO     | __main__:<module>:160 - Step10160, Loss: 3.643888473510742, Grad L2 Norm: 0.022029712796211243
2025-11-23 23:02:05.791 | INFO     | __main__:<module>:160 - Step10170, Loss: 3.7910308837890625, Grad L2 Norm: 0.02138601243495941
2025-11-23 23:02:07.793 | INFO     | __main__:<module>:160 - Step10180, Loss: 3.4647159576416016, Grad L2 Norm: 0.019582875072956085
2025-11-23 23:02:09.811 | INFO     | __main__:<module>:160 - Step10190, Loss: 3.6674630641937256, Grad L2 Norm: 0.020142963156104088
2025-11-23 23:02:11.814 | INFO     | __main__:<module>:160 - Step10200, Loss: 3.4603230953216553, Grad L2 Norm: 0.020329229533672333
2025-11-23 23:02:13.824 | INFO     | __main__:<module>:160 - Step10210, Loss: 3.722175359725952, Grad L2 Norm: 0.020443197339773178
2025-11-23 23:02:15.828 | INFO     | __main__:<module>:160 - Step10220, Loss: 3.5837321281433105, Grad L2 Norm: 0.02160518802702427
2025-11-23 23:02:17.831 | INFO     | __main__:<module>:160 - Step10230, Loss: 3.6370561122894287, Grad L2 Norm: 0.02066873386502266
2025-11-23 23:02:19.836 | INFO     | __main__:<module>:160 - Step10240, Loss: 3.667093515396118, Grad L2 Norm: 0.020335083827376366
2025-11-23 23:02:21.843 | INFO     | __main__:<module>:160 - Step10250, Loss: 3.611410140991211, Grad L2 Norm: 0.020743537694215775
2025-11-23 23:02:23.847 | INFO     | __main__:<module>:160 - Step10260, Loss: 3.5991756916046143, Grad L2 Norm: 0.020335806533694267
2025-11-23 23:02:25.847 | INFO     | __main__:<module>:160 - Step10270, Loss: 3.4300906658172607, Grad L2 Norm: 0.020901301875710487
2025-11-23 23:02:27.848 | INFO     | __main__:<module>:160 - Step10280, Loss: 3.431436538696289, Grad L2 Norm: 0.020113486796617508
2025-11-23 23:02:29.861 | INFO     | __main__:<module>:160 - Step10290, Loss: 3.5518417358398438, Grad L2 Norm: 0.02193617634475231
2025-11-23 23:02:31.861 | INFO     | __main__:<module>:160 - Step10300, Loss: 3.6328582763671875, Grad L2 Norm: 0.022073285654187202
2025-11-23 23:02:33.860 | INFO     | __main__:<module>:160 - Step10310, Loss: 3.698519229888916, Grad L2 Norm: 0.022818492725491524
2025-11-23 23:02:35.856 | INFO     | __main__:<module>:160 - Step10320, Loss: 3.4666600227355957, Grad L2 Norm: 0.021143918856978416
2025-11-23 23:02:37.854 | INFO     | __main__:<module>:160 - Step10330, Loss: 3.8140830993652344, Grad L2 Norm: 0.021196825429797173
2025-11-23 23:02:39.854 | INFO     | __main__:<module>:160 - Step10340, Loss: 3.5201027393341064, Grad L2 Norm: 0.019058920443058014
2025-11-23 23:02:41.855 | INFO     | __main__:<module>:160 - Step10350, Loss: 3.516864061355591, Grad L2 Norm: 0.021182650700211525
2025-11-23 23:02:43.859 | INFO     | __main__:<module>:160 - Step10360, Loss: 3.7093241214752197, Grad L2 Norm: 0.02190224640071392
2025-11-23 23:02:45.856 | INFO     | __main__:<module>:160 - Step10370, Loss: 3.7105326652526855, Grad L2 Norm: 0.0203395988792181
2025-11-23 23:02:47.853 | INFO     | __main__:<module>:160 - Step10380, Loss: 3.649867534637451, Grad L2 Norm: 0.021997371688485146
2025-11-23 23:02:49.853 | INFO     | __main__:<module>:160 - Step10390, Loss: 3.6813764572143555, Grad L2 Norm: 0.0204789899289608
2025-11-23 23:02:51.851 | INFO     | __main__:<module>:160 - Step10400, Loss: 3.743471384048462, Grad L2 Norm: 0.020251421257853508
2025-11-23 23:02:51.852 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:02:53.121 | INFO     | __main__:<module>:181 - validation loss: 3.5803707003593446
2025-11-23 23:02:55.129 | INFO     | __main__:<module>:160 - Step10410, Loss: 3.4767684936523438, Grad L2 Norm: 0.02459363266825676
2025-11-23 23:02:57.131 | INFO     | __main__:<module>:160 - Step10420, Loss: 3.7693071365356445, Grad L2 Norm: 0.022330129519104958
2025-11-23 23:02:59.131 | INFO     | __main__:<module>:160 - Step10430, Loss: 3.7635223865509033, Grad L2 Norm: 0.022508734837174416
2025-11-23 23:03:01.129 | INFO     | __main__:<module>:160 - Step10440, Loss: 3.5993340015411377, Grad L2 Norm: 0.02239547111093998
2025-11-23 23:03:03.128 | INFO     | __main__:<module>:160 - Step10450, Loss: 3.6239495277404785, Grad L2 Norm: 0.022200576961040497
2025-11-23 23:03:05.126 | INFO     | __main__:<module>:160 - Step10460, Loss: 3.6317663192749023, Grad L2 Norm: 0.02175946906208992
2025-11-23 23:03:07.128 | INFO     | __main__:<module>:160 - Step10470, Loss: 3.554795265197754, Grad L2 Norm: 0.01928088627755642
2025-11-23 23:03:09.127 | INFO     | __main__:<module>:160 - Step10480, Loss: 3.5294342041015625, Grad L2 Norm: 0.020851980894804
2025-11-23 23:03:11.124 | INFO     | __main__:<module>:160 - Step10490, Loss: 3.477914810180664, Grad L2 Norm: 0.01876460574567318
2025-11-23 23:03:13.123 | INFO     | __main__:<module>:160 - Step10500, Loss: 3.6700494289398193, Grad L2 Norm: 0.020614761859178543
2025-11-23 23:03:15.122 | INFO     | __main__:<module>:160 - Step10510, Loss: 3.7205801010131836, Grad L2 Norm: 0.021027004346251488
2025-11-23 23:03:17.121 | INFO     | __main__:<module>:160 - Step10520, Loss: 3.5001444816589355, Grad L2 Norm: 0.020798582583665848
2025-11-23 23:03:19.122 | INFO     | __main__:<module>:160 - Step10530, Loss: 3.7105464935302734, Grad L2 Norm: 0.022689079865813255
2025-11-23 23:03:21.120 | INFO     | __main__:<module>:160 - Step10540, Loss: 3.5957744121551514, Grad L2 Norm: 0.021959206089377403
2025-11-23 23:03:23.120 | INFO     | __main__:<module>:160 - Step10550, Loss: 3.6651391983032227, Grad L2 Norm: 0.02205739915370941
2025-11-23 23:03:25.121 | INFO     | __main__:<module>:160 - Step10560, Loss: 3.6126394271850586, Grad L2 Norm: 0.01974027417600155
2025-11-23 23:03:27.120 | INFO     | __main__:<module>:160 - Step10570, Loss: 3.652043342590332, Grad L2 Norm: 0.022009393200278282
2025-11-23 23:03:29.120 | INFO     | __main__:<module>:160 - Step10580, Loss: 3.5624594688415527, Grad L2 Norm: 0.021291224285960197
2025-11-23 23:03:31.121 | INFO     | __main__:<module>:160 - Step10590, Loss: 3.563387393951416, Grad L2 Norm: 0.02127891220152378
2025-11-23 23:03:33.122 | INFO     | __main__:<module>:160 - Step10600, Loss: 3.6019797325134277, Grad L2 Norm: 0.021970657631754875
2025-11-23 23:03:35.119 | INFO     | __main__:<module>:160 - Step10610, Loss: 3.6368746757507324, Grad L2 Norm: 0.022331278771162033
2025-11-23 23:03:37.118 | INFO     | __main__:<module>:160 - Step10620, Loss: 3.6871960163116455, Grad L2 Norm: 0.021586118265986443
2025-11-23 23:03:39.118 | INFO     | __main__:<module>:160 - Step10630, Loss: 3.660257577896118, Grad L2 Norm: 0.021123284474015236
2025-11-23 23:03:41.116 | INFO     | __main__:<module>:160 - Step10640, Loss: 3.587846279144287, Grad L2 Norm: 0.02137635089457035
2025-11-23 23:03:43.115 | INFO     | __main__:<module>:160 - Step10650, Loss: 3.7279486656188965, Grad L2 Norm: 0.02301904186606407
2025-11-23 23:03:45.115 | INFO     | __main__:<module>:160 - Step10660, Loss: 3.618879795074463, Grad L2 Norm: 0.022344423457980156
2025-11-23 23:03:47.120 | INFO     | __main__:<module>:160 - Step10670, Loss: 3.5839343070983887, Grad L2 Norm: 0.020624307915568352
2025-11-23 23:03:49.120 | INFO     | __main__:<module>:160 - Step10680, Loss: 3.7173075675964355, Grad L2 Norm: 0.022235974669456482
2025-11-23 23:03:51.117 | INFO     | __main__:<module>:160 - Step10690, Loss: 3.713453531265259, Grad L2 Norm: 0.021398115903139114
2025-11-23 23:03:53.116 | INFO     | __main__:<module>:160 - Step10700, Loss: 3.473938465118408, Grad L2 Norm: 0.021304508671164513
2025-11-23 23:03:55.114 | INFO     | __main__:<module>:160 - Step10710, Loss: 3.6013309955596924, Grad L2 Norm: 0.021066416054964066
2025-11-23 23:03:57.112 | INFO     | __main__:<module>:160 - Step10720, Loss: 3.5744822025299072, Grad L2 Norm: 0.0208621546626091
2025-11-23 23:03:59.110 | INFO     | __main__:<module>:160 - Step10730, Loss: 3.5720481872558594, Grad L2 Norm: 0.021807340905070305
2025-11-23 23:04:01.111 | INFO     | __main__:<module>:160 - Step10740, Loss: 3.5749804973602295, Grad L2 Norm: 0.02295054867863655
2025-11-23 23:04:03.111 | INFO     | __main__:<module>:160 - Step10750, Loss: 3.5651938915252686, Grad L2 Norm: 0.01890433579683304
2025-11-23 23:04:05.110 | INFO     | __main__:<module>:160 - Step10760, Loss: 3.4499146938323975, Grad L2 Norm: 0.020213589072227478
2025-11-23 23:04:07.111 | INFO     | __main__:<module>:160 - Step10770, Loss: 3.651380777359009, Grad L2 Norm: 0.020249372348189354
2025-11-23 23:04:09.110 | INFO     | __main__:<module>:160 - Step10780, Loss: 3.8020243644714355, Grad L2 Norm: 0.023428594693541527
2025-11-23 23:04:11.109 | INFO     | __main__:<module>:160 - Step10790, Loss: 3.5836586952209473, Grad L2 Norm: 0.020232586190104485
2025-11-23 23:04:13.110 | INFO     | __main__:<module>:160 - Step10800, Loss: 3.6731104850769043, Grad L2 Norm: 0.020346663892269135
2025-11-23 23:04:13.110 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:04:14.382 | INFO     | __main__:<module>:181 - validation loss: 3.62584730386734
2025-11-23 23:04:16.389 | INFO     | __main__:<module>:160 - Step10810, Loss: 3.6104040145874023, Grad L2 Norm: 0.020049797371029854
2025-11-23 23:04:18.389 | INFO     | __main__:<module>:160 - Step10820, Loss: 3.684386968612671, Grad L2 Norm: 0.02036479115486145
2025-11-23 23:04:20.389 | INFO     | __main__:<module>:160 - Step10830, Loss: 3.5908331871032715, Grad L2 Norm: 0.020752256736159325
2025-11-23 23:04:22.387 | INFO     | __main__:<module>:160 - Step10840, Loss: 3.7632076740264893, Grad L2 Norm: 0.021883448585867882
2025-11-23 23:04:24.387 | INFO     | __main__:<module>:160 - Step10850, Loss: 3.753905773162842, Grad L2 Norm: 0.022968139499425888
2025-11-23 23:04:26.387 | INFO     | __main__:<module>:160 - Step10860, Loss: 3.5367488861083984, Grad L2 Norm: 0.020190715789794922
2025-11-23 23:04:28.389 | INFO     | __main__:<module>:160 - Step10870, Loss: 3.6190237998962402, Grad L2 Norm: 0.02036256715655327
2025-11-23 23:04:30.390 | INFO     | __main__:<module>:160 - Step10880, Loss: 3.5471363067626953, Grad L2 Norm: 0.02017497643828392
2025-11-23 23:04:32.397 | INFO     | __main__:<module>:160 - Step10890, Loss: 3.649620771408081, Grad L2 Norm: 0.02118563838303089
2025-11-23 23:04:34.401 | INFO     | __main__:<module>:160 - Step10900, Loss: 3.6021523475646973, Grad L2 Norm: 0.02097696252167225
2025-11-23 23:04:36.400 | INFO     | __main__:<module>:160 - Step10910, Loss: 3.6904494762420654, Grad L2 Norm: 0.019586199894547462
2025-11-23 23:04:38.401 | INFO     | __main__:<module>:160 - Step10920, Loss: 3.784722328186035, Grad L2 Norm: 0.020372938364744186
2025-11-23 23:04:40.398 | INFO     | __main__:<module>:160 - Step10930, Loss: 3.663008451461792, Grad L2 Norm: 0.020213322713971138
2025-11-23 23:04:42.400 | INFO     | __main__:<module>:160 - Step10940, Loss: 3.5263619422912598, Grad L2 Norm: 0.02207431010901928
2025-11-23 23:04:44.397 | INFO     | __main__:<module>:160 - Step10950, Loss: 3.567535638809204, Grad L2 Norm: 0.02085418812930584
2025-11-23 23:04:46.395 | INFO     | __main__:<module>:160 - Step10960, Loss: 3.686323881149292, Grad L2 Norm: 0.023577086627483368
2025-11-23 23:04:48.394 | INFO     | __main__:<module>:160 - Step10970, Loss: 3.696178436279297, Grad L2 Norm: 0.02058017998933792
2025-11-23 23:04:50.394 | INFO     | __main__:<module>:160 - Step10980, Loss: 3.5789308547973633, Grad L2 Norm: 0.020193886011838913
2025-11-23 23:04:52.393 | INFO     | __main__:<module>:160 - Step10990, Loss: 3.5958592891693115, Grad L2 Norm: 0.020906394347548485
2025-11-23 23:04:54.393 | INFO     | __main__:<module>:160 - Step11000, Loss: 3.4757065773010254, Grad L2 Norm: 0.019312473013997078
2025-11-23 23:04:56.392 | INFO     | __main__:<module>:160 - Step11010, Loss: 3.6945509910583496, Grad L2 Norm: 0.0237753763794899
2025-11-23 23:04:58.392 | INFO     | __main__:<module>:160 - Step11020, Loss: 3.419433116912842, Grad L2 Norm: 0.023198144510388374
2025-11-23 23:05:00.391 | INFO     | __main__:<module>:160 - Step11030, Loss: 3.536508798599243, Grad L2 Norm: 0.02392483316361904
2025-11-23 23:05:02.395 | INFO     | __main__:<module>:160 - Step11040, Loss: 3.670501947402954, Grad L2 Norm: 0.020492658019065857
2025-11-23 23:05:04.393 | INFO     | __main__:<module>:160 - Step11050, Loss: 3.5345582962036133, Grad L2 Norm: 0.021460184827446938
2025-11-23 23:05:06.388 | INFO     | __main__:<module>:160 - Step11060, Loss: 3.6423556804656982, Grad L2 Norm: 0.02063605561852455
2025-11-23 23:05:08.387 | INFO     | __main__:<module>:160 - Step11070, Loss: 3.760244369506836, Grad L2 Norm: 0.02196403406560421
2025-11-23 23:05:10.389 | INFO     | __main__:<module>:160 - Step11080, Loss: 3.490250825881958, Grad L2 Norm: 0.020115280523896217
2025-11-23 23:05:12.388 | INFO     | __main__:<module>:160 - Step11090, Loss: 3.848365306854248, Grad L2 Norm: 0.03399340808391571
2025-11-23 23:05:14.387 | INFO     | __main__:<module>:160 - Step11100, Loss: 3.6357479095458984, Grad L2 Norm: 0.022975044324994087
2025-11-23 23:05:16.386 | INFO     | __main__:<module>:160 - Step11110, Loss: 3.695054531097412, Grad L2 Norm: 0.02155607007443905
2025-11-23 23:05:18.385 | INFO     | __main__:<module>:160 - Step11120, Loss: 3.5968127250671387, Grad L2 Norm: 0.021070972084999084
2025-11-23 23:05:20.384 | INFO     | __main__:<module>:160 - Step11130, Loss: 3.6020824909210205, Grad L2 Norm: 0.0210072360932827
2025-11-23 23:05:22.386 | INFO     | __main__:<module>:160 - Step11140, Loss: 3.6394355297088623, Grad L2 Norm: 0.021607322618365288
2025-11-23 23:05:24.384 | INFO     | __main__:<module>:160 - Step11150, Loss: 3.639965534210205, Grad L2 Norm: 0.02036646381020546
2025-11-23 23:05:26.384 | INFO     | __main__:<module>:160 - Step11160, Loss: 3.6545956134796143, Grad L2 Norm: 0.02063475176692009
2025-11-23 23:05:28.386 | INFO     | __main__:<module>:160 - Step11170, Loss: 3.682692289352417, Grad L2 Norm: 0.020405158400535583
2025-11-23 23:05:30.388 | INFO     | __main__:<module>:160 - Step11180, Loss: 3.6217904090881348, Grad L2 Norm: 0.021204374730587006
2025-11-23 23:05:32.389 | INFO     | __main__:<module>:160 - Step11190, Loss: 3.688973903656006, Grad L2 Norm: 0.02170262113213539
2025-11-23 23:05:34.399 | INFO     | __main__:<module>:160 - Step11200, Loss: 3.4994900226593018, Grad L2 Norm: 0.02066660113632679
2025-11-23 23:05:34.400 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:05:35.675 | INFO     | __main__:<module>:181 - validation loss: 3.6059890031814574
2025-11-23 23:05:37.687 | INFO     | __main__:<module>:160 - Step11210, Loss: 3.750805377960205, Grad L2 Norm: 0.02274731546640396
2025-11-23 23:05:39.694 | INFO     | __main__:<module>:160 - Step11220, Loss: 3.5305614471435547, Grad L2 Norm: 0.020642708986997604
2025-11-23 23:05:41.700 | INFO     | __main__:<module>:160 - Step11230, Loss: 3.6629302501678467, Grad L2 Norm: 0.021035244688391685
2025-11-23 23:05:43.701 | INFO     | __main__:<module>:160 - Step11240, Loss: 3.5036516189575195, Grad L2 Norm: 0.021054821088910103
2025-11-23 23:05:45.703 | INFO     | __main__:<module>:160 - Step11250, Loss: 3.46405029296875, Grad L2 Norm: 0.021269632503390312
2025-11-23 23:05:47.702 | INFO     | __main__:<module>:160 - Step11260, Loss: 3.717322826385498, Grad L2 Norm: 0.02181035280227661
2025-11-23 23:05:49.700 | INFO     | __main__:<module>:160 - Step11270, Loss: 3.5785837173461914, Grad L2 Norm: 0.021564006805419922
2025-11-23 23:05:51.699 | INFO     | __main__:<module>:160 - Step11280, Loss: 3.5633480548858643, Grad L2 Norm: 0.022521398961544037
2025-11-23 23:05:53.701 | INFO     | __main__:<module>:160 - Step11290, Loss: 3.6407089233398438, Grad L2 Norm: 0.0203294288367033
2025-11-23 23:05:55.699 | INFO     | __main__:<module>:160 - Step11300, Loss: 3.710512638092041, Grad L2 Norm: 0.020576342940330505
2025-11-23 23:05:57.699 | INFO     | __main__:<module>:160 - Step11310, Loss: 3.516087055206299, Grad L2 Norm: 0.020849034190177917
2025-11-23 23:05:59.699 | INFO     | __main__:<module>:160 - Step11320, Loss: 3.7067832946777344, Grad L2 Norm: 0.024634739384055138
2025-11-23 23:06:01.697 | INFO     | __main__:<module>:160 - Step11330, Loss: 3.4448747634887695, Grad L2 Norm: 0.01982439123094082
2025-11-23 23:06:03.695 | INFO     | __main__:<module>:160 - Step11340, Loss: 3.665482521057129, Grad L2 Norm: 0.022126302123069763
2025-11-23 23:06:05.695 | INFO     | __main__:<module>:160 - Step11350, Loss: 3.6599183082580566, Grad L2 Norm: 0.02211899496614933
2025-11-23 23:06:07.693 | INFO     | __main__:<module>:160 - Step11360, Loss: 3.704055070877075, Grad L2 Norm: 0.022050093859434128
2025-11-23 23:06:09.694 | INFO     | __main__:<module>:160 - Step11370, Loss: 3.6758456230163574, Grad L2 Norm: 0.020753100514411926
2025-11-23 23:06:11.693 | INFO     | __main__:<module>:160 - Step11380, Loss: 3.642713785171509, Grad L2 Norm: 0.021835578605532646
2025-11-23 23:06:13.693 | INFO     | __main__:<module>:160 - Step11390, Loss: 3.631988763809204, Grad L2 Norm: 0.019978588446974754
2025-11-23 23:06:15.695 | INFO     | __main__:<module>:160 - Step11400, Loss: 3.5580453872680664, Grad L2 Norm: 0.020579176023602486
2025-11-23 23:06:17.695 | INFO     | __main__:<module>:160 - Step11410, Loss: 3.649052143096924, Grad L2 Norm: 0.021664520725607872
2025-11-23 23:06:19.691 | INFO     | __main__:<module>:160 - Step11420, Loss: 3.5077266693115234, Grad L2 Norm: 0.020753569900989532
2025-11-23 23:06:21.691 | INFO     | __main__:<module>:160 - Step11430, Loss: 3.5950469970703125, Grad L2 Norm: 0.021455921232700348
2025-11-23 23:06:23.689 | INFO     | __main__:<module>:160 - Step11440, Loss: 3.612189769744873, Grad L2 Norm: 0.019134078174829483
2025-11-23 23:06:25.686 | INFO     | __main__:<module>:160 - Step11450, Loss: 3.807027816772461, Grad L2 Norm: 0.02622460015118122
2025-11-23 23:06:27.687 | INFO     | __main__:<module>:160 - Step11460, Loss: 3.661837339401245, Grad L2 Norm: 0.022155828773975372
2025-11-23 23:06:29.686 | INFO     | __main__:<module>:160 - Step11470, Loss: 3.465151786804199, Grad L2 Norm: 0.021362176164984703
2025-11-23 23:06:31.684 | INFO     | __main__:<module>:160 - Step11480, Loss: 3.6731600761413574, Grad L2 Norm: 0.022895213216543198
2025-11-23 23:06:33.690 | INFO     | __main__:<module>:160 - Step11490, Loss: 3.581557512283325, Grad L2 Norm: 0.01997150480747223
2025-11-23 23:06:35.684 | INFO     | __main__:<module>:160 - Step11500, Loss: 3.6301472187042236, Grad L2 Norm: 0.020462222397327423
2025-11-23 23:06:37.680 | INFO     | __main__:<module>:160 - Step11510, Loss: 3.5168991088867188, Grad L2 Norm: 0.021181337535381317
2025-11-23 23:06:39.679 | INFO     | __main__:<module>:160 - Step11520, Loss: 3.5371077060699463, Grad L2 Norm: 0.0212708692997694
2025-11-23 23:06:41.680 | INFO     | __main__:<module>:160 - Step11530, Loss: 3.648699998855591, Grad L2 Norm: 0.02156185731291771
2025-11-23 23:06:43.681 | INFO     | __main__:<module>:160 - Step11540, Loss: 3.6679062843322754, Grad L2 Norm: 0.020904872566461563
2025-11-23 23:06:45.678 | INFO     | __main__:<module>:160 - Step11550, Loss: 3.5784168243408203, Grad L2 Norm: 0.02222919464111328
2025-11-23 23:06:47.677 | INFO     | __main__:<module>:160 - Step11560, Loss: 3.6404685974121094, Grad L2 Norm: 0.02168053388595581
2025-11-23 23:06:49.676 | INFO     | __main__:<module>:160 - Step11570, Loss: 3.4879393577575684, Grad L2 Norm: 0.02091447077691555
2025-11-23 23:06:51.674 | INFO     | __main__:<module>:160 - Step11580, Loss: 3.5564374923706055, Grad L2 Norm: 0.0203231368213892
2025-11-23 23:06:53.675 | INFO     | __main__:<module>:160 - Step11590, Loss: 3.76912260055542, Grad L2 Norm: 0.023225612938404083
2025-11-23 23:06:55.674 | INFO     | __main__:<module>:160 - Step11600, Loss: 3.5178470611572266, Grad L2 Norm: 0.02000242844223976
2025-11-23 23:06:55.675 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:06:56.944 | INFO     | __main__:<module>:181 - validation loss: 3.6183212399482727
2025-11-23 23:06:58.951 | INFO     | __main__:<module>:160 - Step11610, Loss: 3.5649094581604004, Grad L2 Norm: 0.021913280710577965
2025-11-23 23:07:00.954 | INFO     | __main__:<module>:160 - Step11620, Loss: 3.681143283843994, Grad L2 Norm: 0.020345356315374374
2025-11-23 23:07:02.952 | INFO     | __main__:<module>:160 - Step11630, Loss: 3.560152530670166, Grad L2 Norm: 0.020260360091924667
2025-11-23 23:07:04.950 | INFO     | __main__:<module>:160 - Step11640, Loss: 3.6563544273376465, Grad L2 Norm: 0.020979149267077446
2025-11-23 23:07:06.948 | INFO     | __main__:<module>:160 - Step11650, Loss: 3.5943946838378906, Grad L2 Norm: 0.020329268649220467
2025-11-23 23:07:08.948 | INFO     | __main__:<module>:160 - Step11660, Loss: 3.728127956390381, Grad L2 Norm: 0.021959522739052773
2025-11-23 23:07:10.947 | INFO     | __main__:<module>:160 - Step11670, Loss: 3.6453857421875, Grad L2 Norm: 0.021348433569073677
2025-11-23 23:07:12.940 | INFO     | __main__:<module>:160 - Step11680, Loss: 3.75046968460083, Grad L2 Norm: 0.022979561239480972
2025-11-23 23:07:14.931 | INFO     | __main__:<module>:160 - Step11690, Loss: 3.6511542797088623, Grad L2 Norm: 0.022162552922964096
2025-11-23 23:07:16.927 | INFO     | __main__:<module>:160 - Step11700, Loss: 3.6152358055114746, Grad L2 Norm: 0.02767155133187771
2025-11-23 23:07:18.926 | INFO     | __main__:<module>:160 - Step11710, Loss: 3.547802209854126, Grad L2 Norm: 0.02042648196220398
2025-11-23 23:07:20.926 | INFO     | __main__:<module>:160 - Step11720, Loss: 3.690021514892578, Grad L2 Norm: 0.02216564305126667
2025-11-23 23:07:22.925 | INFO     | __main__:<module>:160 - Step11730, Loss: 3.5607333183288574, Grad L2 Norm: 0.021271727979183197
2025-11-23 23:07:24.921 | INFO     | __main__:<module>:160 - Step11740, Loss: 3.621849298477173, Grad L2 Norm: 0.020288005471229553
2025-11-23 23:07:26.911 | INFO     | __main__:<module>:160 - Step11750, Loss: 3.7211239337921143, Grad L2 Norm: 0.02153106965124607
2025-11-23 23:07:28.902 | INFO     | __main__:<module>:160 - Step11760, Loss: 3.6230359077453613, Grad L2 Norm: 0.021622128784656525
2025-11-23 23:07:30.894 | INFO     | __main__:<module>:160 - Step11770, Loss: 3.62874698638916, Grad L2 Norm: 0.02098078839480877
2025-11-23 23:07:32.886 | INFO     | __main__:<module>:160 - Step11780, Loss: 3.6805062294006348, Grad L2 Norm: 0.02250215969979763
2025-11-23 23:07:34.881 | INFO     | __main__:<module>:160 - Step11790, Loss: 3.56691312789917, Grad L2 Norm: 0.019976966083049774
2025-11-23 23:07:36.879 | INFO     | __main__:<module>:160 - Step11800, Loss: 3.6133475303649902, Grad L2 Norm: 0.023296328261494637
2025-11-23 23:07:38.878 | INFO     | __main__:<module>:160 - Step11810, Loss: 3.5607001781463623, Grad L2 Norm: 0.021196946501731873
2025-11-23 23:07:40.873 | INFO     | __main__:<module>:160 - Step11820, Loss: 3.5042829513549805, Grad L2 Norm: 0.02148459106683731
2025-11-23 23:07:42.863 | INFO     | __main__:<module>:160 - Step11830, Loss: 3.7181825637817383, Grad L2 Norm: 0.022612009197473526
2025-11-23 23:07:44.858 | INFO     | __main__:<module>:160 - Step11840, Loss: 3.602360248565674, Grad L2 Norm: 0.020455822348594666
2025-11-23 23:07:46.858 | INFO     | __main__:<module>:160 - Step11850, Loss: 3.5561139583587646, Grad L2 Norm: 0.020400745794177055
2025-11-23 23:07:48.856 | INFO     | __main__:<module>:160 - Step11860, Loss: 3.6282191276550293, Grad L2 Norm: 0.02071533165872097
2025-11-23 23:07:50.858 | INFO     | __main__:<module>:160 - Step11870, Loss: 3.688121795654297, Grad L2 Norm: 0.021143388003110886
2025-11-23 23:07:52.855 | INFO     | __main__:<module>:160 - Step11880, Loss: 3.6324377059936523, Grad L2 Norm: 0.02029414474964142
2025-11-23 23:07:54.854 | INFO     | __main__:<module>:160 - Step11890, Loss: 3.6839065551757812, Grad L2 Norm: 0.02107561193406582
2025-11-23 23:07:56.857 | INFO     | __main__:<module>:160 - Step11900, Loss: 3.5407910346984863, Grad L2 Norm: 0.020951969549059868
2025-11-23 23:07:58.860 | INFO     | __main__:<module>:160 - Step11910, Loss: 3.696363925933838, Grad L2 Norm: 0.024915577843785286
2025-11-23 23:08:00.856 | INFO     | __main__:<module>:160 - Step11920, Loss: 3.668196201324463, Grad L2 Norm: 0.02310897782444954
2025-11-23 23:08:02.854 | INFO     | __main__:<module>:160 - Step11930, Loss: 3.618378162384033, Grad L2 Norm: 0.02141033299267292
2025-11-23 23:08:04.853 | INFO     | __main__:<module>:160 - Step11940, Loss: 3.5437393188476562, Grad L2 Norm: 0.020334118977189064
2025-11-23 23:08:06.853 | INFO     | __main__:<module>:160 - Step11950, Loss: 3.5343785285949707, Grad L2 Norm: 0.019576361402869225
2025-11-23 23:08:08.853 | INFO     | __main__:<module>:160 - Step11960, Loss: 3.6022963523864746, Grad L2 Norm: 0.019812770187854767
2025-11-23 23:08:10.852 | INFO     | __main__:<module>:160 - Step11970, Loss: 3.5934810638427734, Grad L2 Norm: 0.021561870351433754
2025-11-23 23:08:12.854 | INFO     | __main__:<module>:160 - Step11980, Loss: 3.7111759185791016, Grad L2 Norm: 0.021601159125566483
2025-11-23 23:08:14.854 | INFO     | __main__:<module>:160 - Step11990, Loss: 3.5830178260803223, Grad L2 Norm: 0.021689068526029587
2025-11-23 23:08:16.853 | INFO     | __main__:<module>:160 - Step12000, Loss: 3.592611312866211, Grad L2 Norm: 0.019959863275289536
2025-11-23 23:08:16.853 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:08:18.123 | INFO     | __main__:<module>:181 - validation loss: 3.6040907859802247
2025-11-23 23:08:18.124 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_12000.pt
2025-11-23 23:08:19.780 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-23 23:08:21.762 | INFO     | __main__:<module>:160 - Step12010, Loss: 3.6426024436950684, Grad L2 Norm: 0.0212236437946558
2025-11-23 23:08:23.756 | INFO     | __main__:<module>:160 - Step12020, Loss: 3.7493605613708496, Grad L2 Norm: 0.023527324199676514
2025-11-23 23:08:25.756 | INFO     | __main__:<module>:160 - Step12030, Loss: 3.7246668338775635, Grad L2 Norm: 0.022006884217262268
2025-11-23 23:08:27.752 | INFO     | __main__:<module>:160 - Step12040, Loss: 3.6508679389953613, Grad L2 Norm: 0.02075006440281868
2025-11-23 23:08:29.749 | INFO     | __main__:<module>:160 - Step12050, Loss: 3.6828575134277344, Grad L2 Norm: 0.022997722029685974
2025-11-23 23:08:31.745 | INFO     | __main__:<module>:160 - Step12060, Loss: 3.555677890777588, Grad L2 Norm: 0.02068876288831234
2025-11-23 23:08:33.745 | INFO     | __main__:<module>:160 - Step12070, Loss: 3.594282388687134, Grad L2 Norm: 0.021758021786808968
2025-11-23 23:08:35.744 | INFO     | __main__:<module>:160 - Step12080, Loss: 3.6661014556884766, Grad L2 Norm: 0.02230387181043625
2025-11-23 23:08:37.742 | INFO     | __main__:<module>:160 - Step12090, Loss: 3.538778781890869, Grad L2 Norm: 0.020836269482970238
2025-11-23 23:08:39.740 | INFO     | __main__:<module>:160 - Step12100, Loss: 3.6294498443603516, Grad L2 Norm: 0.02110498957335949
2025-11-23 23:08:41.737 | INFO     | __main__:<module>:160 - Step12110, Loss: 3.7324471473693848, Grad L2 Norm: 0.023527303710579872
2025-11-23 23:08:43.726 | INFO     | __main__:<module>:160 - Step12120, Loss: 3.541926860809326, Grad L2 Norm: 0.024827228859066963
2025-11-23 23:08:45.720 | INFO     | __main__:<module>:160 - Step12130, Loss: 3.5964407920837402, Grad L2 Norm: 0.02019841969013214
2025-11-23 23:08:47.720 | INFO     | __main__:<module>:160 - Step12140, Loss: 3.5685949325561523, Grad L2 Norm: 0.020466621965169907
2025-11-23 23:08:49.719 | INFO     | __main__:<module>:160 - Step12150, Loss: 3.641453742980957, Grad L2 Norm: 0.02190762758255005
2025-11-23 23:08:51.716 | INFO     | __main__:<module>:160 - Step12160, Loss: 3.61100435256958, Grad L2 Norm: 0.021502181887626648
2025-11-23 23:08:53.716 | INFO     | __main__:<module>:160 - Step12170, Loss: 3.578810930252075, Grad L2 Norm: 0.020793279632925987
2025-11-23 23:08:55.716 | INFO     | __main__:<module>:160 - Step12180, Loss: 3.6622962951660156, Grad L2 Norm: 0.022373920306563377
2025-11-23 23:08:57.719 | INFO     | __main__:<module>:160 - Step12190, Loss: 3.6648073196411133, Grad L2 Norm: 0.02065921016037464
2025-11-23 23:08:59.716 | INFO     | __main__:<module>:160 - Step12200, Loss: 3.6542274951934814, Grad L2 Norm: 0.01967404969036579
2025-11-23 23:09:01.714 | INFO     | __main__:<module>:160 - Step12210, Loss: 3.519040107727051, Grad L2 Norm: 0.020390743389725685
2025-11-23 23:09:03.713 | INFO     | __main__:<module>:160 - Step12220, Loss: 3.5581164360046387, Grad L2 Norm: 0.02056913636624813
2025-11-23 23:09:05.706 | INFO     | __main__:<module>:160 - Step12230, Loss: 3.6947059631347656, Grad L2 Norm: 0.021288225427269936
2025-11-23 23:09:07.696 | INFO     | __main__:<module>:160 - Step12240, Loss: 3.663316249847412, Grad L2 Norm: 0.022759057581424713
2025-11-23 23:09:09.692 | INFO     | __main__:<module>:160 - Step12250, Loss: 3.5659546852111816, Grad L2 Norm: 0.02185148186981678
2025-11-23 23:09:11.687 | INFO     | __main__:<module>:160 - Step12260, Loss: 3.6955127716064453, Grad L2 Norm: 0.02491195872426033
2025-11-23 23:09:13.680 | INFO     | __main__:<module>:160 - Step12270, Loss: 3.6034023761749268, Grad L2 Norm: 0.022565143182873726
2025-11-23 23:09:15.672 | INFO     | __main__:<module>:160 - Step12280, Loss: 3.5686535835266113, Grad L2 Norm: 0.021715881302952766
2025-11-23 23:09:17.669 | INFO     | __main__:<module>:160 - Step12290, Loss: 3.608283519744873, Grad L2 Norm: 0.02053145132958889
2025-11-23 23:09:19.670 | INFO     | __main__:<module>:160 - Step12300, Loss: 3.5488805770874023, Grad L2 Norm: 0.02287723869085312
2025-11-23 23:09:21.669 | INFO     | __main__:<module>:160 - Step12310, Loss: 3.470844268798828, Grad L2 Norm: 0.02326422743499279
2025-11-23 23:09:23.669 | INFO     | __main__:<module>:160 - Step12320, Loss: 3.6393938064575195, Grad L2 Norm: 0.0220442283898592
2025-11-23 23:09:25.665 | INFO     | __main__:<module>:160 - Step12330, Loss: 3.578854560852051, Grad L2 Norm: 0.019802682101726532
2025-11-23 23:09:27.666 | INFO     | __main__:<module>:160 - Step12340, Loss: 3.6756720542907715, Grad L2 Norm: 0.021459383890032768
2025-11-23 23:09:29.666 | INFO     | __main__:<module>:160 - Step12350, Loss: 3.6611084938049316, Grad L2 Norm: 0.02128838188946247
2025-11-23 23:09:31.653 | INFO     | __main__:<module>:160 - Step12360, Loss: 3.527953624725342, Grad L2 Norm: 0.020925704389810562
2025-11-23 23:09:33.642 | INFO     | __main__:<module>:160 - Step12370, Loss: 3.655491828918457, Grad L2 Norm: 0.020290955901145935
2025-11-23 23:09:35.641 | INFO     | __main__:<module>:160 - Step12380, Loss: 3.6381516456604004, Grad L2 Norm: 0.0201663076877594
2025-11-23 23:09:37.638 | INFO     | __main__:<module>:160 - Step12390, Loss: 3.502974510192871, Grad L2 Norm: 0.02079663798213005
2025-11-23 23:09:39.640 | INFO     | __main__:<module>:160 - Step12400, Loss: 3.5409202575683594, Grad L2 Norm: 0.021314546465873718
2025-11-23 23:09:39.640 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:09:40.912 | INFO     | __main__:<module>:181 - validation loss: 3.6246163606643678
2025-11-23 23:09:42.920 | INFO     | __main__:<module>:160 - Step12410, Loss: 3.6210455894470215, Grad L2 Norm: 0.02108859084546566
2025-11-23 23:09:44.922 | INFO     | __main__:<module>:160 - Step12420, Loss: 3.5526485443115234, Grad L2 Norm: 0.021562140434980392
2025-11-23 23:09:46.923 | INFO     | __main__:<module>:160 - Step12430, Loss: 3.5977113246917725, Grad L2 Norm: 0.020593833178281784
2025-11-23 23:09:48.921 | INFO     | __main__:<module>:160 - Step12440, Loss: 3.7307591438293457, Grad L2 Norm: 0.022116592153906822
2025-11-23 23:09:50.920 | INFO     | __main__:<module>:160 - Step12450, Loss: 3.6889705657958984, Grad L2 Norm: 0.02168652042746544
2025-11-23 23:09:52.921 | INFO     | __main__:<module>:160 - Step12460, Loss: 3.5728096961975098, Grad L2 Norm: 0.02094891294836998
2025-11-23 23:09:54.920 | INFO     | __main__:<module>:160 - Step12470, Loss: 3.575155258178711, Grad L2 Norm: 0.023193730041384697
2025-11-23 23:09:56.921 | INFO     | __main__:<module>:160 - Step12480, Loss: 3.5546860694885254, Grad L2 Norm: 0.020392797887325287
2025-11-23 23:09:58.921 | INFO     | __main__:<module>:160 - Step12490, Loss: 3.662010669708252, Grad L2 Norm: 0.019581960514187813
2025-11-23 23:10:00.926 | INFO     | __main__:<module>:160 - Step12500, Loss: 3.5791873931884766, Grad L2 Norm: 0.020592957735061646
2025-11-23 23:10:02.925 | INFO     | __main__:<module>:160 - Step12510, Loss: 3.582463264465332, Grad L2 Norm: 0.02060588449239731
2025-11-23 23:10:04.924 | INFO     | __main__:<module>:160 - Step12520, Loss: 3.494131088256836, Grad L2 Norm: 0.021713925525546074
2025-11-23 23:10:06.923 | INFO     | __main__:<module>:160 - Step12530, Loss: 3.4780330657958984, Grad L2 Norm: 0.020520446822047234
2025-11-23 23:10:08.928 | INFO     | __main__:<module>:160 - Step12540, Loss: 3.6207709312438965, Grad L2 Norm: 0.021711153909564018
2025-11-23 23:10:10.933 | INFO     | __main__:<module>:160 - Step12550, Loss: 3.5970091819763184, Grad L2 Norm: 0.023575859144330025
2025-11-23 23:10:12.935 | INFO     | __main__:<module>:160 - Step12560, Loss: 3.6420559883117676, Grad L2 Norm: 0.020427022129297256
2025-11-23 23:10:14.936 | INFO     | __main__:<module>:160 - Step12570, Loss: 3.8081483840942383, Grad L2 Norm: 0.023170018568634987
2025-11-23 23:10:16.937 | INFO     | __main__:<module>:160 - Step12580, Loss: 3.620750665664673, Grad L2 Norm: 0.022641398012638092
2025-11-23 23:10:18.936 | INFO     | __main__:<module>:160 - Step12590, Loss: 3.636047840118408, Grad L2 Norm: 0.021097401157021523
2025-11-23 23:10:20.937 | INFO     | __main__:<module>:160 - Step12600, Loss: 3.616851806640625, Grad L2 Norm: 0.022237880155444145
2025-11-23 23:10:22.939 | INFO     | __main__:<module>:160 - Step12610, Loss: 3.5314149856567383, Grad L2 Norm: 0.019906887784600258
2025-11-23 23:10:24.941 | INFO     | __main__:<module>:160 - Step12620, Loss: 3.4956889152526855, Grad L2 Norm: 0.02133394405245781
2025-11-23 23:10:26.953 | INFO     | __main__:<module>:160 - Step12630, Loss: 3.679229974746704, Grad L2 Norm: 0.022594226524233818
2025-11-23 23:10:28.964 | INFO     | __main__:<module>:160 - Step12640, Loss: 3.4821906089782715, Grad L2 Norm: 0.019366702064871788
2025-11-23 23:10:30.970 | INFO     | __main__:<module>:160 - Step12650, Loss: 3.534266948699951, Grad L2 Norm: 0.02068982645869255
2025-11-23 23:10:32.973 | INFO     | __main__:<module>:160 - Step12660, Loss: 3.678337574005127, Grad L2 Norm: 0.021138114854693413
2025-11-23 23:10:34.976 | INFO     | __main__:<module>:160 - Step12670, Loss: 3.559839963912964, Grad L2 Norm: 0.022936174646019936
2025-11-23 23:10:36.975 | INFO     | __main__:<module>:160 - Step12680, Loss: 3.640329122543335, Grad L2 Norm: 0.02109849639236927
2025-11-23 23:10:38.984 | INFO     | __main__:<module>:160 - Step12690, Loss: 3.6183595657348633, Grad L2 Norm: 0.020179087296128273
2025-11-23 23:10:40.987 | INFO     | __main__:<module>:160 - Step12700, Loss: 3.6842222213745117, Grad L2 Norm: 0.02337057702243328
2025-11-23 23:10:42.989 | INFO     | __main__:<module>:160 - Step12710, Loss: 3.6924424171447754, Grad L2 Norm: 0.02248556725680828
2025-11-23 23:10:44.987 | INFO     | __main__:<module>:160 - Step12720, Loss: 3.717974901199341, Grad L2 Norm: 0.02241414040327072
2025-11-23 23:10:46.989 | INFO     | __main__:<module>:160 - Step12730, Loss: 3.484863042831421, Grad L2 Norm: 0.022553984075784683
2025-11-23 23:10:48.989 | INFO     | __main__:<module>:160 - Step12740, Loss: 3.5391273498535156, Grad L2 Norm: 0.021427297964692116
2025-11-23 23:10:50.994 | INFO     | __main__:<module>:160 - Step12750, Loss: 3.647918462753296, Grad L2 Norm: 0.021007046103477478
2025-11-23 23:10:53.005 | INFO     | __main__:<module>:160 - Step12760, Loss: 3.6653013229370117, Grad L2 Norm: 0.02237066812813282
2025-11-23 23:10:55.012 | INFO     | __main__:<module>:160 - Step12770, Loss: 3.5332040786743164, Grad L2 Norm: 0.02055276744067669
2025-11-23 23:10:57.009 | INFO     | __main__:<module>:160 - Step12780, Loss: 3.570394515991211, Grad L2 Norm: 0.021186692640185356
2025-11-23 23:10:59.017 | INFO     | __main__:<module>:160 - Step12790, Loss: 3.5885767936706543, Grad L2 Norm: 0.022968459874391556
2025-11-23 23:11:01.020 | INFO     | __main__:<module>:160 - Step12800, Loss: 3.7084503173828125, Grad L2 Norm: 0.023711450397968292
2025-11-23 23:11:01.021 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:11:02.290 | INFO     | __main__:<module>:181 - validation loss: 3.588696813583374
2025-11-23 23:11:04.301 | INFO     | __main__:<module>:160 - Step12810, Loss: 3.6442761421203613, Grad L2 Norm: 0.021399421617388725
2025-11-23 23:11:06.302 | INFO     | __main__:<module>:160 - Step12820, Loss: 3.6325674057006836, Grad L2 Norm: 0.021144354715943336
2025-11-23 23:11:08.306 | INFO     | __main__:<module>:160 - Step12830, Loss: 3.546926498413086, Grad L2 Norm: 0.02051425166428089
2025-11-23 23:11:10.303 | INFO     | __main__:<module>:160 - Step12840, Loss: 3.6032485961914062, Grad L2 Norm: 0.021741682663559914
2025-11-23 23:11:12.301 | INFO     | __main__:<module>:160 - Step12850, Loss: 3.600987434387207, Grad L2 Norm: 0.020450996235013008
2025-11-23 23:11:14.298 | INFO     | __main__:<module>:160 - Step12860, Loss: 3.584080219268799, Grad L2 Norm: 0.022373348474502563
2025-11-23 23:11:16.298 | INFO     | __main__:<module>:160 - Step12870, Loss: 3.6545205116271973, Grad L2 Norm: 0.02093615010380745
2025-11-23 23:11:18.306 | INFO     | __main__:<module>:160 - Step12880, Loss: 3.710171699523926, Grad L2 Norm: 0.022846050560474396
2025-11-23 23:11:20.311 | INFO     | __main__:<module>:160 - Step12890, Loss: 3.5560734272003174, Grad L2 Norm: 0.02212785929441452
2025-11-23 23:11:22.314 | INFO     | __main__:<module>:160 - Step12900, Loss: 3.655254364013672, Grad L2 Norm: 0.020929459482431412
2025-11-23 23:11:24.318 | INFO     | __main__:<module>:160 - Step12910, Loss: 3.623560905456543, Grad L2 Norm: 0.021190498024225235
2025-11-23 23:11:26.320 | INFO     | __main__:<module>:160 - Step12920, Loss: 3.5725045204162598, Grad L2 Norm: 0.020456746220588684
2025-11-23 23:11:28.322 | INFO     | __main__:<module>:160 - Step12930, Loss: 3.7082138061523438, Grad L2 Norm: 0.021477971225976944
2025-11-23 23:11:30.328 | INFO     | __main__:<module>:160 - Step12940, Loss: 3.630108594894409, Grad L2 Norm: 0.02136247605085373
2025-11-23 23:11:32.334 | INFO     | __main__:<module>:160 - Step12950, Loss: 3.621797561645508, Grad L2 Norm: 0.021460063755512238
2025-11-23 23:11:34.341 | INFO     | __main__:<module>:160 - Step12960, Loss: 3.7119390964508057, Grad L2 Norm: 0.021086284890770912
2025-11-23 23:11:36.349 | INFO     | __main__:<module>:160 - Step12970, Loss: 3.4413866996765137, Grad L2 Norm: 0.02068326249718666
2025-11-23 23:11:38.357 | INFO     | __main__:<module>:160 - Step12980, Loss: 3.56705904006958, Grad L2 Norm: 0.020479410886764526
2025-11-23 23:11:40.368 | INFO     | __main__:<module>:160 - Step12990, Loss: 3.525259494781494, Grad L2 Norm: 0.020015010610222816
2025-11-23 23:11:42.376 | INFO     | __main__:<module>:160 - Step13000, Loss: 3.7663512229919434, Grad L2 Norm: 0.020957285538315773
2025-11-23 23:11:44.387 | INFO     | __main__:<module>:160 - Step13010, Loss: 3.500278949737549, Grad L2 Norm: 0.021338842809200287
2025-11-23 23:11:46.392 | INFO     | __main__:<module>:160 - Step13020, Loss: 3.5871808528900146, Grad L2 Norm: 0.02010306902229786
2025-11-23 23:11:48.401 | INFO     | __main__:<module>:160 - Step13030, Loss: 3.577101469039917, Grad L2 Norm: 0.020082591101527214
2025-11-23 23:11:50.408 | INFO     | __main__:<module>:160 - Step13040, Loss: 3.492354393005371, Grad L2 Norm: 0.021124472841620445
2025-11-23 23:11:52.409 | INFO     | __main__:<module>:160 - Step13050, Loss: 3.743472099304199, Grad L2 Norm: 0.0225222110748291
2025-11-23 23:11:54.414 | INFO     | __main__:<module>:160 - Step13060, Loss: 3.587794065475464, Grad L2 Norm: 0.02035839483141899
2025-11-23 23:11:56.424 | INFO     | __main__:<module>:160 - Step13070, Loss: 3.6072027683258057, Grad L2 Norm: 0.02035406604409218
2025-11-23 23:11:58.427 | INFO     | __main__:<module>:160 - Step13080, Loss: 3.626422882080078, Grad L2 Norm: 0.020922651514410973
2025-11-23 23:12:00.430 | INFO     | __main__:<module>:160 - Step13090, Loss: 3.675004482269287, Grad L2 Norm: 0.021594339981675148
2025-11-23 23:12:02.429 | INFO     | __main__:<module>:160 - Step13100, Loss: 3.6934401988983154, Grad L2 Norm: 0.022260546684265137
2025-11-23 23:12:04.427 | INFO     | __main__:<module>:160 - Step13110, Loss: 3.540848970413208, Grad L2 Norm: 0.022368298843503
2025-11-23 23:12:06.427 | INFO     | __main__:<module>:160 - Step13120, Loss: 3.5925204753875732, Grad L2 Norm: 0.020953591912984848
2025-11-23 23:12:08.426 | INFO     | __main__:<module>:160 - Step13130, Loss: 3.693530559539795, Grad L2 Norm: 0.024177975952625275
2025-11-23 23:12:10.424 | INFO     | __main__:<module>:160 - Step13140, Loss: 3.569856643676758, Grad L2 Norm: 0.020733868703246117
2025-11-23 23:12:12.422 | INFO     | __main__:<module>:160 - Step13150, Loss: 3.511943817138672, Grad L2 Norm: 0.021117055788636208
2025-11-23 23:12:14.424 | INFO     | __main__:<module>:160 - Step13160, Loss: 3.7029290199279785, Grad L2 Norm: 0.0214038398116827
2025-11-23 23:12:16.447 | INFO     | __main__:<module>:160 - Step13170, Loss: 3.5486817359924316, Grad L2 Norm: 0.02144055999815464
2025-11-23 23:12:18.445 | INFO     | __main__:<module>:160 - Step13180, Loss: 3.5674023628234863, Grad L2 Norm: 0.021584751084446907
2025-11-23 23:12:20.455 | INFO     | __main__:<module>:160 - Step13190, Loss: 3.7203562259674072, Grad L2 Norm: 0.02207116223871708
2025-11-23 23:12:22.456 | INFO     | __main__:<module>:160 - Step13200, Loss: 3.585508346557617, Grad L2 Norm: 0.023928483948111534
2025-11-23 23:12:22.456 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:12:23.729 | INFO     | __main__:<module>:181 - validation loss: 3.609107553958893
2025-11-23 23:12:25.739 | INFO     | __main__:<module>:160 - Step13210, Loss: 3.49745512008667, Grad L2 Norm: 0.02538299188017845
2025-11-23 23:12:27.750 | INFO     | __main__:<module>:160 - Step13220, Loss: 3.6470892429351807, Grad L2 Norm: 0.021260233595967293
2025-11-23 23:12:29.754 | INFO     | __main__:<module>:160 - Step13230, Loss: 3.523794412612915, Grad L2 Norm: 0.019275348633527756
2025-11-23 23:12:31.755 | INFO     | __main__:<module>:160 - Step13240, Loss: 3.4579739570617676, Grad L2 Norm: 0.022994183003902435
2025-11-23 23:12:33.753 | INFO     | __main__:<module>:160 - Step13250, Loss: 3.454880952835083, Grad L2 Norm: 0.021523067727684975
2025-11-23 23:12:35.754 | INFO     | __main__:<module>:160 - Step13260, Loss: 3.8422884941101074, Grad L2 Norm: 0.021414704620838165
2025-11-23 23:12:37.754 | INFO     | __main__:<module>:160 - Step13270, Loss: 3.758835792541504, Grad L2 Norm: 0.02265756018459797
2025-11-23 23:12:39.753 | INFO     | __main__:<module>:160 - Step13280, Loss: 3.5628418922424316, Grad L2 Norm: 0.02052602730691433
2025-11-23 23:12:41.751 | INFO     | __main__:<module>:160 - Step13290, Loss: 3.3963966369628906, Grad L2 Norm: 0.023198222741484642
2025-11-23 23:12:43.751 | INFO     | __main__:<module>:160 - Step13300, Loss: 3.6758873462677, Grad L2 Norm: 0.020448844879865646
2025-11-23 23:12:45.749 | INFO     | __main__:<module>:160 - Step13310, Loss: 3.589303493499756, Grad L2 Norm: 0.020157478749752045
2025-11-23 23:12:47.748 | INFO     | __main__:<module>:160 - Step13320, Loss: 3.5632078647613525, Grad L2 Norm: 0.019705994054675102
2025-11-23 23:12:49.749 | INFO     | __main__:<module>:160 - Step13330, Loss: 3.545036792755127, Grad L2 Norm: 0.022004876285791397
2025-11-23 23:12:51.753 | INFO     | __main__:<module>:160 - Step13340, Loss: 3.5376663208007812, Grad L2 Norm: 0.020307205617427826
2025-11-23 23:12:53.750 | INFO     | __main__:<module>:160 - Step13350, Loss: 3.6686673164367676, Grad L2 Norm: 0.022220440208911896
2025-11-23 23:12:55.750 | INFO     | __main__:<module>:160 - Step13360, Loss: 3.520749092102051, Grad L2 Norm: 0.019117359071969986
2025-11-23 23:12:57.750 | INFO     | __main__:<module>:160 - Step13370, Loss: 3.5939364433288574, Grad L2 Norm: 0.02079281583428383
2025-11-23 23:12:59.747 | INFO     | __main__:<module>:160 - Step13380, Loss: 3.6344542503356934, Grad L2 Norm: 0.021656930446624756
2025-11-23 23:13:01.746 | INFO     | __main__:<module>:160 - Step13390, Loss: 3.7207589149475098, Grad L2 Norm: 0.02124224416911602
2025-11-23 23:13:03.746 | INFO     | __main__:<module>:160 - Step13400, Loss: 3.6479249000549316, Grad L2 Norm: 0.020259445533156395
2025-11-23 23:13:05.748 | INFO     | __main__:<module>:160 - Step13410, Loss: 3.630452871322632, Grad L2 Norm: 0.021662414073944092
2025-11-23 23:13:07.749 | INFO     | __main__:<module>:160 - Step13420, Loss: 3.603118896484375, Grad L2 Norm: 0.020689386874437332
2025-11-23 23:13:09.755 | INFO     | __main__:<module>:160 - Step13430, Loss: 3.4350175857543945, Grad L2 Norm: 0.021052097901701927
2025-11-23 23:13:11.760 | INFO     | __main__:<module>:160 - Step13440, Loss: 3.558785915374756, Grad L2 Norm: 0.021272530779242516
2025-11-23 23:13:13.762 | INFO     | __main__:<module>:160 - Step13450, Loss: 3.521763801574707, Grad L2 Norm: 0.020551063120365143
2025-11-23 23:13:15.763 | INFO     | __main__:<module>:160 - Step13460, Loss: 3.6067023277282715, Grad L2 Norm: 0.020251505076885223
2025-11-23 23:13:17.771 | INFO     | __main__:<module>:160 - Step13470, Loss: 3.53169846534729, Grad L2 Norm: 0.020475471392273903
2025-11-23 23:13:19.776 | INFO     | __main__:<module>:160 - Step13480, Loss: 3.719069480895996, Grad L2 Norm: 0.02464536391198635
2025-11-23 23:13:21.778 | INFO     | __main__:<module>:160 - Step13490, Loss: 3.576280355453491, Grad L2 Norm: 0.02124936692416668
2025-11-23 23:13:23.779 | INFO     | __main__:<module>:160 - Step13500, Loss: 3.6296136379241943, Grad L2 Norm: 0.022985149174928665
2025-11-23 23:13:25.781 | INFO     | __main__:<module>:160 - Step13510, Loss: 3.7038049697875977, Grad L2 Norm: 0.022556856274604797
2025-11-23 23:13:27.780 | INFO     | __main__:<module>:160 - Step13520, Loss: 3.609891891479492, Grad L2 Norm: 0.02084827981889248
2025-11-23 23:13:29.779 | INFO     | __main__:<module>:160 - Step13530, Loss: 3.5452256202697754, Grad L2 Norm: 0.022735562175512314
2025-11-23 23:13:31.779 | INFO     | __main__:<module>:160 - Step13540, Loss: 3.682163953781128, Grad L2 Norm: 0.021397605538368225
2025-11-23 23:13:33.779 | INFO     | __main__:<module>:160 - Step13550, Loss: 3.6794683933258057, Grad L2 Norm: 0.021544843912124634
2025-11-23 23:13:35.777 | INFO     | __main__:<module>:160 - Step13560, Loss: 3.5218491554260254, Grad L2 Norm: 0.020618516951799393
2025-11-23 23:13:37.775 | INFO     | __main__:<module>:160 - Step13570, Loss: 3.7282443046569824, Grad L2 Norm: 0.02261577732861042
2025-11-23 23:13:39.775 | INFO     | __main__:<module>:160 - Step13580, Loss: 3.6937084197998047, Grad L2 Norm: 0.02259039878845215
2025-11-23 23:13:41.773 | INFO     | __main__:<module>:160 - Step13590, Loss: 3.616008758544922, Grad L2 Norm: 0.02033674716949463
2025-11-23 23:13:43.781 | INFO     | __main__:<module>:160 - Step13600, Loss: 3.729522228240967, Grad L2 Norm: 0.02081781066954136
2025-11-23 23:13:43.782 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:13:45.053 | INFO     | __main__:<module>:181 - validation loss: 3.6087238907814028
2025-11-23 23:13:47.068 | INFO     | __main__:<module>:160 - Step13610, Loss: 3.546475887298584, Grad L2 Norm: 0.020746666938066483
2025-11-23 23:13:49.068 | INFO     | __main__:<module>:160 - Step13620, Loss: 3.610685348510742, Grad L2 Norm: 0.022060051560401917
2025-11-23 23:13:51.071 | INFO     | __main__:<module>:160 - Step13630, Loss: 3.4841318130493164, Grad L2 Norm: 0.02060846798121929
2025-11-23 23:13:53.071 | INFO     | __main__:<module>:160 - Step13640, Loss: 3.6565792560577393, Grad L2 Norm: 0.02103303000330925
2025-11-23 23:13:55.070 | INFO     | __main__:<module>:160 - Step13650, Loss: 3.5598578453063965, Grad L2 Norm: 0.021571440622210503
2025-11-23 23:13:57.070 | INFO     | __main__:<module>:160 - Step13660, Loss: 3.6332621574401855, Grad L2 Norm: 0.02310231328010559
2025-11-23 23:13:59.071 | INFO     | __main__:<module>:160 - Step13670, Loss: 3.7300057411193848, Grad L2 Norm: 0.02195361815392971
2025-11-23 23:14:01.077 | INFO     | __main__:<module>:160 - Step13680, Loss: 3.6262714862823486, Grad L2 Norm: 0.021284153684973717
2025-11-23 23:14:03.086 | INFO     | __main__:<module>:160 - Step13690, Loss: 3.61014461517334, Grad L2 Norm: 0.021596480160951614
2025-11-23 23:14:05.091 | INFO     | __main__:<module>:160 - Step13700, Loss: 3.5211589336395264, Grad L2 Norm: 0.021502144634723663
2025-11-23 23:14:07.092 | INFO     | __main__:<module>:160 - Step13710, Loss: 3.6863620281219482, Grad L2 Norm: 0.022711986675858498
2025-11-23 23:14:09.095 | INFO     | __main__:<module>:160 - Step13720, Loss: 3.5272932052612305, Grad L2 Norm: 0.02248036488890648
2025-11-23 23:14:11.104 | INFO     | __main__:<module>:160 - Step13730, Loss: 3.6220340728759766, Grad L2 Norm: 0.024928562343120575
2025-11-23 23:14:13.104 | INFO     | __main__:<module>:160 - Step13740, Loss: 3.6373085975646973, Grad L2 Norm: 0.02209293097257614
2025-11-23 23:14:15.104 | INFO     | __main__:<module>:160 - Step13750, Loss: 3.7834067344665527, Grad L2 Norm: 0.023100418969988823
2025-11-23 23:14:17.104 | INFO     | __main__:<module>:160 - Step13760, Loss: 3.5568885803222656, Grad L2 Norm: 0.02229287289083004
2025-11-23 23:14:19.103 | INFO     | __main__:<module>:160 - Step13770, Loss: 3.6482417583465576, Grad L2 Norm: 0.021036716178059578
2025-11-23 23:14:21.103 | INFO     | __main__:<module>:160 - Step13780, Loss: 3.7191004753112793, Grad L2 Norm: 0.02354353480041027
2025-11-23 23:14:23.104 | INFO     | __main__:<module>:160 - Step13790, Loss: 3.4808149337768555, Grad L2 Norm: 0.020612863823771477
2025-11-23 23:14:25.107 | INFO     | __main__:<module>:160 - Step13800, Loss: 3.663600444793701, Grad L2 Norm: 0.020909085869789124
2025-11-23 23:14:27.116 | INFO     | __main__:<module>:160 - Step13810, Loss: 3.742767333984375, Grad L2 Norm: 0.024408536031842232
2025-11-23 23:14:29.120 | INFO     | __main__:<module>:160 - Step13820, Loss: 3.6428537368774414, Grad L2 Norm: 0.021376386284828186
2025-11-23 23:14:31.128 | INFO     | __main__:<module>:160 - Step13830, Loss: 3.6270179748535156, Grad L2 Norm: 0.021564515307545662
2025-11-23 23:14:33.139 | INFO     | __main__:<module>:160 - Step13840, Loss: 3.4391121864318848, Grad L2 Norm: 0.023063067346811295
2025-11-23 23:14:35.143 | INFO     | __main__:<module>:160 - Step13850, Loss: 3.4790585041046143, Grad L2 Norm: 0.021167507395148277
2025-11-23 23:14:37.151 | INFO     | __main__:<module>:160 - Step13860, Loss: 3.6055643558502197, Grad L2 Norm: 0.022219520062208176
2025-11-23 23:14:39.153 | INFO     | __main__:<module>:160 - Step13870, Loss: 3.5731358528137207, Grad L2 Norm: 0.021964747458696365
2025-11-23 23:14:41.157 | INFO     | __main__:<module>:160 - Step13880, Loss: 3.7336935997009277, Grad L2 Norm: 0.019985921680927277
2025-11-23 23:14:43.157 | INFO     | __main__:<module>:160 - Step13890, Loss: 3.386404037475586, Grad L2 Norm: 0.02128790132701397
2025-11-23 23:14:45.157 | INFO     | __main__:<module>:160 - Step13900, Loss: 3.587973117828369, Grad L2 Norm: 0.020769953727722168
2025-11-23 23:14:47.158 | INFO     | __main__:<module>:160 - Step13910, Loss: 3.626223087310791, Grad L2 Norm: 0.021328937262296677
2025-11-23 23:14:49.159 | INFO     | __main__:<module>:160 - Step13920, Loss: 3.5851407051086426, Grad L2 Norm: 0.020667225122451782
2025-11-23 23:14:51.157 | INFO     | __main__:<module>:160 - Step13930, Loss: 3.6036272048950195, Grad L2 Norm: 0.021061666309833527
2025-11-23 23:14:53.155 | INFO     | __main__:<module>:160 - Step13940, Loss: 3.614346504211426, Grad L2 Norm: 0.020121276378631592
2025-11-23 23:14:55.152 | INFO     | __main__:<module>:160 - Step13950, Loss: 3.587111711502075, Grad L2 Norm: 0.02063540555536747
2025-11-23 23:14:57.152 | INFO     | __main__:<module>:160 - Step13960, Loss: 3.515270471572876, Grad L2 Norm: 0.021689942106604576
2025-11-23 23:14:59.151 | INFO     | __main__:<module>:160 - Step13970, Loss: 3.639172315597534, Grad L2 Norm: 0.020134558901190758
2025-11-23 23:15:01.149 | INFO     | __main__:<module>:160 - Step13980, Loss: 3.72133469581604, Grad L2 Norm: 0.02478792704641819
2025-11-23 23:15:03.150 | INFO     | __main__:<module>:160 - Step13990, Loss: 3.6653668880462646, Grad L2 Norm: 0.020510608330368996
2025-11-23 23:15:05.149 | INFO     | __main__:<module>:160 - Step14000, Loss: 3.5021419525146484, Grad L2 Norm: 0.02137927897274494
2025-11-23 23:15:05.149 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:15:06.424 | INFO     | __main__:<module>:181 - validation loss: 3.616362988948822
2025-11-23 23:15:06.425 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_14000.pt
2025-11-23 23:15:08.117 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-23 23:15:10.102 | INFO     | __main__:<module>:160 - Step14010, Loss: 3.5629053115844727, Grad L2 Norm: 0.020656850188970566
2025-11-23 23:15:12.105 | INFO     | __main__:<module>:160 - Step14020, Loss: 3.6504878997802734, Grad L2 Norm: 0.021859223023056984
2025-11-23 23:15:14.104 | INFO     | __main__:<module>:160 - Step14030, Loss: 3.662785768508911, Grad L2 Norm: 0.02347487024962902
2025-11-23 23:15:16.105 | INFO     | __main__:<module>:160 - Step14040, Loss: 3.7029521465301514, Grad L2 Norm: 0.021580049768090248
2025-11-23 23:15:18.103 | INFO     | __main__:<module>:160 - Step14050, Loss: 3.566007614135742, Grad L2 Norm: 0.022048136219382286
2025-11-23 23:15:20.103 | INFO     | __main__:<module>:160 - Step14060, Loss: 3.553744316101074, Grad L2 Norm: 0.023462722077965736
2025-11-23 23:15:22.101 | INFO     | __main__:<module>:160 - Step14070, Loss: 3.5563929080963135, Grad L2 Norm: 0.02107032760977745
2025-11-23 23:15:24.102 | INFO     | __main__:<module>:160 - Step14080, Loss: 3.5804123878479004, Grad L2 Norm: 0.02454202063381672
2025-11-23 23:15:26.105 | INFO     | __main__:<module>:160 - Step14090, Loss: 3.521961212158203, Grad L2 Norm: 0.023600401356816292
2025-11-23 23:15:28.106 | INFO     | __main__:<module>:160 - Step14100, Loss: 3.5547280311584473, Grad L2 Norm: 0.02193984016776085
2025-11-23 23:15:30.111 | INFO     | __main__:<module>:160 - Step14110, Loss: 3.679123640060425, Grad L2 Norm: 0.020821062847971916
2025-11-23 23:15:32.118 | INFO     | __main__:<module>:160 - Step14120, Loss: 3.571938991546631, Grad L2 Norm: 0.02113867737352848
2025-11-23 23:15:34.118 | INFO     | __main__:<module>:160 - Step14130, Loss: 3.5817816257476807, Grad L2 Norm: 0.02110043726861477
2025-11-23 23:15:36.120 | INFO     | __main__:<module>:160 - Step14140, Loss: 3.704596996307373, Grad L2 Norm: 0.02274475432932377
2025-11-23 23:15:38.120 | INFO     | __main__:<module>:160 - Step14150, Loss: 3.5592613220214844, Grad L2 Norm: 0.022390514612197876
2025-11-23 23:15:40.118 | INFO     | __main__:<module>:160 - Step14160, Loss: 3.524390935897827, Grad L2 Norm: 0.023603470996022224
2025-11-23 23:15:42.118 | INFO     | __main__:<module>:160 - Step14170, Loss: 3.5618462562561035, Grad L2 Norm: 0.020898539572954178
2025-11-23 23:15:44.118 | INFO     | __main__:<module>:160 - Step14180, Loss: 3.7457895278930664, Grad L2 Norm: 0.02244233898818493
2025-11-23 23:15:46.117 | INFO     | __main__:<module>:160 - Step14190, Loss: 3.4350242614746094, Grad L2 Norm: 0.021573513746261597
2025-11-23 23:15:48.117 | INFO     | __main__:<module>:160 - Step14200, Loss: 3.5927014350891113, Grad L2 Norm: 0.02122603729367256
2025-11-23 23:15:50.118 | INFO     | __main__:<module>:160 - Step14210, Loss: 3.614548921585083, Grad L2 Norm: 0.021006392315030098
2025-11-23 23:15:52.124 | INFO     | __main__:<module>:160 - Step14220, Loss: 3.893799304962158, Grad L2 Norm: 0.023656120523810387
2025-11-23 23:15:54.135 | INFO     | __main__:<module>:160 - Step14230, Loss: 3.6006999015808105, Grad L2 Norm: 0.02020052820444107
2025-11-23 23:15:56.137 | INFO     | __main__:<module>:160 - Step14240, Loss: 3.4510111808776855, Grad L2 Norm: 0.023242264986038208
2025-11-23 23:15:58.138 | INFO     | __main__:<module>:160 - Step14250, Loss: 3.752002716064453, Grad L2 Norm: 0.02567715011537075
2025-11-23 23:16:00.138 | INFO     | __main__:<module>:160 - Step14260, Loss: 3.6131343841552734, Grad L2 Norm: 0.021229377016425133
2025-11-23 23:16:02.144 | INFO     | __main__:<module>:160 - Step14270, Loss: 3.6343865394592285, Grad L2 Norm: 0.02136068418622017
2025-11-23 23:16:04.157 | INFO     | __main__:<module>:160 - Step14280, Loss: 3.5359625816345215, Grad L2 Norm: 0.020066864788532257
2025-11-23 23:16:06.168 | INFO     | __main__:<module>:160 - Step14290, Loss: 3.535653829574585, Grad L2 Norm: 0.021253926679491997
2025-11-23 23:16:08.172 | INFO     | __main__:<module>:160 - Step14300, Loss: 3.578099012374878, Grad L2 Norm: 0.021545538678765297
2025-11-23 23:16:10.175 | INFO     | __main__:<module>:160 - Step14310, Loss: 3.6677842140197754, Grad L2 Norm: 0.02216479741036892
2025-11-23 23:16:12.187 | INFO     | __main__:<module>:160 - Step14320, Loss: 3.649740219116211, Grad L2 Norm: 0.020850641652941704
2025-11-23 23:16:14.193 | INFO     | __main__:<module>:160 - Step14330, Loss: 3.716148853302002, Grad L2 Norm: 0.0206088125705719
2025-11-23 23:16:16.205 | INFO     | __main__:<module>:160 - Step14340, Loss: 3.657184600830078, Grad L2 Norm: 0.020999690517783165
2025-11-23 23:16:18.208 | INFO     | __main__:<module>:160 - Step14350, Loss: 3.593883514404297, Grad L2 Norm: 0.020660368725657463
2025-11-23 23:16:20.211 | INFO     | __main__:<module>:160 - Step14360, Loss: 3.5951013565063477, Grad L2 Norm: 0.023269623517990112
2025-11-23 23:16:22.214 | INFO     | __main__:<module>:160 - Step14370, Loss: 3.5940327644348145, Grad L2 Norm: 0.022410310804843903
2025-11-23 23:16:24.220 | INFO     | __main__:<module>:160 - Step14380, Loss: 3.6131343841552734, Grad L2 Norm: 0.0195754524320364
2025-11-23 23:16:26.223 | INFO     | __main__:<module>:160 - Step14390, Loss: 3.6400856971740723, Grad L2 Norm: 0.02039146050810814
2025-11-23 23:16:28.226 | INFO     | __main__:<module>:160 - Step14400, Loss: 3.5403826236724854, Grad L2 Norm: 0.02266460284590721
2025-11-23 23:16:28.226 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:16:29.500 | INFO     | __main__:<module>:181 - validation loss: 3.620710015296936
2025-11-23 23:16:31.518 | INFO     | __main__:<module>:160 - Step14410, Loss: 3.5920472145080566, Grad L2 Norm: 0.02107728272676468
2025-11-23 23:16:33.521 | INFO     | __main__:<module>:160 - Step14420, Loss: 3.587550640106201, Grad L2 Norm: 0.021796036511659622
2025-11-23 23:16:35.522 | INFO     | __main__:<module>:160 - Step14430, Loss: 3.643007278442383, Grad L2 Norm: 0.022702321410179138
2025-11-23 23:16:37.522 | INFO     | __main__:<module>:160 - Step14440, Loss: 3.774052143096924, Grad L2 Norm: 0.022009385749697685
2025-11-23 23:16:39.521 | INFO     | __main__:<module>:160 - Step14450, Loss: 3.492513418197632, Grad L2 Norm: 0.02125617302954197
2025-11-23 23:16:41.520 | INFO     | __main__:<module>:160 - Step14460, Loss: 3.5357778072357178, Grad L2 Norm: 0.02281583845615387
2025-11-23 23:16:43.520 | INFO     | __main__:<module>:160 - Step14470, Loss: 3.5699214935302734, Grad L2 Norm: 0.020483732223510742
2025-11-23 23:16:45.520 | INFO     | __main__:<module>:160 - Step14480, Loss: 3.5576276779174805, Grad L2 Norm: 0.022234875708818436
2025-11-23 23:16:47.518 | INFO     | __main__:<module>:160 - Step14490, Loss: 3.504923105239868, Grad L2 Norm: 0.020043374970555305
2025-11-23 23:16:49.527 | INFO     | __main__:<module>:160 - Step14500, Loss: 3.6286232471466064, Grad L2 Norm: 0.020520970225334167
2025-11-23 23:16:51.542 | INFO     | __main__:<module>:160 - Step14510, Loss: 3.53555965423584, Grad L2 Norm: 0.019323313608765602
2025-11-23 23:16:53.542 | INFO     | __main__:<module>:160 - Step14520, Loss: 3.6667394638061523, Grad L2 Norm: 0.023717986419796944
2025-11-23 23:16:55.545 | INFO     | __main__:<module>:160 - Step14530, Loss: 3.6638853549957275, Grad L2 Norm: 0.020957063883543015
2025-11-23 23:16:57.554 | INFO     | __main__:<module>:160 - Step14540, Loss: 3.511975049972534, Grad L2 Norm: 0.021706175059080124
2025-11-23 23:16:59.559 | INFO     | __main__:<module>:160 - Step14550, Loss: 3.473320960998535, Grad L2 Norm: 0.020223721861839294
2025-11-23 23:17:01.568 | INFO     | __main__:<module>:160 - Step14560, Loss: 3.5899505615234375, Grad L2 Norm: 0.020031800493597984
2025-11-23 23:17:03.574 | INFO     | __main__:<module>:160 - Step14570, Loss: 3.523507833480835, Grad L2 Norm: 0.021351926028728485
2025-11-23 23:17:05.581 | INFO     | __main__:<module>:160 - Step14580, Loss: 3.6323654651641846, Grad L2 Norm: 0.023760661482810974
2025-11-23 23:17:07.593 | INFO     | __main__:<module>:160 - Step14590, Loss: 3.4867897033691406, Grad L2 Norm: 0.02167554944753647
2025-11-23 23:17:09.592 | INFO     | __main__:<module>:160 - Step14600, Loss: 3.664473295211792, Grad L2 Norm: 0.02245553582906723
2025-11-23 23:17:11.591 | INFO     | __main__:<module>:160 - Step14610, Loss: 3.6040923595428467, Grad L2 Norm: 0.02121651917695999
2025-11-23 23:17:13.591 | INFO     | __main__:<module>:160 - Step14620, Loss: 3.6093077659606934, Grad L2 Norm: 0.02241668850183487
2025-11-23 23:17:15.591 | INFO     | __main__:<module>:160 - Step14630, Loss: 3.3375816345214844, Grad L2 Norm: 0.022749396041035652
2025-11-23 23:17:17.590 | INFO     | __main__:<module>:160 - Step14640, Loss: 3.5194146633148193, Grad L2 Norm: 0.021493731066584587
2025-11-23 23:17:19.589 | INFO     | __main__:<module>:160 - Step14650, Loss: 3.7896690368652344, Grad L2 Norm: 0.022776665166020393
2025-11-23 23:17:21.588 | INFO     | __main__:<module>:160 - Step14660, Loss: 3.4807748794555664, Grad L2 Norm: 0.020308809354901314
2025-11-23 23:17:23.587 | INFO     | __main__:<module>:160 - Step14670, Loss: 3.5742151737213135, Grad L2 Norm: 0.021098170429468155
2025-11-23 23:17:25.585 | INFO     | __main__:<module>:160 - Step14680, Loss: 3.4116835594177246, Grad L2 Norm: 0.021398814395070076
2025-11-23 23:17:27.587 | INFO     | __main__:<module>:160 - Step14690, Loss: 3.449847459793091, Grad L2 Norm: 0.021481327712535858
2025-11-23 23:17:29.588 | INFO     | __main__:<module>:160 - Step14700, Loss: 3.5763769149780273, Grad L2 Norm: 0.02061755210161209
2025-11-23 23:17:31.586 | INFO     | __main__:<module>:160 - Step14710, Loss: 3.504610538482666, Grad L2 Norm: 0.02240726165473461
2025-11-23 23:17:33.585 | INFO     | __main__:<module>:160 - Step14720, Loss: 3.757040023803711, Grad L2 Norm: 0.0228276364505291
2025-11-23 23:17:35.586 | INFO     | __main__:<module>:160 - Step14730, Loss: 3.560150146484375, Grad L2 Norm: 0.021422995254397392
2025-11-23 23:17:37.584 | INFO     | __main__:<module>:160 - Step14740, Loss: 3.597734212875366, Grad L2 Norm: 0.02088802494108677
2025-11-23 23:17:39.582 | INFO     | __main__:<module>:160 - Step14750, Loss: 3.5092079639434814, Grad L2 Norm: 0.02052321657538414
2025-11-23 23:17:41.579 | INFO     | __main__:<module>:160 - Step14760, Loss: 3.670788288116455, Grad L2 Norm: 0.02197321131825447
2025-11-23 23:17:43.580 | INFO     | __main__:<module>:160 - Step14770, Loss: 3.543382406234741, Grad L2 Norm: 0.02247282862663269
2025-11-23 23:17:45.582 | INFO     | __main__:<module>:160 - Step14780, Loss: 3.587702989578247, Grad L2 Norm: 0.02027762681245804
2025-11-23 23:17:47.579 | INFO     | __main__:<module>:160 - Step14790, Loss: 3.6269419193267822, Grad L2 Norm: 0.020030079409480095
2025-11-23 23:17:49.577 | INFO     | __main__:<module>:160 - Step14800, Loss: 3.615427017211914, Grad L2 Norm: 0.021868957206606865
2025-11-23 23:17:49.578 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:17:50.847 | INFO     | __main__:<module>:181 - validation loss: 3.628568148612976
2025-11-23 23:17:52.857 | INFO     | __main__:<module>:160 - Step14810, Loss: 3.676301956176758, Grad L2 Norm: 0.02103259786963463
2025-11-23 23:17:54.857 | INFO     | __main__:<module>:160 - Step14820, Loss: 3.624372720718384, Grad L2 Norm: 0.022636182606220245
2025-11-23 23:17:56.858 | INFO     | __main__:<module>:160 - Step14830, Loss: 3.656460762023926, Grad L2 Norm: 0.020439933985471725
2025-11-23 23:17:58.858 | INFO     | __main__:<module>:160 - Step14840, Loss: 3.470615863800049, Grad L2 Norm: 0.02064666897058487
2025-11-23 23:18:00.856 | INFO     | __main__:<module>:160 - Step14850, Loss: 3.576061487197876, Grad L2 Norm: 0.021782396361231804
2025-11-23 23:18:02.856 | INFO     | __main__:<module>:160 - Step14860, Loss: 3.5186333656311035, Grad L2 Norm: 0.020885486155748367
2025-11-23 23:18:04.855 | INFO     | __main__:<module>:160 - Step14870, Loss: 3.5003271102905273, Grad L2 Norm: 0.0208441112190485
2025-11-23 23:18:06.854 | INFO     | __main__:<module>:160 - Step14880, Loss: 3.6579549312591553, Grad L2 Norm: 0.024503936991095543
2025-11-23 23:18:08.851 | INFO     | __main__:<module>:160 - Step14890, Loss: 3.528623104095459, Grad L2 Norm: 0.021528271958231926
2025-11-23 23:18:10.851 | INFO     | __main__:<module>:160 - Step14900, Loss: 3.541116237640381, Grad L2 Norm: 0.021696098148822784
2025-11-23 23:18:12.850 | INFO     | __main__:<module>:160 - Step14910, Loss: 3.7801904678344727, Grad L2 Norm: 0.023450719192624092
2025-11-23 23:18:14.849 | INFO     | __main__:<module>:160 - Step14920, Loss: 3.651576519012451, Grad L2 Norm: 0.02235308103263378
2025-11-23 23:18:16.848 | INFO     | __main__:<module>:160 - Step14930, Loss: 3.5495710372924805, Grad L2 Norm: 0.020762495696544647
2025-11-23 23:18:18.845 | INFO     | __main__:<module>:160 - Step14940, Loss: 3.595691204071045, Grad L2 Norm: 0.02325119450688362
2025-11-23 23:18:20.846 | INFO     | __main__:<module>:160 - Step14950, Loss: 3.6844303607940674, Grad L2 Norm: 0.021891001611948013
2025-11-23 23:18:22.845 | INFO     | __main__:<module>:160 - Step14960, Loss: 3.7295725345611572, Grad L2 Norm: 0.023169107735157013
2025-11-23 23:18:24.846 | INFO     | __main__:<module>:160 - Step14970, Loss: 3.614011287689209, Grad L2 Norm: 0.021660715341567993
2025-11-23 23:18:26.846 | INFO     | __main__:<module>:160 - Step14980, Loss: 3.6263246536254883, Grad L2 Norm: 0.023171396926045418
2025-11-23 23:18:28.845 | INFO     | __main__:<module>:160 - Step14990, Loss: 3.491429328918457, Grad L2 Norm: 0.02086966298520565
2025-11-23 23:18:30.844 | INFO     | __main__:<module>:160 - Step15000, Loss: 3.6343002319335938, Grad L2 Norm: 0.02174651063978672
2025-11-23 23:18:32.843 | INFO     | __main__:<module>:160 - Step15010, Loss: 3.616494655609131, Grad L2 Norm: 0.020565547049045563
2025-11-23 23:18:34.844 | INFO     | __main__:<module>:160 - Step15020, Loss: 3.691394329071045, Grad L2 Norm: 0.02247454784810543
2025-11-23 23:18:36.841 | INFO     | __main__:<module>:160 - Step15030, Loss: 3.6628003120422363, Grad L2 Norm: 0.023287471383810043
2025-11-23 23:18:38.840 | INFO     | __main__:<module>:160 - Step15040, Loss: 3.5264978408813477, Grad L2 Norm: 0.0219158586114645
2025-11-23 23:18:40.840 | INFO     | __main__:<module>:160 - Step15050, Loss: 3.641819953918457, Grad L2 Norm: 0.021220089867711067
2025-11-23 23:18:42.839 | INFO     | __main__:<module>:160 - Step15060, Loss: 3.499415874481201, Grad L2 Norm: 0.02368347905576229
2025-11-23 23:18:44.838 | INFO     | __main__:<module>:160 - Step15070, Loss: 3.6328368186950684, Grad L2 Norm: 0.022621382027864456
2025-11-23 23:18:46.838 | INFO     | __main__:<module>:160 - Step15080, Loss: 3.699831247329712, Grad L2 Norm: 0.023152366280555725
2025-11-23 23:18:48.837 | INFO     | __main__:<module>:160 - Step15090, Loss: 3.5244927406311035, Grad L2 Norm: 0.02215389721095562
2025-11-23 23:18:50.839 | INFO     | __main__:<module>:160 - Step15100, Loss: 3.6234846115112305, Grad L2 Norm: 0.021045813336968422
2025-11-23 23:18:52.839 | INFO     | __main__:<module>:160 - Step15110, Loss: 3.5130326747894287, Grad L2 Norm: 0.022133009508252144
2025-11-23 23:18:54.838 | INFO     | __main__:<module>:160 - Step15120, Loss: 3.598231315612793, Grad L2 Norm: 0.021215716376900673
2025-11-23 23:18:56.837 | INFO     | __main__:<module>:160 - Step15130, Loss: 3.6439859867095947, Grad L2 Norm: 0.021284863352775574
2025-11-23 23:18:58.836 | INFO     | __main__:<module>:160 - Step15140, Loss: 3.666063070297241, Grad L2 Norm: 0.025733210146427155
2025-11-23 23:19:00.836 | INFO     | __main__:<module>:160 - Step15150, Loss: 3.618201971054077, Grad L2 Norm: 0.0210463497787714
2025-11-23 23:19:02.837 | INFO     | __main__:<module>:160 - Step15160, Loss: 3.728569507598877, Grad L2 Norm: 0.022956326603889465
2025-11-23 23:19:04.839 | INFO     | __main__:<module>:160 - Step15170, Loss: 3.6077933311462402, Grad L2 Norm: 0.02133825607597828
2025-11-23 23:19:06.843 | INFO     | __main__:<module>:160 - Step15180, Loss: 3.5880794525146484, Grad L2 Norm: 0.02113049291074276
2025-11-23 23:19:08.842 | INFO     | __main__:<module>:160 - Step15190, Loss: 3.6304550170898438, Grad L2 Norm: 0.020823951810598373
2025-11-23 23:19:10.849 | INFO     | __main__:<module>:160 - Step15200, Loss: 3.592515707015991, Grad L2 Norm: 0.02299167960882187
2025-11-23 23:19:10.850 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:19:12.122 | INFO     | __main__:<module>:181 - validation loss: 3.5915519118309023
2025-11-23 23:19:14.132 | INFO     | __main__:<module>:160 - Step15210, Loss: 3.632410764694214, Grad L2 Norm: 0.02062886208295822
2025-11-23 23:19:16.128 | INFO     | __main__:<module>:160 - Step15220, Loss: 3.5742111206054688, Grad L2 Norm: 0.023021049797534943
2025-11-23 23:19:18.128 | INFO     | __main__:<module>:160 - Step15230, Loss: 3.5859498977661133, Grad L2 Norm: 0.021425699815154076
2025-11-23 23:19:20.129 | INFO     | __main__:<module>:160 - Step15240, Loss: 3.5685412883758545, Grad L2 Norm: 0.021270303055644035
2025-11-23 23:19:22.126 | INFO     | __main__:<module>:160 - Step15250, Loss: 3.559380531311035, Grad L2 Norm: 0.020249973982572556
2025-11-23 23:19:24.127 | INFO     | __main__:<module>:160 - Step15260, Loss: 3.6459782123565674, Grad L2 Norm: 0.021837009117007256
2025-11-23 23:19:26.125 | INFO     | __main__:<module>:160 - Step15270, Loss: 3.576307773590088, Grad L2 Norm: 0.021483778953552246
2025-11-23 23:19:28.125 | INFO     | __main__:<module>:160 - Step15280, Loss: 3.6445436477661133, Grad L2 Norm: 0.019890381023287773
2025-11-23 23:19:30.126 | INFO     | __main__:<module>:160 - Step15290, Loss: 3.5252323150634766, Grad L2 Norm: 0.01952080801129341
2025-11-23 23:19:32.125 | INFO     | __main__:<module>:160 - Step15300, Loss: 3.558215618133545, Grad L2 Norm: 0.02142988331615925
2025-11-23 23:19:34.124 | INFO     | __main__:<module>:160 - Step15310, Loss: 3.6669154167175293, Grad L2 Norm: 0.02380821295082569
2025-11-23 23:19:36.124 | INFO     | __main__:<module>:160 - Step15320, Loss: 3.654384136199951, Grad L2 Norm: 0.020062381401658058
2025-11-23 23:19:38.122 | INFO     | __main__:<module>:160 - Step15330, Loss: 3.6586508750915527, Grad L2 Norm: 0.021445520222187042
2025-11-23 23:19:40.121 | INFO     | __main__:<module>:160 - Step15340, Loss: 3.7210612297058105, Grad L2 Norm: 0.021359803155064583
2025-11-23 23:19:42.122 | INFO     | __main__:<module>:160 - Step15350, Loss: 3.592556953430176, Grad L2 Norm: 0.02009093016386032
2025-11-23 23:19:44.121 | INFO     | __main__:<module>:160 - Step15360, Loss: 3.64756441116333, Grad L2 Norm: 0.021929549053311348
2025-11-23 23:19:46.120 | INFO     | __main__:<module>:160 - Step15370, Loss: 3.6686646938323975, Grad L2 Norm: 0.021510936319828033
2025-11-23 23:19:48.122 | INFO     | __main__:<module>:160 - Step15380, Loss: 3.7010483741760254, Grad L2 Norm: 0.022251874208450317
2025-11-23 23:19:50.120 | INFO     | __main__:<module>:160 - Step15390, Loss: 3.710448980331421, Grad L2 Norm: 0.02195853367447853
2025-11-23 23:19:52.118 | INFO     | __main__:<module>:160 - Step15400, Loss: 3.5255086421966553, Grad L2 Norm: 0.023988965898752213
2025-11-23 23:19:54.116 | INFO     | __main__:<module>:160 - Step15410, Loss: 3.654649019241333, Grad L2 Norm: 0.021992821246385574
2025-11-23 23:19:56.117 | INFO     | __main__:<module>:160 - Step15420, Loss: 3.533080816268921, Grad L2 Norm: 0.022113075479865074
2025-11-23 23:19:58.118 | INFO     | __main__:<module>:160 - Step15430, Loss: 3.544367790222168, Grad L2 Norm: 0.019999902695417404
2025-11-23 23:20:00.119 | INFO     | __main__:<module>:160 - Step15440, Loss: 3.6184146404266357, Grad L2 Norm: 0.02176959440112114
2025-11-23 23:20:02.120 | INFO     | __main__:<module>:160 - Step15450, Loss: 3.632481098175049, Grad L2 Norm: 0.021286919713020325
2025-11-23 23:20:04.120 | INFO     | __main__:<module>:160 - Step15460, Loss: 3.674159288406372, Grad L2 Norm: 0.021590104326605797
2025-11-23 23:20:06.120 | INFO     | __main__:<module>:160 - Step15470, Loss: 3.5925278663635254, Grad L2 Norm: 0.022901169955730438
2025-11-23 23:20:08.118 | INFO     | __main__:<module>:160 - Step15480, Loss: 3.6607704162597656, Grad L2 Norm: 0.021979983896017075
2025-11-23 23:20:10.117 | INFO     | __main__:<module>:160 - Step15490, Loss: 3.6729254722595215, Grad L2 Norm: 0.02147594653069973
2025-11-23 23:20:12.117 | INFO     | __main__:<module>:160 - Step15500, Loss: 3.514185905456543, Grad L2 Norm: 0.021426010876893997
2025-11-23 23:20:14.114 | INFO     | __main__:<module>:160 - Step15510, Loss: 3.7285311222076416, Grad L2 Norm: 0.02249937504529953
2025-11-23 23:20:16.114 | INFO     | __main__:<module>:160 - Step15520, Loss: 3.4890027046203613, Grad L2 Norm: 0.02064542844891548
2025-11-23 23:20:18.114 | INFO     | __main__:<module>:160 - Step15530, Loss: 3.5056543350219727, Grad L2 Norm: 0.021325992420315742
2025-11-23 23:20:20.112 | INFO     | __main__:<module>:160 - Step15540, Loss: 3.6149649620056152, Grad L2 Norm: 0.02165963128209114
2025-11-23 23:20:22.113 | INFO     | __main__:<module>:160 - Step15550, Loss: 3.5882275104522705, Grad L2 Norm: 0.023053821176290512
2025-11-23 23:20:24.113 | INFO     | __main__:<module>:160 - Step15560, Loss: 3.4996862411499023, Grad L2 Norm: 0.02105957642197609
2025-11-23 23:20:26.113 | INFO     | __main__:<module>:160 - Step15570, Loss: 3.7562689781188965, Grad L2 Norm: 0.022762352600693703
2025-11-23 23:20:28.110 | INFO     | __main__:<module>:160 - Step15580, Loss: 3.643152952194214, Grad L2 Norm: 0.020709006115794182
2025-11-23 23:20:30.110 | INFO     | __main__:<module>:160 - Step15590, Loss: 3.6167101860046387, Grad L2 Norm: 0.02252829261124134
2025-11-23 23:20:32.111 | INFO     | __main__:<module>:160 - Step15600, Loss: 3.6992552280426025, Grad L2 Norm: 0.02214382402598858
2025-11-23 23:20:32.112 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:20:33.381 | INFO     | __main__:<module>:181 - validation loss: 3.5992644309997557
2025-11-23 23:20:35.389 | INFO     | __main__:<module>:160 - Step15610, Loss: 3.531139373779297, Grad L2 Norm: 0.020244915038347244
2025-11-23 23:20:37.389 | INFO     | __main__:<module>:160 - Step15620, Loss: 3.6289305686950684, Grad L2 Norm: 0.021207742393016815
2025-11-23 23:20:39.389 | INFO     | __main__:<module>:160 - Step15630, Loss: 3.6733286380767822, Grad L2 Norm: 0.022886015474796295
2025-11-23 23:20:41.388 | INFO     | __main__:<module>:160 - Step15640, Loss: 3.488551378250122, Grad L2 Norm: 0.02104940079152584
2025-11-23 23:20:43.387 | INFO     | __main__:<module>:160 - Step15650, Loss: 3.6120293140411377, Grad L2 Norm: 0.021677592769265175
2025-11-23 23:20:45.386 | INFO     | __main__:<module>:160 - Step15660, Loss: 3.6124353408813477, Grad L2 Norm: 0.021796608343720436
2025-11-23 23:20:47.382 | INFO     | __main__:<module>:160 - Step15670, Loss: 3.6060659885406494, Grad L2 Norm: 0.020513612776994705
2025-11-23 23:20:49.382 | INFO     | __main__:<module>:160 - Step15680, Loss: 3.5309367179870605, Grad L2 Norm: 0.022538205608725548
2025-11-23 23:20:51.381 | INFO     | __main__:<module>:160 - Step15690, Loss: 3.4591126441955566, Grad L2 Norm: 0.022059405222535133
2025-11-23 23:20:53.380 | INFO     | __main__:<module>:160 - Step15700, Loss: 3.644153356552124, Grad L2 Norm: 0.02193540893495083
2025-11-23 23:20:55.382 | INFO     | __main__:<module>:160 - Step15710, Loss: 3.563932418823242, Grad L2 Norm: 0.021569518372416496
2025-11-23 23:20:57.380 | INFO     | __main__:<module>:160 - Step15720, Loss: 3.4356689453125, Grad L2 Norm: 0.02135096862912178
2025-11-23 23:20:59.381 | INFO     | __main__:<module>:160 - Step15730, Loss: 3.613011360168457, Grad L2 Norm: 0.02140180580317974
2025-11-23 23:21:01.379 | INFO     | __main__:<module>:160 - Step15740, Loss: 3.518998146057129, Grad L2 Norm: 0.02074473351240158
2025-11-23 23:21:03.378 | INFO     | __main__:<module>:160 - Step15750, Loss: 3.6262004375457764, Grad L2 Norm: 0.021992960944771767
2025-11-23 23:21:05.377 | INFO     | __main__:<module>:160 - Step15760, Loss: 3.4845809936523438, Grad L2 Norm: 0.021933214738965034
2025-11-23 23:21:07.375 | INFO     | __main__:<module>:160 - Step15770, Loss: 3.420119524002075, Grad L2 Norm: 0.022548982873558998
2025-11-23 23:21:09.375 | INFO     | __main__:<module>:160 - Step15780, Loss: 3.59134840965271, Grad L2 Norm: 0.020450802519917488
2025-11-23 23:21:11.378 | INFO     | __main__:<module>:160 - Step15790, Loss: 3.66691255569458, Grad L2 Norm: 0.020896172150969505
2025-11-23 23:21:13.377 | INFO     | __main__:<module>:160 - Step15800, Loss: 3.581620216369629, Grad L2 Norm: 0.021899376064538956
2025-11-23 23:21:15.377 | INFO     | __main__:<module>:160 - Step15810, Loss: 3.576183557510376, Grad L2 Norm: 0.022053426131606102
2025-11-23 23:21:17.379 | INFO     | __main__:<module>:160 - Step15820, Loss: 3.6573829650878906, Grad L2 Norm: 0.021697672083973885
2025-11-23 23:21:19.378 | INFO     | __main__:<module>:160 - Step15830, Loss: 3.5156044960021973, Grad L2 Norm: 0.02151229977607727
2025-11-23 23:21:21.377 | INFO     | __main__:<module>:160 - Step15840, Loss: 3.486152410507202, Grad L2 Norm: 0.02113160490989685
2025-11-23 23:21:23.377 | INFO     | __main__:<module>:160 - Step15850, Loss: 3.7126240730285645, Grad L2 Norm: 0.021222304552793503
2025-11-23 23:21:25.380 | INFO     | __main__:<module>:160 - Step15860, Loss: 3.592344045639038, Grad L2 Norm: 0.02174423262476921
2025-11-23 23:21:27.379 | INFO     | __main__:<module>:160 - Step15870, Loss: 3.578731060028076, Grad L2 Norm: 0.02222202904522419
2025-11-23 23:21:29.378 | INFO     | __main__:<module>:160 - Step15880, Loss: 3.575338363647461, Grad L2 Norm: 0.021931907162070274
2025-11-23 23:21:31.377 | INFO     | __main__:<module>:160 - Step15890, Loss: 3.649522304534912, Grad L2 Norm: 0.02182144485414028
2025-11-23 23:21:33.377 | INFO     | __main__:<module>:160 - Step15900, Loss: 3.6043972969055176, Grad L2 Norm: 0.022010058164596558
2025-11-23 23:21:35.377 | INFO     | __main__:<module>:160 - Step15910, Loss: 3.5257458686828613, Grad L2 Norm: 0.02218611352145672
2025-11-23 23:21:37.381 | INFO     | __main__:<module>:160 - Step15920, Loss: 3.6655139923095703, Grad L2 Norm: 0.023273887112736702
2025-11-23 23:21:39.389 | INFO     | __main__:<module>:160 - Step15930, Loss: 3.5564019680023193, Grad L2 Norm: 0.022976044565439224
2025-11-23 23:21:41.391 | INFO     | __main__:<module>:160 - Step15940, Loss: 3.5622010231018066, Grad L2 Norm: 0.020882850512862206
2025-11-23 23:21:43.394 | INFO     | __main__:<module>:160 - Step15950, Loss: 3.540342092514038, Grad L2 Norm: 0.021936465054750443
2025-11-23 23:21:45.396 | INFO     | __main__:<module>:160 - Step15960, Loss: 3.6310696601867676, Grad L2 Norm: 0.022095972672104836
2025-11-23 23:21:47.402 | INFO     | __main__:<module>:160 - Step15970, Loss: 3.5672473907470703, Grad L2 Norm: 0.020926959812641144
2025-11-23 23:21:49.409 | INFO     | __main__:<module>:160 - Step15980, Loss: 3.520109176635742, Grad L2 Norm: 0.02132938802242279
2025-11-23 23:21:51.417 | INFO     | __main__:<module>:160 - Step15990, Loss: 3.6313230991363525, Grad L2 Norm: 0.02170133963227272
2025-11-23 23:21:53.427 | INFO     | __main__:<module>:160 - Step16000, Loss: 3.6552393436431885, Grad L2 Norm: 0.02125338278710842
2025-11-23 23:21:53.427 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:21:54.706 | INFO     | __main__:<module>:181 - validation loss: 3.6063212394714355
2025-11-23 23:21:54.706 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_16000.pt
2025-11-23 23:21:56.359 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-23 23:21:58.345 | INFO     | __main__:<module>:160 - Step16010, Loss: 3.7331361770629883, Grad L2 Norm: 0.022501636296510696
2025-11-23 23:22:00.353 | INFO     | __main__:<module>:160 - Step16020, Loss: 3.6028246879577637, Grad L2 Norm: 0.01980365812778473
2025-11-23 23:22:02.362 | INFO     | __main__:<module>:160 - Step16030, Loss: 3.6203041076660156, Grad L2 Norm: 0.021803703159093857
2025-11-23 23:22:04.365 | INFO     | __main__:<module>:160 - Step16040, Loss: 3.539388656616211, Grad L2 Norm: 0.020753219723701477
2025-11-23 23:22:06.367 | INFO     | __main__:<module>:160 - Step16050, Loss: 3.588653087615967, Grad L2 Norm: 0.02224782668054104
2025-11-23 23:22:08.368 | INFO     | __main__:<module>:160 - Step16060, Loss: 3.6806674003601074, Grad L2 Norm: 0.023286381736397743
2025-11-23 23:22:10.368 | INFO     | __main__:<module>:160 - Step16070, Loss: 3.769336700439453, Grad L2 Norm: 0.021691761910915375
2025-11-23 23:22:12.374 | INFO     | __main__:<module>:160 - Step16080, Loss: 3.472456932067871, Grad L2 Norm: 0.020642001181840897
2025-11-23 23:22:14.378 | INFO     | __main__:<module>:160 - Step16090, Loss: 3.646177053451538, Grad L2 Norm: 0.02344793640077114
2025-11-23 23:22:16.378 | INFO     | __main__:<module>:160 - Step16100, Loss: 3.565103054046631, Grad L2 Norm: 0.020117491483688354
2025-11-23 23:22:18.377 | INFO     | __main__:<module>:160 - Step16110, Loss: 3.6382622718811035, Grad L2 Norm: 0.020457591861486435
2025-11-23 23:22:20.380 | INFO     | __main__:<module>:160 - Step16120, Loss: 3.6003823280334473, Grad L2 Norm: 0.021763935685157776
2025-11-23 23:22:22.383 | INFO     | __main__:<module>:160 - Step16130, Loss: 3.674952983856201, Grad L2 Norm: 0.02249179221689701
2025-11-23 23:22:24.386 | INFO     | __main__:<module>:160 - Step16140, Loss: 3.609013080596924, Grad L2 Norm: 0.020985916256904602
2025-11-23 23:22:26.393 | INFO     | __main__:<module>:160 - Step16150, Loss: 3.6065001487731934, Grad L2 Norm: 0.022001735866069794
2025-11-23 23:22:28.398 | INFO     | __main__:<module>:160 - Step16160, Loss: 3.7023472785949707, Grad L2 Norm: 0.02383103407919407
2025-11-23 23:22:30.399 | INFO     | __main__:<module>:160 - Step16170, Loss: 3.5769591331481934, Grad L2 Norm: 0.021396202966570854
2025-11-23 23:22:32.398 | INFO     | __main__:<module>:160 - Step16180, Loss: 3.562514305114746, Grad L2 Norm: 0.020239856094121933
2025-11-23 23:22:34.399 | INFO     | __main__:<module>:160 - Step16190, Loss: 3.562455654144287, Grad L2 Norm: 0.02163204550743103
2025-11-23 23:22:36.399 | INFO     | __main__:<module>:160 - Step16200, Loss: 3.4829559326171875, Grad L2 Norm: 0.022334808483719826
2025-11-23 23:22:38.396 | INFO     | __main__:<module>:160 - Step16210, Loss: 3.4603092670440674, Grad L2 Norm: 0.018999917432665825
2025-11-23 23:22:40.392 | INFO     | __main__:<module>:160 - Step16220, Loss: 3.5140061378479004, Grad L2 Norm: 0.02159460261464119
2025-11-23 23:22:42.392 | INFO     | __main__:<module>:160 - Step16230, Loss: 3.5441792011260986, Grad L2 Norm: 0.021193966269493103
2025-11-23 23:22:44.392 | INFO     | __main__:<module>:160 - Step16240, Loss: 3.5948662757873535, Grad L2 Norm: 0.022952891886234283
2025-11-23 23:22:46.393 | INFO     | __main__:<module>:160 - Step16250, Loss: 3.598834753036499, Grad L2 Norm: 0.020836517214775085
2025-11-23 23:22:48.393 | INFO     | __main__:<module>:160 - Step16260, Loss: 3.4873299598693848, Grad L2 Norm: 0.02047727257013321
2025-11-23 23:22:50.395 | INFO     | __main__:<module>:160 - Step16270, Loss: 3.5381810665130615, Grad L2 Norm: 0.02164452150464058
2025-11-23 23:22:52.400 | INFO     | __main__:<module>:160 - Step16280, Loss: 3.534698009490967, Grad L2 Norm: 0.021335022523999214
2025-11-23 23:22:54.405 | INFO     | __main__:<module>:160 - Step16290, Loss: 3.6910433769226074, Grad L2 Norm: 0.02205054648220539
2025-11-23 23:22:56.405 | INFO     | __main__:<module>:160 - Step16300, Loss: 3.7209014892578125, Grad L2 Norm: 0.02295551635324955
2025-11-23 23:22:58.408 | INFO     | __main__:<module>:160 - Step16310, Loss: 3.7716610431671143, Grad L2 Norm: 0.022642452269792557
2025-11-23 23:23:00.411 | INFO     | __main__:<module>:160 - Step16320, Loss: 3.558870792388916, Grad L2 Norm: 0.02190052717924118
2025-11-23 23:23:02.408 | INFO     | __main__:<module>:160 - Step16330, Loss: 3.502093553543091, Grad L2 Norm: 0.023460200056433678
2025-11-23 23:23:04.406 | INFO     | __main__:<module>:160 - Step16340, Loss: 3.6481003761291504, Grad L2 Norm: 0.02151246927678585
2025-11-23 23:23:06.405 | INFO     | __main__:<module>:160 - Step16350, Loss: 3.619791269302368, Grad L2 Norm: 0.023470625281333923
2025-11-23 23:23:08.405 | INFO     | __main__:<module>:160 - Step16360, Loss: 3.611828565597534, Grad L2 Norm: 0.021809030324220657
2025-11-23 23:23:10.405 | INFO     | __main__:<module>:160 - Step16370, Loss: 3.696528911590576, Grad L2 Norm: 0.02249927632510662
2025-11-23 23:23:12.404 | INFO     | __main__:<module>:160 - Step16380, Loss: 3.517059803009033, Grad L2 Norm: 0.02190111018717289
2025-11-23 23:23:14.402 | INFO     | __main__:<module>:160 - Step16390, Loss: 3.7249276638031006, Grad L2 Norm: 0.022427432239055634
2025-11-23 23:23:16.402 | INFO     | __main__:<module>:160 - Step16400, Loss: 3.670729637145996, Grad L2 Norm: 0.022443411871790886
2025-11-23 23:23:16.403 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:23:17.679 | INFO     | __main__:<module>:181 - validation loss: 3.5802291870117187
2025-11-23 23:23:19.697 | INFO     | __main__:<module>:160 - Step16410, Loss: 3.624997615814209, Grad L2 Norm: 0.02161528915166855
2025-11-23 23:23:21.702 | INFO     | __main__:<module>:160 - Step16420, Loss: 3.560361623764038, Grad L2 Norm: 0.0227795597165823
2025-11-23 23:23:23.705 | INFO     | __main__:<module>:160 - Step16430, Loss: 3.574042558670044, Grad L2 Norm: 0.021414203569293022
2025-11-23 23:23:25.717 | INFO     | __main__:<module>:160 - Step16440, Loss: 3.673964500427246, Grad L2 Norm: 0.020828036591410637
2025-11-23 23:23:27.720 | INFO     | __main__:<module>:160 - Step16450, Loss: 3.6411056518554688, Grad L2 Norm: 0.02118387073278427
2025-11-23 23:23:29.722 | INFO     | __main__:<module>:160 - Step16460, Loss: 3.565962791442871, Grad L2 Norm: 0.023829322308301926
2025-11-23 23:23:31.725 | INFO     | __main__:<module>:160 - Step16470, Loss: 3.595196485519409, Grad L2 Norm: 0.020385676994919777
2025-11-23 23:23:33.737 | INFO     | __main__:<module>:160 - Step16480, Loss: 3.726590633392334, Grad L2 Norm: 0.02510443702340126
2025-11-23 23:23:35.740 | INFO     | __main__:<module>:160 - Step16490, Loss: 3.5829687118530273, Grad L2 Norm: 0.020921820774674416
2025-11-23 23:23:37.751 | INFO     | __main__:<module>:160 - Step16500, Loss: 3.713278293609619, Grad L2 Norm: 0.020835762843489647
2025-11-23 23:23:39.758 | INFO     | __main__:<module>:160 - Step16510, Loss: 3.75504732131958, Grad L2 Norm: 0.02350246161222458
2025-11-23 23:23:41.762 | INFO     | __main__:<module>:160 - Step16520, Loss: 3.6023075580596924, Grad L2 Norm: 0.02137448452413082
2025-11-23 23:23:43.773 | INFO     | __main__:<module>:160 - Step16530, Loss: 3.614272356033325, Grad L2 Norm: 0.021680451929569244
2025-11-23 23:23:45.779 | INFO     | __main__:<module>:160 - Step16540, Loss: 3.7023050785064697, Grad L2 Norm: 0.022338418290019035
2025-11-23 23:23:47.792 | INFO     | __main__:<module>:160 - Step16550, Loss: 3.534353494644165, Grad L2 Norm: 0.02202094905078411
2025-11-23 23:23:49.793 | INFO     | __main__:<module>:160 - Step16560, Loss: 3.603710174560547, Grad L2 Norm: 0.023143429309129715
2025-11-23 23:23:51.795 | INFO     | __main__:<module>:160 - Step16570, Loss: 3.6661581993103027, Grad L2 Norm: 0.022453678771853447
2025-11-23 23:23:53.796 | INFO     | __main__:<module>:160 - Step16580, Loss: 3.6366968154907227, Grad L2 Norm: 0.022710703313350677
2025-11-23 23:23:55.799 | INFO     | __main__:<module>:160 - Step16590, Loss: 3.5869193077087402, Grad L2 Norm: 0.021812142804265022
2025-11-23 23:23:57.807 | INFO     | __main__:<module>:160 - Step16600, Loss: 3.6522462368011475, Grad L2 Norm: 0.022419465705752373
2025-11-23 23:23:59.812 | INFO     | __main__:<module>:160 - Step16610, Loss: 3.6013169288635254, Grad L2 Norm: 0.02316667139530182
2025-11-23 23:24:01.814 | INFO     | __main__:<module>:160 - Step16620, Loss: 3.5950992107391357, Grad L2 Norm: 0.022526388987898827
2025-11-23 23:24:03.822 | INFO     | __main__:<module>:160 - Step16630, Loss: 3.541962146759033, Grad L2 Norm: 0.021281680092215538
2025-11-23 23:24:05.828 | INFO     | __main__:<module>:160 - Step16640, Loss: 3.666686534881592, Grad L2 Norm: 0.020860178396105766
2025-11-23 23:24:07.836 | INFO     | __main__:<module>:160 - Step16650, Loss: 3.5570459365844727, Grad L2 Norm: 0.02083667926490307
2025-11-23 23:24:09.848 | INFO     | __main__:<module>:160 - Step16660, Loss: 3.63977313041687, Grad L2 Norm: 0.024841420352458954
2025-11-23 23:24:11.857 | INFO     | __main__:<module>:160 - Step16670, Loss: 3.592957019805908, Grad L2 Norm: 0.021643562242388725
2025-11-23 23:24:13.865 | INFO     | __main__:<module>:160 - Step16680, Loss: 3.726919651031494, Grad L2 Norm: 0.025354286655783653
2025-11-23 23:24:15.872 | INFO     | __main__:<module>:160 - Step16690, Loss: 3.662400245666504, Grad L2 Norm: 0.023707719519734383
2025-11-23 23:24:17.884 | INFO     | __main__:<module>:160 - Step16700, Loss: 3.4759438037872314, Grad L2 Norm: 0.02190481685101986
2025-11-23 23:24:19.899 | INFO     | __main__:<module>:160 - Step16710, Loss: 3.669485569000244, Grad L2 Norm: 0.021870262920856476
2025-11-23 23:24:21.908 | INFO     | __main__:<module>:160 - Step16720, Loss: 3.619183301925659, Grad L2 Norm: 0.02119567058980465
2025-11-23 23:24:23.918 | INFO     | __main__:<module>:160 - Step16730, Loss: 3.462472915649414, Grad L2 Norm: 0.02070930041372776
2025-11-23 23:24:25.923 | INFO     | __main__:<module>:160 - Step16740, Loss: 3.5244123935699463, Grad L2 Norm: 0.02330569364130497
2025-11-23 23:24:27.934 | INFO     | __main__:<module>:160 - Step16750, Loss: 3.592970132827759, Grad L2 Norm: 0.021960683166980743
2025-11-23 23:24:29.943 | INFO     | __main__:<module>:160 - Step16760, Loss: 3.5075523853302, Grad L2 Norm: 0.01996142975986004
2025-11-23 23:24:31.944 | INFO     | __main__:<module>:160 - Step16770, Loss: 3.575015068054199, Grad L2 Norm: 0.021140316501259804
2025-11-23 23:24:33.955 | INFO     | __main__:<module>:160 - Step16780, Loss: 3.569847583770752, Grad L2 Norm: 0.02253122627735138
2025-11-23 23:24:35.961 | INFO     | __main__:<module>:160 - Step16790, Loss: 3.58689022064209, Grad L2 Norm: 0.02130701020359993
2025-11-23 23:24:37.967 | INFO     | __main__:<module>:160 - Step16800, Loss: 3.663423538208008, Grad L2 Norm: 0.020998962223529816
2025-11-23 23:24:37.968 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:24:39.245 | INFO     | __main__:<module>:181 - validation loss: 3.6161262154579163
2025-11-23 23:24:41.259 | INFO     | __main__:<module>:160 - Step16810, Loss: 3.615544319152832, Grad L2 Norm: 0.01990908943116665
2025-11-23 23:24:43.266 | INFO     | __main__:<module>:160 - Step16820, Loss: 3.5733723640441895, Grad L2 Norm: 0.02210799790918827
2025-11-23 23:24:45.274 | INFO     | __main__:<module>:160 - Step16830, Loss: 3.486698627471924, Grad L2 Norm: 0.02035425789654255
2025-11-23 23:24:47.279 | INFO     | __main__:<module>:160 - Step16840, Loss: 3.753239154815674, Grad L2 Norm: 0.022525280714035034
2025-11-23 23:24:49.281 | INFO     | __main__:<module>:160 - Step16850, Loss: 3.6354541778564453, Grad L2 Norm: 0.021191902458667755
2025-11-23 23:24:51.280 | INFO     | __main__:<module>:160 - Step16860, Loss: 3.4272472858428955, Grad L2 Norm: 0.022184347733855247
2025-11-23 23:24:53.289 | INFO     | __main__:<module>:160 - Step16870, Loss: 3.502502202987671, Grad L2 Norm: 0.021406248211860657
2025-11-23 23:24:55.296 | INFO     | __main__:<module>:160 - Step16880, Loss: 3.7105424404144287, Grad L2 Norm: 0.02128453180193901
2025-11-23 23:24:57.300 | INFO     | __main__:<module>:160 - Step16890, Loss: 3.6789114475250244, Grad L2 Norm: 0.021414540708065033
2025-11-23 23:24:59.310 | INFO     | __main__:<module>:160 - Step16900, Loss: 3.6165108680725098, Grad L2 Norm: 0.022129211574792862
2025-11-23 23:25:01.320 | INFO     | __main__:<module>:160 - Step16910, Loss: 3.5945725440979004, Grad L2 Norm: 0.021603181958198547
2025-11-23 23:25:03.328 | INFO     | __main__:<module>:160 - Step16920, Loss: 3.676283359527588, Grad L2 Norm: 0.019536137580871582
2025-11-23 23:25:05.333 | INFO     | __main__:<module>:160 - Step16930, Loss: 3.4878151416778564, Grad L2 Norm: 0.024065235629677773
2025-11-23 23:25:07.339 | INFO     | __main__:<module>:160 - Step16940, Loss: 3.523906946182251, Grad L2 Norm: 0.022180631756782532
2025-11-23 23:25:09.347 | INFO     | __main__:<module>:160 - Step16950, Loss: 3.6414332389831543, Grad L2 Norm: 0.02126239985227585
2025-11-23 23:25:11.353 | INFO     | __main__:<module>:160 - Step16960, Loss: 3.485945224761963, Grad L2 Norm: 0.021654026582837105
2025-11-23 23:25:13.356 | INFO     | __main__:<module>:160 - Step16970, Loss: 3.546405076980591, Grad L2 Norm: 0.021010858938097954
2025-11-23 23:25:15.361 | INFO     | __main__:<module>:160 - Step16980, Loss: 3.5742156505584717, Grad L2 Norm: 0.02189009077847004
2025-11-23 23:25:17.364 | INFO     | __main__:<module>:160 - Step16990, Loss: 3.5769035816192627, Grad L2 Norm: 0.020901797339320183
2025-11-23 23:25:19.366 | INFO     | __main__:<module>:160 - Step17000, Loss: 3.7031073570251465, Grad L2 Norm: 0.020271798595786095
2025-11-23 23:25:21.365 | INFO     | __main__:<module>:160 - Step17010, Loss: 3.6071362495422363, Grad L2 Norm: 0.024235853925347328
2025-11-23 23:25:23.366 | INFO     | __main__:<module>:160 - Step17020, Loss: 3.6550424098968506, Grad L2 Norm: 0.020850522443652153
2025-11-23 23:25:25.366 | INFO     | __main__:<module>:160 - Step17030, Loss: 3.6702370643615723, Grad L2 Norm: 0.021999655291438103
2025-11-23 23:25:27.368 | INFO     | __main__:<module>:160 - Step17040, Loss: 3.629556655883789, Grad L2 Norm: 0.023433873429894447
2025-11-23 23:25:29.368 | INFO     | __main__:<module>:160 - Step17050, Loss: 3.544201374053955, Grad L2 Norm: 0.022948579862713814
2025-11-23 23:25:31.367 | INFO     | __main__:<module>:160 - Step17060, Loss: 3.65181303024292, Grad L2 Norm: 0.021891452372074127
2025-11-23 23:25:33.366 | INFO     | __main__:<module>:160 - Step17070, Loss: 3.536604404449463, Grad L2 Norm: 0.021362578496336937
2025-11-23 23:25:35.363 | INFO     | __main__:<module>:160 - Step17080, Loss: 3.4950625896453857, Grad L2 Norm: 0.022280532866716385
2025-11-23 23:25:37.361 | INFO     | __main__:<module>:160 - Step17090, Loss: 3.580448627471924, Grad L2 Norm: 0.020536212250590324
2025-11-23 23:25:39.361 | INFO     | __main__:<module>:160 - Step17100, Loss: 3.598482847213745, Grad L2 Norm: 0.022458508610725403
2025-11-23 23:25:41.360 | INFO     | __main__:<module>:160 - Step17110, Loss: 3.6470699310302734, Grad L2 Norm: 0.022971630096435547
2025-11-23 23:25:43.360 | INFO     | __main__:<module>:160 - Step17120, Loss: 3.607149600982666, Grad L2 Norm: 0.022755661979317665
2025-11-23 23:25:45.360 | INFO     | __main__:<module>:160 - Step17130, Loss: 3.6825406551361084, Grad L2 Norm: 0.023141369223594666
2025-11-23 23:25:47.359 | INFO     | __main__:<module>:160 - Step17140, Loss: 3.631856918334961, Grad L2 Norm: 0.021930783987045288
2025-11-23 23:25:49.358 | INFO     | __main__:<module>:160 - Step17150, Loss: 3.543159008026123, Grad L2 Norm: 0.0204720888286829
2025-11-23 23:25:51.357 | INFO     | __main__:<module>:160 - Step17160, Loss: 3.55055570602417, Grad L2 Norm: 0.02042689360678196
2025-11-23 23:25:53.355 | INFO     | __main__:<module>:160 - Step17170, Loss: 3.518367290496826, Grad L2 Norm: 0.02286544255912304
2025-11-23 23:25:55.356 | INFO     | __main__:<module>:160 - Step17180, Loss: 3.6344008445739746, Grad L2 Norm: 0.021705925464630127
2025-11-23 23:25:57.355 | INFO     | __main__:<module>:160 - Step17190, Loss: 3.481886386871338, Grad L2 Norm: 0.02184760570526123
2025-11-23 23:25:59.355 | INFO     | __main__:<module>:160 - Step17200, Loss: 3.593313217163086, Grad L2 Norm: 0.02184249646961689
2025-11-23 23:25:59.356 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:26:00.626 | INFO     | __main__:<module>:181 - validation loss: 3.5798890590667725
2025-11-23 23:26:02.637 | INFO     | __main__:<module>:160 - Step17210, Loss: 3.6042871475219727, Grad L2 Norm: 0.02102254517376423
2025-11-23 23:26:04.636 | INFO     | __main__:<module>:160 - Step17220, Loss: 3.544126272201538, Grad L2 Norm: 0.02049451693892479
2025-11-23 23:26:06.633 | INFO     | __main__:<module>:160 - Step17230, Loss: 3.5461843013763428, Grad L2 Norm: 0.02117113582789898
2025-11-23 23:26:08.632 | INFO     | __main__:<module>:160 - Step17240, Loss: 3.5135560035705566, Grad L2 Norm: 0.021032745018601418
2025-11-23 23:26:10.633 | INFO     | __main__:<module>:160 - Step17250, Loss: 3.5575931072235107, Grad L2 Norm: 0.021712498739361763
2025-11-23 23:26:12.636 | INFO     | __main__:<module>:160 - Step17260, Loss: 3.6913304328918457, Grad L2 Norm: 0.022314762696623802
2025-11-23 23:26:14.644 | INFO     | __main__:<module>:160 - Step17270, Loss: 3.5265727043151855, Grad L2 Norm: 0.02072206884622574
2025-11-23 23:26:16.650 | INFO     | __main__:<module>:160 - Step17280, Loss: 3.548004627227783, Grad L2 Norm: 0.02158881537616253
2025-11-23 23:26:18.649 | INFO     | __main__:<module>:160 - Step17290, Loss: 3.607235908508301, Grad L2 Norm: 0.020760534331202507
2025-11-23 23:26:20.649 | INFO     | __main__:<module>:160 - Step17300, Loss: 3.6133673191070557, Grad L2 Norm: 0.022235412150621414
2025-11-23 23:26:22.648 | INFO     | __main__:<module>:160 - Step17310, Loss: 3.708761215209961, Grad L2 Norm: 0.023625949397683144
2025-11-23 23:26:24.647 | INFO     | __main__:<module>:160 - Step17320, Loss: 3.6089301109313965, Grad L2 Norm: 0.023148946464061737
2025-11-23 23:26:26.647 | INFO     | __main__:<module>:160 - Step17330, Loss: 3.490382671356201, Grad L2 Norm: 0.020750047639012337
2025-11-23 23:26:28.647 | INFO     | __main__:<module>:160 - Step17340, Loss: 3.63139271736145, Grad L2 Norm: 0.0207031462341547
2025-11-23 23:26:30.647 | INFO     | __main__:<module>:160 - Step17350, Loss: 3.7100768089294434, Grad L2 Norm: 0.020624281838536263
2025-11-23 23:26:32.648 | INFO     | __main__:<module>:160 - Step17360, Loss: 3.5108141899108887, Grad L2 Norm: 0.020818032324314117
2025-11-23 23:26:34.648 | INFO     | __main__:<module>:160 - Step17370, Loss: 3.551605224609375, Grad L2 Norm: 0.022263338789343834
2025-11-23 23:26:36.653 | INFO     | __main__:<module>:160 - Step17380, Loss: 3.8239965438842773, Grad L2 Norm: 0.02355080097913742
2025-11-23 23:26:38.661 | INFO     | __main__:<module>:160 - Step17390, Loss: 3.464209794998169, Grad L2 Norm: 0.022204622626304626
2025-11-23 23:26:40.666 | INFO     | __main__:<module>:160 - Step17400, Loss: 3.6721243858337402, Grad L2 Norm: 0.02126448042690754
2025-11-23 23:26:42.677 | INFO     | __main__:<module>:160 - Step17410, Loss: 3.5577855110168457, Grad L2 Norm: 0.021678293123841286
2025-11-23 23:26:44.684 | INFO     | __main__:<module>:160 - Step17420, Loss: 3.482731580734253, Grad L2 Norm: 0.020205343142151833
2025-11-23 23:26:46.686 | INFO     | __main__:<module>:160 - Step17430, Loss: 3.5570733547210693, Grad L2 Norm: 0.022016508504748344
2025-11-23 23:26:48.696 | INFO     | __main__:<module>:160 - Step17440, Loss: 3.6610093116760254, Grad L2 Norm: 0.020273417234420776
2025-11-23 23:26:50.701 | INFO     | __main__:<module>:160 - Step17450, Loss: 3.5370519161224365, Grad L2 Norm: 0.02016492187976837
2025-11-23 23:26:52.703 | INFO     | __main__:<module>:160 - Step17460, Loss: 3.452691078186035, Grad L2 Norm: 0.021056199446320534
2025-11-23 23:26:54.702 | INFO     | __main__:<module>:160 - Step17470, Loss: 3.642137289047241, Grad L2 Norm: 0.02385796792805195
2025-11-23 23:26:56.702 | INFO     | __main__:<module>:160 - Step17480, Loss: 3.5216050148010254, Grad L2 Norm: 0.022124841809272766
2025-11-23 23:26:58.715 | INFO     | __main__:<module>:160 - Step17490, Loss: 3.6211395263671875, Grad L2 Norm: 0.019980816170573235
2025-11-23 23:27:00.721 | INFO     | __main__:<module>:160 - Step17500, Loss: 3.5089645385742188, Grad L2 Norm: 0.020361552014946938
2025-11-23 23:27:02.727 | INFO     | __main__:<module>:160 - Step17510, Loss: 3.646900177001953, Grad L2 Norm: 0.02309565804898739
2025-11-23 23:27:04.732 | INFO     | __main__:<module>:160 - Step17520, Loss: 3.7088379859924316, Grad L2 Norm: 0.021281326189637184
2025-11-23 23:27:06.736 | INFO     | __main__:<module>:160 - Step17530, Loss: 3.684840440750122, Grad L2 Norm: 0.021872831508517265
2025-11-23 23:27:08.738 | INFO     | __main__:<module>:160 - Step17540, Loss: 3.716034412384033, Grad L2 Norm: 0.022069338709115982
2025-11-23 23:27:10.752 | INFO     | __main__:<module>:160 - Step17550, Loss: 3.50081205368042, Grad L2 Norm: 0.021109482273459435
2025-11-23 23:27:12.766 | INFO     | __main__:<module>:160 - Step17560, Loss: 3.654086112976074, Grad L2 Norm: 0.022535225376486778
2025-11-23 23:27:14.777 | INFO     | __main__:<module>:160 - Step17570, Loss: 3.5387871265411377, Grad L2 Norm: 0.02227821946144104
2025-11-23 23:27:16.790 | INFO     | __main__:<module>:160 - Step17580, Loss: 3.5681862831115723, Grad L2 Norm: 0.021787863224744797
2025-11-23 23:27:18.807 | INFO     | __main__:<module>:160 - Step17590, Loss: 3.502244472503662, Grad L2 Norm: 0.02085733599960804
2025-11-23 23:27:20.818 | INFO     | __main__:<module>:160 - Step17600, Loss: 3.5878117084503174, Grad L2 Norm: 0.020666932687163353
2025-11-23 23:27:20.819 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:27:22.098 | INFO     | __main__:<module>:181 - validation loss: 3.593883490562439
2025-11-23 23:27:24.117 | INFO     | __main__:<module>:160 - Step17610, Loss: 3.624610424041748, Grad L2 Norm: 0.02103910595178604
2025-11-23 23:27:26.128 | INFO     | __main__:<module>:160 - Step17620, Loss: 3.535367965698242, Grad L2 Norm: 0.019417105242609978
2025-11-23 23:27:28.134 | INFO     | __main__:<module>:160 - Step17630, Loss: 3.663442611694336, Grad L2 Norm: 0.0217776820063591
2025-11-23 23:27:30.148 | INFO     | __main__:<module>:160 - Step17640, Loss: 3.429964780807495, Grad L2 Norm: 0.022314466536045074
2025-11-23 23:27:32.150 | INFO     | __main__:<module>:160 - Step17650, Loss: 3.642462968826294, Grad L2 Norm: 0.022732261568307877
2025-11-23 23:27:34.152 | INFO     | __main__:<module>:160 - Step17660, Loss: 3.70286226272583, Grad L2 Norm: 0.022315680980682373
2025-11-23 23:27:36.164 | INFO     | __main__:<module>:160 - Step17670, Loss: 3.5482707023620605, Grad L2 Norm: 0.020648105069994926
2025-11-23 23:27:38.171 | INFO     | __main__:<module>:160 - Step17680, Loss: 3.532871723175049, Grad L2 Norm: 0.021057263016700745
2025-11-23 23:27:40.183 | INFO     | __main__:<module>:160 - Step17690, Loss: 3.5665476322174072, Grad L2 Norm: 0.02319033443927765
2025-11-23 23:27:42.184 | INFO     | __main__:<module>:160 - Step17700, Loss: 3.5890417098999023, Grad L2 Norm: 0.020465338602662086
2025-11-23 23:27:44.180 | INFO     | __main__:<module>:160 - Step17710, Loss: 3.5821852684020996, Grad L2 Norm: 0.020567825064063072
2025-11-23 23:27:46.181 | INFO     | __main__:<module>:160 - Step17720, Loss: 3.643005609512329, Grad L2 Norm: 0.021293407306075096
2025-11-23 23:27:48.182 | INFO     | __main__:<module>:160 - Step17730, Loss: 3.5296425819396973, Grad L2 Norm: 0.021318187937140465
2025-11-23 23:27:50.183 | INFO     | __main__:<module>:160 - Step17740, Loss: 3.548095703125, Grad L2 Norm: 0.0208912193775177
2025-11-23 23:27:52.183 | INFO     | __main__:<module>:160 - Step17750, Loss: 3.424102306365967, Grad L2 Norm: 0.021863821893930435
2025-11-23 23:27:54.186 | INFO     | __main__:<module>:160 - Step17760, Loss: 3.6348624229431152, Grad L2 Norm: 0.022118687629699707
2025-11-23 23:27:56.193 | INFO     | __main__:<module>:160 - Step17770, Loss: 3.5441975593566895, Grad L2 Norm: 0.021217714995145798
2025-11-23 23:27:58.196 | INFO     | __main__:<module>:160 - Step17780, Loss: 3.7132339477539062, Grad L2 Norm: 0.02495989203453064
2025-11-23 23:28:00.196 | INFO     | __main__:<module>:160 - Step17790, Loss: 3.5170092582702637, Grad L2 Norm: 0.02078535221517086
2025-11-23 23:28:02.196 | INFO     | __main__:<module>:160 - Step17800, Loss: 3.6556198596954346, Grad L2 Norm: 0.021448327228426933
2025-11-23 23:28:04.195 | INFO     | __main__:<module>:160 - Step17810, Loss: 3.537947416305542, Grad L2 Norm: 0.021318992599844933
2025-11-23 23:28:06.198 | INFO     | __main__:<module>:160 - Step17820, Loss: 3.695701837539673, Grad L2 Norm: 0.02447143755853176
2025-11-23 23:28:08.199 | INFO     | __main__:<module>:160 - Step17830, Loss: 3.588367462158203, Grad L2 Norm: 0.02100556530058384
2025-11-23 23:28:10.196 | INFO     | __main__:<module>:160 - Step17840, Loss: 3.6511504650115967, Grad L2 Norm: 0.0216906126588583
2025-11-23 23:28:12.196 | INFO     | __main__:<module>:160 - Step17850, Loss: 3.5759918689727783, Grad L2 Norm: 0.024025006219744682
2025-11-23 23:28:14.197 | INFO     | __main__:<module>:160 - Step17860, Loss: 3.4590072631835938, Grad L2 Norm: 0.021691489964723587
2025-11-23 23:28:16.203 | INFO     | __main__:<module>:160 - Step17870, Loss: 3.615591287612915, Grad L2 Norm: 0.02120768278837204
2025-11-23 23:28:18.211 | INFO     | __main__:<module>:160 - Step17880, Loss: 3.614102840423584, Grad L2 Norm: 0.021222533658146858
2025-11-23 23:28:20.216 | INFO     | __main__:<module>:160 - Step17890, Loss: 3.739018201828003, Grad L2 Norm: 0.023811498656868935
2025-11-23 23:28:22.215 | INFO     | __main__:<module>:160 - Step17900, Loss: 3.586793899536133, Grad L2 Norm: 0.023390203714370728
2025-11-23 23:28:24.213 | INFO     | __main__:<module>:160 - Step17910, Loss: 3.6503467559814453, Grad L2 Norm: 0.021481428295373917
2025-11-23 23:28:26.212 | INFO     | __main__:<module>:160 - Step17920, Loss: 3.654045343399048, Grad L2 Norm: 0.020417530089616776
2025-11-23 23:28:28.212 | INFO     | __main__:<module>:160 - Step17930, Loss: 3.6492857933044434, Grad L2 Norm: 0.02184501849114895
2025-11-23 23:28:30.210 | INFO     | __main__:<module>:160 - Step17940, Loss: 3.4562325477600098, Grad L2 Norm: 0.02269948087632656
2025-11-23 23:28:32.210 | INFO     | __main__:<module>:160 - Step17950, Loss: 3.628690242767334, Grad L2 Norm: 0.02196080982685089
2025-11-23 23:28:34.210 | INFO     | __main__:<module>:160 - Step17960, Loss: 3.7058799266815186, Grad L2 Norm: 0.020785566419363022
2025-11-23 23:28:36.213 | INFO     | __main__:<module>:160 - Step17970, Loss: 3.6041259765625, Grad L2 Norm: 0.02093527466058731
2025-11-23 23:28:38.209 | INFO     | __main__:<module>:160 - Step17980, Loss: 3.5887861251831055, Grad L2 Norm: 0.02173968032002449
2025-11-23 23:28:40.212 | INFO     | __main__:<module>:160 - Step17990, Loss: 3.5948328971862793, Grad L2 Norm: 0.02214488759636879
2025-11-23 23:28:42.220 | INFO     | __main__:<module>:160 - Step18000, Loss: 3.6547670364379883, Grad L2 Norm: 0.021403875201940536
2025-11-23 23:28:42.221 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:28:43.495 | INFO     | __main__:<module>:181 - validation loss: 3.621790862083435
2025-11-23 23:28:43.496 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_18000.pt
2025-11-23 23:28:45.194 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-23 23:28:47.179 | INFO     | __main__:<module>:160 - Step18010, Loss: 3.46681809425354, Grad L2 Norm: 0.021821843460202217
2025-11-23 23:28:49.181 | INFO     | __main__:<module>:160 - Step18020, Loss: 3.5757222175598145, Grad L2 Norm: 0.021159401163458824
2025-11-23 23:28:51.182 | INFO     | __main__:<module>:160 - Step18030, Loss: 3.595731019973755, Grad L2 Norm: 0.02125498093664646
2025-11-23 23:28:53.184 | INFO     | __main__:<module>:160 - Step18040, Loss: 3.6436307430267334, Grad L2 Norm: 0.021546343341469765
2025-11-23 23:28:55.184 | INFO     | __main__:<module>:160 - Step18050, Loss: 3.565833568572998, Grad L2 Norm: 0.021278956905007362
2025-11-23 23:28:57.186 | INFO     | __main__:<module>:160 - Step18060, Loss: 3.600721836090088, Grad L2 Norm: 0.020796814933419228
2025-11-23 23:28:59.186 | INFO     | __main__:<module>:160 - Step18070, Loss: 3.680116653442383, Grad L2 Norm: 0.02234305813908577
2025-11-23 23:29:01.181 | INFO     | __main__:<module>:160 - Step18080, Loss: 3.663855791091919, Grad L2 Norm: 0.021500246599316597
2025-11-23 23:29:03.180 | INFO     | __main__:<module>:160 - Step18090, Loss: 3.5915913581848145, Grad L2 Norm: 0.02066592127084732
2025-11-23 23:29:05.179 | INFO     | __main__:<module>:160 - Step18100, Loss: 3.5860671997070312, Grad L2 Norm: 0.021815966814756393
2025-11-23 23:29:07.178 | INFO     | __main__:<module>:160 - Step18110, Loss: 3.527902126312256, Grad L2 Norm: 0.021595055237412453
2025-11-23 23:29:09.179 | INFO     | __main__:<module>:160 - Step18120, Loss: 3.739030361175537, Grad L2 Norm: 0.022903617471456528
2025-11-23 23:29:11.178 | INFO     | __main__:<module>:160 - Step18130, Loss: 3.695702075958252, Grad L2 Norm: 0.021404370665550232
2025-11-23 23:29:13.177 | INFO     | __main__:<module>:160 - Step18140, Loss: 3.5201234817504883, Grad L2 Norm: 0.020101996138691902
2025-11-23 23:29:15.180 | INFO     | __main__:<module>:160 - Step18150, Loss: 3.6593000888824463, Grad L2 Norm: 0.022091180086135864
2025-11-23 23:29:17.179 | INFO     | __main__:<module>:160 - Step18160, Loss: 3.5145368576049805, Grad L2 Norm: 0.02058367244899273
2025-11-23 23:29:19.184 | INFO     | __main__:<module>:160 - Step18170, Loss: 3.5753133296966553, Grad L2 Norm: 0.021065061911940575
2025-11-23 23:29:21.193 | INFO     | __main__:<module>:160 - Step18180, Loss: 3.677309036254883, Grad L2 Norm: 0.022206446155905724
2025-11-23 23:29:23.194 | INFO     | __main__:<module>:160 - Step18190, Loss: 3.633492946624756, Grad L2 Norm: 0.02206975407898426
2025-11-23 23:29:25.194 | INFO     | __main__:<module>:160 - Step18200, Loss: 3.5253443717956543, Grad L2 Norm: 0.022228678688406944
2025-11-23 23:29:27.195 | INFO     | __main__:<module>:160 - Step18210, Loss: 3.5298290252685547, Grad L2 Norm: 0.023635469377040863
2025-11-23 23:29:29.199 | INFO     | __main__:<module>:160 - Step18220, Loss: 3.569169044494629, Grad L2 Norm: 0.021479297429323196
2025-11-23 23:29:31.204 | INFO     | __main__:<module>:160 - Step18230, Loss: 3.6530473232269287, Grad L2 Norm: 0.020386841148138046
2025-11-23 23:29:33.215 | INFO     | __main__:<module>:160 - Step18240, Loss: 3.6237144470214844, Grad L2 Norm: 0.021957801654934883
2025-11-23 23:29:35.224 | INFO     | __main__:<module>:160 - Step18250, Loss: 3.505075693130493, Grad L2 Norm: 0.021993376314640045
2025-11-23 23:29:37.232 | INFO     | __main__:<module>:160 - Step18260, Loss: 3.4647676944732666, Grad L2 Norm: 0.021310165524482727
2025-11-23 23:29:39.235 | INFO     | __main__:<module>:160 - Step18270, Loss: 3.530094623565674, Grad L2 Norm: 0.021366145461797714
2025-11-23 23:29:41.246 | INFO     | __main__:<module>:160 - Step18280, Loss: 3.5611729621887207, Grad L2 Norm: 0.020816229283809662
2025-11-23 23:29:43.250 | INFO     | __main__:<module>:160 - Step18290, Loss: 3.5772933959960938, Grad L2 Norm: 0.021368632093071938
2025-11-23 23:29:45.259 | INFO     | __main__:<module>:160 - Step18300, Loss: 3.6284799575805664, Grad L2 Norm: 0.020726298913359642
2025-11-23 23:29:47.267 | INFO     | __main__:<module>:160 - Step18310, Loss: 3.5565037727355957, Grad L2 Norm: 0.019763322547078133
2025-11-23 23:29:49.272 | INFO     | __main__:<module>:160 - Step18320, Loss: 3.521158456802368, Grad L2 Norm: 0.02283422090113163
2025-11-23 23:29:51.279 | INFO     | __main__:<module>:160 - Step18330, Loss: 3.5689051151275635, Grad L2 Norm: 0.024008389562368393
2025-11-23 23:29:53.285 | INFO     | __main__:<module>:160 - Step18340, Loss: 3.60465669631958, Grad L2 Norm: 0.021065792068839073
2025-11-23 23:29:55.287 | INFO     | __main__:<module>:160 - Step18350, Loss: 3.634126901626587, Grad L2 Norm: 0.02066342532634735
2025-11-23 23:29:57.287 | INFO     | __main__:<module>:160 - Step18360, Loss: 3.631871461868286, Grad L2 Norm: 0.021269021555781364
2025-11-23 23:29:59.297 | INFO     | __main__:<module>:160 - Step18370, Loss: 3.6249876022338867, Grad L2 Norm: 0.021819651126861572
2025-11-23 23:30:01.306 | INFO     | __main__:<module>:160 - Step18380, Loss: 3.6333045959472656, Grad L2 Norm: 0.021808164194226265
2025-11-23 23:30:03.314 | INFO     | __main__:<module>:160 - Step18390, Loss: 3.773486614227295, Grad L2 Norm: 0.021884063258767128
2025-11-23 23:30:05.326 | INFO     | __main__:<module>:160 - Step18400, Loss: 3.5803322792053223, Grad L2 Norm: 0.022693613544106483
2025-11-23 23:30:05.326 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:30:06.608 | INFO     | __main__:<module>:181 - validation loss: 3.568252217769623
2025-11-23 23:30:08.622 | INFO     | __main__:<module>:160 - Step18410, Loss: 3.64827823638916, Grad L2 Norm: 0.02079835534095764
2025-11-23 23:30:10.628 | INFO     | __main__:<module>:160 - Step18420, Loss: 3.5582756996154785, Grad L2 Norm: 0.023962581530213356
2025-11-23 23:30:12.637 | INFO     | __main__:<module>:160 - Step18430, Loss: 3.6597914695739746, Grad L2 Norm: 0.021119028329849243
2025-11-23 23:30:14.643 | INFO     | __main__:<module>:160 - Step18440, Loss: 3.6349382400512695, Grad L2 Norm: 0.020914187654852867
2025-11-23 23:30:16.653 | INFO     | __main__:<module>:160 - Step18450, Loss: 3.7068302631378174, Grad L2 Norm: 0.022326523438096046
2025-11-23 23:30:18.661 | INFO     | __main__:<module>:160 - Step18460, Loss: 3.7735602855682373, Grad L2 Norm: 0.022831683978438377
2025-11-23 23:30:20.670 | INFO     | __main__:<module>:160 - Step18470, Loss: 3.5336737632751465, Grad L2 Norm: 0.0202841404825449
2025-11-23 23:30:22.676 | INFO     | __main__:<module>:160 - Step18480, Loss: 3.539496421813965, Grad L2 Norm: 0.023004090413451195
2025-11-23 23:30:24.678 | INFO     | __main__:<module>:160 - Step18490, Loss: 3.6604528427124023, Grad L2 Norm: 0.023327821865677834
2025-11-23 23:30:26.679 | INFO     | __main__:<module>:160 - Step18500, Loss: 3.5352931022644043, Grad L2 Norm: 0.024097152054309845
2025-11-23 23:30:28.680 | INFO     | __main__:<module>:160 - Step18510, Loss: 3.5694961547851562, Grad L2 Norm: 0.020575840026140213
2025-11-23 23:30:30.678 | INFO     | __main__:<module>:160 - Step18520, Loss: 3.6483869552612305, Grad L2 Norm: 0.022054865956306458
2025-11-23 23:30:32.676 | INFO     | __main__:<module>:160 - Step18530, Loss: 3.556729316711426, Grad L2 Norm: 0.02129853516817093
2025-11-23 23:30:34.673 | INFO     | __main__:<module>:160 - Step18540, Loss: 3.6302032470703125, Grad L2 Norm: 0.022772694006562233
2025-11-23 23:30:36.670 | INFO     | __main__:<module>:160 - Step18550, Loss: 3.505667209625244, Grad L2 Norm: 0.02179747074842453
2025-11-23 23:30:38.670 | INFO     | __main__:<module>:160 - Step18560, Loss: 3.586179494857788, Grad L2 Norm: 0.021491698920726776
2025-11-23 23:30:40.672 | INFO     | __main__:<module>:160 - Step18570, Loss: 3.6366147994995117, Grad L2 Norm: 0.021452302113175392
2025-11-23 23:30:42.671 | INFO     | __main__:<module>:160 - Step18580, Loss: 3.799238681793213, Grad L2 Norm: 0.02371235191822052
2025-11-23 23:30:44.670 | INFO     | __main__:<module>:160 - Step18590, Loss: 3.448975086212158, Grad L2 Norm: 0.020493661984801292
2025-11-23 23:30:46.668 | INFO     | __main__:<module>:160 - Step18600, Loss: 3.6357831954956055, Grad L2 Norm: 0.021537600085139275
2025-11-23 23:30:48.670 | INFO     | __main__:<module>:160 - Step18610, Loss: 3.6358275413513184, Grad L2 Norm: 0.021315274760127068
2025-11-23 23:30:50.669 | INFO     | __main__:<module>:160 - Step18620, Loss: 3.598954916000366, Grad L2 Norm: 0.020766668021678925
2025-11-23 23:30:52.668 | INFO     | __main__:<module>:160 - Step18630, Loss: 3.5308268070220947, Grad L2 Norm: 0.023384666070342064
2025-11-23 23:30:54.667 | INFO     | __main__:<module>:160 - Step18640, Loss: 3.6380810737609863, Grad L2 Norm: 0.021333636716008186
2025-11-23 23:30:56.667 | INFO     | __main__:<module>:160 - Step18650, Loss: 3.626676082611084, Grad L2 Norm: 0.022152362391352654
2025-11-23 23:30:58.663 | INFO     | __main__:<module>:160 - Step18660, Loss: 3.6514346599578857, Grad L2 Norm: 0.02321445569396019
2025-11-23 23:31:00.659 | INFO     | __main__:<module>:160 - Step18670, Loss: 3.5605578422546387, Grad L2 Norm: 0.024329954758286476
2025-11-23 23:31:02.659 | INFO     | __main__:<module>:160 - Step18680, Loss: 3.714423894882202, Grad L2 Norm: 0.023694520816206932
2025-11-23 23:31:04.660 | INFO     | __main__:<module>:160 - Step18690, Loss: 3.6161701679229736, Grad L2 Norm: 0.022327613085508347
2025-11-23 23:31:06.660 | INFO     | __main__:<module>:160 - Step18700, Loss: 3.682366371154785, Grad L2 Norm: 0.021556459367275238
2025-11-23 23:31:08.658 | INFO     | __main__:<module>:160 - Step18710, Loss: 3.735434055328369, Grad L2 Norm: 0.020503932610154152
2025-11-23 23:31:10.655 | INFO     | __main__:<module>:160 - Step18720, Loss: 3.6658012866973877, Grad L2 Norm: 0.023093629628419876
2025-11-23 23:31:12.655 | INFO     | __main__:<module>:160 - Step18730, Loss: 3.533740758895874, Grad L2 Norm: 0.022347338497638702
2025-11-23 23:31:14.654 | INFO     | __main__:<module>:160 - Step18740, Loss: 3.647089719772339, Grad L2 Norm: 0.022040411829948425
2025-11-23 23:31:16.654 | INFO     | __main__:<module>:160 - Step18750, Loss: 3.610464096069336, Grad L2 Norm: 0.02162560075521469
2025-11-23 23:31:18.653 | INFO     | __main__:<module>:160 - Step18760, Loss: 3.544510841369629, Grad L2 Norm: 0.021887201815843582
2025-11-23 23:31:20.650 | INFO     | __main__:<module>:160 - Step18770, Loss: 3.6555423736572266, Grad L2 Norm: 0.02186654508113861
2025-11-23 23:31:22.643 | INFO     | __main__:<module>:160 - Step18780, Loss: 3.6499547958374023, Grad L2 Norm: 0.022832902148365974
2025-11-23 23:31:24.635 | INFO     | __main__:<module>:160 - Step18790, Loss: 3.6442315578460693, Grad L2 Norm: 0.021295780315995216
2025-11-23 23:31:26.633 | INFO     | __main__:<module>:160 - Step18800, Loss: 3.6785836219787598, Grad L2 Norm: 0.021051235496997833
2025-11-23 23:31:26.634 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:31:27.903 | INFO     | __main__:<module>:181 - validation loss: 3.59137077331543
2025-11-23 23:31:29.910 | INFO     | __main__:<module>:160 - Step18810, Loss: 3.5571179389953613, Grad L2 Norm: 0.02260359562933445
2025-11-23 23:31:31.909 | INFO     | __main__:<module>:160 - Step18820, Loss: 3.418384075164795, Grad L2 Norm: 0.022696606814861298
2025-11-23 23:31:33.908 | INFO     | __main__:<module>:160 - Step18830, Loss: 3.5219779014587402, Grad L2 Norm: 0.022522304207086563
2025-11-23 23:31:35.909 | INFO     | __main__:<module>:160 - Step18840, Loss: 3.6157360076904297, Grad L2 Norm: 0.021479813382029533
2025-11-23 23:31:37.910 | INFO     | __main__:<module>:160 - Step18850, Loss: 3.4910926818847656, Grad L2 Norm: 0.022745348513126373
2025-11-23 23:31:39.910 | INFO     | __main__:<module>:160 - Step18860, Loss: 3.49847412109375, Grad L2 Norm: 0.02126447483897209
2025-11-23 23:31:41.909 | INFO     | __main__:<module>:160 - Step18870, Loss: 3.62703275680542, Grad L2 Norm: 0.023182019591331482
2025-11-23 23:31:43.909 | INFO     | __main__:<module>:160 - Step18880, Loss: 3.5716702938079834, Grad L2 Norm: 0.02357342652976513
2025-11-23 23:31:45.908 | INFO     | __main__:<module>:160 - Step18890, Loss: 3.681084156036377, Grad L2 Norm: 0.023193268105387688
2025-11-23 23:31:47.907 | INFO     | __main__:<module>:160 - Step18900, Loss: 3.587346076965332, Grad L2 Norm: 0.021552523598074913
2025-11-23 23:31:49.905 | INFO     | __main__:<module>:160 - Step18910, Loss: 3.747406005859375, Grad L2 Norm: 0.021278750151395798
2025-11-23 23:31:51.907 | INFO     | __main__:<module>:160 - Step18920, Loss: 3.618471622467041, Grad L2 Norm: 0.022186279296875
2025-11-23 23:31:53.908 | INFO     | __main__:<module>:160 - Step18930, Loss: 3.5560121536254883, Grad L2 Norm: 0.02254382148385048
2025-11-23 23:31:55.906 | INFO     | __main__:<module>:160 - Step18940, Loss: 3.601228713989258, Grad L2 Norm: 0.021623266860842705
2025-11-23 23:31:57.907 | INFO     | __main__:<module>:160 - Step18950, Loss: 3.4667675495147705, Grad L2 Norm: 0.022304203361272812
2025-11-23 23:31:59.910 | INFO     | __main__:<module>:160 - Step18960, Loss: 3.545051097869873, Grad L2 Norm: 0.02115132473409176
2025-11-23 23:32:01.909 | INFO     | __main__:<module>:160 - Step18970, Loss: 3.608314037322998, Grad L2 Norm: 0.023754259571433067
2025-11-23 23:32:03.912 | INFO     | __main__:<module>:160 - Step18980, Loss: 3.557035446166992, Grad L2 Norm: 0.022629112005233765
2025-11-23 23:32:05.923 | INFO     | __main__:<module>:160 - Step18990, Loss: 3.496030807495117, Grad L2 Norm: 0.022674432024359703
2025-11-23 23:32:07.941 | INFO     | __main__:<module>:160 - Step19000, Loss: 3.6430461406707764, Grad L2 Norm: 0.020650211721658707
2025-11-23 23:32:09.944 | INFO     | __main__:<module>:160 - Step19010, Loss: 3.5765292644500732, Grad L2 Norm: 0.022785382345318794
2025-11-23 23:32:11.941 | INFO     | __main__:<module>:160 - Step19020, Loss: 3.660243034362793, Grad L2 Norm: 0.024543344974517822
2025-11-23 23:32:13.946 | INFO     | __main__:<module>:160 - Step19030, Loss: 3.654463291168213, Grad L2 Norm: 0.021476130932569504
2025-11-23 23:32:15.944 | INFO     | __main__:<module>:160 - Step19040, Loss: 3.698716878890991, Grad L2 Norm: 0.022558925673365593
2025-11-23 23:32:17.940 | INFO     | __main__:<module>:160 - Step19050, Loss: 3.624272346496582, Grad L2 Norm: 0.02138470858335495
2025-11-23 23:32:19.939 | INFO     | __main__:<module>:160 - Step19060, Loss: 3.591268539428711, Grad L2 Norm: 0.01960606873035431
2025-11-23 23:32:21.935 | INFO     | __main__:<module>:160 - Step19070, Loss: 3.666147470474243, Grad L2 Norm: 0.024588068947196007
2025-11-23 23:32:23.932 | INFO     | __main__:<module>:160 - Step19080, Loss: 3.637246608734131, Grad L2 Norm: 0.02341771125793457
2025-11-23 23:32:25.926 | INFO     | __main__:<module>:160 - Step19090, Loss: 3.501884937286377, Grad L2 Norm: 0.020529000088572502
2025-11-23 23:32:27.919 | INFO     | __main__:<module>:160 - Step19100, Loss: 3.628662109375, Grad L2 Norm: 0.02287149243056774
2025-11-23 23:32:29.914 | INFO     | __main__:<module>:160 - Step19110, Loss: 3.6028223037719727, Grad L2 Norm: 0.02122318185865879
2025-11-23 23:32:31.912 | INFO     | __main__:<module>:160 - Step19120, Loss: 3.6573238372802734, Grad L2 Norm: 0.022239333018660545
2025-11-23 23:32:33.910 | INFO     | __main__:<module>:160 - Step19130, Loss: 3.6278252601623535, Grad L2 Norm: 0.021524038165807724
2025-11-23 23:32:35.909 | INFO     | __main__:<module>:160 - Step19140, Loss: 3.595477819442749, Grad L2 Norm: 0.020556243136525154
2025-11-23 23:32:37.907 | INFO     | __main__:<module>:160 - Step19150, Loss: 3.544440984725952, Grad L2 Norm: 0.020412668585777283
2025-11-23 23:32:39.908 | INFO     | __main__:<module>:160 - Step19160, Loss: 3.6372690200805664, Grad L2 Norm: 0.021434053778648376
2025-11-23 23:32:41.906 | INFO     | __main__:<module>:160 - Step19170, Loss: 3.6406893730163574, Grad L2 Norm: 0.020376481115818024
2025-11-23 23:32:43.903 | INFO     | __main__:<module>:160 - Step19180, Loss: 3.5056986808776855, Grad L2 Norm: 0.02161394990980625
2025-11-23 23:32:45.893 | INFO     | __main__:<module>:160 - Step19190, Loss: 3.677156686782837, Grad L2 Norm: 0.0207737497985363
2025-11-23 23:32:47.884 | INFO     | __main__:<module>:160 - Step19200, Loss: 3.7055752277374268, Grad L2 Norm: 0.020803501829504967
2025-11-23 23:32:47.884 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:32:49.149 | INFO     | __main__:<module>:181 - validation loss: 3.6181000232696534
2025-11-23 23:32:51.147 | INFO     | __main__:<module>:160 - Step19210, Loss: 3.567598581314087, Grad L2 Norm: 0.020926792174577713
2025-11-23 23:32:53.132 | INFO     | __main__:<module>:160 - Step19220, Loss: 3.5272793769836426, Grad L2 Norm: 0.0207498911768198
2025-11-23 23:32:55.118 | INFO     | __main__:<module>:160 - Step19230, Loss: 3.5702130794525146, Grad L2 Norm: 0.0218050479888916
2025-11-23 23:32:57.104 | INFO     | __main__:<module>:160 - Step19240, Loss: 3.6729605197906494, Grad L2 Norm: 0.021935394033789635
2025-11-23 23:32:59.095 | INFO     | __main__:<module>:160 - Step19250, Loss: 3.615356922149658, Grad L2 Norm: 0.021986670792102814
2025-11-23 23:33:01.082 | INFO     | __main__:<module>:160 - Step19260, Loss: 3.5815367698669434, Grad L2 Norm: 0.022160518914461136
2025-11-23 23:33:03.065 | INFO     | __main__:<module>:160 - Step19270, Loss: 3.633965492248535, Grad L2 Norm: 0.022126762196421623
2025-11-23 23:33:05.055 | INFO     | __main__:<module>:160 - Step19280, Loss: 3.6319689750671387, Grad L2 Norm: 0.022282011806964874
2025-11-23 23:33:07.041 | INFO     | __main__:<module>:160 - Step19290, Loss: 3.6674532890319824, Grad L2 Norm: 0.021161362528800964
2025-11-23 23:33:09.035 | INFO     | __main__:<module>:160 - Step19300, Loss: 3.5798611640930176, Grad L2 Norm: 0.021169284358620644
2025-11-23 23:33:11.022 | INFO     | __main__:<module>:160 - Step19310, Loss: 3.515223503112793, Grad L2 Norm: 0.021098675206303596
2025-11-23 23:33:13.015 | INFO     | __main__:<module>:160 - Step19320, Loss: 3.6060800552368164, Grad L2 Norm: 0.0222451314330101
2025-11-23 23:33:15.000 | INFO     | __main__:<module>:160 - Step19330, Loss: 3.6058666706085205, Grad L2 Norm: 0.023226479068398476
2025-11-23 23:33:16.985 | INFO     | __main__:<module>:160 - Step19340, Loss: 3.6468968391418457, Grad L2 Norm: 0.020617708563804626
2025-11-23 23:33:18.969 | INFO     | __main__:<module>:160 - Step19350, Loss: 3.552950859069824, Grad L2 Norm: 0.022029001265764236
2025-11-23 23:33:20.954 | INFO     | __main__:<module>:160 - Step19360, Loss: 3.68233060836792, Grad L2 Norm: 0.022405151277780533
2025-11-23 23:33:22.937 | INFO     | __main__:<module>:160 - Step19370, Loss: 3.510110378265381, Grad L2 Norm: 0.01967075653374195
2025-11-23 23:33:24.920 | INFO     | __main__:<module>:160 - Step19380, Loss: 3.6052920818328857, Grad L2 Norm: 0.022107986733317375
2025-11-23 23:33:26.905 | INFO     | __main__:<module>:160 - Step19390, Loss: 3.662227153778076, Grad L2 Norm: 0.02203083597123623
2025-11-23 23:33:28.889 | INFO     | __main__:<module>:160 - Step19400, Loss: 3.481419563293457, Grad L2 Norm: 0.021185914054512978
2025-11-23 23:33:30.874 | INFO     | __main__:<module>:160 - Step19410, Loss: 3.652703285217285, Grad L2 Norm: 0.023209352046251297
2025-11-23 23:33:32.855 | INFO     | __main__:<module>:160 - Step19420, Loss: 3.6139612197875977, Grad L2 Norm: 0.022082265466451645
2025-11-23 23:33:34.831 | INFO     | __main__:<module>:160 - Step19430, Loss: 3.5616772174835205, Grad L2 Norm: 0.020779099315404892
2025-11-23 23:33:36.810 | INFO     | __main__:<module>:160 - Step19440, Loss: 3.6453139781951904, Grad L2 Norm: 0.0220571830868721
2025-11-23 23:33:38.797 | INFO     | __main__:<module>:160 - Step19450, Loss: 3.6183700561523438, Grad L2 Norm: 0.02387317828834057
2025-11-23 23:33:40.784 | INFO     | __main__:<module>:160 - Step19460, Loss: 3.5051403045654297, Grad L2 Norm: 0.02164474129676819
2025-11-23 23:33:42.765 | INFO     | __main__:<module>:160 - Step19470, Loss: 3.6805644035339355, Grad L2 Norm: 0.020639784634113312
2025-11-23 23:33:44.741 | INFO     | __main__:<module>:160 - Step19480, Loss: 3.5582752227783203, Grad L2 Norm: 0.021623816341161728
2025-11-23 23:33:46.718 | INFO     | __main__:<module>:160 - Step19490, Loss: 3.7425131797790527, Grad L2 Norm: 0.023384355008602142
2025-11-23 23:33:48.689 | INFO     | __main__:<module>:160 - Step19500, Loss: 3.5974340438842773, Grad L2 Norm: 0.020051851868629456
2025-11-23 23:33:50.664 | INFO     | __main__:<module>:160 - Step19510, Loss: 3.542417526245117, Grad L2 Norm: 0.02161288447678089
2025-11-23 23:33:52.642 | INFO     | __main__:<module>:160 - Step19520, Loss: 3.721057891845703, Grad L2 Norm: 0.023166021332144737
2025-11-23 23:33:54.611 | INFO     | __main__:<module>:160 - Step19530, Loss: 3.607239246368408, Grad L2 Norm: 0.02105412259697914
2025-11-23 23:33:56.582 | INFO     | __main__:<module>:160 - Step19540, Loss: 3.6495890617370605, Grad L2 Norm: 0.02232448011636734
2025-11-23 23:33:58.559 | INFO     | __main__:<module>:160 - Step19550, Loss: 3.5938944816589355, Grad L2 Norm: 0.022317593917250633
2025-11-23 23:34:00.532 | INFO     | __main__:<module>:160 - Step19560, Loss: 3.640166997909546, Grad L2 Norm: 0.023080797865986824
2025-11-23 23:34:02.503 | INFO     | __main__:<module>:160 - Step19570, Loss: 3.5404937267303467, Grad L2 Norm: 0.022769181057810783
2025-11-23 23:34:04.478 | INFO     | __main__:<module>:160 - Step19580, Loss: 3.4786295890808105, Grad L2 Norm: 0.021947138011455536
2025-11-23 23:34:06.449 | INFO     | __main__:<module>:160 - Step19590, Loss: 3.4797019958496094, Grad L2 Norm: 0.02188108302652836
2025-11-23 23:34:08.418 | INFO     | __main__:<module>:160 - Step19600, Loss: 3.599463701248169, Grad L2 Norm: 0.020426373928785324
2025-11-23 23:34:08.419 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:34:09.670 | INFO     | __main__:<module>:181 - validation loss: 3.6103991985321047
2025-11-23 23:34:11.654 | INFO     | __main__:<module>:160 - Step19610, Loss: 3.5123512744903564, Grad L2 Norm: 0.02259555459022522
2025-11-23 23:34:13.632 | INFO     | __main__:<module>:160 - Step19620, Loss: 3.5781612396240234, Grad L2 Norm: 0.02186012826859951
2025-11-23 23:34:15.607 | INFO     | __main__:<module>:160 - Step19630, Loss: 3.510021924972534, Grad L2 Norm: 0.022402578964829445
2025-11-23 23:34:17.584 | INFO     | __main__:<module>:160 - Step19640, Loss: 3.639167308807373, Grad L2 Norm: 0.021758470684289932
2025-11-23 23:34:19.567 | INFO     | __main__:<module>:160 - Step19650, Loss: 3.7252583503723145, Grad L2 Norm: 0.023592829704284668
2025-11-23 23:34:21.553 | INFO     | __main__:<module>:160 - Step19660, Loss: 3.5963077545166016, Grad L2 Norm: 0.022190788760781288
2025-11-23 23:34:23.532 | INFO     | __main__:<module>:160 - Step19670, Loss: 3.5585389137268066, Grad L2 Norm: 0.021632039919495583
2025-11-23 23:34:25.509 | INFO     | __main__:<module>:160 - Step19680, Loss: 3.6461243629455566, Grad L2 Norm: 0.02442558854818344
2025-11-23 23:34:27.486 | INFO     | __main__:<module>:160 - Step19690, Loss: 3.7194552421569824, Grad L2 Norm: 0.02336459420621395
2025-11-23 23:34:29.455 | INFO     | __main__:<module>:160 - Step19700, Loss: 3.686410427093506, Grad L2 Norm: 0.020858123898506165
2025-11-23 23:34:31.432 | INFO     | __main__:<module>:160 - Step19710, Loss: 3.6456010341644287, Grad L2 Norm: 0.020878424867987633
2025-11-23 23:34:33.410 | INFO     | __main__:<module>:160 - Step19720, Loss: 3.633122682571411, Grad L2 Norm: 0.02122843824326992
2025-11-23 23:34:35.381 | INFO     | __main__:<module>:160 - Step19730, Loss: 3.595463991165161, Grad L2 Norm: 0.022898586466908455
2025-11-23 23:34:37.353 | INFO     | __main__:<module>:160 - Step19740, Loss: 3.5562570095062256, Grad L2 Norm: 0.020712248980998993
2025-11-23 23:34:39.329 | INFO     | __main__:<module>:160 - Step19750, Loss: 3.537693738937378, Grad L2 Norm: 0.021445265039801598
2025-11-23 23:34:41.304 | INFO     | __main__:<module>:160 - Step19760, Loss: 3.4632210731506348, Grad L2 Norm: 0.02086314931511879
2025-11-23 23:34:43.280 | INFO     | __main__:<module>:160 - Step19770, Loss: 3.5537257194519043, Grad L2 Norm: 0.0232864823192358
2025-11-23 23:34:45.259 | INFO     | __main__:<module>:160 - Step19780, Loss: 3.7013494968414307, Grad L2 Norm: 0.02247598208487034
2025-11-23 23:34:47.237 | INFO     | __main__:<module>:160 - Step19790, Loss: 3.7606399059295654, Grad L2 Norm: 0.02178116887807846
2025-11-23 23:34:49.211 | INFO     | __main__:<module>:160 - Step19800, Loss: 3.5463995933532715, Grad L2 Norm: 0.020183410495519638
2025-11-23 23:34:51.186 | INFO     | __main__:<module>:160 - Step19810, Loss: 3.6500449180603027, Grad L2 Norm: 0.02326788753271103
2025-11-23 23:34:53.168 | INFO     | __main__:<module>:160 - Step19820, Loss: 3.4494104385375977, Grad L2 Norm: 0.021768255159258842
2025-11-23 23:34:55.149 | INFO     | __main__:<module>:160 - Step19830, Loss: 3.770472526550293, Grad L2 Norm: 0.02287178859114647
2025-11-23 23:34:57.128 | INFO     | __main__:<module>:160 - Step19840, Loss: 3.6279282569885254, Grad L2 Norm: 0.02230440452694893
2025-11-23 23:34:59.110 | INFO     | __main__:<module>:160 - Step19850, Loss: 3.645493984222412, Grad L2 Norm: 0.020563768222928047
2025-11-23 23:35:01.087 | INFO     | __main__:<module>:160 - Step19860, Loss: 3.4855077266693115, Grad L2 Norm: 0.022960497066378593
2025-11-23 23:35:03.067 | INFO     | __main__:<module>:160 - Step19870, Loss: 3.4171321392059326, Grad L2 Norm: 0.02260265313088894
2025-11-23 23:35:05.057 | INFO     | __main__:<module>:160 - Step19880, Loss: 3.574631690979004, Grad L2 Norm: 0.021834436804056168
2025-11-23 23:35:07.039 | INFO     | __main__:<module>:160 - Step19890, Loss: 3.6480937004089355, Grad L2 Norm: 0.021207425743341446
2025-11-23 23:35:09.022 | INFO     | __main__:<module>:160 - Step19900, Loss: 3.7332370281219482, Grad L2 Norm: 0.024277808144688606
2025-11-23 23:35:11.006 | INFO     | __main__:<module>:160 - Step19910, Loss: 3.6250033378601074, Grad L2 Norm: 0.02319481037557125
2025-11-23 23:35:12.988 | INFO     | __main__:<module>:160 - Step19920, Loss: 3.727660655975342, Grad L2 Norm: 0.024499936029314995
2025-11-23 23:35:14.965 | INFO     | __main__:<module>:160 - Step19930, Loss: 3.6061019897460938, Grad L2 Norm: 0.020647265017032623
2025-11-23 23:35:16.950 | INFO     | __main__:<module>:160 - Step19940, Loss: 3.5754001140594482, Grad L2 Norm: 0.021285859867930412
2025-11-23 23:35:18.934 | INFO     | __main__:<module>:160 - Step19950, Loss: 3.613971710205078, Grad L2 Norm: 0.02127489447593689
2025-11-23 23:35:20.917 | INFO     | __main__:<module>:160 - Step19960, Loss: 3.47415828704834, Grad L2 Norm: 0.019858071580529213
2025-11-23 23:35:22.903 | INFO     | __main__:<module>:160 - Step19970, Loss: 3.545077323913574, Grad L2 Norm: 0.021029958501458168
2025-11-23 23:35:24.890 | INFO     | __main__:<module>:160 - Step19980, Loss: 3.732685089111328, Grad L2 Norm: 0.02224704436957836
2025-11-23 23:35:26.871 | INFO     | __main__:<module>:160 - Step19990, Loss: 3.6330783367156982, Grad L2 Norm: 0.022164881229400635
2025-11-23 23:35:28.853 | INFO     | __main__:<module>:160 - Step20000, Loss: 3.5770537853240967, Grad L2 Norm: 0.023117506876587868
2025-11-23 23:35:28.854 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:35:30.111 | INFO     | __main__:<module>:181 - validation loss: 3.621676766872406
2025-11-23 23:35:30.112 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_20000.pt
2025-11-23 23:35:31.777 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-23 23:35:33.740 | INFO     | __main__:<module>:160 - Step20010, Loss: 3.7246479988098145, Grad L2 Norm: 0.021462908014655113
2025-11-23 23:35:35.713 | INFO     | __main__:<module>:160 - Step20020, Loss: 3.697720527648926, Grad L2 Norm: 0.022763093933463097
2025-11-23 23:35:37.698 | INFO     | __main__:<module>:160 - Step20030, Loss: 3.3854074478149414, Grad L2 Norm: 0.021583884954452515
2025-11-23 23:35:39.680 | INFO     | __main__:<module>:160 - Step20040, Loss: 3.5484445095062256, Grad L2 Norm: 0.023052046075463295
2025-11-23 23:35:41.655 | INFO     | __main__:<module>:160 - Step20050, Loss: 3.6841118335723877, Grad L2 Norm: 0.023113733157515526
2025-11-23 23:35:43.632 | INFO     | __main__:<module>:160 - Step20060, Loss: 3.687657356262207, Grad L2 Norm: 0.02251216024160385
2025-11-23 23:35:45.615 | INFO     | __main__:<module>:160 - Step20070, Loss: 3.406501531600952, Grad L2 Norm: 0.023127440363168716
2025-11-23 23:35:47.592 | INFO     | __main__:<module>:160 - Step20080, Loss: 3.496790885925293, Grad L2 Norm: 0.02087666466832161
2025-11-23 23:35:49.569 | INFO     | __main__:<module>:160 - Step20090, Loss: 3.685863494873047, Grad L2 Norm: 0.022783491760492325
2025-11-23 23:35:51.552 | INFO     | __main__:<module>:160 - Step20100, Loss: 3.587966203689575, Grad L2 Norm: 0.021898452192544937
2025-11-23 23:35:53.537 | INFO     | __main__:<module>:160 - Step20110, Loss: 3.5204453468322754, Grad L2 Norm: 0.022245444357395172
2025-11-23 23:35:55.516 | INFO     | __main__:<module>:160 - Step20120, Loss: 3.5789194107055664, Grad L2 Norm: 0.019748790189623833
2025-11-23 23:35:57.501 | INFO     | __main__:<module>:160 - Step20130, Loss: 3.692770481109619, Grad L2 Norm: 0.022754114121198654
2025-11-23 23:35:59.483 | INFO     | __main__:<module>:160 - Step20140, Loss: 3.6636483669281006, Grad L2 Norm: 0.02246726304292679
2025-11-23 23:36:01.466 | INFO     | __main__:<module>:160 - Step20150, Loss: 3.5706167221069336, Grad L2 Norm: 0.020976025611162186
2025-11-23 23:36:03.450 | INFO     | __main__:<module>:160 - Step20160, Loss: 3.596970319747925, Grad L2 Norm: 0.02355794422328472
2025-11-23 23:36:05.435 | INFO     | __main__:<module>:160 - Step20170, Loss: 3.6346054077148438, Grad L2 Norm: 0.02279014140367508
2025-11-23 23:36:07.414 | INFO     | __main__:<module>:160 - Step20180, Loss: 3.535433292388916, Grad L2 Norm: 0.0228150375187397
2025-11-23 23:36:09.392 | INFO     | __main__:<module>:160 - Step20190, Loss: 3.588498115539551, Grad L2 Norm: 0.021167971193790436
2025-11-23 23:36:11.375 | INFO     | __main__:<module>:160 - Step20200, Loss: 3.497464656829834, Grad L2 Norm: 0.024266401305794716
2025-11-23 23:36:13.355 | INFO     | __main__:<module>:160 - Step20210, Loss: 3.622313976287842, Grad L2 Norm: 0.02243352122604847
2025-11-23 23:36:15.334 | INFO     | __main__:<module>:160 - Step20220, Loss: 3.5544803142547607, Grad L2 Norm: 0.022604884579777718
2025-11-23 23:36:17.316 | INFO     | __main__:<module>:160 - Step20230, Loss: 3.725708484649658, Grad L2 Norm: 0.022784091532230377
2025-11-23 23:36:19.301 | INFO     | __main__:<module>:160 - Step20240, Loss: 3.583524227142334, Grad L2 Norm: 0.022168710827827454
2025-11-23 23:36:21.283 | INFO     | __main__:<module>:160 - Step20250, Loss: 3.509521007537842, Grad L2 Norm: 0.02162301354110241
2025-11-23 23:36:23.268 | INFO     | __main__:<module>:160 - Step20260, Loss: 3.5795035362243652, Grad L2 Norm: 0.022124653682112694
2025-11-23 23:36:25.253 | INFO     | __main__:<module>:160 - Step20270, Loss: 3.4902138710021973, Grad L2 Norm: 0.021539729088544846
2025-11-23 23:36:27.241 | INFO     | __main__:<module>:160 - Step20280, Loss: 3.5943472385406494, Grad L2 Norm: 0.021573232486844063
2025-11-23 23:36:29.231 | INFO     | __main__:<module>:160 - Step20290, Loss: 3.504544496536255, Grad L2 Norm: 0.02160612680017948
2025-11-23 23:36:31.212 | INFO     | __main__:<module>:160 - Step20300, Loss: 3.6531543731689453, Grad L2 Norm: 0.02144288271665573
2025-11-23 23:36:33.199 | INFO     | __main__:<module>:160 - Step20310, Loss: 3.5117692947387695, Grad L2 Norm: 0.020993907004594803
2025-11-23 23:36:35.189 | INFO     | __main__:<module>:160 - Step20320, Loss: 3.5344595909118652, Grad L2 Norm: 0.02095206454396248
2025-11-23 23:36:37.180 | INFO     | __main__:<module>:160 - Step20330, Loss: 3.5959935188293457, Grad L2 Norm: 0.021952316164970398
2025-11-23 23:36:39.168 | INFO     | __main__:<module>:160 - Step20340, Loss: 3.512343168258667, Grad L2 Norm: 0.02319723553955555
2025-11-23 23:36:41.151 | INFO     | __main__:<module>:160 - Step20350, Loss: 3.5810413360595703, Grad L2 Norm: 0.021979298442602158
2025-11-23 23:36:43.142 | INFO     | __main__:<module>:160 - Step20360, Loss: 3.596242904663086, Grad L2 Norm: 0.021486226469278336
2025-11-23 23:36:45.129 | INFO     | __main__:<module>:160 - Step20370, Loss: 3.594461679458618, Grad L2 Norm: 0.021235017105937004
2025-11-23 23:36:47.124 | INFO     | __main__:<module>:160 - Step20380, Loss: 3.635100841522217, Grad L2 Norm: 0.0226141344755888
2025-11-23 23:36:49.111 | INFO     | __main__:<module>:160 - Step20390, Loss: 3.6544971466064453, Grad L2 Norm: 0.02194954641163349
2025-11-23 23:36:51.106 | INFO     | __main__:<module>:160 - Step20400, Loss: 3.611022472381592, Grad L2 Norm: 0.022683346644043922
2025-11-23 23:36:51.107 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:36:52.372 | INFO     | __main__:<module>:181 - validation loss: 3.6014084696769713
2025-11-23 23:36:54.370 | INFO     | __main__:<module>:160 - Step20410, Loss: 3.489368438720703, Grad L2 Norm: 0.023005813360214233
2025-11-23 23:36:56.363 | INFO     | __main__:<module>:160 - Step20420, Loss: 3.5810742378234863, Grad L2 Norm: 0.024065563455224037
2025-11-23 23:36:58.348 | INFO     | __main__:<module>:160 - Step20430, Loss: 3.6925554275512695, Grad L2 Norm: 0.02255850099027157
2025-11-23 23:37:00.342 | INFO     | __main__:<module>:160 - Step20440, Loss: 3.871156692504883, Grad L2 Norm: 0.02347715012729168
2025-11-23 23:37:02.340 | INFO     | __main__:<module>:160 - Step20450, Loss: 3.5375661849975586, Grad L2 Norm: 0.02176307514309883
2025-11-23 23:37:04.335 | INFO     | __main__:<module>:160 - Step20460, Loss: 3.64626145362854, Grad L2 Norm: 0.023583795875310898
2025-11-23 23:37:06.324 | INFO     | __main__:<module>:160 - Step20470, Loss: 3.4898416996002197, Grad L2 Norm: 0.02203723043203354
2025-11-23 23:37:08.321 | INFO     | __main__:<module>:160 - Step20480, Loss: 3.6016855239868164, Grad L2 Norm: 0.021043216809630394
2025-11-23 23:37:10.321 | INFO     | __main__:<module>:160 - Step20490, Loss: 3.703810214996338, Grad L2 Norm: 0.023232821375131607
2025-11-23 23:37:12.321 | INFO     | __main__:<module>:160 - Step20500, Loss: 3.680583953857422, Grad L2 Norm: 0.024495931342244148
2025-11-23 23:37:14.321 | INFO     | __main__:<module>:160 - Step20510, Loss: 3.5540900230407715, Grad L2 Norm: 0.02165360562503338
2025-11-23 23:37:16.319 | INFO     | __main__:<module>:160 - Step20520, Loss: 3.709052085876465, Grad L2 Norm: 0.022076280787587166
2025-11-23 23:37:18.317 | INFO     | __main__:<module>:160 - Step20530, Loss: 3.6079840660095215, Grad L2 Norm: 0.02209603600203991
2025-11-23 23:37:20.316 | INFO     | __main__:<module>:160 - Step20540, Loss: 3.6310768127441406, Grad L2 Norm: 0.021551067009568214
2025-11-23 23:37:22.315 | INFO     | __main__:<module>:160 - Step20550, Loss: 3.7068591117858887, Grad L2 Norm: 0.02027122676372528
2025-11-23 23:37:24.315 | INFO     | __main__:<module>:160 - Step20560, Loss: 3.6792755126953125, Grad L2 Norm: 0.0229378379881382
2025-11-23 23:37:26.314 | INFO     | __main__:<module>:160 - Step20570, Loss: 3.448636531829834, Grad L2 Norm: 0.02111320197582245
2025-11-23 23:37:28.311 | INFO     | __main__:<module>:160 - Step20580, Loss: 3.5620148181915283, Grad L2 Norm: 0.022003788501024246
2025-11-23 23:37:30.304 | INFO     | __main__:<module>:160 - Step20590, Loss: 3.618802547454834, Grad L2 Norm: 0.022748678922653198
2025-11-23 23:37:32.293 | INFO     | __main__:<module>:160 - Step20600, Loss: 3.6174495220184326, Grad L2 Norm: 0.026350317522883415
2025-11-23 23:37:34.290 | INFO     | __main__:<module>:160 - Step20610, Loss: 3.527711868286133, Grad L2 Norm: 0.02104484848678112
2025-11-23 23:37:36.290 | INFO     | __main__:<module>:160 - Step20620, Loss: 3.4804418087005615, Grad L2 Norm: 0.022463668137788773
2025-11-23 23:37:38.290 | INFO     | __main__:<module>:160 - Step20630, Loss: 3.6392831802368164, Grad L2 Norm: 0.023993607610464096
2025-11-23 23:37:40.291 | INFO     | __main__:<module>:160 - Step20640, Loss: 3.6338672637939453, Grad L2 Norm: 0.02298578992486
2025-11-23 23:37:42.289 | INFO     | __main__:<module>:160 - Step20650, Loss: 3.7200429439544678, Grad L2 Norm: 0.023617662489414215
2025-11-23 23:37:44.288 | INFO     | __main__:<module>:160 - Step20660, Loss: 3.522451400756836, Grad L2 Norm: 0.022570377215743065
2025-11-23 23:37:46.287 | INFO     | __main__:<module>:160 - Step20670, Loss: 3.5000691413879395, Grad L2 Norm: 0.02170179970562458
2025-11-23 23:37:48.287 | INFO     | __main__:<module>:160 - Step20680, Loss: 3.6035609245300293, Grad L2 Norm: 0.02182791195809841
2025-11-23 23:37:50.287 | INFO     | __main__:<module>:160 - Step20690, Loss: 3.5648088455200195, Grad L2 Norm: 0.02154974266886711
2025-11-23 23:37:52.283 | INFO     | __main__:<module>:160 - Step20700, Loss: 3.559009552001953, Grad L2 Norm: 0.01974557153880596
2025-11-23 23:37:54.283 | INFO     | __main__:<module>:160 - Step20710, Loss: 3.5394394397735596, Grad L2 Norm: 0.022194093093276024
2025-11-23 23:37:56.280 | INFO     | __main__:<module>:160 - Step20720, Loss: 3.7050509452819824, Grad L2 Norm: 0.02250635251402855
2025-11-23 23:37:58.273 | INFO     | __main__:<module>:160 - Step20730, Loss: 3.6075239181518555, Grad L2 Norm: 0.021812837570905685
2025-11-23 23:38:00.266 | INFO     | __main__:<module>:160 - Step20740, Loss: 3.452899694442749, Grad L2 Norm: 0.021498896181583405
2025-11-23 23:38:02.263 | INFO     | __main__:<module>:160 - Step20750, Loss: 3.6384193897247314, Grad L2 Norm: 0.022213252261281013
2025-11-23 23:38:04.262 | INFO     | __main__:<module>:160 - Step20760, Loss: 3.4527153968811035, Grad L2 Norm: 0.023732135072350502
2025-11-23 23:38:06.262 | INFO     | __main__:<module>:160 - Step20770, Loss: 3.547395706176758, Grad L2 Norm: 0.021105997264385223
2025-11-23 23:38:08.260 | INFO     | __main__:<module>:160 - Step20780, Loss: 3.669020175933838, Grad L2 Norm: 0.022543596103787422
2025-11-23 23:38:10.258 | INFO     | __main__:<module>:160 - Step20790, Loss: 3.598611354827881, Grad L2 Norm: 0.0225873664021492
2025-11-23 23:38:12.257 | INFO     | __main__:<module>:160 - Step20800, Loss: 3.5517570972442627, Grad L2 Norm: 0.02441924251616001
2025-11-23 23:38:12.257 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:38:13.526 | INFO     | __main__:<module>:181 - validation loss: 3.5720840215682985
2025-11-23 23:38:15.526 | INFO     | __main__:<module>:160 - Step20810, Loss: 3.4660048484802246, Grad L2 Norm: 0.021391736343503
2025-11-23 23:38:17.518 | INFO     | __main__:<module>:160 - Step20820, Loss: 3.7146310806274414, Grad L2 Norm: 0.0220401082187891
2025-11-23 23:38:19.512 | INFO     | __main__:<module>:160 - Step20830, Loss: 3.632058620452881, Grad L2 Norm: 0.021168822422623634
2025-11-23 23:38:21.502 | INFO     | __main__:<module>:160 - Step20840, Loss: 3.567309856414795, Grad L2 Norm: 0.02149142138659954
2025-11-23 23:38:23.497 | INFO     | __main__:<module>:160 - Step20850, Loss: 3.7052130699157715, Grad L2 Norm: 0.02158198319375515
2025-11-23 23:38:25.493 | INFO     | __main__:<module>:160 - Step20860, Loss: 3.586686611175537, Grad L2 Norm: 0.02252422459423542
2025-11-23 23:38:27.494 | INFO     | __main__:<module>:160 - Step20870, Loss: 3.5765395164489746, Grad L2 Norm: 0.023402420803904533
2025-11-23 23:38:29.495 | INFO     | __main__:<module>:160 - Step20880, Loss: 3.5817015171051025, Grad L2 Norm: 0.023410003632307053
2025-11-23 23:38:31.494 | INFO     | __main__:<module>:160 - Step20890, Loss: 3.6147336959838867, Grad L2 Norm: 0.021908793598413467
2025-11-23 23:38:33.495 | INFO     | __main__:<module>:160 - Step20900, Loss: 3.570594072341919, Grad L2 Norm: 0.021719589829444885
2025-11-23 23:38:35.490 | INFO     | __main__:<module>:160 - Step20910, Loss: 3.5794129371643066, Grad L2 Norm: 0.021138446405529976
2025-11-23 23:38:37.481 | INFO     | __main__:<module>:160 - Step20920, Loss: 3.5830421447753906, Grad L2 Norm: 0.021215928718447685
2025-11-23 23:38:39.475 | INFO     | __main__:<module>:160 - Step20930, Loss: 3.5159246921539307, Grad L2 Norm: 0.02038472704589367
2025-11-23 23:38:41.470 | INFO     | __main__:<module>:160 - Step20940, Loss: 3.6339774131774902, Grad L2 Norm: 0.022597352042794228
2025-11-23 23:38:43.472 | INFO     | __main__:<module>:160 - Step20950, Loss: 3.5876996517181396, Grad L2 Norm: 0.021043315529823303
2025-11-23 23:38:45.472 | INFO     | __main__:<module>:160 - Step20960, Loss: 3.4800400733947754, Grad L2 Norm: 0.023095885291695595
2025-11-23 23:38:47.475 | INFO     | __main__:<module>:160 - Step20970, Loss: 3.582172393798828, Grad L2 Norm: 0.021836381405591965
2025-11-23 23:38:49.476 | INFO     | __main__:<module>:160 - Step20980, Loss: 3.534515857696533, Grad L2 Norm: 0.021145334467291832
2025-11-23 23:38:51.473 | INFO     | __main__:<module>:160 - Step20990, Loss: 3.5601413249969482, Grad L2 Norm: 0.023948850110173225
2025-11-23 23:38:53.471 | INFO     | __main__:<module>:160 - Step21000, Loss: 3.5855579376220703, Grad L2 Norm: 0.021138442680239677
2025-11-23 23:38:55.472 | INFO     | __main__:<module>:160 - Step21010, Loss: 3.624677896499634, Grad L2 Norm: 0.022339755669236183
2025-11-23 23:38:57.473 | INFO     | __main__:<module>:160 - Step21020, Loss: 3.608097553253174, Grad L2 Norm: 0.022051379084587097
2025-11-23 23:38:59.476 | INFO     | __main__:<module>:160 - Step21030, Loss: 3.61700177192688, Grad L2 Norm: 0.021518586203455925
2025-11-23 23:39:01.475 | INFO     | __main__:<module>:160 - Step21040, Loss: 3.549208402633667, Grad L2 Norm: 0.021324682980775833
2025-11-23 23:39:03.473 | INFO     | __main__:<module>:160 - Step21050, Loss: 3.649998188018799, Grad L2 Norm: 0.022548576816916466
2025-11-23 23:39:05.473 | INFO     | __main__:<module>:160 - Step21060, Loss: 3.657782554626465, Grad L2 Norm: 0.020956184715032578
2025-11-23 23:39:07.472 | INFO     | __main__:<module>:160 - Step21070, Loss: 3.6876659393310547, Grad L2 Norm: 0.024373330175876617
2025-11-23 23:39:09.469 | INFO     | __main__:<module>:160 - Step21080, Loss: 3.5034797191619873, Grad L2 Norm: 0.020141910761594772
2025-11-23 23:39:11.467 | INFO     | __main__:<module>:160 - Step21090, Loss: 3.6130874156951904, Grad L2 Norm: 0.023318316787481308
2025-11-23 23:39:13.469 | INFO     | __main__:<module>:160 - Step21100, Loss: 3.6485259532928467, Grad L2 Norm: 0.0229503121227026
2025-11-23 23:39:15.469 | INFO     | __main__:<module>:160 - Step21110, Loss: 3.651543617248535, Grad L2 Norm: 0.022985540330410004
2025-11-23 23:39:17.473 | INFO     | __main__:<module>:160 - Step21120, Loss: 3.6729464530944824, Grad L2 Norm: 0.022690560668706894
2025-11-23 23:39:19.484 | INFO     | __main__:<module>:160 - Step21130, Loss: 3.5084609985351562, Grad L2 Norm: 0.021293314173817635
2025-11-23 23:39:21.485 | INFO     | __main__:<module>:160 - Step21140, Loss: 3.490245819091797, Grad L2 Norm: 0.020100582391023636
2025-11-23 23:39:23.484 | INFO     | __main__:<module>:160 - Step21150, Loss: 3.6113409996032715, Grad L2 Norm: 0.024329986423254013
2025-11-23 23:39:25.483 | INFO     | __main__:<module>:160 - Step21160, Loss: 3.584963321685791, Grad L2 Norm: 0.021273696795105934
2025-11-23 23:39:27.484 | INFO     | __main__:<module>:160 - Step21170, Loss: 3.596285343170166, Grad L2 Norm: 0.022277632728219032
2025-11-23 23:39:29.483 | INFO     | __main__:<module>:160 - Step21180, Loss: 3.487849235534668, Grad L2 Norm: 0.022897984832525253
2025-11-23 23:39:31.481 | INFO     | __main__:<module>:160 - Step21190, Loss: 3.6405768394470215, Grad L2 Norm: 0.02190355770289898
2025-11-23 23:39:33.478 | INFO     | __main__:<module>:160 - Step21200, Loss: 3.584728717803955, Grad L2 Norm: 0.02225392684340477
2025-11-23 23:39:33.478 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:39:34.750 | INFO     | __main__:<module>:181 - validation loss: 3.5920854210853577
2025-11-23 23:39:36.757 | INFO     | __main__:<module>:160 - Step21210, Loss: 3.6495468616485596, Grad L2 Norm: 0.02210356295108795
2025-11-23 23:39:38.759 | INFO     | __main__:<module>:160 - Step21220, Loss: 3.5429866313934326, Grad L2 Norm: 0.020460741594433784
2025-11-23 23:39:40.758 | INFO     | __main__:<module>:160 - Step21230, Loss: 3.5845484733581543, Grad L2 Norm: 0.022014576941728592
2025-11-23 23:39:42.758 | INFO     | __main__:<module>:160 - Step21240, Loss: 3.697526454925537, Grad L2 Norm: 0.023878587409853935
2025-11-23 23:39:44.758 | INFO     | __main__:<module>:160 - Step21250, Loss: 3.6010050773620605, Grad L2 Norm: 0.02245117910206318
2025-11-23 23:39:46.757 | INFO     | __main__:<module>:160 - Step21260, Loss: 3.528014898300171, Grad L2 Norm: 0.022100528702139854
2025-11-23 23:39:48.761 | INFO     | __main__:<module>:160 - Step21270, Loss: 3.4344382286071777, Grad L2 Norm: 0.022849269211292267
2025-11-23 23:39:50.770 | INFO     | __main__:<module>:160 - Step21280, Loss: 3.5017333030700684, Grad L2 Norm: 0.020159810781478882
2025-11-23 23:39:52.776 | INFO     | __main__:<module>:160 - Step21290, Loss: 3.587852954864502, Grad L2 Norm: 0.02087731473147869
2025-11-23 23:39:54.778 | INFO     | __main__:<module>:160 - Step21300, Loss: 3.428119659423828, Grad L2 Norm: 0.021384557709097862
2025-11-23 23:39:56.787 | INFO     | __main__:<module>:160 - Step21310, Loss: 3.6175436973571777, Grad L2 Norm: 0.021787654608488083
2025-11-23 23:39:58.793 | INFO     | __main__:<module>:160 - Step21320, Loss: 3.5857834815979004, Grad L2 Norm: 0.02078990451991558
2025-11-23 23:40:00.795 | INFO     | __main__:<module>:160 - Step21330, Loss: 3.6821768283843994, Grad L2 Norm: 0.021678192541003227
2025-11-23 23:40:02.807 | INFO     | __main__:<module>:160 - Step21340, Loss: 3.610057830810547, Grad L2 Norm: 0.02229812741279602
2025-11-23 23:40:04.818 | INFO     | __main__:<module>:160 - Step21350, Loss: 3.4854488372802734, Grad L2 Norm: 0.020886637270450592
2025-11-23 23:40:06.829 | INFO     | __main__:<module>:160 - Step21360, Loss: 3.474161386489868, Grad L2 Norm: 0.023404112085700035
2025-11-23 23:40:08.845 | INFO     | __main__:<module>:160 - Step21370, Loss: 3.7252964973449707, Grad L2 Norm: 0.023387985303997993
2025-11-23 23:40:10.855 | INFO     | __main__:<module>:160 - Step21380, Loss: 3.6580233573913574, Grad L2 Norm: 0.022890763357281685
2025-11-23 23:40:12.869 | INFO     | __main__:<module>:160 - Step21390, Loss: 3.668501853942871, Grad L2 Norm: 0.021781984716653824
2025-11-23 23:40:14.876 | INFO     | __main__:<module>:160 - Step21400, Loss: 3.536910057067871, Grad L2 Norm: 0.022136537358164787
2025-11-23 23:40:16.884 | INFO     | __main__:<module>:160 - Step21410, Loss: 3.665949821472168, Grad L2 Norm: 0.023079749196767807
2025-11-23 23:40:18.887 | INFO     | __main__:<module>:160 - Step21420, Loss: 3.5134425163269043, Grad L2 Norm: 0.022958802059292793
2025-11-23 23:40:20.889 | INFO     | __main__:<module>:160 - Step21430, Loss: 3.657571315765381, Grad L2 Norm: 0.02156805619597435
2025-11-23 23:40:22.889 | INFO     | __main__:<module>:160 - Step21440, Loss: 3.6209473609924316, Grad L2 Norm: 0.02235511504113674
2025-11-23 23:40:24.891 | INFO     | __main__:<module>:160 - Step21450, Loss: 3.6724257469177246, Grad L2 Norm: 0.0232913326472044
2025-11-23 23:40:26.901 | INFO     | __main__:<module>:160 - Step21460, Loss: 3.6716575622558594, Grad L2 Norm: 0.02288079634308815
2025-11-23 23:40:28.906 | INFO     | __main__:<module>:160 - Step21470, Loss: 3.6175026893615723, Grad L2 Norm: 0.02374221198260784
2025-11-23 23:40:30.907 | INFO     | __main__:<module>:160 - Step21480, Loss: 3.5556421279907227, Grad L2 Norm: 0.022035423666238785
2025-11-23 23:40:32.919 | INFO     | __main__:<module>:160 - Step21490, Loss: 3.482522964477539, Grad L2 Norm: 0.023256439715623856
2025-11-23 23:40:34.924 | INFO     | __main__:<module>:160 - Step21500, Loss: 3.713723659515381, Grad L2 Norm: 0.021339401602745056
2025-11-23 23:40:36.935 | INFO     | __main__:<module>:160 - Step21510, Loss: 3.5867257118225098, Grad L2 Norm: 0.021986328065395355
2025-11-23 23:40:38.942 | INFO     | __main__:<module>:160 - Step21520, Loss: 3.4987640380859375, Grad L2 Norm: 0.02090180292725563
2025-11-23 23:40:40.944 | INFO     | __main__:<module>:160 - Step21530, Loss: 3.601335287094116, Grad L2 Norm: 0.022761525586247444
2025-11-23 23:40:42.958 | INFO     | __main__:<module>:160 - Step21540, Loss: 3.579158067703247, Grad L2 Norm: 0.025316232815384865
2025-11-23 23:40:44.968 | INFO     | __main__:<module>:160 - Step21550, Loss: 3.5323948860168457, Grad L2 Norm: 0.02038339339196682
2025-11-23 23:40:46.981 | INFO     | __main__:<module>:160 - Step21560, Loss: 3.464179515838623, Grad L2 Norm: 0.022012094035744667
2025-11-23 23:40:48.993 | INFO     | __main__:<module>:160 - Step21570, Loss: 3.6177284717559814, Grad L2 Norm: 0.022720634937286377
2025-11-23 23:40:51.004 | INFO     | __main__:<module>:160 - Step21580, Loss: 3.53237247467041, Grad L2 Norm: 0.021495969966053963
2025-11-23 23:40:53.018 | INFO     | __main__:<module>:160 - Step21590, Loss: 3.659348964691162, Grad L2 Norm: 0.01985805854201317
2025-11-23 23:40:55.032 | INFO     | __main__:<module>:160 - Step21600, Loss: 3.6105196475982666, Grad L2 Norm: 0.02459208108484745
2025-11-23 23:40:55.033 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:40:56.312 | INFO     | __main__:<module>:181 - validation loss: 3.5668848276138307
2025-11-23 23:40:58.332 | INFO     | __main__:<module>:160 - Step21610, Loss: 3.734790325164795, Grad L2 Norm: 0.02103792130947113
2025-11-23 23:41:00.341 | INFO     | __main__:<module>:160 - Step21620, Loss: 3.6854448318481445, Grad L2 Norm: 0.0277104414999485
2025-11-23 23:41:02.356 | INFO     | __main__:<module>:160 - Step21630, Loss: 3.7377963066101074, Grad L2 Norm: 0.022764606401324272
2025-11-23 23:41:04.371 | INFO     | __main__:<module>:160 - Step21640, Loss: 3.5542044639587402, Grad L2 Norm: 0.02220597118139267
2025-11-23 23:41:06.384 | INFO     | __main__:<module>:160 - Step21650, Loss: 3.6017861366271973, Grad L2 Norm: 0.022138897329568863
2025-11-23 23:41:08.392 | INFO     | __main__:<module>:160 - Step21660, Loss: 3.7007083892822266, Grad L2 Norm: 0.022126037627458572
2025-11-23 23:41:10.401 | INFO     | __main__:<module>:160 - Step21670, Loss: 3.6424407958984375, Grad L2 Norm: 0.025740288197994232
2025-11-23 23:41:12.412 | INFO     | __main__:<module>:160 - Step21680, Loss: 3.4615232944488525, Grad L2 Norm: 0.022624650970101357
2025-11-23 23:41:14.422 | INFO     | __main__:<module>:160 - Step21690, Loss: 3.554879665374756, Grad L2 Norm: 0.021998561918735504
2025-11-23 23:41:16.433 | INFO     | __main__:<module>:160 - Step21700, Loss: 3.631199359893799, Grad L2 Norm: 0.021097103133797646
2025-11-23 23:41:18.453 | INFO     | __main__:<module>:160 - Step21710, Loss: 3.5894649028778076, Grad L2 Norm: 0.022459181025624275
2025-11-23 23:41:20.467 | INFO     | __main__:<module>:160 - Step21720, Loss: 3.738372802734375, Grad L2 Norm: 0.02284061536192894
2025-11-23 23:41:22.470 | INFO     | __main__:<module>:160 - Step21730, Loss: 3.6432175636291504, Grad L2 Norm: 0.02193899266421795
2025-11-23 23:41:24.474 | INFO     | __main__:<module>:160 - Step21740, Loss: 3.553093433380127, Grad L2 Norm: 0.020785562694072723
2025-11-23 23:41:26.483 | INFO     | __main__:<module>:160 - Step21750, Loss: 3.563223361968994, Grad L2 Norm: 0.019639406353235245
2025-11-23 23:41:28.485 | INFO     | __main__:<module>:160 - Step21760, Loss: 3.752723217010498, Grad L2 Norm: 0.022406216710805893
2025-11-23 23:41:30.489 | INFO     | __main__:<module>:160 - Step21770, Loss: 3.433020830154419, Grad L2 Norm: 0.022283047437667847
2025-11-23 23:41:32.498 | INFO     | __main__:<module>:160 - Step21780, Loss: 3.710177183151245, Grad L2 Norm: 0.021388569846749306
2025-11-23 23:41:34.504 | INFO     | __main__:<module>:160 - Step21790, Loss: 3.513711929321289, Grad L2 Norm: 0.020574470981955528
2025-11-23 23:41:36.506 | INFO     | __main__:<module>:160 - Step21800, Loss: 3.5133914947509766, Grad L2 Norm: 0.02105684205889702
2025-11-23 23:41:38.512 | INFO     | __main__:<module>:160 - Step21810, Loss: 3.6943178176879883, Grad L2 Norm: 0.023769045248627663
2025-11-23 23:41:40.521 | INFO     | __main__:<module>:160 - Step21820, Loss: 3.6413111686706543, Grad L2 Norm: 0.02354642003774643
2025-11-23 23:41:42.533 | INFO     | __main__:<module>:160 - Step21830, Loss: 3.448652744293213, Grad L2 Norm: 0.019664397463202477
2025-11-23 23:41:44.539 | INFO     | __main__:<module>:160 - Step21840, Loss: 3.4078733921051025, Grad L2 Norm: 0.020093582570552826
2025-11-23 23:58:30.772 | INFO     | __main__:<module>:160 - Step21850, Loss: 3.6418404579162598, Grad L2 Norm: 0.020861875265836716
2025-11-23 23:58:32.151 | INFO     | __main__:<module>:160 - Step21860, Loss: 3.607076406478882, Grad L2 Norm: 0.021671000868082047
2025-11-23 23:58:33.531 | INFO     | __main__:<module>:160 - Step21870, Loss: 3.4892847537994385, Grad L2 Norm: 0.021257827058434486
2025-11-23 23:58:34.912 | INFO     | __main__:<module>:160 - Step21880, Loss: 3.518897533416748, Grad L2 Norm: 0.021803734824061394
2025-11-23 23:58:36.294 | INFO     | __main__:<module>:160 - Step21890, Loss: 3.636021137237549, Grad L2 Norm: 0.020615559071302414
2025-11-23 23:58:37.678 | INFO     | __main__:<module>:160 - Step21900, Loss: 3.540794610977173, Grad L2 Norm: 0.02122160792350769
2025-11-23 23:58:39.061 | INFO     | __main__:<module>:160 - Step21910, Loss: 3.5232038497924805, Grad L2 Norm: 0.021295296028256416
2025-11-23 23:58:40.443 | INFO     | __main__:<module>:160 - Step21920, Loss: 3.6065356731414795, Grad L2 Norm: 0.023749863728880882
2025-11-23 23:58:41.826 | INFO     | __main__:<module>:160 - Step21930, Loss: 3.7107903957366943, Grad L2 Norm: 0.02187419682741165
2025-11-23 23:58:43.212 | INFO     | __main__:<module>:160 - Step21940, Loss: 3.6094701290130615, Grad L2 Norm: 0.021497750654816628
2025-11-23 23:58:44.598 | INFO     | __main__:<module>:160 - Step21950, Loss: 3.550177574157715, Grad L2 Norm: 0.0223615113645792
2025-11-23 23:58:45.988 | INFO     | __main__:<module>:160 - Step21960, Loss: 3.5403740406036377, Grad L2 Norm: 0.022575944662094116
2025-11-23 23:58:47.383 | INFO     | __main__:<module>:160 - Step21970, Loss: 3.6689891815185547, Grad L2 Norm: 0.022687995806336403
2025-11-23 23:58:48.773 | INFO     | __main__:<module>:160 - Step21980, Loss: 3.7013745307922363, Grad L2 Norm: 0.023210439831018448
2025-11-23 23:58:50.165 | INFO     | __main__:<module>:160 - Step21990, Loss: 3.584895133972168, Grad L2 Norm: 0.02159777097404003
2025-11-23 23:58:51.557 | INFO     | __main__:<module>:160 - Step22000, Loss: 3.688584566116333, Grad L2 Norm: 0.022170018404722214
2025-11-23 23:58:51.558 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:58:52.364 | INFO     | __main__:<module>:181 - validation loss: 3.6081783890724184
2025-11-23 23:58:52.364 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_22000.pt
2025-11-23 23:58:54.064 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-23 23:58:55.452 | INFO     | __main__:<module>:160 - Step22010, Loss: 3.534649610519409, Grad L2 Norm: 0.021506480872631073
2025-11-23 23:58:56.844 | INFO     | __main__:<module>:160 - Step22020, Loss: 3.743691921234131, Grad L2 Norm: 0.022370073944330215
2025-11-23 23:58:58.238 | INFO     | __main__:<module>:160 - Step22030, Loss: 3.4759230613708496, Grad L2 Norm: 0.02258588932454586
2025-11-23 23:58:59.630 | INFO     | __main__:<module>:160 - Step22040, Loss: 3.72477650642395, Grad L2 Norm: 0.024075811728835106
2025-11-23 23:59:01.025 | INFO     | __main__:<module>:160 - Step22050, Loss: 3.4658360481262207, Grad L2 Norm: 0.02140960656106472
2025-11-23 23:59:02.423 | INFO     | __main__:<module>:160 - Step22060, Loss: 3.418189764022827, Grad L2 Norm: 0.02248816005885601
2025-11-23 23:59:03.823 | INFO     | __main__:<module>:160 - Step22070, Loss: 3.8791399002075195, Grad L2 Norm: 0.027305247262120247
2025-11-23 23:59:05.222 | INFO     | __main__:<module>:160 - Step22080, Loss: 3.541353702545166, Grad L2 Norm: 0.023760827258229256
2025-11-23 23:59:06.623 | INFO     | __main__:<module>:160 - Step22090, Loss: 3.5645108222961426, Grad L2 Norm: 0.023588303476572037
2025-11-23 23:59:08.023 | INFO     | __main__:<module>:160 - Step22100, Loss: 3.571296215057373, Grad L2 Norm: 0.02193334512412548
2025-11-23 23:59:09.424 | INFO     | __main__:<module>:160 - Step22110, Loss: 3.5913538932800293, Grad L2 Norm: 0.020879745483398438
2025-11-23 23:59:10.826 | INFO     | __main__:<module>:160 - Step22120, Loss: 3.602912664413452, Grad L2 Norm: 0.02400125563144684
2025-11-23 23:59:12.225 | INFO     | __main__:<module>:160 - Step22130, Loss: 3.539933681488037, Grad L2 Norm: 0.021761814132332802
2025-11-23 23:59:13.625 | INFO     | __main__:<module>:160 - Step22140, Loss: 3.552403450012207, Grad L2 Norm: 0.020930474624037743
2025-11-23 23:59:15.029 | INFO     | __main__:<module>:160 - Step22150, Loss: 3.641510009765625, Grad L2 Norm: 0.02185245417058468
2025-11-23 23:59:16.431 | INFO     | __main__:<module>:160 - Step22160, Loss: 3.653257369995117, Grad L2 Norm: 0.022199906408786774
2025-11-23 23:59:17.837 | INFO     | __main__:<module>:160 - Step22170, Loss: 3.59041166305542, Grad L2 Norm: 0.02388291247189045
2025-11-23 23:59:19.243 | INFO     | __main__:<module>:160 - Step22180, Loss: 3.6424560546875, Grad L2 Norm: 0.021446136757731438
2025-11-23 23:59:20.647 | INFO     | __main__:<module>:160 - Step22190, Loss: 3.602198362350464, Grad L2 Norm: 0.020514393225312233
2025-11-23 23:59:22.055 | INFO     | __main__:<module>:160 - Step22200, Loss: 3.671133518218994, Grad L2 Norm: 0.02294054813683033
2025-11-23 23:59:23.461 | INFO     | __main__:<module>:160 - Step22210, Loss: 3.636949300765991, Grad L2 Norm: 0.02123398892581463
2025-11-23 23:59:24.865 | INFO     | __main__:<module>:160 - Step22220, Loss: 3.5455102920532227, Grad L2 Norm: 0.02145591750741005
2025-11-23 23:59:26.270 | INFO     | __main__:<module>:160 - Step22230, Loss: 3.6419739723205566, Grad L2 Norm: 0.0223914235830307
2025-11-23 23:59:27.678 | INFO     | __main__:<module>:160 - Step22240, Loss: 3.552605628967285, Grad L2 Norm: 0.020445672795176506
2025-11-23 23:59:29.087 | INFO     | __main__:<module>:160 - Step22250, Loss: 3.5195987224578857, Grad L2 Norm: 0.02075411193072796
2025-11-23 23:59:30.494 | INFO     | __main__:<module>:160 - Step22260, Loss: 3.5076699256896973, Grad L2 Norm: 0.02396000176668167
2025-11-23 23:59:31.902 | INFO     | __main__:<module>:160 - Step22270, Loss: 3.610706090927124, Grad L2 Norm: 0.022657152265310287
2025-11-23 23:59:33.310 | INFO     | __main__:<module>:160 - Step22280, Loss: 3.68391752243042, Grad L2 Norm: 0.022614004090428352
2025-11-23 23:59:34.720 | INFO     | __main__:<module>:160 - Step22290, Loss: 3.620302677154541, Grad L2 Norm: 0.021198073402047157
2025-11-23 23:59:36.129 | INFO     | __main__:<module>:160 - Step22300, Loss: 3.5717194080352783, Grad L2 Norm: 0.021876569837331772
2025-11-23 23:59:37.537 | INFO     | __main__:<module>:160 - Step22310, Loss: 3.501274347305298, Grad L2 Norm: 0.020113574340939522
2025-11-23 23:59:38.943 | INFO     | __main__:<module>:160 - Step22320, Loss: 3.6926498413085938, Grad L2 Norm: 0.02274148352444172
2025-11-23 23:59:40.352 | INFO     | __main__:<module>:160 - Step22330, Loss: 3.60575795173645, Grad L2 Norm: 0.022149285301566124
2025-11-23 23:59:41.761 | INFO     | __main__:<module>:160 - Step22340, Loss: 3.586791753768921, Grad L2 Norm: 0.022104164585471153
2025-11-23 23:59:43.195 | INFO     | __main__:<module>:160 - Step22350, Loss: 3.6209983825683594, Grad L2 Norm: 0.022177767008543015
2025-11-23 23:59:44.687 | INFO     | __main__:<module>:160 - Step22360, Loss: 3.7627811431884766, Grad L2 Norm: 0.02459457702934742
2025-11-23 23:59:46.174 | INFO     | __main__:<module>:160 - Step22370, Loss: 3.6815617084503174, Grad L2 Norm: 0.020991690456867218
2025-11-23 23:59:47.681 | INFO     | __main__:<module>:160 - Step22380, Loss: 3.5674386024475098, Grad L2 Norm: 0.022232281044125557
2025-11-23 23:59:49.187 | INFO     | __main__:<module>:160 - Step22390, Loss: 3.7308566570281982, Grad L2 Norm: 0.022134963423013687
2025-11-23 23:59:50.692 | INFO     | __main__:<module>:160 - Step22400, Loss: 3.548798084259033, Grad L2 Norm: 0.022893797606229782
2025-11-23 23:59:50.693 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-23 23:59:51.596 | INFO     | __main__:<module>:181 - validation loss: 3.605854070186615
2025-11-23 23:59:53.109 | INFO     | __main__:<module>:160 - Step22410, Loss: 3.438992977142334, Grad L2 Norm: 0.020585505291819572
2025-11-23 23:59:54.614 | INFO     | __main__:<module>:160 - Step22420, Loss: 3.500861406326294, Grad L2 Norm: 0.020529774948954582
2025-11-23 23:59:56.121 | INFO     | __main__:<module>:160 - Step22430, Loss: 3.7410356998443604, Grad L2 Norm: 0.021296635270118713
2025-11-23 23:59:57.627 | INFO     | __main__:<module>:160 - Step22440, Loss: 3.523874044418335, Grad L2 Norm: 0.020547861233353615
2025-11-23 23:59:59.131 | INFO     | __main__:<module>:160 - Step22450, Loss: 3.5436058044433594, Grad L2 Norm: 0.022779256105422974
2025-11-24 00:00:00.638 | INFO     | __main__:<module>:160 - Step22460, Loss: 3.645082712173462, Grad L2 Norm: 0.02281799539923668
2025-11-24 00:00:02.146 | INFO     | __main__:<module>:160 - Step22470, Loss: 3.5888237953186035, Grad L2 Norm: 0.02302771434187889
2025-11-24 00:00:03.713 | INFO     | __main__:<module>:160 - Step22480, Loss: 3.550826072692871, Grad L2 Norm: 0.022482963278889656
2025-11-24 00:00:05.316 | INFO     | __main__:<module>:160 - Step22490, Loss: 3.65350341796875, Grad L2 Norm: 0.021724069491028786
2025-11-24 00:00:06.916 | INFO     | __main__:<module>:160 - Step22500, Loss: 3.5659573078155518, Grad L2 Norm: 0.021635117009282112
2025-11-24 00:00:08.516 | INFO     | __main__:<module>:160 - Step22510, Loss: 3.573270797729492, Grad L2 Norm: 0.020637057721614838
2025-11-24 00:00:10.115 | INFO     | __main__:<module>:160 - Step22520, Loss: 3.536259889602661, Grad L2 Norm: 0.021348780021071434
2025-11-24 00:00:11.714 | INFO     | __main__:<module>:160 - Step22530, Loss: 3.4987435340881348, Grad L2 Norm: 0.020478013902902603
2025-11-24 00:00:13.314 | INFO     | __main__:<module>:160 - Step22540, Loss: 3.64078688621521, Grad L2 Norm: 0.02083132229745388
2025-11-24 00:00:14.913 | INFO     | __main__:<module>:160 - Step22550, Loss: 3.499549627304077, Grad L2 Norm: 0.021982332691550255
2025-11-24 00:00:16.513 | INFO     | __main__:<module>:160 - Step22560, Loss: 3.573678493499756, Grad L2 Norm: 0.02375246211886406
2025-11-24 00:00:18.111 | INFO     | __main__:<module>:160 - Step22570, Loss: 3.4880199432373047, Grad L2 Norm: 0.021909404546022415
2025-11-24 00:00:19.711 | INFO     | __main__:<module>:160 - Step22580, Loss: 3.551917791366577, Grad L2 Norm: 0.02147555537521839
2025-11-24 00:00:21.311 | INFO     | __main__:<module>:160 - Step22590, Loss: 3.5662944316864014, Grad L2 Norm: 0.02234623022377491
2025-11-24 00:00:22.911 | INFO     | __main__:<module>:160 - Step22600, Loss: 3.5549917221069336, Grad L2 Norm: 0.021318059414625168
2025-11-24 00:00:24.510 | INFO     | __main__:<module>:160 - Step22610, Loss: 3.478898525238037, Grad L2 Norm: 0.02189592644572258
2025-11-24 00:00:26.111 | INFO     | __main__:<module>:160 - Step22620, Loss: 3.5558929443359375, Grad L2 Norm: 0.022462906315922737
2025-11-24 00:00:27.710 | INFO     | __main__:<module>:160 - Step22630, Loss: 3.669983148574829, Grad L2 Norm: 0.022251548245549202
2025-11-24 00:00:29.309 | INFO     | __main__:<module>:160 - Step22640, Loss: 3.557607889175415, Grad L2 Norm: 0.02262370102107525
2025-11-24 00:00:30.909 | INFO     | __main__:<module>:160 - Step22650, Loss: 3.607191801071167, Grad L2 Norm: 0.02272326499223709
2025-11-24 00:00:32.507 | INFO     | __main__:<module>:160 - Step22660, Loss: 3.603102207183838, Grad L2 Norm: 0.01983320713043213
2025-11-24 00:00:34.108 | INFO     | __main__:<module>:160 - Step22670, Loss: 3.527906894683838, Grad L2 Norm: 0.02174748107790947
2025-11-24 00:00:35.707 | INFO     | __main__:<module>:160 - Step22680, Loss: 3.474672317504883, Grad L2 Norm: 0.021588731557130814
2025-11-24 00:00:37.307 | INFO     | __main__:<module>:160 - Step22690, Loss: 3.562514305114746, Grad L2 Norm: 0.0220666341483593
2025-11-24 00:00:38.905 | INFO     | __main__:<module>:160 - Step22700, Loss: 3.5024259090423584, Grad L2 Norm: 0.020280975848436356
2025-11-24 00:00:40.506 | INFO     | __main__:<module>:160 - Step22710, Loss: 3.5499720573425293, Grad L2 Norm: 0.02123747393488884
2025-11-24 00:00:42.105 | INFO     | __main__:<module>:160 - Step22720, Loss: 3.5411109924316406, Grad L2 Norm: 0.02255009301006794
2025-11-24 00:00:43.705 | INFO     | __main__:<module>:160 - Step22730, Loss: 3.555769205093384, Grad L2 Norm: 0.021941756829619408
2025-11-24 00:00:45.303 | INFO     | __main__:<module>:160 - Step22740, Loss: 3.61039137840271, Grad L2 Norm: 0.023018859326839447
2025-11-24 00:00:46.902 | INFO     | __main__:<module>:160 - Step22750, Loss: 3.4987432956695557, Grad L2 Norm: 0.022863095626235008
2025-11-24 00:00:48.503 | INFO     | __main__:<module>:160 - Step22760, Loss: 3.612969398498535, Grad L2 Norm: 0.021747998893260956
2025-11-24 00:00:50.103 | INFO     | __main__:<module>:160 - Step22770, Loss: 3.731293201446533, Grad L2 Norm: 0.021958988159894943
2025-11-24 00:00:51.703 | INFO     | __main__:<module>:160 - Step22780, Loss: 3.592560291290283, Grad L2 Norm: 0.02095162495970726
2025-11-24 00:00:53.302 | INFO     | __main__:<module>:160 - Step22790, Loss: 3.5593419075012207, Grad L2 Norm: 0.021556714549660683
2025-11-24 00:00:54.901 | INFO     | __main__:<module>:160 - Step22800, Loss: 3.601107597351074, Grad L2 Norm: 0.02271592989563942
2025-11-24 00:00:54.902 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:00:55.891 | INFO     | __main__:<module>:181 - validation loss: 3.5990846157073975
2025-11-24 00:00:57.531 | INFO     | __main__:<module>:160 - Step22810, Loss: 3.4369428157806396, Grad L2 Norm: 0.02092319168150425
2025-11-24 00:00:59.244 | INFO     | __main__:<module>:160 - Step22820, Loss: 3.47312331199646, Grad L2 Norm: 0.022180916741490364
2025-11-24 00:01:00.953 | INFO     | __main__:<module>:160 - Step22830, Loss: 3.49560546875, Grad L2 Norm: 0.02134552411735058
2025-11-24 00:01:02.665 | INFO     | __main__:<module>:160 - Step22840, Loss: 3.635450839996338, Grad L2 Norm: 0.02187068574130535
2025-11-24 00:01:04.375 | INFO     | __main__:<module>:160 - Step22850, Loss: 3.5443670749664307, Grad L2 Norm: 0.020993299782276154
2025-11-24 00:01:06.086 | INFO     | __main__:<module>:160 - Step22860, Loss: 3.5414299964904785, Grad L2 Norm: 0.021208392456173897
2025-11-24 00:01:07.795 | INFO     | __main__:<module>:160 - Step22870, Loss: 3.607335329055786, Grad L2 Norm: 0.022096620872616768
2025-11-24 00:01:09.511 | INFO     | __main__:<module>:160 - Step22880, Loss: 3.552699565887451, Grad L2 Norm: 0.02139720320701599
2025-11-24 00:01:11.223 | INFO     | __main__:<module>:160 - Step22890, Loss: 3.611859083175659, Grad L2 Norm: 0.023226385936141014
2025-11-24 00:01:12.934 | INFO     | __main__:<module>:160 - Step22900, Loss: 3.469130516052246, Grad L2 Norm: 0.021972239017486572
2025-11-24 00:01:14.647 | INFO     | __main__:<module>:160 - Step22910, Loss: 3.858977794647217, Grad L2 Norm: 0.025075072422623634
2025-11-24 00:01:16.359 | INFO     | __main__:<module>:160 - Step22920, Loss: 3.5447070598602295, Grad L2 Norm: 0.022693663835525513
2025-11-24 00:01:18.070 | INFO     | __main__:<module>:160 - Step22930, Loss: 3.564668655395508, Grad L2 Norm: 0.021092208102345467
2025-11-24 00:01:19.781 | INFO     | __main__:<module>:160 - Step22940, Loss: 3.547208786010742, Grad L2 Norm: 0.019752925261855125
2025-11-24 00:01:21.491 | INFO     | __main__:<module>:160 - Step22950, Loss: 3.4673681259155273, Grad L2 Norm: 0.021748878061771393
2025-11-24 00:01:23.202 | INFO     | __main__:<module>:160 - Step22960, Loss: 3.667525053024292, Grad L2 Norm: 0.022802190855145454
2025-11-24 00:01:24.912 | INFO     | __main__:<module>:160 - Step22970, Loss: 3.6056511402130127, Grad L2 Norm: 0.024079080671072006
2025-11-24 00:01:26.624 | INFO     | __main__:<module>:160 - Step22980, Loss: 3.7064437866210938, Grad L2 Norm: 0.020927652716636658
2025-11-24 00:01:28.334 | INFO     | __main__:<module>:160 - Step22990, Loss: 3.6200122833251953, Grad L2 Norm: 0.021964671090245247
2025-11-24 00:01:30.044 | INFO     | __main__:<module>:160 - Step23000, Loss: 3.579564094543457, Grad L2 Norm: 0.021678604185581207
2025-11-24 00:01:31.758 | INFO     | __main__:<module>:160 - Step23010, Loss: 3.734039783477783, Grad L2 Norm: 0.023145796731114388
2025-11-24 00:01:33.468 | INFO     | __main__:<module>:160 - Step23020, Loss: 3.692840337753296, Grad L2 Norm: 0.021712563931941986
2025-11-24 00:01:35.179 | INFO     | __main__:<module>:160 - Step23030, Loss: 3.497882843017578, Grad L2 Norm: 0.02152274362742901
2025-11-24 00:01:36.888 | INFO     | __main__:<module>:160 - Step23040, Loss: 3.6662986278533936, Grad L2 Norm: 0.02327319048345089
2025-11-24 00:01:38.598 | INFO     | __main__:<module>:160 - Step23050, Loss: 3.6094658374786377, Grad L2 Norm: 0.022738017141819
2025-11-24 00:01:40.309 | INFO     | __main__:<module>:160 - Step23060, Loss: 3.59622859954834, Grad L2 Norm: 0.02558429352939129
2025-11-24 00:01:42.020 | INFO     | __main__:<module>:160 - Step23070, Loss: 3.530550003051758, Grad L2 Norm: 0.02134978398680687
2025-11-24 00:01:43.731 | INFO     | __main__:<module>:160 - Step23080, Loss: 3.5886054039001465, Grad L2 Norm: 0.022012818604707718
2025-11-24 00:01:45.440 | INFO     | __main__:<module>:160 - Step23090, Loss: 3.6678199768066406, Grad L2 Norm: 0.02360489033162594
2025-11-24 00:01:47.151 | INFO     | __main__:<module>:160 - Step23100, Loss: 3.4965109825134277, Grad L2 Norm: 0.022607946768403053
2025-11-24 00:01:48.861 | INFO     | __main__:<module>:160 - Step23110, Loss: 3.54390025138855, Grad L2 Norm: 0.020973047241568565
2025-11-24 00:01:50.574 | INFO     | __main__:<module>:160 - Step23120, Loss: 3.766134262084961, Grad L2 Norm: 0.02172210067510605
2025-11-24 00:01:52.284 | INFO     | __main__:<module>:160 - Step23130, Loss: 3.748586654663086, Grad L2 Norm: 0.022746194154024124
2025-11-24 00:01:53.995 | INFO     | __main__:<module>:160 - Step23140, Loss: 3.550734043121338, Grad L2 Norm: 0.021224400028586388
2025-11-24 00:01:55.707 | INFO     | __main__:<module>:160 - Step23150, Loss: 3.5236473083496094, Grad L2 Norm: 0.022223547101020813
2025-11-24 00:01:57.416 | INFO     | __main__:<module>:160 - Step23160, Loss: 3.567997694015503, Grad L2 Norm: 0.021652499213814735
2025-11-24 00:01:59.130 | INFO     | __main__:<module>:160 - Step23170, Loss: 3.701204538345337, Grad L2 Norm: 0.02166706696152687
2025-11-24 00:02:00.841 | INFO     | __main__:<module>:160 - Step23180, Loss: 3.614471673965454, Grad L2 Norm: 0.0218051690608263
2025-11-24 00:02:02.554 | INFO     | __main__:<module>:160 - Step23190, Loss: 3.687629222869873, Grad L2 Norm: 0.023428823798894882
2025-11-24 00:02:04.267 | INFO     | __main__:<module>:160 - Step23200, Loss: 3.5474114418029785, Grad L2 Norm: 0.02069796808063984
2025-11-24 00:02:04.267 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:02:05.282 | INFO     | __main__:<module>:181 - validation loss: 3.5842386960983275
2025-11-24 00:02:06.997 | INFO     | __main__:<module>:160 - Step23210, Loss: 3.5276973247528076, Grad L2 Norm: 0.02192520722746849
2025-11-24 00:02:08.732 | INFO     | __main__:<module>:160 - Step23220, Loss: 3.5876402854919434, Grad L2 Norm: 0.02070261910557747
2025-11-24 00:02:10.467 | INFO     | __main__:<module>:160 - Step23230, Loss: 3.6201586723327637, Grad L2 Norm: 0.0227422583848238
2025-11-24 00:02:12.204 | INFO     | __main__:<module>:160 - Step23240, Loss: 3.514120578765869, Grad L2 Norm: 0.021059921011328697
2025-11-24 00:02:13.893 | INFO     | __main__:<module>:160 - Step23250, Loss: 3.648589611053467, Grad L2 Norm: 0.022810623049736023
2025-11-24 00:02:15.620 | INFO     | __main__:<module>:160 - Step23260, Loss: 3.5722506046295166, Grad L2 Norm: 0.021746525540947914
2025-11-24 00:02:17.357 | INFO     | __main__:<module>:160 - Step23270, Loss: 3.470590829849243, Grad L2 Norm: 0.021222516894340515
2025-11-24 00:02:19.092 | INFO     | __main__:<module>:160 - Step23280, Loss: 3.6369118690490723, Grad L2 Norm: 0.02241695113480091
2025-11-24 00:02:20.827 | INFO     | __main__:<module>:160 - Step23290, Loss: 3.6048903465270996, Grad L2 Norm: 0.021862929686903954
2025-11-24 00:02:22.563 | INFO     | __main__:<module>:160 - Step23300, Loss: 3.6209869384765625, Grad L2 Norm: 0.023309843614697456
2025-11-24 00:02:24.301 | INFO     | __main__:<module>:160 - Step23310, Loss: 3.5942561626434326, Grad L2 Norm: 0.021664872765541077
2025-11-24 00:02:26.037 | INFO     | __main__:<module>:160 - Step23320, Loss: 3.565581798553467, Grad L2 Norm: 0.021741120144724846
2025-11-24 00:02:27.772 | INFO     | __main__:<module>:160 - Step23330, Loss: 3.547420024871826, Grad L2 Norm: 0.021316874772310257
2025-11-24 00:02:29.498 | INFO     | __main__:<module>:160 - Step23340, Loss: 3.540818929672241, Grad L2 Norm: 0.021061044186353683
2025-11-24 00:02:31.226 | INFO     | __main__:<module>:160 - Step23350, Loss: 3.7644693851470947, Grad L2 Norm: 0.02431866154074669
2025-11-24 00:02:32.949 | INFO     | __main__:<module>:160 - Step23360, Loss: 3.6014862060546875, Grad L2 Norm: 0.022102292627096176
2025-11-24 00:02:34.679 | INFO     | __main__:<module>:160 - Step23370, Loss: 3.601546287536621, Grad L2 Norm: 0.021684791892766953
2025-11-24 00:02:36.396 | INFO     | __main__:<module>:160 - Step23380, Loss: 3.5969247817993164, Grad L2 Norm: 0.022566525265574455
2025-11-24 00:02:38.120 | INFO     | __main__:<module>:160 - Step23390, Loss: 3.675180673599243, Grad L2 Norm: 0.023227229714393616
2025-11-24 00:02:39.845 | INFO     | __main__:<module>:160 - Step23400, Loss: 3.4799656867980957, Grad L2 Norm: 0.020580407232046127
2025-11-24 00:02:41.570 | INFO     | __main__:<module>:160 - Step23410, Loss: 3.6152405738830566, Grad L2 Norm: 0.021707775071263313
2025-11-24 00:02:43.296 | INFO     | __main__:<module>:160 - Step23420, Loss: 3.499300956726074, Grad L2 Norm: 0.02166440337896347
2025-11-24 00:02:45.016 | INFO     | __main__:<module>:160 - Step23430, Loss: 3.735024929046631, Grad L2 Norm: 0.024673396721482277
2025-11-24 00:02:46.728 | INFO     | __main__:<module>:160 - Step23440, Loss: 3.5130085945129395, Grad L2 Norm: 0.0214338768273592
2025-11-24 00:02:48.453 | INFO     | __main__:<module>:160 - Step23450, Loss: 3.6117794513702393, Grad L2 Norm: 0.021499279886484146
2025-11-24 00:02:50.171 | INFO     | __main__:<module>:160 - Step23460, Loss: 3.5663907527923584, Grad L2 Norm: 0.021905774250626564
2025-11-24 00:02:51.898 | INFO     | __main__:<module>:160 - Step23470, Loss: 3.5895678997039795, Grad L2 Norm: 0.020860470831394196
2025-11-24 00:02:53.622 | INFO     | __main__:<module>:160 - Step23480, Loss: 3.5994200706481934, Grad L2 Norm: 0.023184731602668762
2025-11-24 00:02:55.336 | INFO     | __main__:<module>:160 - Step23490, Loss: 3.4079794883728027, Grad L2 Norm: 0.022366663441061974
2025-11-24 00:02:57.064 | INFO     | __main__:<module>:160 - Step23500, Loss: 3.6059837341308594, Grad L2 Norm: 0.02261880598962307
2025-11-24 00:02:58.784 | INFO     | __main__:<module>:160 - Step23510, Loss: 3.5666494369506836, Grad L2 Norm: 0.020878229290246964
2025-11-24 00:03:00.510 | INFO     | __main__:<module>:160 - Step23520, Loss: 3.5929739475250244, Grad L2 Norm: 0.021123940125107765
2025-11-24 00:03:02.223 | INFO     | __main__:<module>:160 - Step23530, Loss: 3.6112875938415527, Grad L2 Norm: 0.02213834412395954
2025-11-24 00:03:03.931 | INFO     | __main__:<module>:160 - Step23540, Loss: 3.526054620742798, Grad L2 Norm: 0.021602090448141098
2025-11-24 00:03:05.660 | INFO     | __main__:<module>:160 - Step23550, Loss: 3.47320818901062, Grad L2 Norm: 0.0225355364382267
2025-11-24 00:03:07.386 | INFO     | __main__:<module>:160 - Step23560, Loss: 3.495666742324829, Grad L2 Norm: 0.020666107535362244
2025-11-24 00:03:09.113 | INFO     | __main__:<module>:160 - Step23570, Loss: 3.5677218437194824, Grad L2 Norm: 0.02220325730741024
2025-11-24 00:03:10.838 | INFO     | __main__:<module>:160 - Step23580, Loss: 3.443352222442627, Grad L2 Norm: 0.021941659972071648
2025-11-24 00:03:12.565 | INFO     | __main__:<module>:160 - Step23590, Loss: 3.7191014289855957, Grad L2 Norm: 0.024149475619196892
2025-11-24 00:03:14.279 | INFO     | __main__:<module>:160 - Step23600, Loss: 3.597195863723755, Grad L2 Norm: 0.024856895208358765
2025-11-24 00:03:14.280 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:03:15.297 | INFO     | __main__:<module>:181 - validation loss: 3.572449040412903
2025-11-24 00:03:17.010 | INFO     | __main__:<module>:160 - Step23610, Loss: 3.6722795963287354, Grad L2 Norm: 0.021934717893600464
2025-11-24 00:03:18.739 | INFO     | __main__:<module>:160 - Step23620, Loss: 3.5299806594848633, Grad L2 Norm: 0.02265165001153946
2025-11-24 00:03:20.457 | INFO     | __main__:<module>:160 - Step23630, Loss: 3.634561538696289, Grad L2 Norm: 0.022141583263874054
2025-11-24 00:03:22.180 | INFO     | __main__:<module>:160 - Step23640, Loss: 3.459212064743042, Grad L2 Norm: 0.02134820632636547
2025-11-24 00:03:23.908 | INFO     | __main__:<module>:160 - Step23650, Loss: 3.589829444885254, Grad L2 Norm: 0.02120302990078926
2025-11-24 00:03:25.621 | INFO     | __main__:<module>:160 - Step23660, Loss: 3.600412368774414, Grad L2 Norm: 0.02013913355767727
2025-11-24 00:03:27.349 | INFO     | __main__:<module>:160 - Step23670, Loss: 3.6459221839904785, Grad L2 Norm: 0.02138493023812771
2025-11-24 00:03:29.064 | INFO     | __main__:<module>:160 - Step23680, Loss: 3.5749807357788086, Grad L2 Norm: 0.021521195769309998
2025-11-24 00:03:30.781 | INFO     | __main__:<module>:160 - Step23690, Loss: 3.5681889057159424, Grad L2 Norm: 0.02219056896865368
2025-11-24 00:03:32.504 | INFO     | __main__:<module>:160 - Step23700, Loss: 3.501554489135742, Grad L2 Norm: 0.022016828879714012
2025-11-24 00:03:34.219 | INFO     | __main__:<module>:160 - Step23710, Loss: 3.5925536155700684, Grad L2 Norm: 0.022473324090242386
2025-11-24 00:03:35.946 | INFO     | __main__:<module>:160 - Step23720, Loss: 3.517073631286621, Grad L2 Norm: 0.020563757047057152
2025-11-24 00:03:37.661 | INFO     | __main__:<module>:160 - Step23730, Loss: 3.568427801132202, Grad L2 Norm: 0.021802177652716637
2025-11-24 00:03:39.379 | INFO     | __main__:<module>:160 - Step23740, Loss: 3.6690821647644043, Grad L2 Norm: 0.022217318415641785
2025-11-24 00:03:41.114 | INFO     | __main__:<module>:160 - Step23750, Loss: 3.5682125091552734, Grad L2 Norm: 0.02324303612112999
2025-11-24 00:03:42.836 | INFO     | __main__:<module>:160 - Step23760, Loss: 3.5721535682678223, Grad L2 Norm: 0.02217712439596653
2025-11-24 00:03:44.563 | INFO     | __main__:<module>:160 - Step23770, Loss: 3.5441486835479736, Grad L2 Norm: 0.021743956953287125
2025-11-24 00:03:46.298 | INFO     | __main__:<module>:160 - Step23780, Loss: 3.512608051300049, Grad L2 Norm: 0.021096788346767426
2025-11-24 00:03:48.087 | INFO     | __main__:<module>:160 - Step23790, Loss: 3.56660532951355, Grad L2 Norm: 0.021847190335392952
2025-11-24 00:03:50.140 | INFO     | __main__:<module>:160 - Step23800, Loss: 3.451977252960205, Grad L2 Norm: 0.02064059115946293
2025-11-24 00:03:52.189 | INFO     | __main__:<module>:160 - Step23810, Loss: 3.563565492630005, Grad L2 Norm: 0.021264560520648956
2025-11-24 00:03:54.240 | INFO     | __main__:<module>:160 - Step23820, Loss: 3.5707454681396484, Grad L2 Norm: 0.024952534586191177
2025-11-24 00:03:56.286 | INFO     | __main__:<module>:160 - Step23830, Loss: 3.6356656551361084, Grad L2 Norm: 0.022440621629357338
2025-11-24 00:03:58.329 | INFO     | __main__:<module>:160 - Step23840, Loss: 3.4785120487213135, Grad L2 Norm: 0.022790636867284775
2025-11-24 00:04:00.373 | INFO     | __main__:<module>:160 - Step23850, Loss: 3.577054023742676, Grad L2 Norm: 0.020862607285380363
2025-11-24 00:04:02.416 | INFO     | __main__:<module>:160 - Step23860, Loss: 3.492084503173828, Grad L2 Norm: 0.024101080372929573
2025-11-24 00:04:04.463 | INFO     | __main__:<module>:160 - Step23870, Loss: 3.59688401222229, Grad L2 Norm: 0.02213478460907936
2025-11-24 00:04:06.500 | INFO     | __main__:<module>:160 - Step23880, Loss: 3.523263931274414, Grad L2 Norm: 0.021034888923168182
2025-11-24 00:04:08.538 | INFO     | __main__:<module>:160 - Step23890, Loss: 3.519768714904785, Grad L2 Norm: 0.021552037447690964
2025-11-24 00:04:10.578 | INFO     | __main__:<module>:160 - Step23900, Loss: 3.394261121749878, Grad L2 Norm: 0.022011108696460724
2025-11-24 00:04:12.622 | INFO     | __main__:<module>:160 - Step23910, Loss: 3.583804130554199, Grad L2 Norm: 0.021057356148958206
2025-11-24 00:04:14.663 | INFO     | __main__:<module>:160 - Step23920, Loss: 3.5396265983581543, Grad L2 Norm: 0.025052327662706375
2025-11-24 00:04:16.716 | INFO     | __main__:<module>:160 - Step23930, Loss: 3.5024471282958984, Grad L2 Norm: 0.021354056894779205
2025-11-24 00:04:18.758 | INFO     | __main__:<module>:160 - Step23940, Loss: 3.6350131034851074, Grad L2 Norm: 0.023297876119613647
2025-11-24 00:04:20.802 | INFO     | __main__:<module>:160 - Step23950, Loss: 3.577174186706543, Grad L2 Norm: 0.023207727819681168
2025-11-24 00:04:22.853 | INFO     | __main__:<module>:160 - Step23960, Loss: 3.695467472076416, Grad L2 Norm: 0.02298331819474697
2025-11-24 00:04:24.897 | INFO     | __main__:<module>:160 - Step23970, Loss: 3.647993564605713, Grad L2 Norm: 0.021875815466046333
2025-11-24 00:04:26.941 | INFO     | __main__:<module>:160 - Step23980, Loss: 3.5191853046417236, Grad L2 Norm: 0.023232033476233482
2025-11-24 00:04:28.992 | INFO     | __main__:<module>:160 - Step23990, Loss: 3.7025020122528076, Grad L2 Norm: 0.022739265114068985
2025-11-24 00:04:31.041 | INFO     | __main__:<module>:160 - Step24000, Loss: 3.5819411277770996, Grad L2 Norm: 0.020578989759087563
2025-11-24 00:04:31.041 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:04:32.348 | INFO     | __main__:<module>:181 - validation loss: 3.5959134101867676
2025-11-24 00:04:32.349 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_24000.pt
2025-11-24 00:04:34.219 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 00:04:36.252 | INFO     | __main__:<module>:160 - Step24010, Loss: 3.6122498512268066, Grad L2 Norm: 0.022883988916873932
2025-11-24 00:04:38.291 | INFO     | __main__:<module>:160 - Step24020, Loss: 3.5549092292785645, Grad L2 Norm: 0.023331161588430405
2025-11-24 00:04:40.332 | INFO     | __main__:<module>:160 - Step24030, Loss: 3.616025924682617, Grad L2 Norm: 0.02135697938501835
2025-11-24 00:04:42.375 | INFO     | __main__:<module>:160 - Step24040, Loss: 3.5764966011047363, Grad L2 Norm: 0.021676644682884216
2025-11-24 00:04:44.424 | INFO     | __main__:<module>:160 - Step24050, Loss: 3.533334732055664, Grad L2 Norm: 0.022487785667181015
2025-11-24 00:04:46.470 | INFO     | __main__:<module>:160 - Step24060, Loss: 3.5837721824645996, Grad L2 Norm: 0.022417772561311722
2025-11-24 00:04:48.520 | INFO     | __main__:<module>:160 - Step24070, Loss: 3.611751079559326, Grad L2 Norm: 0.02359444461762905
2025-11-24 00:04:50.568 | INFO     | __main__:<module>:160 - Step24080, Loss: 3.5741753578186035, Grad L2 Norm: 0.02285808138549328
2025-11-24 00:04:52.613 | INFO     | __main__:<module>:160 - Step24090, Loss: 3.4916622638702393, Grad L2 Norm: 0.02245718613266945
2025-11-24 00:04:54.664 | INFO     | __main__:<module>:160 - Step24100, Loss: 3.570098638534546, Grad L2 Norm: 0.02184681035578251
2025-11-24 00:04:56.708 | INFO     | __main__:<module>:160 - Step24110, Loss: 3.634091377258301, Grad L2 Norm: 0.02200498804450035
2025-11-24 00:04:58.758 | INFO     | __main__:<module>:160 - Step24120, Loss: 3.5215423107147217, Grad L2 Norm: 0.023458465933799744
2025-11-24 00:05:00.804 | INFO     | __main__:<module>:160 - Step24130, Loss: 3.5784106254577637, Grad L2 Norm: 0.020949503406882286
2025-11-24 00:05:02.847 | INFO     | __main__:<module>:160 - Step24140, Loss: 3.547288417816162, Grad L2 Norm: 0.022616278380155563
2025-11-24 00:05:04.886 | INFO     | __main__:<module>:160 - Step24150, Loss: 3.469766616821289, Grad L2 Norm: 0.02063846029341221
2025-11-24 00:05:06.924 | INFO     | __main__:<module>:160 - Step24160, Loss: 3.4694442749023438, Grad L2 Norm: 0.021817423403263092
2025-11-24 00:05:08.960 | INFO     | __main__:<module>:160 - Step24170, Loss: 3.6716809272766113, Grad L2 Norm: 0.023429693654179573
2025-11-24 00:05:10.998 | INFO     | __main__:<module>:160 - Step24180, Loss: 3.6426916122436523, Grad L2 Norm: 0.022904960438609123
2025-11-24 00:05:13.038 | INFO     | __main__:<module>:160 - Step24190, Loss: 3.7513136863708496, Grad L2 Norm: 0.022134311497211456
2025-11-24 00:05:15.067 | INFO     | __main__:<module>:160 - Step24200, Loss: 3.8277273178100586, Grad L2 Norm: 0.022544149309396744
2025-11-24 00:05:17.098 | INFO     | __main__:<module>:160 - Step24210, Loss: 3.585001230239868, Grad L2 Norm: 0.022640177980065346
2025-11-24 00:05:19.135 | INFO     | __main__:<module>:160 - Step24220, Loss: 3.805172920227051, Grad L2 Norm: 0.023402947932481766
2025-11-24 00:05:21.167 | INFO     | __main__:<module>:160 - Step24230, Loss: 3.635435104370117, Grad L2 Norm: 0.022813530638813972
2025-11-24 00:05:23.194 | INFO     | __main__:<module>:160 - Step24240, Loss: 3.496649742126465, Grad L2 Norm: 0.02254081517457962
2025-11-24 00:05:25.230 | INFO     | __main__:<module>:160 - Step24250, Loss: 3.6587486267089844, Grad L2 Norm: 0.024477703496813774
2025-11-24 00:05:27.257 | INFO     | __main__:<module>:160 - Step24260, Loss: 3.6055259704589844, Grad L2 Norm: 0.022230997681617737
2025-11-24 00:05:29.287 | INFO     | __main__:<module>:160 - Step24270, Loss: 3.7563281059265137, Grad L2 Norm: 0.023665592074394226
2025-11-24 00:05:31.314 | INFO     | __main__:<module>:160 - Step24280, Loss: 3.71268367767334, Grad L2 Norm: 0.024008916690945625
2025-11-24 00:05:33.350 | INFO     | __main__:<module>:160 - Step24290, Loss: 3.5815086364746094, Grad L2 Norm: 0.021802162751555443
2025-11-24 00:05:35.375 | INFO     | __main__:<module>:160 - Step24300, Loss: 3.5241706371307373, Grad L2 Norm: 0.02144433557987213
2025-11-24 00:05:37.401 | INFO     | __main__:<module>:160 - Step24310, Loss: 3.4991378784179688, Grad L2 Norm: 0.020855624228715897
2025-11-24 00:05:39.428 | INFO     | __main__:<module>:160 - Step24320, Loss: 3.6694791316986084, Grad L2 Norm: 0.02346878871321678
2025-11-24 00:05:41.458 | INFO     | __main__:<module>:160 - Step24330, Loss: 3.5899577140808105, Grad L2 Norm: 0.022708499804139137
2025-11-24 00:05:43.488 | INFO     | __main__:<module>:160 - Step24340, Loss: 3.6268224716186523, Grad L2 Norm: 0.021770279854536057
2025-11-24 00:05:45.514 | INFO     | __main__:<module>:160 - Step24350, Loss: 3.5942001342773438, Grad L2 Norm: 0.02157684974372387
2025-11-24 00:05:47.542 | INFO     | __main__:<module>:160 - Step24360, Loss: 3.4326658248901367, Grad L2 Norm: 0.021439218893647194
2025-11-24 00:05:49.567 | INFO     | __main__:<module>:160 - Step24370, Loss: 3.7785165309906006, Grad L2 Norm: 0.03448661044239998
2025-11-24 00:05:51.595 | INFO     | __main__:<module>:160 - Step24380, Loss: 3.5864310264587402, Grad L2 Norm: 0.02249571494758129
2025-11-24 00:05:53.625 | INFO     | __main__:<module>:160 - Step24390, Loss: 3.5673699378967285, Grad L2 Norm: 0.020732294768095016
2025-11-24 00:05:55.657 | INFO     | __main__:<module>:160 - Step24400, Loss: 3.49355411529541, Grad L2 Norm: 0.022569438442587852
2025-11-24 00:05:55.658 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:05:56.949 | INFO     | __main__:<module>:181 - validation loss: 3.597994315624237
2025-11-24 00:05:58.986 | INFO     | __main__:<module>:160 - Step24410, Loss: 3.6014294624328613, Grad L2 Norm: 0.02174440398812294
2025-11-24 00:06:01.026 | INFO     | __main__:<module>:160 - Step24420, Loss: 3.555819034576416, Grad L2 Norm: 0.02669190801680088
2025-11-24 00:06:03.063 | INFO     | __main__:<module>:160 - Step24430, Loss: 3.5721240043640137, Grad L2 Norm: 0.021642563864588737
2025-11-24 00:06:05.099 | INFO     | __main__:<module>:160 - Step24440, Loss: 3.5498366355895996, Grad L2 Norm: 0.021033167839050293
2025-11-24 00:06:07.129 | INFO     | __main__:<module>:160 - Step24450, Loss: 3.4767978191375732, Grad L2 Norm: 0.021620750427246094
2025-11-24 00:06:09.161 | INFO     | __main__:<module>:160 - Step24460, Loss: 3.636169910430908, Grad L2 Norm: 0.02165973000228405
2025-11-24 00:06:11.195 | INFO     | __main__:<module>:160 - Step24470, Loss: 3.5912933349609375, Grad L2 Norm: 0.022846516221761703
2025-11-24 00:06:13.224 | INFO     | __main__:<module>:160 - Step24480, Loss: 3.602482318878174, Grad L2 Norm: 0.021540045738220215
2025-11-24 00:06:15.255 | INFO     | __main__:<module>:160 - Step24490, Loss: 3.5433402061462402, Grad L2 Norm: 0.021287789568305016
2025-11-24 00:06:17.296 | INFO     | __main__:<module>:160 - Step24500, Loss: 3.4794843196868896, Grad L2 Norm: 0.020181991159915924
2025-11-24 00:06:19.332 | INFO     | __main__:<module>:160 - Step24510, Loss: 3.5900373458862305, Grad L2 Norm: 0.023572789505124092
2025-11-24 00:06:21.368 | INFO     | __main__:<module>:160 - Step24520, Loss: 3.548278331756592, Grad L2 Norm: 0.023347526788711548
2025-11-24 00:06:23.408 | INFO     | __main__:<module>:160 - Step24530, Loss: 3.5431933403015137, Grad L2 Norm: 0.02115747518837452
2025-11-24 00:06:25.451 | INFO     | __main__:<module>:160 - Step24540, Loss: 3.594315528869629, Grad L2 Norm: 0.021886708214879036
2025-11-24 00:06:27.496 | INFO     | __main__:<module>:160 - Step24550, Loss: 3.6648576259613037, Grad L2 Norm: 0.02621520310640335
2025-11-24 00:06:29.537 | INFO     | __main__:<module>:160 - Step24560, Loss: 3.5218191146850586, Grad L2 Norm: 0.02109142579138279
2025-11-24 00:06:31.577 | INFO     | __main__:<module>:160 - Step24570, Loss: 3.548394203186035, Grad L2 Norm: 0.02115577459335327
2025-11-24 00:06:33.621 | INFO     | __main__:<module>:160 - Step24580, Loss: 3.605640411376953, Grad L2 Norm: 0.025617871433496475
2025-11-24 00:06:35.660 | INFO     | __main__:<module>:160 - Step24590, Loss: 3.4660730361938477, Grad L2 Norm: 0.022434134036302567
2025-11-24 00:06:37.696 | INFO     | __main__:<module>:160 - Step24600, Loss: 3.5583667755126953, Grad L2 Norm: 0.02168847620487213
2025-11-24 00:06:39.732 | INFO     | __main__:<module>:160 - Step24610, Loss: 3.583411455154419, Grad L2 Norm: 0.02208707481622696
2025-11-24 00:06:41.773 | INFO     | __main__:<module>:160 - Step24620, Loss: 3.570117473602295, Grad L2 Norm: 0.021851954981684685
2025-11-24 00:06:43.810 | INFO     | __main__:<module>:160 - Step24630, Loss: 3.6440482139587402, Grad L2 Norm: 0.024761037901043892
2025-11-24 00:06:45.850 | INFO     | __main__:<module>:160 - Step24640, Loss: 3.6545214653015137, Grad L2 Norm: 0.021881375461816788
2025-11-24 00:06:47.890 | INFO     | __main__:<module>:160 - Step24650, Loss: 3.639599561691284, Grad L2 Norm: 0.023922335356473923
2025-11-24 00:06:49.931 | INFO     | __main__:<module>:160 - Step24660, Loss: 3.5797109603881836, Grad L2 Norm: 0.023878272622823715
2025-11-24 00:06:51.971 | INFO     | __main__:<module>:160 - Step24670, Loss: 3.516538143157959, Grad L2 Norm: 0.0202974583953619
2025-11-24 00:06:54.009 | INFO     | __main__:<module>:160 - Step24680, Loss: 3.5173115730285645, Grad L2 Norm: 0.02142915688455105
2025-11-24 00:06:56.054 | INFO     | __main__:<module>:160 - Step24690, Loss: 3.592494487762451, Grad L2 Norm: 0.021390454843640327
2025-11-24 00:06:58.094 | INFO     | __main__:<module>:160 - Step24700, Loss: 3.5567266941070557, Grad L2 Norm: 0.021251967176795006
2025-11-24 00:07:00.139 | INFO     | __main__:<module>:160 - Step24710, Loss: 3.503690719604492, Grad L2 Norm: 0.02360706962645054
2025-11-24 00:07:02.174 | INFO     | __main__:<module>:160 - Step24720, Loss: 3.6214818954467773, Grad L2 Norm: 0.022313004359602928
2025-11-24 00:07:04.212 | INFO     | __main__:<module>:160 - Step24730, Loss: 3.4691200256347656, Grad L2 Norm: 0.02184341475367546
2025-11-24 00:07:06.250 | INFO     | __main__:<module>:160 - Step24740, Loss: 3.655510902404785, Grad L2 Norm: 0.02101478911936283
2025-11-24 00:07:08.289 | INFO     | __main__:<module>:160 - Step24750, Loss: 3.6741199493408203, Grad L2 Norm: 0.022778330370783806
2025-11-24 00:07:10.332 | INFO     | __main__:<module>:160 - Step24760, Loss: 3.6504502296447754, Grad L2 Norm: 0.022255893796682358
2025-11-24 00:07:12.369 | INFO     | __main__:<module>:160 - Step24770, Loss: 3.5273454189300537, Grad L2 Norm: 0.022320901975035667
2025-11-24 00:07:14.407 | INFO     | __main__:<module>:160 - Step24780, Loss: 3.5786564350128174, Grad L2 Norm: 0.02245897613465786
2025-11-24 00:07:16.442 | INFO     | __main__:<module>:160 - Step24790, Loss: 3.524813175201416, Grad L2 Norm: 0.021270962432026863
2025-11-24 00:07:18.478 | INFO     | __main__:<module>:160 - Step24800, Loss: 3.5835683345794678, Grad L2 Norm: 0.02140568196773529
2025-11-24 00:07:18.478 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:07:19.769 | INFO     | __main__:<module>:181 - validation loss: 3.5915678262710573
2025-11-24 00:07:21.820 | INFO     | __main__:<module>:160 - Step24810, Loss: 3.653520107269287, Grad L2 Norm: 0.02235765941441059
2025-11-24 00:07:23.860 | INFO     | __main__:<module>:160 - Step24820, Loss: 3.5500752925872803, Grad L2 Norm: 0.02141641639173031
2025-11-24 00:07:25.897 | INFO     | __main__:<module>:160 - Step24830, Loss: 3.495893955230713, Grad L2 Norm: 0.023241110146045685
2025-11-24 00:07:27.930 | INFO     | __main__:<module>:160 - Step24840, Loss: 3.5743184089660645, Grad L2 Norm: 0.02079187147319317
2025-11-24 00:07:29.961 | INFO     | __main__:<module>:160 - Step24850, Loss: 3.631049394607544, Grad L2 Norm: 0.022533873096108437
2025-11-24 00:07:31.995 | INFO     | __main__:<module>:160 - Step24860, Loss: 3.440707206726074, Grad L2 Norm: 0.02096819505095482
2025-11-24 00:07:34.033 | INFO     | __main__:<module>:160 - Step24870, Loss: 3.399657726287842, Grad L2 Norm: 0.02313939481973648
2025-11-24 00:07:36.063 | INFO     | __main__:<module>:160 - Step24880, Loss: 3.689678192138672, Grad L2 Norm: 0.02288879081606865
2025-11-24 00:07:38.091 | INFO     | __main__:<module>:160 - Step24890, Loss: 3.5138936042785645, Grad L2 Norm: 0.021456239745020866
2025-11-24 00:07:40.123 | INFO     | __main__:<module>:160 - Step24900, Loss: 3.5077340602874756, Grad L2 Norm: 0.021060019731521606
2025-11-24 00:07:42.152 | INFO     | __main__:<module>:160 - Step24910, Loss: 3.6119279861450195, Grad L2 Norm: 0.022324584424495697
2025-11-24 00:07:44.187 | INFO     | __main__:<module>:160 - Step24920, Loss: 3.60736083984375, Grad L2 Norm: 0.021103572100400925
2025-11-24 00:07:46.217 | INFO     | __main__:<module>:160 - Step24930, Loss: 3.5512266159057617, Grad L2 Norm: 0.020374011248350143
2025-11-24 00:07:48.248 | INFO     | __main__:<module>:160 - Step24940, Loss: 3.5577449798583984, Grad L2 Norm: 0.0235275961458683
2025-11-24 00:07:50.283 | INFO     | __main__:<module>:160 - Step24950, Loss: 3.5321998596191406, Grad L2 Norm: 0.022429849952459335
2025-11-24 00:07:52.310 | INFO     | __main__:<module>:160 - Step24960, Loss: 3.6404240131378174, Grad L2 Norm: 0.021662704646587372
2025-11-24 00:07:54.345 | INFO     | __main__:<module>:160 - Step24970, Loss: 3.6866962909698486, Grad L2 Norm: 0.022463330999016762
2025-11-24 00:07:56.375 | INFO     | __main__:<module>:160 - Step24980, Loss: 3.5354270935058594, Grad L2 Norm: 0.02169184945523739
2025-11-24 00:07:58.405 | INFO     | __main__:<module>:160 - Step24990, Loss: 3.5210275650024414, Grad L2 Norm: 0.02208855003118515
2025-11-24 00:08:00.441 | INFO     | __main__:<module>:160 - Step25000, Loss: 3.540473699569702, Grad L2 Norm: 0.021884841844439507
2025-11-24 00:08:02.470 | INFO     | __main__:<module>:160 - Step25010, Loss: 3.520841121673584, Grad L2 Norm: 0.022166253998875618
2025-11-24 00:08:04.500 | INFO     | __main__:<module>:160 - Step25020, Loss: 3.7259037494659424, Grad L2 Norm: 0.023066258057951927
2025-11-24 00:08:06.530 | INFO     | __main__:<module>:160 - Step25030, Loss: 3.6106503009796143, Grad L2 Norm: 0.022223692387342453
2025-11-24 00:08:08.560 | INFO     | __main__:<module>:160 - Step25040, Loss: 3.6538796424865723, Grad L2 Norm: 0.021724320948123932
2025-11-24 00:08:10.590 | INFO     | __main__:<module>:160 - Step25050, Loss: 3.5299339294433594, Grad L2 Norm: 0.024320021271705627
2025-11-24 00:08:12.613 | INFO     | __main__:<module>:160 - Step25060, Loss: 3.6223180294036865, Grad L2 Norm: 0.021995428949594498
2025-11-24 00:08:14.637 | INFO     | __main__:<module>:160 - Step25070, Loss: 3.4859514236450195, Grad L2 Norm: 0.021487943828105927
2025-11-24 00:08:16.661 | INFO     | __main__:<module>:160 - Step25080, Loss: 3.6406679153442383, Grad L2 Norm: 0.022066263481974602
2025-11-24 00:08:18.694 | INFO     | __main__:<module>:160 - Step25090, Loss: 3.670569896697998, Grad L2 Norm: 0.023303357884287834
2025-11-24 00:08:20.718 | INFO     | __main__:<module>:160 - Step25100, Loss: 3.647797107696533, Grad L2 Norm: 0.022496208548545837
2025-11-24 00:08:22.745 | INFO     | __main__:<module>:160 - Step25110, Loss: 3.635613441467285, Grad L2 Norm: 0.0233790073543787
2025-11-24 00:08:24.775 | INFO     | __main__:<module>:160 - Step25120, Loss: 3.7556066513061523, Grad L2 Norm: 0.024030422791838646
2025-11-24 00:08:26.803 | INFO     | __main__:<module>:160 - Step25130, Loss: 3.5263731479644775, Grad L2 Norm: 0.02300732396543026
2025-11-24 00:08:28.833 | INFO     | __main__:<module>:160 - Step25140, Loss: 3.5420265197753906, Grad L2 Norm: 0.02274625562131405
2025-11-24 00:08:30.864 | INFO     | __main__:<module>:160 - Step25150, Loss: 3.456679344177246, Grad L2 Norm: 0.02208227477967739
2025-11-24 00:08:32.893 | INFO     | __main__:<module>:160 - Step25160, Loss: 3.5736794471740723, Grad L2 Norm: 0.02381708100438118
2025-11-24 00:08:34.925 | INFO     | __main__:<module>:160 - Step25170, Loss: 3.576831340789795, Grad L2 Norm: 0.021354567259550095
2025-11-24 00:08:36.957 | INFO     | __main__:<module>:160 - Step25180, Loss: 3.5672240257263184, Grad L2 Norm: 0.022707797586917877
2025-11-24 00:08:38.991 | INFO     | __main__:<module>:160 - Step25190, Loss: 3.653672695159912, Grad L2 Norm: 0.022618576884269714
2025-11-24 00:08:41.029 | INFO     | __main__:<module>:160 - Step25200, Loss: 3.7061593532562256, Grad L2 Norm: 0.023282337933778763
2025-11-24 00:08:41.029 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:08:42.318 | INFO     | __main__:<module>:181 - validation loss: 3.5875104784965517
2025-11-24 00:08:44.362 | INFO     | __main__:<module>:160 - Step25210, Loss: 3.6951069831848145, Grad L2 Norm: 0.022544316947460175
2025-11-24 00:08:46.392 | INFO     | __main__:<module>:160 - Step25220, Loss: 3.642808198928833, Grad L2 Norm: 0.021768808364868164
2025-11-24 00:08:48.430 | INFO     | __main__:<module>:160 - Step25230, Loss: 3.4966282844543457, Grad L2 Norm: 0.022299064323306084
2025-11-24 00:08:50.470 | INFO     | __main__:<module>:160 - Step25240, Loss: 3.5823287963867188, Grad L2 Norm: 0.02295747771859169
2025-11-24 00:08:52.504 | INFO     | __main__:<module>:160 - Step25250, Loss: 3.5707955360412598, Grad L2 Norm: 0.020659781992435455
2025-11-24 00:08:54.537 | INFO     | __main__:<module>:160 - Step25260, Loss: 3.4963278770446777, Grad L2 Norm: 0.02436472289264202
2025-11-24 00:08:56.570 | INFO     | __main__:<module>:160 - Step25270, Loss: 3.6648061275482178, Grad L2 Norm: 0.022522343322634697
2025-11-24 00:08:58.608 | INFO     | __main__:<module>:160 - Step25280, Loss: 3.451481580734253, Grad L2 Norm: 0.02245369553565979
2025-11-24 00:09:00.647 | INFO     | __main__:<module>:160 - Step25290, Loss: 3.409939765930176, Grad L2 Norm: 0.02195616066455841
2025-11-24 00:09:02.684 | INFO     | __main__:<module>:160 - Step25300, Loss: 3.6179187297821045, Grad L2 Norm: 0.022362105548381805
2025-11-24 00:09:04.720 | INFO     | __main__:<module>:160 - Step25310, Loss: 3.580327033996582, Grad L2 Norm: 0.02155969850718975
2025-11-24 00:09:06.751 | INFO     | __main__:<module>:160 - Step25320, Loss: 3.4820804595947266, Grad L2 Norm: 0.021683597937226295
2025-11-24 00:09:08.788 | INFO     | __main__:<module>:160 - Step25330, Loss: 3.642181396484375, Grad L2 Norm: 0.020989054813981056
2025-11-24 00:09:10.828 | INFO     | __main__:<module>:160 - Step25340, Loss: 3.492516040802002, Grad L2 Norm: 0.020662939175963402
2025-11-24 00:09:12.867 | INFO     | __main__:<module>:160 - Step25350, Loss: 3.7152581214904785, Grad L2 Norm: 0.023846887052059174
2025-11-24 00:09:14.909 | INFO     | __main__:<module>:160 - Step25360, Loss: 3.5365285873413086, Grad L2 Norm: 0.021677564829587936
2025-11-24 00:09:16.948 | INFO     | __main__:<module>:160 - Step25370, Loss: 3.6294898986816406, Grad L2 Norm: 0.021719694137573242
2025-11-24 00:09:18.985 | INFO     | __main__:<module>:160 - Step25380, Loss: 3.53591251373291, Grad L2 Norm: 0.020941732451319695
2025-11-24 00:09:21.023 | INFO     | __main__:<module>:160 - Step25390, Loss: 3.5669896602630615, Grad L2 Norm: 0.021691543981432915
2025-11-24 00:09:23.059 | INFO     | __main__:<module>:160 - Step25400, Loss: 3.4064624309539795, Grad L2 Norm: 0.02462712861597538
2025-11-24 00:09:25.095 | INFO     | __main__:<module>:160 - Step25410, Loss: 3.4919352531433105, Grad L2 Norm: 0.021985042840242386
2025-11-24 00:09:27.129 | INFO     | __main__:<module>:160 - Step25420, Loss: 3.684147834777832, Grad L2 Norm: 0.022223200649023056
2025-11-24 00:09:29.160 | INFO     | __main__:<module>:160 - Step25430, Loss: 3.56496524810791, Grad L2 Norm: 0.022358037531375885
2025-11-24 00:09:31.199 | INFO     | __main__:<module>:160 - Step25440, Loss: 3.392857074737549, Grad L2 Norm: 0.020691946148872375
2025-11-24 00:09:33.240 | INFO     | __main__:<module>:160 - Step25450, Loss: 3.5191361904144287, Grad L2 Norm: 0.020926257595419884
2025-11-24 00:09:35.278 | INFO     | __main__:<module>:160 - Step25460, Loss: 3.5817322731018066, Grad L2 Norm: 0.02205922082066536
2025-11-24 00:09:37.316 | INFO     | __main__:<module>:160 - Step25470, Loss: 3.3812856674194336, Grad L2 Norm: 0.021913085132837296
2025-11-24 00:09:39.354 | INFO     | __main__:<module>:160 - Step25480, Loss: 3.4879322052001953, Grad L2 Norm: 0.0220184326171875
2025-11-24 00:09:41.385 | INFO     | __main__:<module>:160 - Step25490, Loss: 3.5478854179382324, Grad L2 Norm: 0.022887427359819412
2025-11-24 00:09:43.413 | INFO     | __main__:<module>:160 - Step25500, Loss: 3.6126413345336914, Grad L2 Norm: 0.024849317967891693
2025-11-24 00:09:45.450 | INFO     | __main__:<module>:160 - Step25510, Loss: 3.4827799797058105, Grad L2 Norm: 0.02198615111410618
2025-11-24 00:09:47.486 | INFO     | __main__:<module>:160 - Step25520, Loss: 3.6504199504852295, Grad L2 Norm: 0.022811122238636017
2025-11-24 00:09:49.512 | INFO     | __main__:<module>:160 - Step25530, Loss: 3.5480175018310547, Grad L2 Norm: 0.02186630293726921
2025-11-24 00:09:51.550 | INFO     | __main__:<module>:160 - Step25540, Loss: 3.523533821105957, Grad L2 Norm: 0.02114773355424404
2025-11-24 00:09:53.582 | INFO     | __main__:<module>:160 - Step25550, Loss: 3.743936061859131, Grad L2 Norm: 0.02270485647022724
2025-11-24 00:09:55.610 | INFO     | __main__:<module>:160 - Step25560, Loss: 3.558647632598877, Grad L2 Norm: 0.022065119817852974
2025-11-24 00:09:57.645 | INFO     | __main__:<module>:160 - Step25570, Loss: 3.5883584022521973, Grad L2 Norm: 0.02165961265563965
2025-11-24 00:09:59.680 | INFO     | __main__:<module>:160 - Step25580, Loss: 3.4841928482055664, Grad L2 Norm: 0.02155298739671707
2025-11-24 00:10:01.709 | INFO     | __main__:<module>:160 - Step25590, Loss: 3.61362361907959, Grad L2 Norm: 0.02411891706287861
2025-11-24 00:10:03.745 | INFO     | __main__:<module>:160 - Step25600, Loss: 3.57358980178833, Grad L2 Norm: 0.021529508754611015
2025-11-24 00:10:03.746 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:10:05.037 | INFO     | __main__:<module>:181 - validation loss: 3.580603063106537
2025-11-24 00:10:07.081 | INFO     | __main__:<module>:160 - Step25610, Loss: 3.7213797569274902, Grad L2 Norm: 0.0212942473590374
2025-11-24 00:10:09.110 | INFO     | __main__:<module>:160 - Step25620, Loss: 3.5195932388305664, Grad L2 Norm: 0.02203364297747612
2025-11-24 00:10:11.141 | INFO     | __main__:<module>:160 - Step25630, Loss: 3.6135826110839844, Grad L2 Norm: 0.02096475288271904
2025-11-24 00:10:13.168 | INFO     | __main__:<module>:160 - Step25640, Loss: 3.558663845062256, Grad L2 Norm: 0.019967306405305862
2025-11-24 00:10:15.199 | INFO     | __main__:<module>:160 - Step25650, Loss: 3.454983711242676, Grad L2 Norm: 0.021755697205662727
2025-11-24 00:10:17.221 | INFO     | __main__:<module>:160 - Step25660, Loss: 3.533435821533203, Grad L2 Norm: 0.023074472323060036
2025-11-24 00:10:19.248 | INFO     | __main__:<module>:160 - Step25670, Loss: 3.6918909549713135, Grad L2 Norm: 0.021168610081076622
2025-11-24 00:10:21.274 | INFO     | __main__:<module>:160 - Step25680, Loss: 3.57470965385437, Grad L2 Norm: 0.02276662550866604
2025-11-24 00:10:23.298 | INFO     | __main__:<module>:160 - Step25690, Loss: 3.5446255207061768, Grad L2 Norm: 0.022206986322999
2025-11-24 00:10:25.330 | INFO     | __main__:<module>:160 - Step25700, Loss: 3.5877914428710938, Grad L2 Norm: 0.021814266219735146
2025-11-24 00:10:27.357 | INFO     | __main__:<module>:160 - Step25710, Loss: 3.6071996688842773, Grad L2 Norm: 0.022217240184545517
2025-11-24 00:10:29.384 | INFO     | __main__:<module>:160 - Step25720, Loss: 3.4578053951263428, Grad L2 Norm: 0.021236183121800423
2025-11-24 00:10:31.413 | INFO     | __main__:<module>:160 - Step25730, Loss: 3.8645777702331543, Grad L2 Norm: 0.027171799913048744
2025-11-24 00:10:33.437 | INFO     | __main__:<module>:160 - Step25740, Loss: 3.8065695762634277, Grad L2 Norm: 0.02742900885641575
2025-11-24 00:10:35.465 | INFO     | __main__:<module>:160 - Step25750, Loss: 3.5446276664733887, Grad L2 Norm: 0.022383786737918854
2025-11-24 00:10:37.492 | INFO     | __main__:<module>:160 - Step25760, Loss: 3.528796672821045, Grad L2 Norm: 0.021175803616642952
2025-11-24 00:10:39.524 | INFO     | __main__:<module>:160 - Step25770, Loss: 3.487521171569824, Grad L2 Norm: 0.02072049304842949
2025-11-24 00:10:41.555 | INFO     | __main__:<module>:160 - Step25780, Loss: 3.6369450092315674, Grad L2 Norm: 0.02386993169784546
2025-11-24 00:10:43.586 | INFO     | __main__:<module>:160 - Step25790, Loss: 3.5468366146087646, Grad L2 Norm: 0.02053808979690075
2025-11-24 00:10:45.615 | INFO     | __main__:<module>:160 - Step25800, Loss: 3.5460739135742188, Grad L2 Norm: 0.021965542808175087
2025-11-24 00:10:47.648 | INFO     | __main__:<module>:160 - Step25810, Loss: 3.5427446365356445, Grad L2 Norm: 0.02109331637620926
2025-11-24 00:10:49.670 | INFO     | __main__:<module>:160 - Step25820, Loss: 3.6204657554626465, Grad L2 Norm: 0.022179894149303436
2025-11-24 00:10:51.692 | INFO     | __main__:<module>:160 - Step25830, Loss: 3.7482199668884277, Grad L2 Norm: 0.023185040801763535
2025-11-24 00:10:53.719 | INFO     | __main__:<module>:160 - Step25840, Loss: 3.5741629600524902, Grad L2 Norm: 0.021944262087345123
2025-11-24 00:10:55.747 | INFO     | __main__:<module>:160 - Step25850, Loss: 3.7649178504943848, Grad L2 Norm: 0.023737074807286263
2025-11-24 00:10:57.774 | INFO     | __main__:<module>:160 - Step25860, Loss: 3.5442028045654297, Grad L2 Norm: 0.021073536947369576
2025-11-24 00:10:59.795 | INFO     | __main__:<module>:160 - Step25870, Loss: 3.5611934661865234, Grad L2 Norm: 0.020781181752681732
2025-11-24 00:11:01.814 | INFO     | __main__:<module>:160 - Step25880, Loss: 3.521545886993408, Grad L2 Norm: 0.02148735709488392
2025-11-24 00:11:03.839 | INFO     | __main__:<module>:160 - Step25890, Loss: 3.7123281955718994, Grad L2 Norm: 0.021579882130026817
2025-11-24 00:11:05.856 | INFO     | __main__:<module>:160 - Step25900, Loss: 3.5475900173187256, Grad L2 Norm: 0.02182883396744728
2025-11-24 00:11:07.878 | INFO     | __main__:<module>:160 - Step25910, Loss: 3.4829647541046143, Grad L2 Norm: 0.022419458255171776
2025-11-24 00:11:09.900 | INFO     | __main__:<module>:160 - Step25920, Loss: 3.5872061252593994, Grad L2 Norm: 0.021621471270918846
2025-11-24 00:11:11.920 | INFO     | __main__:<module>:160 - Step25930, Loss: 3.4983954429626465, Grad L2 Norm: 0.02179020270705223
2025-11-24 00:11:13.938 | INFO     | __main__:<module>:160 - Step25940, Loss: 3.4791641235351562, Grad L2 Norm: 0.023528221994638443
2025-11-24 00:11:15.949 | INFO     | __main__:<module>:160 - Step25950, Loss: 3.6247544288635254, Grad L2 Norm: 0.022241676226258278
2025-11-24 00:11:17.965 | INFO     | __main__:<module>:160 - Step25960, Loss: 3.5695371627807617, Grad L2 Norm: 0.020894022658467293
2025-11-24 00:11:19.979 | INFO     | __main__:<module>:160 - Step25970, Loss: 3.463092088699341, Grad L2 Norm: 0.02157435566186905
2025-11-24 00:11:21.991 | INFO     | __main__:<module>:160 - Step25980, Loss: 3.55474853515625, Grad L2 Norm: 0.021163078024983406
2025-11-24 00:11:24.005 | INFO     | __main__:<module>:160 - Step25990, Loss: 3.6005802154541016, Grad L2 Norm: 0.023680297657847404
2025-11-24 00:11:26.024 | INFO     | __main__:<module>:160 - Step26000, Loss: 3.500983238220215, Grad L2 Norm: 0.021806174889206886
2025-11-24 00:11:26.025 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:11:27.306 | INFO     | __main__:<module>:181 - validation loss: 3.618264174461365
2025-11-24 00:11:27.307 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_26000.pt
2025-11-24 00:11:29.031 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 00:11:31.022 | INFO     | __main__:<module>:160 - Step26010, Loss: 3.484492778778076, Grad L2 Norm: 0.023576779291033745
2025-11-24 00:11:33.032 | INFO     | __main__:<module>:160 - Step26020, Loss: 3.5645627975463867, Grad L2 Norm: 0.021227236837148666
2025-11-24 00:11:35.041 | INFO     | __main__:<module>:160 - Step26030, Loss: 3.5164036750793457, Grad L2 Norm: 0.024962352588772774
2025-11-24 00:11:37.050 | INFO     | __main__:<module>:160 - Step26040, Loss: 3.540910482406616, Grad L2 Norm: 0.02151203528046608
2025-11-24 00:11:39.059 | INFO     | __main__:<module>:160 - Step26050, Loss: 3.6751813888549805, Grad L2 Norm: 0.022602470591664314
2025-11-24 00:11:41.074 | INFO     | __main__:<module>:160 - Step26060, Loss: 3.518139362335205, Grad L2 Norm: 0.021353300660848618
2025-11-24 00:11:43.090 | INFO     | __main__:<module>:160 - Step26070, Loss: 3.5782198905944824, Grad L2 Norm: 0.02281726337969303
2025-11-24 00:11:45.102 | INFO     | __main__:<module>:160 - Step26080, Loss: 3.633416175842285, Grad L2 Norm: 0.022035866975784302
2025-11-24 00:11:47.118 | INFO     | __main__:<module>:160 - Step26090, Loss: 3.5669755935668945, Grad L2 Norm: 0.023690365254878998
2025-11-24 00:11:49.138 | INFO     | __main__:<module>:160 - Step26100, Loss: 3.577101707458496, Grad L2 Norm: 0.02255360595881939
2025-11-24 00:11:51.160 | INFO     | __main__:<module>:160 - Step26110, Loss: 3.629333257675171, Grad L2 Norm: 0.02274223417043686
2025-11-24 00:11:53.179 | INFO     | __main__:<module>:160 - Step26120, Loss: 3.532724618911743, Grad L2 Norm: 0.020923372358083725
2025-11-24 00:11:55.197 | INFO     | __main__:<module>:160 - Step26130, Loss: 3.637071371078491, Grad L2 Norm: 0.022036055102944374
2025-11-24 00:11:57.225 | INFO     | __main__:<module>:160 - Step26140, Loss: 3.532953977584839, Grad L2 Norm: 0.022630970925092697
2025-11-24 00:11:59.237 | INFO     | __main__:<module>:160 - Step26150, Loss: 3.5700459480285645, Grad L2 Norm: 0.022240087389945984
2025-11-24 00:12:01.253 | INFO     | __main__:<module>:160 - Step26160, Loss: 3.61574387550354, Grad L2 Norm: 0.022293049842119217
2025-11-24 00:12:03.270 | INFO     | __main__:<module>:160 - Step26170, Loss: 3.535945415496826, Grad L2 Norm: 0.021881135180592537
2025-11-24 00:12:05.291 | INFO     | __main__:<module>:160 - Step26180, Loss: 3.6635608673095703, Grad L2 Norm: 0.02187894843518734
2025-11-24 00:12:07.320 | INFO     | __main__:<module>:160 - Step26190, Loss: 3.725587844848633, Grad L2 Norm: 0.02489136904478073
2025-11-24 00:12:09.341 | INFO     | __main__:<module>:160 - Step26200, Loss: 3.6035091876983643, Grad L2 Norm: 0.022428061813116074
2025-11-24 00:12:11.354 | INFO     | __main__:<module>:160 - Step26210, Loss: 3.494349718093872, Grad L2 Norm: 0.022090964019298553
2025-11-24 00:12:13.373 | INFO     | __main__:<module>:160 - Step26220, Loss: 3.663440704345703, Grad L2 Norm: 0.022953327745199203
2025-11-24 00:12:15.391 | INFO     | __main__:<module>:160 - Step26230, Loss: 3.634320020675659, Grad L2 Norm: 0.02320767380297184
2025-11-24 00:12:17.409 | INFO     | __main__:<module>:160 - Step26240, Loss: 3.615264654159546, Grad L2 Norm: 0.023246213793754578
2025-11-24 00:12:19.428 | INFO     | __main__:<module>:160 - Step26250, Loss: 3.6917717456817627, Grad L2 Norm: 0.022956881672143936
2025-11-24 00:12:21.445 | INFO     | __main__:<module>:160 - Step26260, Loss: 3.668416976928711, Grad L2 Norm: 0.02146148309111595
2025-11-24 00:12:23.463 | INFO     | __main__:<module>:160 - Step26270, Loss: 3.564392566680908, Grad L2 Norm: 0.023028060793876648
2025-11-24 00:12:25.481 | INFO     | __main__:<module>:160 - Step26280, Loss: 3.6815102100372314, Grad L2 Norm: 0.023062163963913918
2025-11-24 00:12:27.497 | INFO     | __main__:<module>:160 - Step26290, Loss: 3.409886360168457, Grad L2 Norm: 0.02292984537780285
2025-11-24 00:12:29.508 | INFO     | __main__:<module>:160 - Step26300, Loss: 3.607491970062256, Grad L2 Norm: 0.02267901971936226
2025-11-24 00:12:31.523 | INFO     | __main__:<module>:160 - Step26310, Loss: 3.4931893348693848, Grad L2 Norm: 0.02281819097697735
2025-11-24 00:12:33.537 | INFO     | __main__:<module>:160 - Step26320, Loss: 3.5801124572753906, Grad L2 Norm: 0.022577155381441116
2025-11-24 00:12:35.556 | INFO     | __main__:<module>:160 - Step26330, Loss: 3.525637149810791, Grad L2 Norm: 0.021020740270614624
2025-11-24 00:12:37.575 | INFO     | __main__:<module>:160 - Step26340, Loss: 3.494904041290283, Grad L2 Norm: 0.02306176722049713
2025-11-24 00:12:39.597 | INFO     | __main__:<module>:160 - Step26350, Loss: 3.569141387939453, Grad L2 Norm: 0.023294927552342415
2025-11-24 00:12:41.615 | INFO     | __main__:<module>:160 - Step26360, Loss: 3.490410327911377, Grad L2 Norm: 0.02240104041993618
2025-11-24 00:12:43.635 | INFO     | __main__:<module>:160 - Step26370, Loss: 3.4956769943237305, Grad L2 Norm: 0.021175093948841095
2025-11-24 00:12:45.659 | INFO     | __main__:<module>:160 - Step26380, Loss: 3.495058536529541, Grad L2 Norm: 0.020398207008838654
2025-11-24 00:12:47.688 | INFO     | __main__:<module>:160 - Step26390, Loss: 3.5115294456481934, Grad L2 Norm: 0.021999862045049667
2025-11-24 00:12:49.707 | INFO     | __main__:<module>:160 - Step26400, Loss: 3.6702427864074707, Grad L2 Norm: 0.022800056263804436
2025-11-24 00:12:49.708 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:12:50.991 | INFO     | __main__:<module>:181 - validation loss: 3.5902825593948364
2025-11-24 00:12:53.020 | INFO     | __main__:<module>:160 - Step26410, Loss: 3.4769129753112793, Grad L2 Norm: 0.020812319591641426
2025-11-24 00:12:55.037 | INFO     | __main__:<module>:160 - Step26420, Loss: 3.540949821472168, Grad L2 Norm: 0.02252885326743126
2025-11-24 00:12:57.055 | INFO     | __main__:<module>:160 - Step26430, Loss: 3.455900192260742, Grad L2 Norm: 0.02160235121846199
2025-11-24 00:12:59.070 | INFO     | __main__:<module>:160 - Step26440, Loss: 3.5679619312286377, Grad L2 Norm: 0.023655621334910393
2025-11-24 00:13:01.095 | INFO     | __main__:<module>:160 - Step26450, Loss: 3.5220258235931396, Grad L2 Norm: 0.022095074877142906
2025-11-24 00:13:03.114 | INFO     | __main__:<module>:160 - Step26460, Loss: 3.584167003631592, Grad L2 Norm: 0.023043273016810417
2025-11-24 00:13:05.138 | INFO     | __main__:<module>:160 - Step26470, Loss: 3.5255680084228516, Grad L2 Norm: 0.02165256440639496
2025-11-24 00:13:07.160 | INFO     | __main__:<module>:160 - Step26480, Loss: 3.6287896633148193, Grad L2 Norm: 0.02122986502945423
2025-11-24 00:13:09.187 | INFO     | __main__:<module>:160 - Step26490, Loss: 3.5523457527160645, Grad L2 Norm: 0.02137105166912079
2025-11-24 00:13:11.214 | INFO     | __main__:<module>:160 - Step26500, Loss: 3.536806583404541, Grad L2 Norm: 0.023719238117337227
2025-11-24 00:13:13.235 | INFO     | __main__:<module>:160 - Step26510, Loss: 3.701829671859741, Grad L2 Norm: 0.02150028757750988
2025-11-24 00:13:15.262 | INFO     | __main__:<module>:160 - Step26520, Loss: 3.6243228912353516, Grad L2 Norm: 0.021698379889130592
2025-11-24 00:13:17.284 | INFO     | __main__:<module>:160 - Step26530, Loss: 3.5279903411865234, Grad L2 Norm: 0.023334288969635963
2025-11-24 00:13:19.310 | INFO     | __main__:<module>:160 - Step26540, Loss: 3.6435985565185547, Grad L2 Norm: 0.02283148467540741
2025-11-24 00:13:21.333 | INFO     | __main__:<module>:160 - Step26550, Loss: 3.7007486820220947, Grad L2 Norm: 0.02235456556081772
2025-11-24 00:13:23.362 | INFO     | __main__:<module>:160 - Step26560, Loss: 3.5682177543640137, Grad L2 Norm: 0.021841799840331078
2025-11-24 00:13:25.393 | INFO     | __main__:<module>:160 - Step26570, Loss: 3.5713019371032715, Grad L2 Norm: 0.020436836406588554
2025-11-24 00:13:27.418 | INFO     | __main__:<module>:160 - Step26580, Loss: 3.6307358741760254, Grad L2 Norm: 0.022217918187379837
2025-11-24 00:13:29.445 | INFO     | __main__:<module>:160 - Step26590, Loss: 3.6044325828552246, Grad L2 Norm: 0.022452211007475853
2025-11-24 00:13:31.481 | INFO     | __main__:<module>:160 - Step26600, Loss: 3.5512962341308594, Grad L2 Norm: 0.022998373955488205
2025-11-24 00:13:33.518 | INFO     | __main__:<module>:160 - Step26610, Loss: 3.5675618648529053, Grad L2 Norm: 0.021357150748372078
2025-11-24 00:13:35.545 | INFO     | __main__:<module>:160 - Step26620, Loss: 3.550654888153076, Grad L2 Norm: 0.022105012089014053
2025-11-24 00:13:37.579 | INFO     | __main__:<module>:160 - Step26630, Loss: 3.619981050491333, Grad L2 Norm: 0.02363366261124611
2025-11-24 00:13:39.617 | INFO     | __main__:<module>:160 - Step26640, Loss: 3.6921486854553223, Grad L2 Norm: 0.02430642955005169
2025-11-24 00:13:41.646 | INFO     | __main__:<module>:160 - Step26650, Loss: 3.486110210418701, Grad L2 Norm: 0.021393807604908943
2025-11-24 00:13:43.677 | INFO     | __main__:<module>:160 - Step26660, Loss: 3.4651033878326416, Grad L2 Norm: 0.02159646712243557
2025-11-24 00:13:45.715 | INFO     | __main__:<module>:160 - Step26670, Loss: 3.5634124279022217, Grad L2 Norm: 0.02111199125647545
2025-11-24 00:13:47.744 | INFO     | __main__:<module>:160 - Step26680, Loss: 3.632370948791504, Grad L2 Norm: 0.02072140760719776
2025-11-24 00:13:49.773 | INFO     | __main__:<module>:160 - Step26690, Loss: 3.5661239624023438, Grad L2 Norm: 0.022333934903144836
2025-11-24 00:13:51.803 | INFO     | __main__:<module>:160 - Step26700, Loss: 3.47835111618042, Grad L2 Norm: 0.022359687834978104
2025-11-24 00:13:53.834 | INFO     | __main__:<module>:160 - Step26710, Loss: 3.4562904834747314, Grad L2 Norm: 0.021011000499129295
2025-11-24 00:13:55.872 | INFO     | __main__:<module>:160 - Step26720, Loss: 3.4518234729766846, Grad L2 Norm: 0.02163163758814335
2025-11-24 00:13:57.910 | INFO     | __main__:<module>:160 - Step26730, Loss: 3.61598801612854, Grad L2 Norm: 0.02174104005098343
2025-11-24 00:13:59.949 | INFO     | __main__:<module>:160 - Step26740, Loss: 3.6171579360961914, Grad L2 Norm: 0.021075718104839325
2025-11-24 00:14:01.984 | INFO     | __main__:<module>:160 - Step26750, Loss: 3.6621639728546143, Grad L2 Norm: 0.02238050475716591
2025-11-24 00:14:04.021 | INFO     | __main__:<module>:160 - Step26760, Loss: 3.5565524101257324, Grad L2 Norm: 0.01963345892727375
2025-11-24 00:14:06.057 | INFO     | __main__:<module>:160 - Step26770, Loss: 3.6770825386047363, Grad L2 Norm: 0.02160182036459446
2025-11-24 00:14:08.094 | INFO     | __main__:<module>:160 - Step26780, Loss: 3.6016740798950195, Grad L2 Norm: 0.021007634699344635
2025-11-24 00:14:10.137 | INFO     | __main__:<module>:160 - Step26790, Loss: 3.56032133102417, Grad L2 Norm: 0.02245354652404785
2025-11-24 00:14:12.176 | INFO     | __main__:<module>:160 - Step26800, Loss: 3.6161375045776367, Grad L2 Norm: 0.021449854597449303
2025-11-24 00:14:12.176 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:14:13.473 | INFO     | __main__:<module>:181 - validation loss: 3.6060267210006716
2025-11-24 00:14:15.523 | INFO     | __main__:<module>:160 - Step26810, Loss: 3.55180287361145, Grad L2 Norm: 0.021753910928964615
2025-11-24 00:14:17.566 | INFO     | __main__:<module>:160 - Step26820, Loss: 3.5276284217834473, Grad L2 Norm: 0.022355999797582626
2025-11-24 00:14:19.598 | INFO     | __main__:<module>:160 - Step26830, Loss: 3.5033535957336426, Grad L2 Norm: 0.022329967468976974
2025-11-24 00:14:21.634 | INFO     | __main__:<module>:160 - Step26840, Loss: 3.6021223068237305, Grad L2 Norm: 0.023439010605216026
2025-11-24 00:14:23.673 | INFO     | __main__:<module>:160 - Step26850, Loss: 3.4960265159606934, Grad L2 Norm: 0.022719983011484146
2025-11-24 00:14:25.711 | INFO     | __main__:<module>:160 - Step26860, Loss: 3.424511432647705, Grad L2 Norm: 0.020958393812179565
2025-11-24 00:14:27.754 | INFO     | __main__:<module>:160 - Step26870, Loss: 3.695664882659912, Grad L2 Norm: 0.022237900644540787
2025-11-24 00:14:29.800 | INFO     | __main__:<module>:160 - Step26880, Loss: 3.5500998497009277, Grad L2 Norm: 0.023233875632286072
2025-11-24 00:14:31.842 | INFO     | __main__:<module>:160 - Step26890, Loss: 3.4936280250549316, Grad L2 Norm: 0.021770967170596123
2025-11-24 00:14:33.880 | INFO     | __main__:<module>:160 - Step26900, Loss: 3.4468295574188232, Grad L2 Norm: 0.023105844855308533
2025-11-24 00:14:35.914 | INFO     | __main__:<module>:160 - Step26910, Loss: 3.613825798034668, Grad L2 Norm: 0.024706846103072166
2025-11-24 00:14:37.949 | INFO     | __main__:<module>:160 - Step26920, Loss: 3.516676425933838, Grad L2 Norm: 0.022377965971827507
2025-11-24 00:14:39.995 | INFO     | __main__:<module>:160 - Step26930, Loss: 3.5640640258789062, Grad L2 Norm: 0.021323002874851227
2025-11-24 00:14:42.039 | INFO     | __main__:<module>:160 - Step26940, Loss: 3.733426094055176, Grad L2 Norm: 0.020883893594145775
2025-11-24 00:14:44.079 | INFO     | __main__:<module>:160 - Step26950, Loss: 3.5557820796966553, Grad L2 Norm: 0.021401677280664444
2025-11-24 00:14:46.121 | INFO     | __main__:<module>:160 - Step26960, Loss: 3.5743865966796875, Grad L2 Norm: 0.022415976971387863
2025-11-24 00:14:48.164 | INFO     | __main__:<module>:160 - Step26970, Loss: 3.5887889862060547, Grad L2 Norm: 0.02132781408727169
2025-11-24 00:14:50.204 | INFO     | __main__:<module>:160 - Step26980, Loss: 3.5900042057037354, Grad L2 Norm: 0.022377843037247658
2025-11-24 00:14:52.252 | INFO     | __main__:<module>:160 - Step26990, Loss: 3.7118091583251953, Grad L2 Norm: 0.022831758484244347
2025-11-24 00:14:54.301 | INFO     | __main__:<module>:160 - Step27000, Loss: 3.5888185501098633, Grad L2 Norm: 0.02095978707075119
2025-11-24 00:14:56.354 | INFO     | __main__:<module>:160 - Step27010, Loss: 3.5472092628479004, Grad L2 Norm: 0.02038292959332466
2025-11-24 00:14:58.404 | INFO     | __main__:<module>:160 - Step27020, Loss: 3.522380828857422, Grad L2 Norm: 0.021090619266033173
2025-11-24 00:15:00.457 | INFO     | __main__:<module>:160 - Step27030, Loss: 3.598343849182129, Grad L2 Norm: 0.02194385416805744
2025-11-24 00:15:02.507 | INFO     | __main__:<module>:160 - Step27040, Loss: 3.6031157970428467, Grad L2 Norm: 0.02228856086730957
2025-11-24 00:15:04.554 | INFO     | __main__:<module>:160 - Step27050, Loss: 3.529125690460205, Grad L2 Norm: 0.022001031786203384
2025-11-24 00:15:06.603 | INFO     | __main__:<module>:160 - Step27060, Loss: 3.5259504318237305, Grad L2 Norm: 0.02161734364926815
2025-11-24 00:15:08.655 | INFO     | __main__:<module>:160 - Step27070, Loss: 3.6628365516662598, Grad L2 Norm: 0.02184230275452137
2025-11-24 00:15:10.711 | INFO     | __main__:<module>:160 - Step27080, Loss: 3.553436040878296, Grad L2 Norm: 0.02260255441069603
2025-11-24 00:15:12.766 | INFO     | __main__:<module>:160 - Step27090, Loss: 3.4908199310302734, Grad L2 Norm: 0.021807188168168068
2025-11-24 00:15:14.813 | INFO     | __main__:<module>:160 - Step27100, Loss: 3.656266689300537, Grad L2 Norm: 0.02372221276164055
2025-11-24 00:15:16.868 | INFO     | __main__:<module>:160 - Step27110, Loss: 3.6025218963623047, Grad L2 Norm: 0.02177003026008606
2025-11-24 00:15:18.925 | INFO     | __main__:<module>:160 - Step27120, Loss: 3.5328927040100098, Grad L2 Norm: 0.022984541952610016
2025-11-24 00:15:20.978 | INFO     | __main__:<module>:160 - Step27130, Loss: 3.5279581546783447, Grad L2 Norm: 0.022950220853090286
2025-11-24 00:15:23.031 | INFO     | __main__:<module>:160 - Step27140, Loss: 3.7439229488372803, Grad L2 Norm: 0.023292342200875282
2025-11-24 00:15:25.079 | INFO     | __main__:<module>:160 - Step27150, Loss: 3.582084894180298, Grad L2 Norm: 0.021114885807037354
2025-11-24 00:15:27.127 | INFO     | __main__:<module>:160 - Step27160, Loss: 3.5265250205993652, Grad L2 Norm: 0.022937413305044174
2025-11-24 00:15:29.172 | INFO     | __main__:<module>:160 - Step27170, Loss: 3.609677791595459, Grad L2 Norm: 0.02265223115682602
2025-11-24 00:15:31.223 | INFO     | __main__:<module>:160 - Step27180, Loss: 3.551464080810547, Grad L2 Norm: 0.022288057953119278
2025-11-24 00:15:33.266 | INFO     | __main__:<module>:160 - Step27190, Loss: 3.585137367248535, Grad L2 Norm: 0.02216215431690216
2025-11-24 00:15:35.309 | INFO     | __main__:<module>:160 - Step27200, Loss: 3.568068742752075, Grad L2 Norm: 0.0211541336029768
2025-11-24 00:15:35.309 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:15:36.609 | INFO     | __main__:<module>:181 - validation loss: 3.5786513805389406
2025-11-24 00:15:38.664 | INFO     | __main__:<module>:160 - Step27210, Loss: 3.40551495552063, Grad L2 Norm: 0.022084612399339676
2025-11-24 00:15:40.707 | INFO     | __main__:<module>:160 - Step27220, Loss: 3.722710132598877, Grad L2 Norm: 0.02399606816470623
2025-11-24 00:15:42.751 | INFO     | __main__:<module>:160 - Step27230, Loss: 3.6233315467834473, Grad L2 Norm: 0.022565118968486786
2025-11-24 00:15:44.795 | INFO     | __main__:<module>:160 - Step27240, Loss: 3.5805935859680176, Grad L2 Norm: 0.021897127851843834
2025-11-24 00:15:46.846 | INFO     | __main__:<module>:160 - Step27250, Loss: 3.6027262210845947, Grad L2 Norm: 0.02245664782822132
2025-11-24 00:15:48.894 | INFO     | __main__:<module>:160 - Step27260, Loss: 3.4824588298797607, Grad L2 Norm: 0.021216515451669693
2025-11-24 00:15:50.946 | INFO     | __main__:<module>:160 - Step27270, Loss: 3.524102210998535, Grad L2 Norm: 0.020961357280611992
2025-11-24 00:15:52.998 | INFO     | __main__:<module>:160 - Step27280, Loss: 3.6560282707214355, Grad L2 Norm: 0.02272026613354683
2025-11-24 00:15:55.047 | INFO     | __main__:<module>:160 - Step27290, Loss: 3.5911073684692383, Grad L2 Norm: 0.02117745764553547
2025-11-24 00:15:57.098 | INFO     | __main__:<module>:160 - Step27300, Loss: 3.6873552799224854, Grad L2 Norm: 0.02452586218714714
2025-11-24 00:15:59.144 | INFO     | __main__:<module>:160 - Step27310, Loss: 3.6360204219818115, Grad L2 Norm: 0.022163530811667442
2025-11-24 00:16:01.195 | INFO     | __main__:<module>:160 - Step27320, Loss: 3.6363325119018555, Grad L2 Norm: 0.02211395464837551
2025-11-24 00:16:03.244 | INFO     | __main__:<module>:160 - Step27330, Loss: 3.690058708190918, Grad L2 Norm: 0.022221161052584648
2025-11-24 00:16:05.293 | INFO     | __main__:<module>:160 - Step27340, Loss: 3.597238302230835, Grad L2 Norm: 0.02197514846920967
2025-11-24 00:16:07.336 | INFO     | __main__:<module>:160 - Step27350, Loss: 3.5152928829193115, Grad L2 Norm: 0.02207650989294052
2025-11-24 00:16:09.378 | INFO     | __main__:<module>:160 - Step27360, Loss: 3.455734968185425, Grad L2 Norm: 0.02284293808043003
2025-11-24 00:16:11.418 | INFO     | __main__:<module>:160 - Step27370, Loss: 3.659914493560791, Grad L2 Norm: 0.02166791632771492
2025-11-24 00:16:13.458 | INFO     | __main__:<module>:160 - Step27380, Loss: 3.462810516357422, Grad L2 Norm: 0.021373329684138298
2025-11-24 00:16:15.499 | INFO     | __main__:<module>:160 - Step27390, Loss: 3.7418479919433594, Grad L2 Norm: 0.022424079477787018
2025-11-24 00:16:17.538 | INFO     | __main__:<module>:160 - Step27400, Loss: 3.6723103523254395, Grad L2 Norm: 0.02167152799665928
2025-11-24 00:16:19.573 | INFO     | __main__:<module>:160 - Step27410, Loss: 3.6576592922210693, Grad L2 Norm: 0.023347841575741768
2025-11-24 00:16:21.611 | INFO     | __main__:<module>:160 - Step27420, Loss: 3.6831936836242676, Grad L2 Norm: 0.023978833109140396
2025-11-24 00:16:23.651 | INFO     | __main__:<module>:160 - Step27430, Loss: 3.532897472381592, Grad L2 Norm: 0.021093294024467468
2025-11-24 00:16:25.688 | INFO     | __main__:<module>:160 - Step27440, Loss: 3.5941288471221924, Grad L2 Norm: 0.022647833451628685
2025-11-24 00:16:27.728 | INFO     | __main__:<module>:160 - Step27450, Loss: 3.5339980125427246, Grad L2 Norm: 0.02107366919517517
2025-11-24 00:16:29.765 | INFO     | __main__:<module>:160 - Step27460, Loss: 3.672940492630005, Grad L2 Norm: 0.02315087988972664
2025-11-24 00:16:31.798 | INFO     | __main__:<module>:160 - Step27470, Loss: 3.6038308143615723, Grad L2 Norm: 0.021719012409448624
2025-11-24 00:16:33.827 | INFO     | __main__:<module>:160 - Step27480, Loss: 3.5641016960144043, Grad L2 Norm: 0.022235192358493805
2025-11-24 00:16:35.865 | INFO     | __main__:<module>:160 - Step27490, Loss: 3.5516514778137207, Grad L2 Norm: 0.02324865572154522
2025-11-24 00:16:37.901 | INFO     | __main__:<module>:160 - Step27500, Loss: 3.581249713897705, Grad L2 Norm: 0.022549500688910484
2025-11-24 00:16:39.932 | INFO     | __main__:<module>:160 - Step27510, Loss: 3.533289909362793, Grad L2 Norm: 0.023179054260253906
2025-11-24 00:16:41.961 | INFO     | __main__:<module>:160 - Step27520, Loss: 3.6053428649902344, Grad L2 Norm: 0.02314973995089531
2025-11-24 00:16:43.999 | INFO     | __main__:<module>:160 - Step27530, Loss: 3.5516064167022705, Grad L2 Norm: 0.021392708644270897
2025-11-24 00:16:46.030 | INFO     | __main__:<module>:160 - Step27540, Loss: 3.5439014434814453, Grad L2 Norm: 0.02127991057932377
2025-11-24 00:16:48.061 | INFO     | __main__:<module>:160 - Step27550, Loss: 3.4652440547943115, Grad L2 Norm: 0.021496886387467384
2025-11-24 00:16:50.098 | INFO     | __main__:<module>:160 - Step27560, Loss: 3.537212610244751, Grad L2 Norm: 0.021968815475702286
2025-11-24 00:16:52.135 | INFO     | __main__:<module>:160 - Step27570, Loss: 3.660404682159424, Grad L2 Norm: 0.021989163011312485
2025-11-24 00:16:54.163 | INFO     | __main__:<module>:160 - Step27580, Loss: 3.4847934246063232, Grad L2 Norm: 0.026597466319799423
2025-11-24 00:16:56.197 | INFO     | __main__:<module>:160 - Step27590, Loss: 3.608762741088867, Grad L2 Norm: 0.022188818082213402
2025-11-24 00:16:58.233 | INFO     | __main__:<module>:160 - Step27600, Loss: 3.486811637878418, Grad L2 Norm: 0.021634383127093315
2025-11-24 00:16:58.234 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:16:59.526 | INFO     | __main__:<module>:181 - validation loss: 3.5910882353782654
2025-11-24 00:17:01.577 | INFO     | __main__:<module>:160 - Step27610, Loss: 3.6341392993927, Grad L2 Norm: 0.021695386618375778
2025-11-24 00:17:03.615 | INFO     | __main__:<module>:160 - Step27620, Loss: 3.5034303665161133, Grad L2 Norm: 0.021336272358894348
2025-11-24 00:17:05.652 | INFO     | __main__:<module>:160 - Step27630, Loss: 3.5939130783081055, Grad L2 Norm: 0.02282293513417244
2025-11-24 00:17:07.682 | INFO     | __main__:<module>:160 - Step27640, Loss: 3.500021457672119, Grad L2 Norm: 0.020938439294695854
2025-11-24 00:17:09.715 | INFO     | __main__:<module>:160 - Step27650, Loss: 3.637482166290283, Grad L2 Norm: 0.022594286128878593
2025-11-24 00:17:11.753 | INFO     | __main__:<module>:160 - Step27660, Loss: 3.515871047973633, Grad L2 Norm: 0.02260453812777996
2025-11-24 00:17:13.792 | INFO     | __main__:<module>:160 - Step27670, Loss: 3.629859685897827, Grad L2 Norm: 0.02151765488088131
2025-11-24 00:17:15.825 | INFO     | __main__:<module>:160 - Step27680, Loss: 3.632272243499756, Grad L2 Norm: 0.02167099341750145
2025-11-24 00:17:17.853 | INFO     | __main__:<module>:160 - Step27690, Loss: 3.591853141784668, Grad L2 Norm: 0.02342371456325054
2025-11-24 00:17:19.889 | INFO     | __main__:<module>:160 - Step27700, Loss: 3.7004828453063965, Grad L2 Norm: 0.025961078703403473
2025-11-24 00:17:21.927 | INFO     | __main__:<module>:160 - Step27710, Loss: 3.4777307510375977, Grad L2 Norm: 0.020660385489463806
2025-11-24 00:17:23.952 | INFO     | __main__:<module>:160 - Step27720, Loss: 3.7178032398223877, Grad L2 Norm: 0.023281117901206017
2025-11-24 00:17:25.989 | INFO     | __main__:<module>:160 - Step27730, Loss: 3.5702152252197266, Grad L2 Norm: 0.02230042964220047
2025-11-24 00:17:28.028 | INFO     | __main__:<module>:160 - Step27740, Loss: 3.562760353088379, Grad L2 Norm: 0.022969316691160202
2025-11-24 00:17:30.058 | INFO     | __main__:<module>:160 - Step27750, Loss: 3.5662107467651367, Grad L2 Norm: 0.022239651530981064
2025-11-24 00:17:32.090 | INFO     | __main__:<module>:160 - Step27760, Loss: 3.6450929641723633, Grad L2 Norm: 0.023777788504958153
2025-11-24 00:17:34.126 | INFO     | __main__:<module>:160 - Step27770, Loss: 3.533419370651245, Grad L2 Norm: 0.023397820070385933
2025-11-24 00:17:36.163 | INFO     | __main__:<module>:160 - Step27780, Loss: 3.6124114990234375, Grad L2 Norm: 0.0207214318215847
2025-11-24 00:17:38.195 | INFO     | __main__:<module>:160 - Step27790, Loss: 3.6394920349121094, Grad L2 Norm: 0.021092982962727547
2025-11-24 00:17:40.228 | INFO     | __main__:<module>:160 - Step27800, Loss: 3.5531110763549805, Grad L2 Norm: 0.020035376772284508
2025-11-24 00:17:42.266 | INFO     | __main__:<module>:160 - Step27810, Loss: 3.668144941329956, Grad L2 Norm: 0.023381328210234642
2025-11-24 00:17:44.304 | INFO     | __main__:<module>:160 - Step27820, Loss: 3.553762912750244, Grad L2 Norm: 0.021876579150557518
2025-11-24 00:17:46.342 | INFO     | __main__:<module>:160 - Step27830, Loss: 3.582854747772217, Grad L2 Norm: 0.020489413291215897
2025-11-24 00:17:48.379 | INFO     | __main__:<module>:160 - Step27840, Loss: 3.679763078689575, Grad L2 Norm: 0.022732213139533997
2025-11-24 00:17:50.415 | INFO     | __main__:<module>:160 - Step27850, Loss: 3.549346685409546, Grad L2 Norm: 0.021995985880494118
2025-11-24 00:17:52.444 | INFO     | __main__:<module>:160 - Step27860, Loss: 3.546034336090088, Grad L2 Norm: 0.023441888391971588
2025-11-24 00:17:54.480 | INFO     | __main__:<module>:160 - Step27870, Loss: 3.6200385093688965, Grad L2 Norm: 0.02237851358950138
2025-11-24 00:17:56.520 | INFO     | __main__:<module>:160 - Step27880, Loss: 3.5529141426086426, Grad L2 Norm: 0.025066379457712173
2025-11-24 00:17:58.557 | INFO     | __main__:<module>:160 - Step27890, Loss: 3.5748257637023926, Grad L2 Norm: 0.02349723130464554
2025-11-24 00:18:00.590 | INFO     | __main__:<module>:160 - Step27900, Loss: 3.592374324798584, Grad L2 Norm: 0.023917395621538162
2025-11-24 00:18:02.620 | INFO     | __main__:<module>:160 - Step27910, Loss: 3.646517038345337, Grad L2 Norm: 0.021292313933372498
2025-11-24 00:18:04.657 | INFO     | __main__:<module>:160 - Step27920, Loss: 3.689126968383789, Grad L2 Norm: 0.023197870701551437
2025-11-24 00:18:06.695 | INFO     | __main__:<module>:160 - Step27930, Loss: 3.570075035095215, Grad L2 Norm: 0.021707110106945038
2025-11-24 00:18:08.733 | INFO     | __main__:<module>:160 - Step27940, Loss: 3.642728567123413, Grad L2 Norm: 0.02180386334657669
2025-11-24 00:18:10.769 | INFO     | __main__:<module>:160 - Step27950, Loss: 3.713991641998291, Grad L2 Norm: 0.02516002766788006
2025-11-24 00:18:12.801 | INFO     | __main__:<module>:160 - Step27960, Loss: 3.590996026992798, Grad L2 Norm: 0.02219436690211296
2025-11-24 00:18:14.835 | INFO     | __main__:<module>:160 - Step27970, Loss: 3.534698963165283, Grad L2 Norm: 0.020729022100567818
2025-11-24 00:18:16.875 | INFO     | __main__:<module>:160 - Step27980, Loss: 3.599332094192505, Grad L2 Norm: 0.021565010771155357
2025-11-24 00:18:18.912 | INFO     | __main__:<module>:160 - Step27990, Loss: 3.6327672004699707, Grad L2 Norm: 0.02216593734920025
2025-11-24 00:18:20.951 | INFO     | __main__:<module>:160 - Step28000, Loss: 3.622391700744629, Grad L2 Norm: 0.022163348272442818
2025-11-24 00:18:20.952 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:18:22.246 | INFO     | __main__:<module>:181 - validation loss: 3.5499460220336916
2025-11-24 00:18:22.247 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_28000.pt
2025-11-24 00:18:23.979 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 00:18:26.001 | INFO     | __main__:<module>:160 - Step28010, Loss: 3.549785614013672, Grad L2 Norm: 0.022725308313965797
2025-11-24 00:18:28.022 | INFO     | __main__:<module>:160 - Step28020, Loss: 3.5143349170684814, Grad L2 Norm: 0.0220686923712492
2025-11-24 00:18:30.045 | INFO     | __main__:<module>:160 - Step28030, Loss: 3.514327049255371, Grad L2 Norm: 0.02168605849146843
2025-11-24 00:18:32.065 | INFO     | __main__:<module>:160 - Step28040, Loss: 3.5994577407836914, Grad L2 Norm: 0.021461330354213715
2025-11-24 00:18:34.087 | INFO     | __main__:<module>:160 - Step28050, Loss: 3.5656135082244873, Grad L2 Norm: 0.02435889095067978
2025-11-24 00:18:36.110 | INFO     | __main__:<module>:160 - Step28060, Loss: 3.5992910861968994, Grad L2 Norm: 0.022333135828375816
2025-11-24 00:18:38.133 | INFO     | __main__:<module>:160 - Step28070, Loss: 3.586988925933838, Grad L2 Norm: 0.022096041589975357
2025-11-24 00:18:40.152 | INFO     | __main__:<module>:160 - Step28080, Loss: 3.496148109436035, Grad L2 Norm: 0.022078247740864754
2025-11-24 00:18:42.179 | INFO     | __main__:<module>:160 - Step28090, Loss: 3.5109145641326904, Grad L2 Norm: 0.022566664963960648
2025-11-24 00:18:44.205 | INFO     | __main__:<module>:160 - Step28100, Loss: 3.6018428802490234, Grad L2 Norm: 0.022454988211393356
2025-11-24 00:18:46.240 | INFO     | __main__:<module>:160 - Step28110, Loss: 3.6708977222442627, Grad L2 Norm: 0.02215767651796341
2025-11-24 00:18:48.270 | INFO     | __main__:<module>:160 - Step28120, Loss: 3.581374168395996, Grad L2 Norm: 0.021958645433187485
2025-11-24 00:18:50.298 | INFO     | __main__:<module>:160 - Step28130, Loss: 3.523371458053589, Grad L2 Norm: 0.023308467119932175
2025-11-24 00:18:52.324 | INFO     | __main__:<module>:160 - Step28140, Loss: 3.5606460571289062, Grad L2 Norm: 0.02267657406628132
2025-11-24 00:18:54.358 | INFO     | __main__:<module>:160 - Step28150, Loss: 3.6190335750579834, Grad L2 Norm: 0.02307489700615406
2025-11-24 00:18:56.385 | INFO     | __main__:<module>:160 - Step28160, Loss: 3.5463953018188477, Grad L2 Norm: 0.020780909806489944
2025-11-24 00:18:58.415 | INFO     | __main__:<module>:160 - Step28170, Loss: 3.760371208190918, Grad L2 Norm: 0.02165394276380539
2025-11-24 00:19:00.441 | INFO     | __main__:<module>:160 - Step28180, Loss: 3.522873878479004, Grad L2 Norm: 0.021872106939554214
2025-11-24 00:19:02.475 | INFO     | __main__:<module>:160 - Step28190, Loss: 3.6718783378601074, Grad L2 Norm: 0.02254270389676094
2025-11-24 00:19:04.504 | INFO     | __main__:<module>:160 - Step28200, Loss: 3.664590358734131, Grad L2 Norm: 0.022427132353186607
2025-11-24 00:19:06.537 | INFO     | __main__:<module>:160 - Step28210, Loss: 3.5983152389526367, Grad L2 Norm: 0.021098507568240166
2025-11-24 00:19:08.577 | INFO     | __main__:<module>:160 - Step28220, Loss: 3.6064743995666504, Grad L2 Norm: 0.019735408946871758
2025-11-24 00:19:10.616 | INFO     | __main__:<module>:160 - Step28230, Loss: 3.607842445373535, Grad L2 Norm: 0.020894302055239677
2025-11-24 00:19:12.656 | INFO     | __main__:<module>:160 - Step28240, Loss: 3.4141440391540527, Grad L2 Norm: 0.02257855236530304
2025-11-24 00:19:14.699 | INFO     | __main__:<module>:160 - Step28250, Loss: 3.5519309043884277, Grad L2 Norm: 0.02135646343231201
2025-11-24 00:19:16.742 | INFO     | __main__:<module>:160 - Step28260, Loss: 3.5766611099243164, Grad L2 Norm: 0.021015772596001625
2025-11-24 00:19:18.787 | INFO     | __main__:<module>:160 - Step28270, Loss: 3.6475536823272705, Grad L2 Norm: 0.022164922207593918
2025-11-24 00:19:20.832 | INFO     | __main__:<module>:160 - Step28280, Loss: 3.5728986263275146, Grad L2 Norm: 0.02118556573987007
2025-11-24 00:19:22.878 | INFO     | __main__:<module>:160 - Step28290, Loss: 3.525865077972412, Grad L2 Norm: 0.021684128791093826
2025-11-24 00:19:24.927 | INFO     | __main__:<module>:160 - Step28300, Loss: 3.5485877990722656, Grad L2 Norm: 0.021868443116545677
2025-11-24 00:19:26.971 | INFO     | __main__:<module>:160 - Step28310, Loss: 3.641963005065918, Grad L2 Norm: 0.023923754692077637
2025-11-24 00:19:29.014 | INFO     | __main__:<module>:160 - Step28320, Loss: 3.654703140258789, Grad L2 Norm: 0.026242956519126892
2025-11-24 00:19:31.060 | INFO     | __main__:<module>:160 - Step28330, Loss: 3.411123752593994, Grad L2 Norm: 0.02233705297112465
2025-11-24 00:19:33.106 | INFO     | __main__:<module>:160 - Step28340, Loss: 3.4427294731140137, Grad L2 Norm: 0.0229157917201519
2025-11-24 00:19:35.151 | INFO     | __main__:<module>:160 - Step28350, Loss: 3.6321451663970947, Grad L2 Norm: 0.022640757262706757
2025-11-24 00:19:37.196 | INFO     | __main__:<module>:160 - Step28360, Loss: 3.517620325088501, Grad L2 Norm: 0.021451178938150406
2025-11-24 00:19:39.248 | INFO     | __main__:<module>:160 - Step28370, Loss: 3.6264610290527344, Grad L2 Norm: 0.021674955263733864
2025-11-24 00:19:41.299 | INFO     | __main__:<module>:160 - Step28380, Loss: 3.4285449981689453, Grad L2 Norm: 0.02421768195927143
2025-11-24 00:19:43.350 | INFO     | __main__:<module>:160 - Step28390, Loss: 3.6083452701568604, Grad L2 Norm: 0.022067803889513016
2025-11-24 00:19:45.393 | INFO     | __main__:<module>:160 - Step28400, Loss: 3.579568386077881, Grad L2 Norm: 0.02255435287952423
2025-11-24 00:19:45.394 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:19:46.699 | INFO     | __main__:<module>:181 - validation loss: 3.559697890281677
2025-11-24 00:19:48.748 | INFO     | __main__:<module>:160 - Step28410, Loss: 3.5437979698181152, Grad L2 Norm: 0.021075809374451637
2025-11-24 00:19:50.791 | INFO     | __main__:<module>:160 - Step28420, Loss: 3.6715917587280273, Grad L2 Norm: 0.021682504564523697
2025-11-24 00:19:52.832 | INFO     | __main__:<module>:160 - Step28430, Loss: 3.5612151622772217, Grad L2 Norm: 0.021015837788581848
2025-11-24 00:19:54.868 | INFO     | __main__:<module>:160 - Step28440, Loss: 3.5120863914489746, Grad L2 Norm: 0.021909132599830627
2025-11-24 00:19:56.902 | INFO     | __main__:<module>:160 - Step28450, Loss: 3.589632987976074, Grad L2 Norm: 0.02408071793615818
2025-11-24 00:19:58.940 | INFO     | __main__:<module>:160 - Step28460, Loss: 3.5341672897338867, Grad L2 Norm: 0.022233489900827408
2025-11-24 00:20:00.971 | INFO     | __main__:<module>:160 - Step28470, Loss: 3.4796924591064453, Grad L2 Norm: 0.020548000931739807
2025-11-24 00:20:02.996 | INFO     | __main__:<module>:160 - Step28480, Loss: 3.534120559692383, Grad L2 Norm: 0.02156759612262249
2025-11-24 00:20:05.024 | INFO     | __main__:<module>:160 - Step28490, Loss: 3.7273294925689697, Grad L2 Norm: 0.028818311169743538
2025-11-24 00:20:07.053 | INFO     | __main__:<module>:160 - Step28500, Loss: 3.7307331562042236, Grad L2 Norm: 0.02242172881960869
2025-11-24 00:20:09.074 | INFO     | __main__:<module>:160 - Step28510, Loss: 3.58001708984375, Grad L2 Norm: 0.022770315408706665
2025-11-24 00:20:11.096 | INFO     | __main__:<module>:160 - Step28520, Loss: 3.603957414627075, Grad L2 Norm: 0.021759139373898506
2025-11-24 00:20:13.118 | INFO     | __main__:<module>:160 - Step28530, Loss: 3.5230226516723633, Grad L2 Norm: 0.02269941195845604
2025-11-24 00:20:15.140 | INFO     | __main__:<module>:160 - Step28540, Loss: 3.515204429626465, Grad L2 Norm: 0.021821195259690285
2025-11-24 00:20:17.171 | INFO     | __main__:<module>:160 - Step28550, Loss: 3.4790871143341064, Grad L2 Norm: 0.021799379959702492
2025-11-24 00:20:19.197 | INFO     | __main__:<module>:160 - Step28560, Loss: 3.4535417556762695, Grad L2 Norm: 0.02110741287469864
2025-11-24 00:20:21.229 | INFO     | __main__:<module>:160 - Step28570, Loss: 3.4410524368286133, Grad L2 Norm: 0.021723970770835876
2025-11-24 00:20:23.252 | INFO     | __main__:<module>:160 - Step28580, Loss: 3.6479082107543945, Grad L2 Norm: 0.026713844388723373
2025-11-24 00:20:25.280 | INFO     | __main__:<module>:160 - Step28590, Loss: 3.5390372276306152, Grad L2 Norm: 0.022020656615495682
2025-11-24 00:20:27.311 | INFO     | __main__:<module>:160 - Step28600, Loss: 3.667208671569824, Grad L2 Norm: 0.02197604812681675
2025-11-24 00:20:29.340 | INFO     | __main__:<module>:160 - Step28610, Loss: 3.604248523712158, Grad L2 Norm: 0.02179737202823162
2025-11-24 00:20:31.369 | INFO     | __main__:<module>:160 - Step28620, Loss: 3.6555228233337402, Grad L2 Norm: 0.02391696721315384
2025-11-24 00:20:33.398 | INFO     | __main__:<module>:160 - Step28630, Loss: 3.512845277786255, Grad L2 Norm: 0.024126732721924782
2025-11-24 00:20:35.428 | INFO     | __main__:<module>:160 - Step28640, Loss: 3.598618984222412, Grad L2 Norm: 0.02475595846772194
2025-11-24 00:20:37.458 | INFO     | __main__:<module>:160 - Step28650, Loss: 3.57366681098938, Grad L2 Norm: 0.02232416719198227
2025-11-24 00:20:39.488 | INFO     | __main__:<module>:160 - Step28660, Loss: 3.5850462913513184, Grad L2 Norm: 0.021271390840411186
2025-11-24 00:20:41.519 | INFO     | __main__:<module>:160 - Step28670, Loss: 3.6345858573913574, Grad L2 Norm: 0.02496287226676941
2025-11-24 00:20:43.546 | INFO     | __main__:<module>:160 - Step28680, Loss: 3.50419282913208, Grad L2 Norm: 0.021392161026597023
2025-11-24 00:20:45.579 | INFO     | __main__:<module>:160 - Step28690, Loss: 3.5766987800598145, Grad L2 Norm: 0.023143842816352844
2025-11-24 00:20:47.604 | INFO     | __main__:<module>:160 - Step28700, Loss: 3.660141944885254, Grad L2 Norm: 0.02485467679798603
2025-11-24 00:20:49.629 | INFO     | __main__:<module>:160 - Step28710, Loss: 3.5320394039154053, Grad L2 Norm: 0.02038784883916378
2025-11-24 00:20:51.656 | INFO     | __main__:<module>:160 - Step28720, Loss: 3.610826253890991, Grad L2 Norm: 0.022004399448633194
2025-11-24 00:20:53.681 | INFO     | __main__:<module>:160 - Step28730, Loss: 3.6634068489074707, Grad L2 Norm: 0.02255222015082836
2025-11-24 00:20:55.711 | INFO     | __main__:<module>:160 - Step28740, Loss: 3.5897719860076904, Grad L2 Norm: 0.02261853776872158
2025-11-24 00:20:57.741 | INFO     | __main__:<module>:160 - Step28750, Loss: 3.5343427658081055, Grad L2 Norm: 0.022152850404381752
2025-11-24 00:20:59.776 | INFO     | __main__:<module>:160 - Step28760, Loss: 3.516571521759033, Grad L2 Norm: 0.021385017782449722
2025-11-24 00:21:01.805 | INFO     | __main__:<module>:160 - Step28770, Loss: 3.6010537147521973, Grad L2 Norm: 0.022062048316001892
2025-11-24 00:21:03.837 | INFO     | __main__:<module>:160 - Step28780, Loss: 3.595095634460449, Grad L2 Norm: 0.021887164562940598
2025-11-24 00:21:05.861 | INFO     | __main__:<module>:160 - Step28790, Loss: 3.6468098163604736, Grad L2 Norm: 0.02096368558704853
2025-11-24 00:21:07.889 | INFO     | __main__:<module>:160 - Step28800, Loss: 3.5166916847229004, Grad L2 Norm: 0.02085161954164505
2025-11-24 00:21:07.890 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:21:09.180 | INFO     | __main__:<module>:181 - validation loss: 3.577695906162262
2025-11-24 00:21:11.216 | INFO     | __main__:<module>:160 - Step28810, Loss: 3.621225357055664, Grad L2 Norm: 0.021467411890625954
2025-11-24 00:21:13.247 | INFO     | __main__:<module>:160 - Step28820, Loss: 3.553450107574463, Grad L2 Norm: 0.0225641168653965
2025-11-24 00:21:15.274 | INFO     | __main__:<module>:160 - Step28830, Loss: 3.563589572906494, Grad L2 Norm: 0.022096771746873856
2025-11-24 00:21:17.299 | INFO     | __main__:<module>:160 - Step28840, Loss: 3.579808235168457, Grad L2 Norm: 0.022229088470339775
2025-11-24 00:21:19.332 | INFO     | __main__:<module>:160 - Step28850, Loss: 3.6123483180999756, Grad L2 Norm: 0.02221784181892872
2025-11-24 00:21:21.358 | INFO     | __main__:<module>:160 - Step28860, Loss: 3.6822166442871094, Grad L2 Norm: 0.022262360900640488
2025-11-24 00:21:23.390 | INFO     | __main__:<module>:160 - Step28870, Loss: 3.760197162628174, Grad L2 Norm: 0.023863546550273895
2025-11-24 00:21:25.419 | INFO     | __main__:<module>:160 - Step28880, Loss: 3.5841565132141113, Grad L2 Norm: 0.022134829312562943
2025-11-24 00:21:27.446 | INFO     | __main__:<module>:160 - Step28890, Loss: 3.4542508125305176, Grad L2 Norm: 0.021588753908872604
2025-11-24 00:21:29.465 | INFO     | __main__:<module>:160 - Step28900, Loss: 3.533215045928955, Grad L2 Norm: 0.022609194740653038
2025-11-24 00:21:31.488 | INFO     | __main__:<module>:160 - Step28910, Loss: 3.6074395179748535, Grad L2 Norm: 0.02207145094871521
2025-11-24 00:21:33.513 | INFO     | __main__:<module>:160 - Step28920, Loss: 3.632469654083252, Grad L2 Norm: 0.02185910940170288
2025-11-24 00:21:35.538 | INFO     | __main__:<module>:160 - Step28930, Loss: 3.582411289215088, Grad L2 Norm: 0.022539587691426277
2025-11-24 00:21:37.564 | INFO     | __main__:<module>:160 - Step28940, Loss: 3.567715883255005, Grad L2 Norm: 0.022479362785816193
2025-11-24 00:21:39.590 | INFO     | __main__:<module>:160 - Step28950, Loss: 3.522833824157715, Grad L2 Norm: 0.021777991205453873
2025-11-24 00:21:41.620 | INFO     | __main__:<module>:160 - Step28960, Loss: 3.654679298400879, Grad L2 Norm: 0.02346426621079445
2025-11-24 00:21:43.645 | INFO     | __main__:<module>:160 - Step28970, Loss: 3.5788912773132324, Grad L2 Norm: 0.022562582045793533
2025-11-24 00:21:45.671 | INFO     | __main__:<module>:160 - Step28980, Loss: 3.534173011779785, Grad L2 Norm: 0.023199880495667458
2025-11-24 00:21:47.700 | INFO     | __main__:<module>:160 - Step28990, Loss: 3.7000293731689453, Grad L2 Norm: 0.022114818915724754
2025-11-24 00:21:49.725 | INFO     | __main__:<module>:160 - Step29000, Loss: 3.6804616451263428, Grad L2 Norm: 0.022429104894399643
2025-11-24 00:21:51.750 | INFO     | __main__:<module>:160 - Step29010, Loss: 3.5922601222991943, Grad L2 Norm: 0.022437162697315216
2025-11-24 00:21:53.774 | INFO     | __main__:<module>:160 - Step29020, Loss: 3.685344696044922, Grad L2 Norm: 0.025345733389258385
2025-11-24 00:21:55.800 | INFO     | __main__:<module>:160 - Step29030, Loss: 3.6447558403015137, Grad L2 Norm: 0.0228995680809021
2025-11-24 00:21:57.822 | INFO     | __main__:<module>:160 - Step29040, Loss: 3.5573854446411133, Grad L2 Norm: 0.02268075942993164
2025-11-24 00:21:59.843 | INFO     | __main__:<module>:160 - Step29050, Loss: 3.6636247634887695, Grad L2 Norm: 0.022665362805128098
2025-11-24 00:22:01.867 | INFO     | __main__:<module>:160 - Step29060, Loss: 3.436180830001831, Grad L2 Norm: 0.023029925301671028
2025-11-24 00:22:03.895 | INFO     | __main__:<module>:160 - Step29070, Loss: 3.64210844039917, Grad L2 Norm: 0.02265704795718193
2025-11-24 00:22:05.919 | INFO     | __main__:<module>:160 - Step29080, Loss: 3.5492560863494873, Grad L2 Norm: 0.021415412425994873
2025-11-24 00:22:07.946 | INFO     | __main__:<module>:160 - Step29090, Loss: 3.494481086730957, Grad L2 Norm: 0.02302582561969757
2025-11-24 00:22:09.968 | INFO     | __main__:<module>:160 - Step29100, Loss: 3.402674436569214, Grad L2 Norm: 0.021104177460074425
2025-11-24 00:22:11.996 | INFO     | __main__:<module>:160 - Step29110, Loss: 3.6790409088134766, Grad L2 Norm: 0.022320907562971115
2025-11-24 00:22:14.019 | INFO     | __main__:<module>:160 - Step29120, Loss: 3.542161226272583, Grad L2 Norm: 0.02202531322836876
2025-11-24 00:22:16.049 | INFO     | __main__:<module>:160 - Step29130, Loss: 3.511458396911621, Grad L2 Norm: 0.023155471310019493
2025-11-24 00:22:18.075 | INFO     | __main__:<module>:160 - Step29140, Loss: 3.5739965438842773, Grad L2 Norm: 0.021203763782978058
2025-11-24 00:22:20.104 | INFO     | __main__:<module>:160 - Step29150, Loss: 3.600092649459839, Grad L2 Norm: 0.023513348773121834
2025-11-24 00:22:22.127 | INFO     | __main__:<module>:160 - Step29160, Loss: 3.5560526847839355, Grad L2 Norm: 0.021487850695848465
2025-11-24 00:22:24.151 | INFO     | __main__:<module>:160 - Step29170, Loss: 3.6088058948516846, Grad L2 Norm: 0.02353166975080967
2025-11-24 00:22:26.174 | INFO     | __main__:<module>:160 - Step29180, Loss: 3.5833182334899902, Grad L2 Norm: 0.02189037576317787
2025-11-24 00:22:28.195 | INFO     | __main__:<module>:160 - Step29190, Loss: 3.735537528991699, Grad L2 Norm: 0.021624870598316193
2025-11-24 00:22:30.223 | INFO     | __main__:<module>:160 - Step29200, Loss: 3.5801753997802734, Grad L2 Norm: 0.022881601005792618
2025-11-24 00:22:30.224 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:22:31.510 | INFO     | __main__:<module>:181 - validation loss: 3.5912768959999086
2025-11-24 00:22:33.548 | INFO     | __main__:<module>:160 - Step29210, Loss: 3.519437551498413, Grad L2 Norm: 0.02212437056005001
2025-11-24 00:22:35.575 | INFO     | __main__:<module>:160 - Step29220, Loss: 3.603388786315918, Grad L2 Norm: 0.021176423877477646
2025-11-24 00:22:37.608 | INFO     | __main__:<module>:160 - Step29230, Loss: 3.531867504119873, Grad L2 Norm: 0.02163754589855671
2025-11-24 00:22:39.630 | INFO     | __main__:<module>:160 - Step29240, Loss: 3.4987308979034424, Grad L2 Norm: 0.020817788317799568
2025-11-24 00:22:41.651 | INFO     | __main__:<module>:160 - Step29250, Loss: 3.5604357719421387, Grad L2 Norm: 0.02035699598491192
2025-11-24 00:22:43.682 | INFO     | __main__:<module>:160 - Step29260, Loss: 3.573930025100708, Grad L2 Norm: 0.02306603267788887
2025-11-24 00:22:45.709 | INFO     | __main__:<module>:160 - Step29270, Loss: 3.5303843021392822, Grad L2 Norm: 0.021436013281345367
2025-11-24 00:22:47.736 | INFO     | __main__:<module>:160 - Step29280, Loss: 3.558759927749634, Grad L2 Norm: 0.02303808368742466
2025-11-24 00:22:49.756 | INFO     | __main__:<module>:160 - Step29290, Loss: 3.748568534851074, Grad L2 Norm: 0.024531107395887375
2025-11-24 00:22:51.784 | INFO     | __main__:<module>:160 - Step29300, Loss: 3.6268391609191895, Grad L2 Norm: 0.02340235374867916
2025-11-24 00:22:53.809 | INFO     | __main__:<module>:160 - Step29310, Loss: 3.6255223751068115, Grad L2 Norm: 0.02391212247312069
2025-11-24 00:22:55.836 | INFO     | __main__:<module>:160 - Step29320, Loss: 3.5516269207000732, Grad L2 Norm: 0.021099746227264404
2025-11-24 00:22:57.861 | INFO     | __main__:<module>:160 - Step29330, Loss: 3.6536340713500977, Grad L2 Norm: 0.0214032344520092
2025-11-24 00:22:59.885 | INFO     | __main__:<module>:160 - Step29340, Loss: 3.7206711769104004, Grad L2 Norm: 0.023045135661959648
2025-11-24 00:23:01.914 | INFO     | __main__:<module>:160 - Step29350, Loss: 3.650998115539551, Grad L2 Norm: 0.02217135578393936
2025-11-24 00:23:03.936 | INFO     | __main__:<module>:160 - Step29360, Loss: 3.61377215385437, Grad L2 Norm: 0.023258298635482788
2025-11-24 00:23:05.960 | INFO     | __main__:<module>:160 - Step29370, Loss: 3.556119680404663, Grad L2 Norm: 0.02184941992163658
2025-11-24 00:23:07.981 | INFO     | __main__:<module>:160 - Step29380, Loss: 3.5982978343963623, Grad L2 Norm: 0.022065848112106323
2025-11-24 00:23:10.004 | INFO     | __main__:<module>:160 - Step29390, Loss: 3.601503849029541, Grad L2 Norm: 0.023547235876321793
2025-11-24 00:23:12.031 | INFO     | __main__:<module>:160 - Step29400, Loss: 3.541081428527832, Grad L2 Norm: 0.02186412364244461
2025-11-24 00:23:14.051 | INFO     | __main__:<module>:160 - Step29410, Loss: 3.4925739765167236, Grad L2 Norm: 0.02120290696620941
2025-11-24 00:23:16.077 | INFO     | __main__:<module>:160 - Step29420, Loss: 3.4919440746307373, Grad L2 Norm: 0.022534381598234177
2025-11-24 00:23:18.101 | INFO     | __main__:<module>:160 - Step29430, Loss: 3.58377742767334, Grad L2 Norm: 0.02156449481844902
2025-11-24 00:23:20.124 | INFO     | __main__:<module>:160 - Step29440, Loss: 3.522332191467285, Grad L2 Norm: 0.02118370123207569
2025-11-24 00:23:22.143 | INFO     | __main__:<module>:160 - Step29450, Loss: 3.632761240005493, Grad L2 Norm: 0.021857913583517075
2025-11-24 00:23:24.160 | INFO     | __main__:<module>:160 - Step29460, Loss: 3.6149089336395264, Grad L2 Norm: 0.022141916677355766
2025-11-24 00:23:26.179 | INFO     | __main__:<module>:160 - Step29470, Loss: 3.5285801887512207, Grad L2 Norm: 0.022758424282073975
2025-11-24 00:23:28.198 | INFO     | __main__:<module>:160 - Step29480, Loss: 3.4992682933807373, Grad L2 Norm: 0.021567638963460922
2025-11-24 00:23:30.214 | INFO     | __main__:<module>:160 - Step29490, Loss: 3.559394359588623, Grad L2 Norm: 0.021773193031549454
2025-11-24 00:23:32.227 | INFO     | __main__:<module>:160 - Step29500, Loss: 3.552985191345215, Grad L2 Norm: 0.021449292078614235
2025-11-24 00:23:34.238 | INFO     | __main__:<module>:160 - Step29510, Loss: 3.6659069061279297, Grad L2 Norm: 0.02244933322072029
2025-11-24 00:23:36.254 | INFO     | __main__:<module>:160 - Step29520, Loss: 3.652521848678589, Grad L2 Norm: 0.02203318662941456
2025-11-24 00:23:38.268 | INFO     | __main__:<module>:160 - Step29530, Loss: 3.5365633964538574, Grad L2 Norm: 0.020545275881886482
2025-11-24 00:23:40.277 | INFO     | __main__:<module>:160 - Step29540, Loss: 3.5782623291015625, Grad L2 Norm: 0.021765025332570076
2025-11-24 00:23:42.289 | INFO     | __main__:<module>:160 - Step29550, Loss: 3.546293020248413, Grad L2 Norm: 0.021919578313827515
2025-11-24 00:23:44.297 | INFO     | __main__:<module>:160 - Step29560, Loss: 3.8024003505706787, Grad L2 Norm: 0.02525506354868412
2025-11-24 00:23:46.307 | INFO     | __main__:<module>:160 - Step29570, Loss: 3.7310822010040283, Grad L2 Norm: 0.02233576960861683
2025-11-24 00:23:48.316 | INFO     | __main__:<module>:160 - Step29580, Loss: 3.5363166332244873, Grad L2 Norm: 0.02170262485742569
2025-11-24 00:23:50.328 | INFO     | __main__:<module>:160 - Step29590, Loss: 3.603397846221924, Grad L2 Norm: 0.020673707127571106
2025-11-24 00:23:52.347 | INFO     | __main__:<module>:160 - Step29600, Loss: 3.4790942668914795, Grad L2 Norm: 0.02432716079056263
2025-11-24 00:23:52.347 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:23:53.630 | INFO     | __main__:<module>:181 - validation loss: 3.589533257484436
2025-11-24 00:23:55.657 | INFO     | __main__:<module>:160 - Step29610, Loss: 3.5253043174743652, Grad L2 Norm: 0.021178891882300377
2025-11-24 00:23:57.674 | INFO     | __main__:<module>:160 - Step29620, Loss: 3.5245871543884277, Grad L2 Norm: 0.02329283207654953
2025-11-24 00:23:59.692 | INFO     | __main__:<module>:160 - Step29630, Loss: 3.534999132156372, Grad L2 Norm: 0.02322528325021267
2025-11-24 00:24:01.705 | INFO     | __main__:<module>:160 - Step29640, Loss: 3.4775853157043457, Grad L2 Norm: 0.023641761392354965
2025-11-24 00:24:03.720 | INFO     | __main__:<module>:160 - Step29650, Loss: 3.5923471450805664, Grad L2 Norm: 0.02381243370473385
2025-11-24 00:24:05.732 | INFO     | __main__:<module>:160 - Step29660, Loss: 3.5234556198120117, Grad L2 Norm: 0.02178424969315529
2025-11-24 00:24:07.747 | INFO     | __main__:<module>:160 - Step29670, Loss: 3.700019359588623, Grad L2 Norm: 0.023499298840761185
2025-11-24 00:24:09.761 | INFO     | __main__:<module>:160 - Step29680, Loss: 3.4996137619018555, Grad L2 Norm: 0.02198687568306923
2025-11-24 00:24:11.780 | INFO     | __main__:<module>:160 - Step29690, Loss: 3.527883529663086, Grad L2 Norm: 0.021634602919220924
2025-11-24 00:24:13.798 | INFO     | __main__:<module>:160 - Step29700, Loss: 3.5274338722229004, Grad L2 Norm: 0.02364632673561573
2025-11-24 00:24:15.811 | INFO     | __main__:<module>:160 - Step29710, Loss: 3.525294542312622, Grad L2 Norm: 0.022058431059122086
2025-11-24 00:24:17.827 | INFO     | __main__:<module>:160 - Step29720, Loss: 3.519030809402466, Grad L2 Norm: 0.02128254808485508
2025-11-24 00:24:19.842 | INFO     | __main__:<module>:160 - Step29730, Loss: 3.6043686866760254, Grad L2 Norm: 0.02280478924512863
2025-11-24 00:24:21.861 | INFO     | __main__:<module>:160 - Step29740, Loss: 3.533022165298462, Grad L2 Norm: 0.022280316799879074
2025-11-24 00:24:23.876 | INFO     | __main__:<module>:160 - Step29750, Loss: 3.6074535846710205, Grad L2 Norm: 0.023014064878225327
2025-11-24 00:24:25.894 | INFO     | __main__:<module>:160 - Step29760, Loss: 3.4832303524017334, Grad L2 Norm: 0.020607268437743187
2025-11-24 00:24:27.916 | INFO     | __main__:<module>:160 - Step29770, Loss: 3.6325297355651855, Grad L2 Norm: 0.022573648020625114
2025-11-24 00:24:29.937 | INFO     | __main__:<module>:160 - Step29780, Loss: 3.598134994506836, Grad L2 Norm: 0.021691830828785896
2025-11-24 00:24:31.960 | INFO     | __main__:<module>:160 - Step29790, Loss: 3.5137243270874023, Grad L2 Norm: 0.021136626601219177
2025-11-24 00:24:33.987 | INFO     | __main__:<module>:160 - Step29800, Loss: 3.492490530014038, Grad L2 Norm: 0.021948663517832756
2025-11-24 00:24:36.005 | INFO     | __main__:<module>:160 - Step29810, Loss: 3.550175666809082, Grad L2 Norm: 0.022164693102240562
2025-11-24 00:24:38.023 | INFO     | __main__:<module>:160 - Step29820, Loss: 3.5854649543762207, Grad L2 Norm: 0.022076644003391266
2025-11-24 00:24:40.045 | INFO     | __main__:<module>:160 - Step29830, Loss: 3.637632131576538, Grad L2 Norm: 0.0249013751745224
2025-11-24 00:24:42.062 | INFO     | __main__:<module>:160 - Step29840, Loss: 3.457928419113159, Grad L2 Norm: 0.02214033529162407
2025-11-24 00:24:44.084 | INFO     | __main__:<module>:160 - Step29850, Loss: 3.640575885772705, Grad L2 Norm: 0.022469790652394295
2025-11-24 00:24:46.099 | INFO     | __main__:<module>:160 - Step29860, Loss: 3.5051181316375732, Grad L2 Norm: 0.023152844980359077
2025-11-24 00:24:48.114 | INFO     | __main__:<module>:160 - Step29870, Loss: 3.602975845336914, Grad L2 Norm: 0.020414503291249275
2025-11-24 00:24:50.127 | INFO     | __main__:<module>:160 - Step29880, Loss: 3.475703239440918, Grad L2 Norm: 0.023153895512223244
2025-11-24 00:24:52.138 | INFO     | __main__:<module>:160 - Step29890, Loss: 3.560763359069824, Grad L2 Norm: 0.022427214309573174
2025-11-24 00:24:54.154 | INFO     | __main__:<module>:160 - Step29900, Loss: 3.6056904792785645, Grad L2 Norm: 0.022558309137821198
2025-11-24 00:24:56.170 | INFO     | __main__:<module>:160 - Step29910, Loss: 3.446420192718506, Grad L2 Norm: 0.02240876480937004
2025-11-24 00:24:58.188 | INFO     | __main__:<module>:160 - Step29920, Loss: 3.570796012878418, Grad L2 Norm: 0.02269642986357212
2025-11-24 00:25:00.204 | INFO     | __main__:<module>:160 - Step29930, Loss: 3.549656867980957, Grad L2 Norm: 0.02010289952158928
2025-11-24 00:25:02.216 | INFO     | __main__:<module>:160 - Step29940, Loss: 3.651313066482544, Grad L2 Norm: 0.021903248503804207
2025-11-24 00:25:04.234 | INFO     | __main__:<module>:160 - Step29950, Loss: 3.6737916469573975, Grad L2 Norm: 0.022086545825004578
2025-11-24 00:25:06.251 | INFO     | __main__:<module>:160 - Step29960, Loss: 3.5764169692993164, Grad L2 Norm: 0.02353304997086525
2025-11-24 00:25:08.270 | INFO     | __main__:<module>:160 - Step29970, Loss: 3.6199371814727783, Grad L2 Norm: 0.02162591740489006
2025-11-24 00:25:10.288 | INFO     | __main__:<module>:160 - Step29980, Loss: 3.7082810401916504, Grad L2 Norm: 0.024301469326019287
2025-11-24 00:25:12.305 | INFO     | __main__:<module>:160 - Step29990, Loss: 3.5175299644470215, Grad L2 Norm: 0.020911363884806633
2025-11-24 00:25:14.322 | INFO     | __main__:<module>:160 - Step30000, Loss: 3.4889535903930664, Grad L2 Norm: 0.023861274123191833
2025-11-24 00:25:14.323 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:25:15.610 | INFO     | __main__:<module>:181 - validation loss: 3.5835820913314818
2025-11-24 00:25:15.611 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_30000.pt
2025-11-24 00:25:17.306 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 00:25:19.299 | INFO     | __main__:<module>:160 - Step30010, Loss: 3.6446762084960938, Grad L2 Norm: 0.02325518988072872
2025-11-24 00:25:21.304 | INFO     | __main__:<module>:160 - Step30020, Loss: 3.690479278564453, Grad L2 Norm: 0.022814704105257988
2025-11-24 00:25:23.318 | INFO     | __main__:<module>:160 - Step30030, Loss: 3.4842662811279297, Grad L2 Norm: 0.022950058802962303
2025-11-24 00:25:25.334 | INFO     | __main__:<module>:160 - Step30040, Loss: 3.5227956771850586, Grad L2 Norm: 0.021699531003832817
2025-11-24 00:25:27.343 | INFO     | __main__:<module>:160 - Step30050, Loss: 3.61936616897583, Grad L2 Norm: 0.023334572091698647
2025-11-24 00:25:29.352 | INFO     | __main__:<module>:160 - Step30060, Loss: 3.508049964904785, Grad L2 Norm: 0.02065299265086651
2025-11-24 00:25:31.362 | INFO     | __main__:<module>:160 - Step30070, Loss: 3.596618890762329, Grad L2 Norm: 0.021190298721194267
2025-11-24 00:25:33.368 | INFO     | __main__:<module>:160 - Step30080, Loss: 3.4984655380249023, Grad L2 Norm: 0.02155960164964199
2025-11-24 00:25:35.377 | INFO     | __main__:<module>:160 - Step30090, Loss: 3.498070240020752, Grad L2 Norm: 0.02307821810245514
2025-11-24 00:25:37.387 | INFO     | __main__:<module>:160 - Step30100, Loss: 3.5497307777404785, Grad L2 Norm: 0.02082384191453457
2025-11-24 00:25:39.393 | INFO     | __main__:<module>:160 - Step30110, Loss: 3.551030397415161, Grad L2 Norm: 0.02062205970287323
2025-11-24 00:25:41.398 | INFO     | __main__:<module>:160 - Step30120, Loss: 3.8260138034820557, Grad L2 Norm: 0.025458265095949173
2025-11-24 00:25:43.404 | INFO     | __main__:<module>:160 - Step30130, Loss: 3.466759204864502, Grad L2 Norm: 0.02263197861611843
2025-11-24 00:25:45.417 | INFO     | __main__:<module>:160 - Step30140, Loss: 3.4954376220703125, Grad L2 Norm: 0.022267218679189682
2025-11-24 00:25:47.422 | INFO     | __main__:<module>:160 - Step30150, Loss: 3.516956090927124, Grad L2 Norm: 0.02055027149617672
2025-11-24 00:25:49.429 | INFO     | __main__:<module>:160 - Step30160, Loss: 3.5123138427734375, Grad L2 Norm: 0.022256841883063316
2025-11-24 00:25:51.441 | INFO     | __main__:<module>:160 - Step30170, Loss: 3.531245708465576, Grad L2 Norm: 0.021727409213781357
2025-11-24 00:25:53.452 | INFO     | __main__:<module>:160 - Step30180, Loss: 3.5932865142822266, Grad L2 Norm: 0.021806159988045692
2025-11-24 00:25:55.458 | INFO     | __main__:<module>:160 - Step30190, Loss: 3.5281693935394287, Grad L2 Norm: 0.022874295711517334
2025-11-24 00:25:57.470 | INFO     | __main__:<module>:160 - Step30200, Loss: 3.589017629623413, Grad L2 Norm: 0.021854976192116737
2025-11-24 00:25:59.474 | INFO     | __main__:<module>:160 - Step30210, Loss: 3.5644216537475586, Grad L2 Norm: 0.020610971376299858
2025-11-24 00:26:01.482 | INFO     | __main__:<module>:160 - Step30220, Loss: 3.6196203231811523, Grad L2 Norm: 0.021391477435827255
2025-11-24 00:26:03.490 | INFO     | __main__:<module>:160 - Step30230, Loss: 3.607327938079834, Grad L2 Norm: 0.023609017953276634
2025-11-24 00:26:05.499 | INFO     | __main__:<module>:160 - Step30240, Loss: 3.456533432006836, Grad L2 Norm: 0.02345847710967064
2025-11-24 00:26:07.510 | INFO     | __main__:<module>:160 - Step30250, Loss: 3.6103241443634033, Grad L2 Norm: 0.02253296785056591
2025-11-24 00:26:09.526 | INFO     | __main__:<module>:160 - Step30260, Loss: 3.6216039657592773, Grad L2 Norm: 0.024254117161035538
2025-11-24 00:26:11.543 | INFO     | __main__:<module>:160 - Step30270, Loss: 3.5655598640441895, Grad L2 Norm: 0.023471055552363396
2025-11-24 00:26:13.554 | INFO     | __main__:<module>:160 - Step30280, Loss: 3.6006529331207275, Grad L2 Norm: 0.02313661389052868
2025-11-24 00:26:15.566 | INFO     | __main__:<module>:160 - Step30290, Loss: 3.6197829246520996, Grad L2 Norm: 0.023012882098555565
2025-11-24 00:26:17.580 | INFO     | __main__:<module>:160 - Step30300, Loss: 3.646123170852661, Grad L2 Norm: 0.021051259711384773
2025-11-24 00:26:19.591 | INFO     | __main__:<module>:160 - Step30310, Loss: 3.720043659210205, Grad L2 Norm: 0.02459718845784664
2025-11-24 00:26:21.606 | INFO     | __main__:<module>:160 - Step30320, Loss: 3.6349916458129883, Grad L2 Norm: 0.02201216109097004
2025-11-24 00:26:23.621 | INFO     | __main__:<module>:160 - Step30330, Loss: 3.7127771377563477, Grad L2 Norm: 0.022803986445069313
2025-11-24 00:26:25.638 | INFO     | __main__:<module>:160 - Step30340, Loss: 3.581183433532715, Grad L2 Norm: 0.023044826462864876
2025-11-24 00:26:27.652 | INFO     | __main__:<module>:160 - Step30350, Loss: 3.624464988708496, Grad L2 Norm: 0.022808095440268517
2025-11-24 00:26:29.666 | INFO     | __main__:<module>:160 - Step30360, Loss: 3.5749669075012207, Grad L2 Norm: 0.02142631821334362
2025-11-24 00:26:31.684 | INFO     | __main__:<module>:160 - Step30370, Loss: 3.665482997894287, Grad L2 Norm: 0.02396663837134838
2025-11-24 00:26:33.700 | INFO     | __main__:<module>:160 - Step30380, Loss: 3.5056285858154297, Grad L2 Norm: 0.021627062931656837
2025-11-24 00:26:35.716 | INFO     | __main__:<module>:160 - Step30390, Loss: 3.503024101257324, Grad L2 Norm: 0.02052146941423416
2025-11-24 00:26:37.729 | INFO     | __main__:<module>:160 - Step30400, Loss: 3.6403284072875977, Grad L2 Norm: 0.023434383794665337
2025-11-24 00:26:37.729 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:26:39.010 | INFO     | __main__:<module>:181 - validation loss: 3.5843327045440674
2025-11-24 00:26:41.036 | INFO     | __main__:<module>:160 - Step30410, Loss: 3.47139835357666, Grad L2 Norm: 0.02141222357749939
2025-11-24 00:26:43.054 | INFO     | __main__:<module>:160 - Step30420, Loss: 3.60036563873291, Grad L2 Norm: 0.02238488383591175
2025-11-24 00:26:45.073 | INFO     | __main__:<module>:160 - Step30430, Loss: 3.627310037612915, Grad L2 Norm: 0.023181749507784843
2025-11-24 00:26:47.092 | INFO     | __main__:<module>:160 - Step30440, Loss: 3.5687315464019775, Grad L2 Norm: 0.020605338737368584
2025-11-24 00:26:49.111 | INFO     | __main__:<module>:160 - Step30450, Loss: 3.6089463233947754, Grad L2 Norm: 0.023043319582939148
2025-11-24 00:26:51.131 | INFO     | __main__:<module>:160 - Step30460, Loss: 3.658748149871826, Grad L2 Norm: 0.02266097627580166
2025-11-24 00:26:53.149 | INFO     | __main__:<module>:160 - Step30470, Loss: 3.475424289703369, Grad L2 Norm: 0.023709049448370934
2025-11-24 00:26:55.166 | INFO     | __main__:<module>:160 - Step30480, Loss: 3.712386131286621, Grad L2 Norm: 0.021659813821315765
2025-11-24 00:26:57.181 | INFO     | __main__:<module>:160 - Step30490, Loss: 3.5224926471710205, Grad L2 Norm: 0.02071508578956127
2025-11-24 00:26:59.198 | INFO     | __main__:<module>:160 - Step30500, Loss: 3.5500147342681885, Grad L2 Norm: 0.02192794904112816
2025-11-24 00:27:01.212 | INFO     | __main__:<module>:160 - Step30510, Loss: 3.537580966949463, Grad L2 Norm: 0.024339785799384117
2025-11-24 00:27:03.223 | INFO     | __main__:<module>:160 - Step30520, Loss: 3.508208751678467, Grad L2 Norm: 0.022033415734767914
2025-11-24 00:27:05.236 | INFO     | __main__:<module>:160 - Step30530, Loss: 3.60551381111145, Grad L2 Norm: 0.02340097539126873
2025-11-24 00:27:07.251 | INFO     | __main__:<module>:160 - Step30540, Loss: 3.496870517730713, Grad L2 Norm: 0.021883277222514153
2025-11-24 00:27:09.264 | INFO     | __main__:<module>:160 - Step30550, Loss: 3.61220645904541, Grad L2 Norm: 0.023731142282485962
2025-11-24 00:27:11.279 | INFO     | __main__:<module>:160 - Step30560, Loss: 3.6512210369110107, Grad L2 Norm: 0.02112317457795143
2025-11-24 00:27:13.294 | INFO     | __main__:<module>:160 - Step30570, Loss: 3.6470980644226074, Grad L2 Norm: 0.0210696030408144
2025-11-24 00:27:15.310 | INFO     | __main__:<module>:160 - Step30580, Loss: 3.7176990509033203, Grad L2 Norm: 0.02102055959403515
2025-11-24 00:27:17.331 | INFO     | __main__:<module>:160 - Step30590, Loss: 3.636279821395874, Grad L2 Norm: 0.021798957139253616
2025-11-24 00:27:19.346 | INFO     | __main__:<module>:160 - Step30600, Loss: 3.5646684169769287, Grad L2 Norm: 0.021701352670788765
2025-11-24 00:27:21.359 | INFO     | __main__:<module>:160 - Step30610, Loss: 3.563397169113159, Grad L2 Norm: 0.022268470376729965
2025-11-24 00:27:23.372 | INFO     | __main__:<module>:160 - Step30620, Loss: 3.6034350395202637, Grad L2 Norm: 0.02225281484425068
2025-11-24 00:27:25.388 | INFO     | __main__:<module>:160 - Step30630, Loss: 3.5892364978790283, Grad L2 Norm: 0.02132268063724041
2025-11-24 00:27:27.406 | INFO     | __main__:<module>:160 - Step30640, Loss: 3.534860134124756, Grad L2 Norm: 0.021164080128073692
2025-11-24 00:27:29.422 | INFO     | __main__:<module>:160 - Step30650, Loss: 3.516322135925293, Grad L2 Norm: 0.02178916521370411
2025-11-24 00:27:31.442 | INFO     | __main__:<module>:160 - Step30660, Loss: 3.527263641357422, Grad L2 Norm: 0.023603832349181175
2025-11-24 00:27:33.461 | INFO     | __main__:<module>:160 - Step30670, Loss: 3.6040632724761963, Grad L2 Norm: 0.022017138078808784
2025-11-24 00:27:35.481 | INFO     | __main__:<module>:160 - Step30680, Loss: 3.4901084899902344, Grad L2 Norm: 0.02090027742087841
2025-11-24 00:27:37.502 | INFO     | __main__:<module>:160 - Step30690, Loss: 3.5023422241210938, Grad L2 Norm: 0.02108183316886425
2025-11-24 00:27:39.518 | INFO     | __main__:<module>:160 - Step30700, Loss: 3.54013729095459, Grad L2 Norm: 0.0221706610172987
2025-11-24 00:27:41.536 | INFO     | __main__:<module>:160 - Step30710, Loss: 3.565135955810547, Grad L2 Norm: 0.022741252556443214
2025-11-24 00:27:43.555 | INFO     | __main__:<module>:160 - Step30720, Loss: 3.4971060752868652, Grad L2 Norm: 0.02026456966996193
2025-11-24 00:27:45.576 | INFO     | __main__:<module>:160 - Step30730, Loss: 3.536777973175049, Grad L2 Norm: 0.02115267887711525
2025-11-24 00:27:47.595 | INFO     | __main__:<module>:160 - Step30740, Loss: 3.621004104614258, Grad L2 Norm: 0.02225418947637081
2025-11-24 00:27:49.615 | INFO     | __main__:<module>:160 - Step30750, Loss: 3.570474624633789, Grad L2 Norm: 0.0220719575881958
2025-11-24 00:27:51.633 | INFO     | __main__:<module>:160 - Step30760, Loss: 3.599623680114746, Grad L2 Norm: 0.022596966475248337
2025-11-24 00:27:53.652 | INFO     | __main__:<module>:160 - Step30770, Loss: 3.617924690246582, Grad L2 Norm: 0.02207185886800289
2025-11-24 00:27:55.673 | INFO     | __main__:<module>:160 - Step30780, Loss: 3.515176773071289, Grad L2 Norm: 0.020425131544470787
2025-11-24 00:27:57.693 | INFO     | __main__:<module>:160 - Step30790, Loss: 3.6972970962524414, Grad L2 Norm: 0.022772643715143204
2025-11-24 00:27:59.710 | INFO     | __main__:<module>:160 - Step30800, Loss: 3.701051950454712, Grad L2 Norm: 0.0230251494795084
2025-11-24 00:27:59.711 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:28:00.998 | INFO     | __main__:<module>:181 - validation loss: 3.563136899471283
2025-11-24 00:28:03.028 | INFO     | __main__:<module>:160 - Step30810, Loss: 3.5350136756896973, Grad L2 Norm: 0.021557394415140152
2025-11-24 00:28:05.047 | INFO     | __main__:<module>:160 - Step30820, Loss: 3.4618375301361084, Grad L2 Norm: 0.024434709921479225
2025-11-24 00:28:07.062 | INFO     | __main__:<module>:160 - Step30830, Loss: 3.6016812324523926, Grad L2 Norm: 0.022911863401532173
2025-11-24 00:28:09.077 | INFO     | __main__:<module>:160 - Step30840, Loss: 3.5955941677093506, Grad L2 Norm: 0.022127196192741394
2025-11-24 00:28:11.094 | INFO     | __main__:<module>:160 - Step30850, Loss: 3.5421462059020996, Grad L2 Norm: 0.02238256111741066
2025-11-24 00:28:13.111 | INFO     | __main__:<module>:160 - Step30860, Loss: 3.579859733581543, Grad L2 Norm: 0.022474544122815132
2025-11-24 00:28:15.125 | INFO     | __main__:<module>:160 - Step30870, Loss: 3.646779775619507, Grad L2 Norm: 0.021041803061962128
2025-11-24 00:28:17.136 | INFO     | __main__:<module>:160 - Step30880, Loss: 3.50138521194458, Grad L2 Norm: 0.020993927493691444
2025-11-24 00:28:19.150 | INFO     | __main__:<module>:160 - Step30890, Loss: 3.5904335975646973, Grad L2 Norm: 0.021570676937699318
2025-11-24 00:28:21.166 | INFO     | __main__:<module>:160 - Step30900, Loss: 3.5520715713500977, Grad L2 Norm: 0.02104537934064865
2025-11-24 00:28:23.183 | INFO     | __main__:<module>:160 - Step30910, Loss: 3.4908785820007324, Grad L2 Norm: 0.02218719571828842
2025-11-24 00:28:25.202 | INFO     | __main__:<module>:160 - Step30920, Loss: 3.686846971511841, Grad L2 Norm: 0.023547673597931862
2025-11-24 00:28:27.216 | INFO     | __main__:<module>:160 - Step30930, Loss: 3.631711483001709, Grad L2 Norm: 0.022890174761414528
2025-11-24 00:28:29.227 | INFO     | __main__:<module>:160 - Step30940, Loss: 3.4628844261169434, Grad L2 Norm: 0.021895650774240494
2025-11-24 00:28:31.242 | INFO     | __main__:<module>:160 - Step30950, Loss: 3.669215679168701, Grad L2 Norm: 0.02398996613919735
2025-11-24 00:28:33.251 | INFO     | __main__:<module>:160 - Step30960, Loss: 3.5142054557800293, Grad L2 Norm: 0.0219823457300663
2025-11-24 00:28:35.265 | INFO     | __main__:<module>:160 - Step30970, Loss: 3.594266891479492, Grad L2 Norm: 0.02062569558620453
2025-11-24 00:28:37.278 | INFO     | __main__:<module>:160 - Step30980, Loss: 3.6645560264587402, Grad L2 Norm: 0.02295476384460926
2025-11-24 00:28:39.286 | INFO     | __main__:<module>:160 - Step30990, Loss: 3.640617847442627, Grad L2 Norm: 0.023630106821656227
2025-11-24 00:28:41.301 | INFO     | __main__:<module>:160 - Step31000, Loss: 3.549232244491577, Grad L2 Norm: 0.021069342270493507
2025-11-24 00:28:43.311 | INFO     | __main__:<module>:160 - Step31010, Loss: 3.583998680114746, Grad L2 Norm: 0.021976923570036888
2025-11-24 00:28:45.322 | INFO     | __main__:<module>:160 - Step31020, Loss: 3.637012243270874, Grad L2 Norm: 0.023819511756300926
2025-11-24 00:28:47.333 | INFO     | __main__:<module>:160 - Step31030, Loss: 3.621175765991211, Grad L2 Norm: 0.023849425837397575
2025-11-24 00:28:49.344 | INFO     | __main__:<module>:160 - Step31040, Loss: 3.6448657512664795, Grad L2 Norm: 0.02320238947868347
2025-11-24 00:28:51.359 | INFO     | __main__:<module>:160 - Step31050, Loss: 3.60856294631958, Grad L2 Norm: 0.02147529274225235
2025-11-24 00:28:53.373 | INFO     | __main__:<module>:160 - Step31060, Loss: 3.6264657974243164, Grad L2 Norm: 0.02408708445727825
2025-11-24 00:28:55.382 | INFO     | __main__:<module>:160 - Step31070, Loss: 3.6386892795562744, Grad L2 Norm: 0.022970236837863922
2025-11-24 00:28:57.397 | INFO     | __main__:<module>:160 - Step31080, Loss: 3.5276782512664795, Grad L2 Norm: 0.024401340633630753
2025-11-24 00:28:59.408 | INFO     | __main__:<module>:160 - Step31090, Loss: 3.4814634323120117, Grad L2 Norm: 0.022649861872196198
2025-11-24 00:29:01.421 | INFO     | __main__:<module>:160 - Step31100, Loss: 3.5289082527160645, Grad L2 Norm: 0.02193506620824337
2025-11-24 00:29:03.440 | INFO     | __main__:<module>:160 - Step31110, Loss: 3.55364990234375, Grad L2 Norm: 0.026161620393395424
2025-11-24 00:29:05.457 | INFO     | __main__:<module>:160 - Step31120, Loss: 3.513348340988159, Grad L2 Norm: 0.021471098065376282
2025-11-24 00:29:07.472 | INFO     | __main__:<module>:160 - Step31130, Loss: 3.565406084060669, Grad L2 Norm: 0.02206464670598507
2025-11-24 00:29:09.485 | INFO     | __main__:<module>:160 - Step31140, Loss: 3.6224112510681152, Grad L2 Norm: 0.02157306671142578
2025-11-24 00:29:11.498 | INFO     | __main__:<module>:160 - Step31150, Loss: 3.663851261138916, Grad L2 Norm: 0.024338793009519577
2025-11-24 00:29:13.513 | INFO     | __main__:<module>:160 - Step31160, Loss: 3.5898900032043457, Grad L2 Norm: 0.024326011538505554
2025-11-24 00:29:15.527 | INFO     | __main__:<module>:160 - Step31170, Loss: 3.5588035583496094, Grad L2 Norm: 0.02161571756005287
2025-11-24 00:29:17.538 | INFO     | __main__:<module>:160 - Step31180, Loss: 3.7576653957366943, Grad L2 Norm: 0.023669714108109474
2025-11-24 00:29:19.555 | INFO     | __main__:<module>:160 - Step31190, Loss: 3.5483877658843994, Grad L2 Norm: 0.023307429626584053
2025-11-24 00:29:21.571 | INFO     | __main__:<module>:160 - Step31200, Loss: 3.602871894836426, Grad L2 Norm: 0.022289050742983818
2025-11-24 00:29:21.572 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:29:22.856 | INFO     | __main__:<module>:181 - validation loss: 3.5678892493247987
2025-11-24 00:29:24.881 | INFO     | __main__:<module>:160 - Step31210, Loss: 3.493586540222168, Grad L2 Norm: 0.021448997780680656
2025-11-24 00:29:26.896 | INFO     | __main__:<module>:160 - Step31220, Loss: 3.5062875747680664, Grad L2 Norm: 0.02128469944000244
2025-11-24 00:29:28.907 | INFO     | __main__:<module>:160 - Step31230, Loss: 3.5389628410339355, Grad L2 Norm: 0.02122902311384678
2025-11-24 00:29:30.915 | INFO     | __main__:<module>:160 - Step31240, Loss: 3.563615322113037, Grad L2 Norm: 0.02355894073843956
2025-11-24 00:29:32.927 | INFO     | __main__:<module>:160 - Step31250, Loss: 3.7128701210021973, Grad L2 Norm: 0.023775940760970116
2025-11-24 00:29:34.940 | INFO     | __main__:<module>:160 - Step31260, Loss: 3.5859124660491943, Grad L2 Norm: 0.023772718384861946
2025-11-24 00:29:36.952 | INFO     | __main__:<module>:160 - Step31270, Loss: 3.589402198791504, Grad L2 Norm: 0.021597549319267273
2025-11-24 00:29:38.965 | INFO     | __main__:<module>:160 - Step31280, Loss: 3.597750186920166, Grad L2 Norm: 0.02208087220788002
2025-11-24 00:29:40.972 | INFO     | __main__:<module>:160 - Step31290, Loss: 3.639598846435547, Grad L2 Norm: 0.02380487322807312
2025-11-24 00:29:42.985 | INFO     | __main__:<module>:160 - Step31300, Loss: 3.572042465209961, Grad L2 Norm: 0.021208228543400764
2025-11-24 00:29:44.995 | INFO     | __main__:<module>:160 - Step31310, Loss: 3.718247413635254, Grad L2 Norm: 0.024168124422430992
2025-11-24 00:29:47.002 | INFO     | __main__:<module>:160 - Step31320, Loss: 3.5909600257873535, Grad L2 Norm: 0.02326212078332901
2025-11-24 00:29:49.008 | INFO     | __main__:<module>:160 - Step31330, Loss: 3.570948362350464, Grad L2 Norm: 0.021569164469838142
2025-11-24 00:29:51.016 | INFO     | __main__:<module>:160 - Step31340, Loss: 3.496180295944214, Grad L2 Norm: 0.024202216416597366
2025-11-24 00:29:53.021 | INFO     | __main__:<module>:160 - Step31350, Loss: 3.5004377365112305, Grad L2 Norm: 0.021913250908255577
2025-11-24 00:29:55.024 | INFO     | __main__:<module>:160 - Step31360, Loss: 3.6026272773742676, Grad L2 Norm: 0.022776169702410698
2025-11-24 00:29:57.034 | INFO     | __main__:<module>:160 - Step31370, Loss: 3.5472021102905273, Grad L2 Norm: 0.021612701937556267
2025-11-24 00:29:59.042 | INFO     | __main__:<module>:160 - Step31380, Loss: 3.4214415550231934, Grad L2 Norm: 0.022462494671344757
2025-11-24 00:30:01.051 | INFO     | __main__:<module>:160 - Step31390, Loss: 3.650934934616089, Grad L2 Norm: 0.02364037185907364
2025-11-24 00:30:03.057 | INFO     | __main__:<module>:160 - Step31400, Loss: 3.449556589126587, Grad L2 Norm: 0.022564979270100594
2025-11-24 00:30:05.064 | INFO     | __main__:<module>:160 - Step31410, Loss: 3.596829414367676, Grad L2 Norm: 0.021281816065311432
2025-11-24 00:30:07.073 | INFO     | __main__:<module>:160 - Step31420, Loss: 3.57069730758667, Grad L2 Norm: 0.02240699715912342
2025-11-24 00:30:09.080 | INFO     | __main__:<module>:160 - Step31430, Loss: 3.642350912094116, Grad L2 Norm: 0.02333778701722622
2025-11-24 00:30:11.090 | INFO     | __main__:<module>:160 - Step31440, Loss: 3.528146982192993, Grad L2 Norm: 0.024310141801834106
2025-11-24 00:30:13.096 | INFO     | __main__:<module>:160 - Step31450, Loss: 3.6624596118927, Grad L2 Norm: 0.02406187728047371
2025-11-24 00:30:15.098 | INFO     | __main__:<module>:160 - Step31460, Loss: 3.637885093688965, Grad L2 Norm: 0.023111287504434586
2025-11-24 00:30:17.102 | INFO     | __main__:<module>:160 - Step31470, Loss: 3.550583839416504, Grad L2 Norm: 0.020904961973428726
2025-11-24 00:30:19.110 | INFO     | __main__:<module>:160 - Step31480, Loss: 3.551572322845459, Grad L2 Norm: 0.02170534059405327
2025-11-24 00:30:21.117 | INFO     | __main__:<module>:160 - Step31490, Loss: 3.561344861984253, Grad L2 Norm: 0.021233728155493736
2025-11-24 00:30:23.126 | INFO     | __main__:<module>:160 - Step31500, Loss: 3.488983392715454, Grad L2 Norm: 0.022609926760196686
2025-11-24 00:30:25.130 | INFO     | __main__:<module>:160 - Step31510, Loss: 3.60513973236084, Grad L2 Norm: 0.023127226158976555
2025-11-24 00:30:27.132 | INFO     | __main__:<module>:160 - Step31520, Loss: 3.5878796577453613, Grad L2 Norm: 0.021644968539476395
2025-11-24 00:30:29.144 | INFO     | __main__:<module>:160 - Step31530, Loss: 3.5043206214904785, Grad L2 Norm: 0.022913295775651932
2025-11-24 00:30:31.154 | INFO     | __main__:<module>:160 - Step31540, Loss: 3.5504989624023438, Grad L2 Norm: 0.023556634783744812
2025-11-24 00:30:33.167 | INFO     | __main__:<module>:160 - Step31550, Loss: 3.636199712753296, Grad L2 Norm: 0.023140622302889824
2025-11-24 00:30:35.178 | INFO     | __main__:<module>:160 - Step31560, Loss: 3.5911855697631836, Grad L2 Norm: 0.023192614316940308
2025-11-24 00:30:37.189 | INFO     | __main__:<module>:160 - Step31570, Loss: 3.651773691177368, Grad L2 Norm: 0.02196865901350975
2025-11-24 00:30:39.201 | INFO     | __main__:<module>:160 - Step31580, Loss: 3.472687005996704, Grad L2 Norm: 0.02212563529610634
2025-11-24 00:30:41.211 | INFO     | __main__:<module>:160 - Step31590, Loss: 3.519357919692993, Grad L2 Norm: 0.021644748747348785
2025-11-24 00:30:43.225 | INFO     | __main__:<module>:160 - Step31600, Loss: 3.5769152641296387, Grad L2 Norm: 0.02292226068675518
2025-11-24 00:30:43.226 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:30:44.508 | INFO     | __main__:<module>:181 - validation loss: 3.572148048877716
2025-11-24 00:30:46.529 | INFO     | __main__:<module>:160 - Step31610, Loss: 3.725985527038574, Grad L2 Norm: 0.023253368213772774
2025-11-24 00:30:48.544 | INFO     | __main__:<module>:160 - Step31620, Loss: 3.628394603729248, Grad L2 Norm: 0.021068129688501358
2025-11-24 00:30:50.550 | INFO     | __main__:<module>:160 - Step31630, Loss: 3.5708937644958496, Grad L2 Norm: 0.02317955531179905
2025-11-24 00:30:52.562 | INFO     | __main__:<module>:160 - Step31640, Loss: 3.4453516006469727, Grad L2 Norm: 0.022675713524222374
2025-11-24 00:30:54.572 | INFO     | __main__:<module>:160 - Step31650, Loss: 3.4931507110595703, Grad L2 Norm: 0.02280420809984207
2025-11-24 00:30:56.583 | INFO     | __main__:<module>:160 - Step31660, Loss: 3.613006114959717, Grad L2 Norm: 0.02081996761262417
2025-11-24 00:30:58.594 | INFO     | __main__:<module>:160 - Step31670, Loss: 3.497922897338867, Grad L2 Norm: 0.02276596799492836
2025-11-24 00:31:00.606 | INFO     | __main__:<module>:160 - Step31680, Loss: 3.61378812789917, Grad L2 Norm: 0.021770108491182327
2025-11-24 00:31:02.619 | INFO     | __main__:<module>:160 - Step31690, Loss: 3.417440176010132, Grad L2 Norm: 0.022540032863616943
2025-11-24 00:31:04.634 | INFO     | __main__:<module>:160 - Step31700, Loss: 3.537719249725342, Grad L2 Norm: 0.022117530927062035
2025-11-24 00:31:06.641 | INFO     | __main__:<module>:160 - Step31710, Loss: 3.4852914810180664, Grad L2 Norm: 0.022322162985801697
2025-11-24 00:31:08.654 | INFO     | __main__:<module>:160 - Step31720, Loss: 3.51921010017395, Grad L2 Norm: 0.02227855660021305
2025-11-24 00:31:10.666 | INFO     | __main__:<module>:160 - Step31730, Loss: 3.6088905334472656, Grad L2 Norm: 0.022118842229247093
2025-11-24 00:31:12.676 | INFO     | __main__:<module>:160 - Step31740, Loss: 3.662693500518799, Grad L2 Norm: 0.022578122094273567
2025-11-24 00:31:14.680 | INFO     | __main__:<module>:160 - Step31750, Loss: 3.5554721355438232, Grad L2 Norm: 0.02193339727818966
2025-11-24 00:31:16.689 | INFO     | __main__:<module>:160 - Step31760, Loss: 3.5360517501831055, Grad L2 Norm: 0.022266875952482224
2025-11-24 00:31:18.691 | INFO     | __main__:<module>:160 - Step31770, Loss: 3.4086546897888184, Grad L2 Norm: 0.021372051909565926
2025-11-24 00:31:20.694 | INFO     | __main__:<module>:160 - Step31780, Loss: 3.5841965675354004, Grad L2 Norm: 0.027091922238469124
2025-11-24 00:31:22.697 | INFO     | __main__:<module>:160 - Step31790, Loss: 3.646509885787964, Grad L2 Norm: 0.025651467964053154
2025-11-24 00:31:24.708 | INFO     | __main__:<module>:160 - Step31800, Loss: 3.489081859588623, Grad L2 Norm: 0.02351025864481926
2025-11-24 00:31:26.716 | INFO     | __main__:<module>:160 - Step31810, Loss: 3.4936342239379883, Grad L2 Norm: 0.021583644673228264
2025-11-24 00:31:28.726 | INFO     | __main__:<module>:160 - Step31820, Loss: 3.574671506881714, Grad L2 Norm: 0.023267891258001328
2025-11-24 00:31:30.736 | INFO     | __main__:<module>:160 - Step31830, Loss: 3.5558013916015625, Grad L2 Norm: 0.023502811789512634
2025-11-24 00:31:32.749 | INFO     | __main__:<module>:160 - Step31840, Loss: 3.416907548904419, Grad L2 Norm: 0.023588191717863083
2025-11-24 00:31:34.762 | INFO     | __main__:<module>:160 - Step31850, Loss: 3.5176877975463867, Grad L2 Norm: 0.021314408630132675
2025-11-24 00:31:36.774 | INFO     | __main__:<module>:160 - Step31860, Loss: 3.6135520935058594, Grad L2 Norm: 0.02301236242055893
2025-11-24 00:31:38.787 | INFO     | __main__:<module>:160 - Step31870, Loss: 3.609638214111328, Grad L2 Norm: 0.02289734035730362
2025-11-24 00:31:40.795 | INFO     | __main__:<module>:160 - Step31880, Loss: 3.638904571533203, Grad L2 Norm: 0.02171294204890728
2025-11-24 00:31:42.807 | INFO     | __main__:<module>:160 - Step31890, Loss: 3.5160422325134277, Grad L2 Norm: 0.022114835679531097
2025-11-24 00:31:44.813 | INFO     | __main__:<module>:160 - Step31900, Loss: 3.5042648315429688, Grad L2 Norm: 0.022827276960015297
2025-11-24 00:31:46.825 | INFO     | __main__:<module>:160 - Step31910, Loss: 3.540389060974121, Grad L2 Norm: 0.02202228084206581
2025-11-24 00:31:48.831 | INFO     | __main__:<module>:160 - Step31920, Loss: 3.61603045463562, Grad L2 Norm: 0.02241595834493637
2025-11-24 00:31:50.840 | INFO     | __main__:<module>:160 - Step31930, Loss: 3.5618233680725098, Grad L2 Norm: 0.022233085706830025
2025-11-24 00:31:52.843 | INFO     | __main__:<module>:160 - Step31940, Loss: 3.6233720779418945, Grad L2 Norm: 0.023122277110815048
2025-11-24 00:31:54.847 | INFO     | __main__:<module>:160 - Step31950, Loss: 3.5469040870666504, Grad L2 Norm: 0.02115633524954319
2025-11-24 00:31:56.856 | INFO     | __main__:<module>:160 - Step31960, Loss: 3.62044095993042, Grad L2 Norm: 0.022196831181645393
2025-11-24 00:31:58.862 | INFO     | __main__:<module>:160 - Step31970, Loss: 3.5008556842803955, Grad L2 Norm: 0.021069113165140152
2025-11-24 00:32:00.867 | INFO     | __main__:<module>:160 - Step31980, Loss: 3.7411816120147705, Grad L2 Norm: 0.0234671737998724
2025-11-24 00:32:02.875 | INFO     | __main__:<module>:160 - Step31990, Loss: 3.647663116455078, Grad L2 Norm: 0.02195891924202442
2025-11-24 00:32:04.880 | INFO     | __main__:<module>:160 - Step32000, Loss: 3.5897216796875, Grad L2 Norm: 0.021627886220812798
2025-11-24 00:32:04.881 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:32:06.155 | INFO     | __main__:<module>:181 - validation loss: 3.573223555088043
2025-11-24 00:32:06.156 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_32000.pt
2025-11-24 00:32:07.835 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 00:32:09.812 | INFO     | __main__:<module>:160 - Step32010, Loss: 3.449619770050049, Grad L2 Norm: 0.021535629406571388
2025-11-24 00:32:11.813 | INFO     | __main__:<module>:160 - Step32020, Loss: 3.5681910514831543, Grad L2 Norm: 0.02282201312482357
2025-11-24 00:32:13.813 | INFO     | __main__:<module>:160 - Step32030, Loss: 3.6842997074127197, Grad L2 Norm: 0.023256614804267883
2025-11-24 00:32:15.812 | INFO     | __main__:<module>:160 - Step32040, Loss: 3.565387725830078, Grad L2 Norm: 0.02161136455833912
2025-11-24 00:32:17.814 | INFO     | __main__:<module>:160 - Step32050, Loss: 3.5422117710113525, Grad L2 Norm: 0.021012311801314354
2025-11-24 00:32:19.813 | INFO     | __main__:<module>:160 - Step32060, Loss: 3.567808151245117, Grad L2 Norm: 0.021342186257243156
2025-11-24 00:32:21.812 | INFO     | __main__:<module>:160 - Step32070, Loss: 3.61985182762146, Grad L2 Norm: 0.02268981747329235
2025-11-24 00:32:23.811 | INFO     | __main__:<module>:160 - Step32080, Loss: 3.445401668548584, Grad L2 Norm: 0.022471679374575615
2025-11-24 00:32:25.810 | INFO     | __main__:<module>:160 - Step32090, Loss: 3.653372287750244, Grad L2 Norm: 0.02256220206618309
2025-11-24 00:32:27.810 | INFO     | __main__:<module>:160 - Step32100, Loss: 3.603196620941162, Grad L2 Norm: 0.0210854671895504
2025-11-24 00:32:29.814 | INFO     | __main__:<module>:160 - Step32110, Loss: 3.534834623336792, Grad L2 Norm: 0.022221790626645088
2025-11-24 00:32:31.817 | INFO     | __main__:<module>:160 - Step32120, Loss: 3.4244070053100586, Grad L2 Norm: 0.022129420191049576
2025-11-24 00:32:33.818 | INFO     | __main__:<module>:160 - Step32130, Loss: 3.552846908569336, Grad L2 Norm: 0.02254856377840042
2025-11-24 00:32:35.824 | INFO     | __main__:<module>:160 - Step32140, Loss: 3.620004653930664, Grad L2 Norm: 0.021754832938313484
2025-11-24 00:32:37.827 | INFO     | __main__:<module>:160 - Step32150, Loss: 3.3765060901641846, Grad L2 Norm: 0.02197282761335373
2025-11-24 00:32:39.826 | INFO     | __main__:<module>:160 - Step32160, Loss: 3.6058757305145264, Grad L2 Norm: 0.021434875205159187
2025-11-24 00:32:41.828 | INFO     | __main__:<module>:160 - Step32170, Loss: 3.721813678741455, Grad L2 Norm: 0.023793725296854973
2025-11-24 00:32:43.828 | INFO     | __main__:<module>:160 - Step32180, Loss: 3.5726919174194336, Grad L2 Norm: 0.023410677909851074
2025-11-24 00:32:45.830 | INFO     | __main__:<module>:160 - Step32190, Loss: 3.379530906677246, Grad L2 Norm: 0.02051743119955063
2025-11-24 00:32:47.829 | INFO     | __main__:<module>:160 - Step32200, Loss: 3.613105297088623, Grad L2 Norm: 0.02108439803123474
2025-11-24 00:32:49.831 | INFO     | __main__:<module>:160 - Step32210, Loss: 3.622150421142578, Grad L2 Norm: 0.020835082978010178
2025-11-24 00:32:51.831 | INFO     | __main__:<module>:160 - Step32220, Loss: 3.6781129837036133, Grad L2 Norm: 0.022989435121417046
2025-11-24 00:32:53.836 | INFO     | __main__:<module>:160 - Step32230, Loss: 3.5464413166046143, Grad L2 Norm: 0.02267320826649666
2025-11-24 00:32:55.842 | INFO     | __main__:<module>:160 - Step32240, Loss: 3.4930667877197266, Grad L2 Norm: 0.021933309733867645
2025-11-24 00:32:57.845 | INFO     | __main__:<module>:160 - Step32250, Loss: 3.7647171020507812, Grad L2 Norm: 0.022927993908524513
2025-11-24 00:32:59.848 | INFO     | __main__:<module>:160 - Step32260, Loss: 3.5529472827911377, Grad L2 Norm: 0.022273901849985123
2025-11-24 00:33:01.854 | INFO     | __main__:<module>:160 - Step32270, Loss: 3.619720935821533, Grad L2 Norm: 0.024032894521951675
2025-11-24 00:33:03.863 | INFO     | __main__:<module>:160 - Step32280, Loss: 3.5624687671661377, Grad L2 Norm: 0.02112986519932747
2025-11-24 00:33:05.866 | INFO     | __main__:<module>:160 - Step32290, Loss: 3.5943610668182373, Grad L2 Norm: 0.023356273770332336
2025-11-24 00:33:07.870 | INFO     | __main__:<module>:160 - Step32300, Loss: 3.5587973594665527, Grad L2 Norm: 0.021524833515286446
2025-11-24 00:33:09.877 | INFO     | __main__:<module>:160 - Step32310, Loss: 3.506441831588745, Grad L2 Norm: 0.021273469552397728
2025-11-24 00:33:11.882 | INFO     | __main__:<module>:160 - Step32320, Loss: 3.71163010597229, Grad L2 Norm: 0.023078909143805504
2025-11-24 00:33:13.890 | INFO     | __main__:<module>:160 - Step32330, Loss: 3.4524104595184326, Grad L2 Norm: 0.02301742136478424
2025-11-24 00:33:15.899 | INFO     | __main__:<module>:160 - Step32340, Loss: 3.524947166442871, Grad L2 Norm: 0.02209318056702614
2025-11-24 00:33:17.903 | INFO     | __main__:<module>:160 - Step32350, Loss: 3.684568166732788, Grad L2 Norm: 0.0213292445987463
2025-11-24 00:33:19.913 | INFO     | __main__:<module>:160 - Step32360, Loss: 3.524501323699951, Grad L2 Norm: 0.02102394960820675
2025-11-24 00:33:21.919 | INFO     | __main__:<module>:160 - Step32370, Loss: 3.666306972503662, Grad L2 Norm: 0.025773227214813232
2025-11-24 00:33:23.923 | INFO     | __main__:<module>:160 - Step32380, Loss: 3.6585216522216797, Grad L2 Norm: 0.022871553897857666
2025-11-24 00:33:25.933 | INFO     | __main__:<module>:160 - Step32390, Loss: 3.614899158477783, Grad L2 Norm: 0.02208062820136547
2025-11-24 00:33:27.937 | INFO     | __main__:<module>:160 - Step32400, Loss: 3.5753841400146484, Grad L2 Norm: 0.02107877843081951
2025-11-24 00:33:27.938 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:33:29.214 | INFO     | __main__:<module>:181 - validation loss: 3.5256993055343626
2025-11-24 00:33:31.230 | INFO     | __main__:<module>:160 - Step32410, Loss: 3.563724994659424, Grad L2 Norm: 0.022054389119148254
2025-11-24 00:33:33.235 | INFO     | __main__:<module>:160 - Step32420, Loss: 3.5846128463745117, Grad L2 Norm: 0.027318889275193214
2025-11-24 00:33:35.238 | INFO     | __main__:<module>:160 - Step32430, Loss: 3.553184747695923, Grad L2 Norm: 0.022143622860312462
2025-11-24 00:33:37.239 | INFO     | __main__:<module>:160 - Step32440, Loss: 3.6197476387023926, Grad L2 Norm: 0.023866869509220123
2025-11-24 00:33:39.241 | INFO     | __main__:<module>:160 - Step32450, Loss: 3.5792036056518555, Grad L2 Norm: 0.021858684718608856
2025-11-24 00:33:41.247 | INFO     | __main__:<module>:160 - Step32460, Loss: 3.5783839225769043, Grad L2 Norm: 0.021134212613105774
2025-11-24 00:33:43.251 | INFO     | __main__:<module>:160 - Step32470, Loss: 3.502229690551758, Grad L2 Norm: 0.021551726385951042
2025-11-24 00:33:45.253 | INFO     | __main__:<module>:160 - Step32480, Loss: 3.6772422790527344, Grad L2 Norm: 0.02232847549021244
2025-11-24 00:33:47.256 | INFO     | __main__:<module>:160 - Step32490, Loss: 3.5746617317199707, Grad L2 Norm: 0.022099776193499565
2025-11-24 00:33:49.266 | INFO     | __main__:<module>:160 - Step32500, Loss: 3.592411994934082, Grad L2 Norm: 0.022594811394810677
2025-11-24 00:33:51.277 | INFO     | __main__:<module>:160 - Step32510, Loss: 3.635099411010742, Grad L2 Norm: 0.023536067456007004
2025-11-24 00:33:53.292 | INFO     | __main__:<module>:160 - Step32520, Loss: 3.3933894634246826, Grad L2 Norm: 0.021485358476638794
2025-11-24 00:33:55.310 | INFO     | __main__:<module>:160 - Step32530, Loss: 3.591287136077881, Grad L2 Norm: 0.020633157342672348
2025-11-24 00:33:57.324 | INFO     | __main__:<module>:160 - Step32540, Loss: 3.6054577827453613, Grad L2 Norm: 0.022034386172890663
2025-11-24 00:33:59.330 | INFO     | __main__:<module>:160 - Step32550, Loss: 3.4899163246154785, Grad L2 Norm: 0.020498309284448624
2025-11-24 00:34:01.339 | INFO     | __main__:<module>:160 - Step32560, Loss: 3.551307201385498, Grad L2 Norm: 0.022499216720461845
2025-11-24 00:34:03.348 | INFO     | __main__:<module>:160 - Step32570, Loss: 3.5238990783691406, Grad L2 Norm: 0.020889561623334885
2025-11-24 00:34:05.362 | INFO     | __main__:<module>:160 - Step32580, Loss: 3.6510825157165527, Grad L2 Norm: 0.020515792071819305
2025-11-24 00:34:07.379 | INFO     | __main__:<module>:160 - Step32590, Loss: 3.496239185333252, Grad L2 Norm: 0.02059461548924446
2025-11-24 00:34:09.393 | INFO     | __main__:<module>:160 - Step32600, Loss: 3.7087574005126953, Grad L2 Norm: 0.023356784135103226
2025-11-24 00:34:11.403 | INFO     | __main__:<module>:160 - Step32610, Loss: 3.6389901638031006, Grad L2 Norm: 0.02273343876004219
2025-11-24 00:34:13.416 | INFO     | __main__:<module>:160 - Step32620, Loss: 3.6149892807006836, Grad L2 Norm: 0.022037707269191742
2025-11-24 00:34:15.428 | INFO     | __main__:<module>:160 - Step32630, Loss: 3.548348903656006, Grad L2 Norm: 0.021315298974514008
2025-11-24 00:34:17.446 | INFO     | __main__:<module>:160 - Step32640, Loss: 3.547593116760254, Grad L2 Norm: 0.022305689752101898
2025-11-24 00:34:19.465 | INFO     | __main__:<module>:160 - Step32650, Loss: 3.746913433074951, Grad L2 Norm: 0.022113310173153877
2025-11-24 00:34:21.486 | INFO     | __main__:<module>:160 - Step32660, Loss: 3.4922828674316406, Grad L2 Norm: 0.020575309172272682
2025-11-24 00:34:23.505 | INFO     | __main__:<module>:160 - Step32670, Loss: 3.620171546936035, Grad L2 Norm: 0.022185444831848145
2025-11-24 00:34:25.527 | INFO     | __main__:<module>:160 - Step32680, Loss: 3.5592312812805176, Grad L2 Norm: 0.021120522171258926
2025-11-24 00:34:27.545 | INFO     | __main__:<module>:160 - Step32690, Loss: 3.605034589767456, Grad L2 Norm: 0.023343797773122787
2025-11-24 00:34:29.565 | INFO     | __main__:<module>:160 - Step32700, Loss: 3.619978904724121, Grad L2 Norm: 0.021559759974479675
2025-11-24 00:34:31.584 | INFO     | __main__:<module>:160 - Step32710, Loss: 3.483576536178589, Grad L2 Norm: 0.021754849702119827
2025-11-24 00:34:33.610 | INFO     | __main__:<module>:160 - Step32720, Loss: 3.4770495891571045, Grad L2 Norm: 0.020508816465735435
2025-11-24 00:34:35.625 | INFO     | __main__:<module>:160 - Step32730, Loss: 3.689788818359375, Grad L2 Norm: 0.023135149851441383
2025-11-24 00:34:37.639 | INFO     | __main__:<module>:160 - Step32740, Loss: 3.4879310131073, Grad L2 Norm: 0.022591669112443924
2025-11-24 00:34:39.658 | INFO     | __main__:<module>:160 - Step32750, Loss: 3.6298820972442627, Grad L2 Norm: 0.02223491668701172
2025-11-24 00:34:41.680 | INFO     | __main__:<module>:160 - Step32760, Loss: 3.5904979705810547, Grad L2 Norm: 0.022855864837765694
2025-11-24 00:34:43.700 | INFO     | __main__:<module>:160 - Step32770, Loss: 3.558300018310547, Grad L2 Norm: 0.023904312402009964
2025-11-24 00:34:45.716 | INFO     | __main__:<module>:160 - Step32780, Loss: 3.5049924850463867, Grad L2 Norm: 0.023152729496359825
2025-11-24 00:34:47.734 | INFO     | __main__:<module>:160 - Step32790, Loss: 3.7880802154541016, Grad L2 Norm: 0.024864764884114265
2025-11-24 00:34:49.755 | INFO     | __main__:<module>:160 - Step32800, Loss: 3.485623836517334, Grad L2 Norm: 0.021779682487249374
2025-11-24 00:34:49.756 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:34:51.040 | INFO     | __main__:<module>:181 - validation loss: 3.5717367053031923
2025-11-24 00:34:53.070 | INFO     | __main__:<module>:160 - Step32810, Loss: 3.678032398223877, Grad L2 Norm: 0.02306920848786831
2025-11-24 00:34:55.095 | INFO     | __main__:<module>:160 - Step32820, Loss: 3.551786422729492, Grad L2 Norm: 0.02329881116747856
2025-11-24 00:34:57.121 | INFO     | __main__:<module>:160 - Step32830, Loss: 3.3898136615753174, Grad L2 Norm: 0.023754410445690155
2025-11-24 00:34:59.145 | INFO     | __main__:<module>:160 - Step32840, Loss: 3.6144394874572754, Grad L2 Norm: 0.021785272285342216
2025-11-24 00:35:01.166 | INFO     | __main__:<module>:160 - Step32850, Loss: 3.49802303314209, Grad L2 Norm: 0.020465901121497154
2025-11-24 00:35:03.184 | INFO     | __main__:<module>:160 - Step32860, Loss: 3.662015914916992, Grad L2 Norm: 0.024280864745378494
2025-11-24 00:35:05.203 | INFO     | __main__:<module>:160 - Step32870, Loss: 3.6391706466674805, Grad L2 Norm: 0.022118698805570602
2025-11-24 00:35:07.224 | INFO     | __main__:<module>:160 - Step32880, Loss: 3.615379810333252, Grad L2 Norm: 0.021997908130288124
2025-11-24 00:35:09.246 | INFO     | __main__:<module>:160 - Step32890, Loss: 3.7587506771087646, Grad L2 Norm: 0.02451135776937008
2025-11-24 00:35:11.275 | INFO     | __main__:<module>:160 - Step32900, Loss: 3.6327595710754395, Grad L2 Norm: 0.02189670503139496
2025-11-24 00:35:13.298 | INFO     | __main__:<module>:160 - Step32910, Loss: 3.635810375213623, Grad L2 Norm: 0.022031784057617188
2025-11-24 00:35:15.318 | INFO     | __main__:<module>:160 - Step32920, Loss: 3.557996988296509, Grad L2 Norm: 0.023686887696385384
2025-11-24 00:35:17.342 | INFO     | __main__:<module>:160 - Step32930, Loss: 3.5336899757385254, Grad L2 Norm: 0.02274244837462902
2025-11-24 00:35:19.366 | INFO     | __main__:<module>:160 - Step32940, Loss: 3.614283561706543, Grad L2 Norm: 0.021967874839901924
2025-11-24 00:35:21.388 | INFO     | __main__:<module>:160 - Step32950, Loss: 3.5304975509643555, Grad L2 Norm: 0.022510141134262085
2025-11-24 00:35:23.414 | INFO     | __main__:<module>:160 - Step32960, Loss: 3.581442356109619, Grad L2 Norm: 0.021831553429365158
2025-11-24 00:35:25.439 | INFO     | __main__:<module>:160 - Step32970, Loss: 3.5437216758728027, Grad L2 Norm: 0.021954912692308426
2025-11-24 00:35:27.465 | INFO     | __main__:<module>:160 - Step32980, Loss: 3.561041831970215, Grad L2 Norm: 0.0227519478648901
2025-11-24 00:35:29.487 | INFO     | __main__:<module>:160 - Step32990, Loss: 3.7415976524353027, Grad L2 Norm: 0.021675070747733116
2025-11-24 00:35:31.510 | INFO     | __main__:<module>:160 - Step33000, Loss: 3.541750431060791, Grad L2 Norm: 0.022663118317723274
2025-11-24 00:35:33.535 | INFO     | __main__:<module>:160 - Step33010, Loss: 3.617568016052246, Grad L2 Norm: 0.022560730576515198
2025-11-24 00:35:35.558 | INFO     | __main__:<module>:160 - Step33020, Loss: 3.460385799407959, Grad L2 Norm: 0.022760728374123573
2025-11-24 00:35:37.582 | INFO     | __main__:<module>:160 - Step33030, Loss: 3.602158546447754, Grad L2 Norm: 0.020214589312672615
2025-11-24 00:35:39.601 | INFO     | __main__:<module>:160 - Step33040, Loss: 3.5295984745025635, Grad L2 Norm: 0.023402974009513855
2025-11-24 00:35:41.619 | INFO     | __main__:<module>:160 - Step33050, Loss: 3.5343332290649414, Grad L2 Norm: 0.021882930770516396
2025-11-24 00:35:43.641 | INFO     | __main__:<module>:160 - Step33060, Loss: 3.499596118927002, Grad L2 Norm: 0.023290466517210007
2025-11-24 00:35:45.666 | INFO     | __main__:<module>:160 - Step33070, Loss: 3.4570248126983643, Grad L2 Norm: 0.02110646478831768
2025-11-24 00:35:47.687 | INFO     | __main__:<module>:160 - Step33080, Loss: 3.4977645874023438, Grad L2 Norm: 0.021395832300186157
2025-11-24 00:35:49.697 | INFO     | __main__:<module>:160 - Step33090, Loss: 3.6473660469055176, Grad L2 Norm: 0.02180570177733898
2025-11-24 00:35:51.711 | INFO     | __main__:<module>:160 - Step33100, Loss: 3.51949143409729, Grad L2 Norm: 0.02262234315276146
2025-11-24 00:35:53.727 | INFO     | __main__:<module>:160 - Step33110, Loss: 3.6599984169006348, Grad L2 Norm: 0.025675244629383087
2025-11-24 00:35:55.745 | INFO     | __main__:<module>:160 - Step33120, Loss: 3.5271527767181396, Grad L2 Norm: 0.02236480452120304
2025-11-24 00:35:57.765 | INFO     | __main__:<module>:160 - Step33130, Loss: 3.675305128097534, Grad L2 Norm: 0.02226925455033779
2025-11-24 00:35:59.779 | INFO     | __main__:<module>:160 - Step33140, Loss: 3.5945401191711426, Grad L2 Norm: 0.022558668628335
2025-11-24 00:36:01.794 | INFO     | __main__:<module>:160 - Step33150, Loss: 3.602296829223633, Grad L2 Norm: 0.022423742339015007
2025-11-24 00:36:03.812 | INFO     | __main__:<module>:160 - Step33160, Loss: 3.389580011367798, Grad L2 Norm: 0.020888321101665497
2025-11-24 00:36:05.832 | INFO     | __main__:<module>:160 - Step33170, Loss: 3.5527503490448, Grad L2 Norm: 0.021222827956080437
2025-11-24 00:36:07.851 | INFO     | __main__:<module>:160 - Step33180, Loss: 3.593651294708252, Grad L2 Norm: 0.022981150075793266
2025-11-24 00:36:09.869 | INFO     | __main__:<module>:160 - Step33190, Loss: 3.4983062744140625, Grad L2 Norm: 0.02147245593369007
2025-11-24 00:36:11.882 | INFO     | __main__:<module>:160 - Step33200, Loss: 3.5689620971679688, Grad L2 Norm: 0.02323370985686779
2025-11-24 00:36:11.883 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:36:13.165 | INFO     | __main__:<module>:181 - validation loss: 3.572605812549591
2025-11-24 00:36:15.185 | INFO     | __main__:<module>:160 - Step33210, Loss: 3.739867687225342, Grad L2 Norm: 0.02276020310819149
2025-11-24 00:36:17.200 | INFO     | __main__:<module>:160 - Step33220, Loss: 3.623577117919922, Grad L2 Norm: 0.022058086469769478
2025-11-24 00:36:19.218 | INFO     | __main__:<module>:160 - Step33230, Loss: 3.708627700805664, Grad L2 Norm: 0.022918138653039932
2025-11-24 00:36:21.237 | INFO     | __main__:<module>:160 - Step33240, Loss: 3.5407705307006836, Grad L2 Norm: 0.02193620055913925
2025-11-24 00:36:23.248 | INFO     | __main__:<module>:160 - Step33250, Loss: 3.5774946212768555, Grad L2 Norm: 0.021136822178959846
2025-11-24 00:36:25.264 | INFO     | __main__:<module>:160 - Step33260, Loss: 3.572657585144043, Grad L2 Norm: 0.02235463820397854
2025-11-24 00:36:27.282 | INFO     | __main__:<module>:160 - Step33270, Loss: 3.549077272415161, Grad L2 Norm: 0.023889558389782906
2025-11-24 00:36:29.303 | INFO     | __main__:<module>:160 - Step33280, Loss: 3.668182373046875, Grad L2 Norm: 0.02226644568145275
2025-11-24 00:36:31.315 | INFO     | __main__:<module>:160 - Step33290, Loss: 3.6130783557891846, Grad L2 Norm: 0.02277032658457756
2025-11-24 00:36:33.331 | INFO     | __main__:<module>:160 - Step33300, Loss: 3.471381187438965, Grad L2 Norm: 0.02104632928967476
2025-11-24 00:36:35.342 | INFO     | __main__:<module>:160 - Step33310, Loss: 3.573481798171997, Grad L2 Norm: 0.02177521586418152
2025-11-24 00:36:37.361 | INFO     | __main__:<module>:160 - Step33320, Loss: 3.7034387588500977, Grad L2 Norm: 0.022538909688591957
2025-11-24 00:36:39.378 | INFO     | __main__:<module>:160 - Step33330, Loss: 3.572349786758423, Grad L2 Norm: 0.022531941533088684
2025-11-24 00:36:41.393 | INFO     | __main__:<module>:160 - Step33340, Loss: 3.5118517875671387, Grad L2 Norm: 0.022391078993678093
2025-11-24 00:36:43.413 | INFO     | __main__:<module>:160 - Step33350, Loss: 3.585474967956543, Grad L2 Norm: 0.02174096181988716
2025-11-24 00:36:45.432 | INFO     | __main__:<module>:160 - Step33360, Loss: 3.5080442428588867, Grad L2 Norm: 0.02109331265091896
2025-11-24 00:36:47.451 | INFO     | __main__:<module>:160 - Step33370, Loss: 3.5966298580169678, Grad L2 Norm: 0.02152196876704693
2025-11-24 00:36:49.471 | INFO     | __main__:<module>:160 - Step33380, Loss: 3.552306652069092, Grad L2 Norm: 0.021963851526379585
2025-11-24 00:36:51.482 | INFO     | __main__:<module>:160 - Step33390, Loss: 3.6106925010681152, Grad L2 Norm: 0.024203302338719368
2025-11-24 00:36:53.498 | INFO     | __main__:<module>:160 - Step33400, Loss: 3.563579797744751, Grad L2 Norm: 0.0217174980789423
2025-11-24 00:36:55.529 | INFO     | __main__:<module>:160 - Step33410, Loss: 3.6108736991882324, Grad L2 Norm: 0.023479806259274483
2025-11-24 00:36:57.551 | INFO     | __main__:<module>:160 - Step33420, Loss: 3.5694775581359863, Grad L2 Norm: 0.02363220416009426
2025-11-24 00:36:59.577 | INFO     | __main__:<module>:160 - Step33430, Loss: 3.6051807403564453, Grad L2 Norm: 0.024196887388825417
2025-11-24 00:37:01.599 | INFO     | __main__:<module>:160 - Step33440, Loss: 3.6822102069854736, Grad L2 Norm: 0.022578172385692596
2025-11-24 00:37:03.626 | INFO     | __main__:<module>:160 - Step33450, Loss: 3.6371304988861084, Grad L2 Norm: 0.021514587104320526
2025-11-24 00:37:05.653 | INFO     | __main__:<module>:160 - Step33460, Loss: 3.5342798233032227, Grad L2 Norm: 0.021675385534763336
2025-11-24 00:37:07.685 | INFO     | __main__:<module>:160 - Step33470, Loss: 3.5746564865112305, Grad L2 Norm: 0.022870127111673355
2025-11-24 00:37:09.716 | INFO     | __main__:<module>:160 - Step33480, Loss: 3.5072784423828125, Grad L2 Norm: 0.022909153252840042
2025-11-24 00:37:11.748 | INFO     | __main__:<module>:160 - Step33490, Loss: 3.689702033996582, Grad L2 Norm: 0.02332761511206627
2025-11-24 00:37:13.783 | INFO     | __main__:<module>:160 - Step33500, Loss: 3.5136656761169434, Grad L2 Norm: 0.023490922525525093
2025-11-24 00:37:15.822 | INFO     | __main__:<module>:160 - Step33510, Loss: 3.626708984375, Grad L2 Norm: 0.022935613989830017
2025-11-24 00:37:17.851 | INFO     | __main__:<module>:160 - Step33520, Loss: 3.5713467597961426, Grad L2 Norm: 0.022015545517206192
2025-11-24 00:37:19.882 | INFO     | __main__:<module>:160 - Step33530, Loss: 3.5427212715148926, Grad L2 Norm: 0.021571185439825058
2025-11-24 00:37:21.920 | INFO     | __main__:<module>:160 - Step33540, Loss: 3.536635398864746, Grad L2 Norm: 0.022433919832110405
2025-11-24 00:37:23.952 | INFO     | __main__:<module>:160 - Step33550, Loss: 3.6775355339050293, Grad L2 Norm: 0.023923859000205994
2025-11-24 00:37:25.982 | INFO     | __main__:<module>:160 - Step33560, Loss: 3.532531499862671, Grad L2 Norm: 0.021831896156072617
2025-11-24 00:37:28.019 | INFO     | __main__:<module>:160 - Step33570, Loss: 3.5125949382781982, Grad L2 Norm: 0.02259247377514839
2025-11-24 00:37:30.059 | INFO     | __main__:<module>:160 - Step33580, Loss: 3.6786084175109863, Grad L2 Norm: 0.028122974559664726
2025-11-24 00:37:32.097 | INFO     | __main__:<module>:160 - Step33590, Loss: 3.513582229614258, Grad L2 Norm: 0.01998983882367611
2025-11-24 00:37:34.137 | INFO     | __main__:<module>:160 - Step33600, Loss: 3.5259509086608887, Grad L2 Norm: 0.022799959406256676
2025-11-24 00:37:34.138 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:37:35.437 | INFO     | __main__:<module>:181 - validation loss: 3.592143142223358
2025-11-24 00:37:37.486 | INFO     | __main__:<module>:160 - Step33610, Loss: 3.465765953063965, Grad L2 Norm: 0.02234978973865509
2025-11-24 00:37:39.527 | INFO     | __main__:<module>:160 - Step33620, Loss: 3.6522316932678223, Grad L2 Norm: 0.02264580875635147
2025-11-24 00:37:41.573 | INFO     | __main__:<module>:160 - Step33630, Loss: 3.591494083404541, Grad L2 Norm: 0.022701721638441086
2025-11-24 00:37:43.609 | INFO     | __main__:<module>:160 - Step33640, Loss: 3.4795022010803223, Grad L2 Norm: 0.021613236516714096
2025-11-24 00:37:45.642 | INFO     | __main__:<module>:160 - Step33650, Loss: 3.5514206886291504, Grad L2 Norm: 0.021362196654081345
2025-11-24 00:37:47.677 | INFO     | __main__:<module>:160 - Step33660, Loss: 3.6263532638549805, Grad L2 Norm: 0.02313118614256382
2025-11-24 00:37:49.715 | INFO     | __main__:<module>:160 - Step33670, Loss: 3.4932827949523926, Grad L2 Norm: 0.022112643346190453
2025-11-24 00:37:51.754 | INFO     | __main__:<module>:160 - Step33680, Loss: 3.5163497924804688, Grad L2 Norm: 0.022054381668567657
2025-11-24 00:37:53.786 | INFO     | __main__:<module>:160 - Step33690, Loss: 3.63810133934021, Grad L2 Norm: 0.022935770452022552
2025-11-24 00:37:55.820 | INFO     | __main__:<module>:160 - Step33700, Loss: 3.5524606704711914, Grad L2 Norm: 0.021180501207709312
2025-11-24 00:37:57.857 | INFO     | __main__:<module>:160 - Step33710, Loss: 3.3399219512939453, Grad L2 Norm: 0.021465763449668884
2025-11-24 00:37:59.896 | INFO     | __main__:<module>:160 - Step33720, Loss: 3.382359743118286, Grad L2 Norm: 0.02273176982998848
2025-11-24 00:38:01.936 | INFO     | __main__:<module>:160 - Step33730, Loss: 3.4640722274780273, Grad L2 Norm: 0.020998770371079445
2025-11-24 00:38:03.978 | INFO     | __main__:<module>:160 - Step33740, Loss: 3.619678497314453, Grad L2 Norm: 0.022270094603300095
2025-11-24 00:38:06.022 | INFO     | __main__:<module>:160 - Step33750, Loss: 3.508302688598633, Grad L2 Norm: 0.02143198996782303
2025-11-24 00:38:08.070 | INFO     | __main__:<module>:160 - Step33760, Loss: 3.6426148414611816, Grad L2 Norm: 0.023201001808047295
2025-11-24 00:38:10.111 | INFO     | __main__:<module>:160 - Step33770, Loss: 3.6658101081848145, Grad L2 Norm: 0.02425657957792282
2025-11-24 00:38:12.155 | INFO     | __main__:<module>:160 - Step33780, Loss: 3.48287034034729, Grad L2 Norm: 0.0204713623970747
2025-11-24 00:38:14.201 | INFO     | __main__:<module>:160 - Step33790, Loss: 3.581911325454712, Grad L2 Norm: 0.021466953679919243
2025-11-24 00:38:16.249 | INFO     | __main__:<module>:160 - Step33800, Loss: 3.49099063873291, Grad L2 Norm: 0.023026349022984505
2025-11-24 00:38:18.297 | INFO     | __main__:<module>:160 - Step33810, Loss: 3.5519776344299316, Grad L2 Norm: 0.02130635641515255
2025-11-24 00:38:20.347 | INFO     | __main__:<module>:160 - Step33820, Loss: 3.558945894241333, Grad L2 Norm: 0.025395074859261513
2025-11-24 00:38:22.399 | INFO     | __main__:<module>:160 - Step33830, Loss: 3.6905264854431152, Grad L2 Norm: 0.02192051149904728
2025-11-24 00:38:24.454 | INFO     | __main__:<module>:160 - Step33840, Loss: 3.5394606590270996, Grad L2 Norm: 0.023922493681311607
2025-11-24 00:38:26.506 | INFO     | __main__:<module>:160 - Step33850, Loss: 3.6265039443969727, Grad L2 Norm: 0.020979182794690132
2025-11-24 00:38:28.554 | INFO     | __main__:<module>:160 - Step33860, Loss: 3.555460214614868, Grad L2 Norm: 0.021462488919496536
2025-11-24 00:38:30.604 | INFO     | __main__:<module>:160 - Step33870, Loss: 3.607952833175659, Grad L2 Norm: 0.02405165694653988
2025-11-24 00:38:32.656 | INFO     | __main__:<module>:160 - Step33880, Loss: 3.6308791637420654, Grad L2 Norm: 0.021984241902828217
2025-11-24 00:38:34.706 | INFO     | __main__:<module>:160 - Step33890, Loss: 3.620997905731201, Grad L2 Norm: 0.023858511820435524
2025-11-24 00:38:36.757 | INFO     | __main__:<module>:160 - Step33900, Loss: 3.4572019577026367, Grad L2 Norm: 0.021625733003020287
2025-11-24 00:38:38.805 | INFO     | __main__:<module>:160 - Step33910, Loss: 3.611806869506836, Grad L2 Norm: 0.023442918434739113
2025-11-24 00:38:40.853 | INFO     | __main__:<module>:160 - Step33920, Loss: 3.5604090690612793, Grad L2 Norm: 0.022313853725790977
2025-11-24 00:38:42.899 | INFO     | __main__:<module>:160 - Step33930, Loss: 3.5289480686187744, Grad L2 Norm: 0.022935638204216957
2025-11-24 00:38:44.942 | INFO     | __main__:<module>:160 - Step33940, Loss: 3.6668272018432617, Grad L2 Norm: 0.02385220304131508
2025-11-24 00:38:46.985 | INFO     | __main__:<module>:160 - Step33950, Loss: 3.4193623065948486, Grad L2 Norm: 0.021159561350941658
2025-11-24 00:38:49.028 | INFO     | __main__:<module>:160 - Step33960, Loss: 3.5610899925231934, Grad L2 Norm: 0.024457911029458046
2025-11-24 00:38:51.077 | INFO     | __main__:<module>:160 - Step33970, Loss: 3.6150825023651123, Grad L2 Norm: 0.022540627047419548
2025-11-24 00:38:53.123 | INFO     | __main__:<module>:160 - Step33980, Loss: 3.547147512435913, Grad L2 Norm: 0.023106662556529045
2025-11-24 00:38:55.168 | INFO     | __main__:<module>:160 - Step33990, Loss: 3.634920597076416, Grad L2 Norm: 0.021063275635242462
2025-11-24 00:38:57.219 | INFO     | __main__:<module>:160 - Step34000, Loss: 3.6303491592407227, Grad L2 Norm: 0.02176916040480137
2025-11-24 00:38:57.219 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:38:58.523 | INFO     | __main__:<module>:181 - validation loss: 3.58667733669281
2025-11-24 00:38:58.523 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_34000.pt
2025-11-24 00:39:00.394 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 00:39:02.419 | INFO     | __main__:<module>:160 - Step34010, Loss: 3.622758150100708, Grad L2 Norm: 0.024280831217765808
2025-11-24 00:39:04.456 | INFO     | __main__:<module>:160 - Step34020, Loss: 3.60044002532959, Grad L2 Norm: 0.021227901801466942
2025-11-24 00:39:06.500 | INFO     | __main__:<module>:160 - Step34030, Loss: 3.621980667114258, Grad L2 Norm: 0.02327915094792843
2025-11-24 00:39:08.545 | INFO     | __main__:<module>:160 - Step34040, Loss: 3.7376632690429688, Grad L2 Norm: 0.022517167031764984
2025-11-24 00:39:10.593 | INFO     | __main__:<module>:160 - Step34050, Loss: 3.5267138481140137, Grad L2 Norm: 0.02304222248494625
2025-11-24 00:39:12.636 | INFO     | __main__:<module>:160 - Step34060, Loss: 3.5246739387512207, Grad L2 Norm: 0.021323367953300476
2025-11-24 00:39:14.680 | INFO     | __main__:<module>:160 - Step34070, Loss: 3.6421282291412354, Grad L2 Norm: 0.021453121677041054
2025-11-24 00:39:16.727 | INFO     | __main__:<module>:160 - Step34080, Loss: 3.492300033569336, Grad L2 Norm: 0.02267456240952015
2025-11-24 00:39:18.770 | INFO     | __main__:<module>:160 - Step34090, Loss: 3.5500831604003906, Grad L2 Norm: 0.02218514308333397
2025-11-24 00:39:20.813 | INFO     | __main__:<module>:160 - Step34100, Loss: 3.596609115600586, Grad L2 Norm: 0.023991571739315987
2025-11-24 00:39:22.854 | INFO     | __main__:<module>:160 - Step34110, Loss: 3.6283254623413086, Grad L2 Norm: 0.02125881239771843
2025-11-24 00:39:24.897 | INFO     | __main__:<module>:160 - Step34120, Loss: 3.649395704269409, Grad L2 Norm: 0.023550311103463173
2025-11-24 00:39:26.944 | INFO     | __main__:<module>:160 - Step34130, Loss: 3.551514148712158, Grad L2 Norm: 0.02268487960100174
2025-11-24 00:39:28.990 | INFO     | __main__:<module>:160 - Step34140, Loss: 3.537627696990967, Grad L2 Norm: 0.022513819858431816
2025-11-24 00:39:31.032 | INFO     | __main__:<module>:160 - Step34150, Loss: 3.4307827949523926, Grad L2 Norm: 0.020915189757943153
2025-11-24 00:39:33.074 | INFO     | __main__:<module>:160 - Step34160, Loss: 3.4649369716644287, Grad L2 Norm: 0.021770872175693512
2025-11-24 00:39:35.119 | INFO     | __main__:<module>:160 - Step34170, Loss: 3.4254472255706787, Grad L2 Norm: 0.021810023114085197
2025-11-24 00:39:37.161 | INFO     | __main__:<module>:160 - Step34180, Loss: 3.4338669776916504, Grad L2 Norm: 0.021110929548740387
2025-11-24 00:39:39.202 | INFO     | __main__:<module>:160 - Step34190, Loss: 3.584336042404175, Grad L2 Norm: 0.0220510084182024
2025-11-24 00:39:41.242 | INFO     | __main__:<module>:160 - Step34200, Loss: 3.529019355773926, Grad L2 Norm: 0.02137789875268936
2025-11-24 00:39:43.282 | INFO     | __main__:<module>:160 - Step34210, Loss: 3.6828393936157227, Grad L2 Norm: 0.022658195346593857
2025-11-24 00:39:45.324 | INFO     | __main__:<module>:160 - Step34220, Loss: 3.6768884658813477, Grad L2 Norm: 0.02431589551270008
2025-11-24 00:39:47.369 | INFO     | __main__:<module>:160 - Step34230, Loss: 3.596041679382324, Grad L2 Norm: 0.022374937310814857
2025-11-24 00:39:49.411 | INFO     | __main__:<module>:160 - Step34240, Loss: 3.615036964416504, Grad L2 Norm: 0.02218770422041416
2025-11-24 00:39:51.451 | INFO     | __main__:<module>:160 - Step34250, Loss: 3.54492449760437, Grad L2 Norm: 0.0219772607088089
2025-11-24 00:39:53.494 | INFO     | __main__:<module>:160 - Step34260, Loss: 3.614777088165283, Grad L2 Norm: 0.02213890105485916
2025-11-24 00:39:55.535 | INFO     | __main__:<module>:160 - Step34270, Loss: 3.4989378452301025, Grad L2 Norm: 0.023894548416137695
2025-11-24 00:39:57.578 | INFO     | __main__:<module>:160 - Step34280, Loss: 3.5663249492645264, Grad L2 Norm: 0.021905601024627686
2025-11-24 00:39:59.618 | INFO     | __main__:<module>:160 - Step34290, Loss: 3.7293639183044434, Grad L2 Norm: 0.023021938279271126
2025-11-24 00:40:01.662 | INFO     | __main__:<module>:160 - Step34300, Loss: 3.601609945297241, Grad L2 Norm: 0.02262190543115139
2025-11-24 00:40:03.712 | INFO     | __main__:<module>:160 - Step34310, Loss: 3.433636426925659, Grad L2 Norm: 0.022537123411893845
2025-11-24 00:40:05.756 | INFO     | __main__:<module>:160 - Step34320, Loss: 3.5258235931396484, Grad L2 Norm: 0.02126934379339218
2025-11-24 00:40:07.805 | INFO     | __main__:<module>:160 - Step34330, Loss: 3.510784864425659, Grad L2 Norm: 0.021246327087283134
2025-11-24 00:40:09.854 | INFO     | __main__:<module>:160 - Step34340, Loss: 3.5278313159942627, Grad L2 Norm: 0.021517612040042877
2025-11-24 00:40:11.898 | INFO     | __main__:<module>:160 - Step34350, Loss: 3.639038562774658, Grad L2 Norm: 0.025085778906941414
2025-11-24 00:40:13.952 | INFO     | __main__:<module>:160 - Step34360, Loss: 3.6249184608459473, Grad L2 Norm: 0.023851191624999046
2025-11-24 00:40:16.003 | INFO     | __main__:<module>:160 - Step34370, Loss: 3.4872031211853027, Grad L2 Norm: 0.02229294553399086
2025-11-24 00:40:18.056 | INFO     | __main__:<module>:160 - Step34380, Loss: 3.5096182823181152, Grad L2 Norm: 0.021288549527525902
2025-11-24 00:40:20.111 | INFO     | __main__:<module>:160 - Step34390, Loss: 3.6784262657165527, Grad L2 Norm: 0.02288629300892353
2025-11-24 00:40:22.168 | INFO     | __main__:<module>:160 - Step34400, Loss: 3.608123779296875, Grad L2 Norm: 0.023663340136408806
2025-11-24 00:40:22.169 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:40:23.476 | INFO     | __main__:<module>:181 - validation loss: 3.597377800941467
2025-11-24 00:40:25.540 | INFO     | __main__:<module>:160 - Step34410, Loss: 3.6444993019104004, Grad L2 Norm: 0.022996477782726288
2025-11-24 00:40:27.591 | INFO     | __main__:<module>:160 - Step34420, Loss: 3.694957733154297, Grad L2 Norm: 0.023502366617321968
2025-11-24 00:40:29.637 | INFO     | __main__:<module>:160 - Step34430, Loss: 3.499093532562256, Grad L2 Norm: 0.024474438279867172
2025-11-24 00:40:31.688 | INFO     | __main__:<module>:160 - Step34440, Loss: 3.6069529056549072, Grad L2 Norm: 0.022750375792384148
2025-11-24 00:40:33.736 | INFO     | __main__:<module>:160 - Step34450, Loss: 3.6908023357391357, Grad L2 Norm: 0.0223378948867321
2025-11-24 00:40:35.790 | INFO     | __main__:<module>:160 - Step34460, Loss: 3.528231620788574, Grad L2 Norm: 0.0217908825725317
2025-11-24 00:40:37.843 | INFO     | __main__:<module>:160 - Step34470, Loss: 3.576551675796509, Grad L2 Norm: 0.023168766871094704
2025-11-24 00:40:39.893 | INFO     | __main__:<module>:160 - Step34480, Loss: 3.5251927375793457, Grad L2 Norm: 0.02288566157221794
2025-11-24 00:40:41.945 | INFO     | __main__:<module>:160 - Step34490, Loss: 3.6157236099243164, Grad L2 Norm: 0.022453542798757553
2025-11-24 00:40:44.001 | INFO     | __main__:<module>:160 - Step34500, Loss: 3.5376110076904297, Grad L2 Norm: 0.023150358349084854
2025-11-24 00:40:46.057 | INFO     | __main__:<module>:160 - Step34510, Loss: 3.5231122970581055, Grad L2 Norm: 0.02130921371281147
2025-11-24 00:40:48.103 | INFO     | __main__:<module>:160 - Step34520, Loss: 3.609470844268799, Grad L2 Norm: 0.021407708525657654
2025-11-24 00:40:50.152 | INFO     | __main__:<module>:160 - Step34530, Loss: 3.5619072914123535, Grad L2 Norm: 0.02276286669075489
2025-11-24 00:40:52.200 | INFO     | __main__:<module>:160 - Step34540, Loss: 3.547395706176758, Grad L2 Norm: 0.02226715162396431
2025-11-24 00:40:54.249 | INFO     | __main__:<module>:160 - Step34550, Loss: 3.5247607231140137, Grad L2 Norm: 0.02216559834778309
2025-11-24 00:40:56.298 | INFO     | __main__:<module>:160 - Step34560, Loss: 3.583440065383911, Grad L2 Norm: 0.02250443585216999
2025-11-24 00:40:58.348 | INFO     | __main__:<module>:160 - Step34570, Loss: 3.543858528137207, Grad L2 Norm: 0.022618798539042473
2025-11-24 00:41:00.398 | INFO     | __main__:<module>:160 - Step34580, Loss: 3.554202079772949, Grad L2 Norm: 0.022959835827350616
2025-11-24 00:41:02.443 | INFO     | __main__:<module>:160 - Step34590, Loss: 3.5330793857574463, Grad L2 Norm: 0.02345147915184498
2025-11-24 00:41:04.494 | INFO     | __main__:<module>:160 - Step34600, Loss: 3.5569381713867188, Grad L2 Norm: 0.021549370139837265
2025-11-24 00:41:06.539 | INFO     | __main__:<module>:160 - Step34610, Loss: 3.4681954383850098, Grad L2 Norm: 0.021777842193841934
2025-11-24 00:41:08.583 | INFO     | __main__:<module>:160 - Step34620, Loss: 3.654719829559326, Grad L2 Norm: 0.023329446092247963
2025-11-24 00:41:10.622 | INFO     | __main__:<module>:160 - Step34630, Loss: 3.615448236465454, Grad L2 Norm: 0.022589677944779396
2025-11-24 00:41:12.669 | INFO     | __main__:<module>:160 - Step34640, Loss: 3.5910985469818115, Grad L2 Norm: 0.023870287463068962
2025-11-24 00:41:14.709 | INFO     | __main__:<module>:160 - Step34650, Loss: 3.568657398223877, Grad L2 Norm: 0.02347305603325367
2025-11-24 00:41:16.749 | INFO     | __main__:<module>:160 - Step34660, Loss: 3.567446231842041, Grad L2 Norm: 0.02203461527824402
2025-11-24 00:41:18.787 | INFO     | __main__:<module>:160 - Step34670, Loss: 3.491184949874878, Grad L2 Norm: 0.023367727175354958
2025-11-24 00:41:20.822 | INFO     | __main__:<module>:160 - Step34680, Loss: 3.495382308959961, Grad L2 Norm: 0.02284024842083454
2025-11-24 00:41:22.856 | INFO     | __main__:<module>:160 - Step34690, Loss: 3.499389171600342, Grad L2 Norm: 0.023607827723026276
2025-11-24 00:41:24.892 | INFO     | __main__:<module>:160 - Step34700, Loss: 3.586717128753662, Grad L2 Norm: 0.026033218950033188
2025-11-24 00:41:26.929 | INFO     | __main__:<module>:160 - Step34710, Loss: 3.3730037212371826, Grad L2 Norm: 0.022358542308211327
2025-11-24 00:41:28.967 | INFO     | __main__:<module>:160 - Step34720, Loss: 3.46614408493042, Grad L2 Norm: 0.022077258676290512
2025-11-24 00:41:31.006 | INFO     | __main__:<module>:160 - Step34730, Loss: 3.5632483959198, Grad L2 Norm: 0.023802239447832108
2025-11-24 00:41:33.041 | INFO     | __main__:<module>:160 - Step34740, Loss: 3.5735156536102295, Grad L2 Norm: 0.02390497550368309
2025-11-24 00:41:35.080 | INFO     | __main__:<module>:160 - Step34750, Loss: 3.7474868297576904, Grad L2 Norm: 0.025349974632263184
2025-11-24 00:41:37.113 | INFO     | __main__:<module>:160 - Step34760, Loss: 3.506715774536133, Grad L2 Norm: 0.02313874289393425
2025-11-24 00:41:39.146 | INFO     | __main__:<module>:160 - Step34770, Loss: 3.5007381439208984, Grad L2 Norm: 0.021984275430440903
2025-11-24 00:41:41.184 | INFO     | __main__:<module>:160 - Step34780, Loss: 3.570497751235962, Grad L2 Norm: 0.021787164732813835
2025-11-24 00:41:43.221 | INFO     | __main__:<module>:160 - Step34790, Loss: 3.600714683532715, Grad L2 Norm: 0.0215078704059124
2025-11-24 00:41:45.264 | INFO     | __main__:<module>:160 - Step34800, Loss: 3.692817211151123, Grad L2 Norm: 0.024156862869858742
2025-11-24 00:41:45.265 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:41:46.557 | INFO     | __main__:<module>:181 - validation loss: 3.5606308579444885
2025-11-24 00:41:48.600 | INFO     | __main__:<module>:160 - Step34810, Loss: 3.5849950313568115, Grad L2 Norm: 0.022147975862026215
2025-11-24 00:41:50.638 | INFO     | __main__:<module>:160 - Step34820, Loss: 3.527559757232666, Grad L2 Norm: 0.023602766916155815
2025-11-24 00:41:52.678 | INFO     | __main__:<module>:160 - Step34830, Loss: 3.4932360649108887, Grad L2 Norm: 0.021563757210969925
2025-11-24 00:41:54.714 | INFO     | __main__:<module>:160 - Step34840, Loss: 3.5772693157196045, Grad L2 Norm: 0.02258620411157608
2025-11-24 00:41:56.755 | INFO     | __main__:<module>:160 - Step34850, Loss: 3.718547821044922, Grad L2 Norm: 0.023508518934249878
2025-11-24 00:41:58.785 | INFO     | __main__:<module>:160 - Step34860, Loss: 3.6200666427612305, Grad L2 Norm: 0.022722000256180763
2025-11-24 00:42:00.813 | INFO     | __main__:<module>:160 - Step34870, Loss: 3.5307486057281494, Grad L2 Norm: 0.022251594811677933
2025-11-24 00:42:02.851 | INFO     | __main__:<module>:160 - Step34880, Loss: 3.39251446723938, Grad L2 Norm: 0.022397711873054504
2025-11-24 00:42:04.876 | INFO     | __main__:<module>:160 - Step34890, Loss: 3.6488022804260254, Grad L2 Norm: 0.021274283528327942
2025-11-24 00:42:06.911 | INFO     | __main__:<module>:160 - Step34900, Loss: 3.5112881660461426, Grad L2 Norm: 0.020905792713165283
2025-11-24 00:42:08.940 | INFO     | __main__:<module>:160 - Step34910, Loss: 3.747568130493164, Grad L2 Norm: 0.022743239998817444
2025-11-24 00:42:10.968 | INFO     | __main__:<module>:160 - Step34920, Loss: 3.4880003929138184, Grad L2 Norm: 0.02147173509001732
2025-11-24 00:42:12.996 | INFO     | __main__:<module>:160 - Step34930, Loss: 3.5774588584899902, Grad L2 Norm: 0.02342328056693077
2025-11-24 00:42:15.027 | INFO     | __main__:<module>:160 - Step34940, Loss: 3.461958646774292, Grad L2 Norm: 0.021907556802034378
2025-11-24 00:42:17.063 | INFO     | __main__:<module>:160 - Step34950, Loss: 3.5630550384521484, Grad L2 Norm: 0.02288554608821869
2025-11-24 00:42:19.090 | INFO     | __main__:<module>:160 - Step34960, Loss: 3.6139135360717773, Grad L2 Norm: 0.022151052951812744
2025-11-24 00:42:21.124 | INFO     | __main__:<module>:160 - Step34970, Loss: 3.5560667514801025, Grad L2 Norm: 0.02239842899143696
2025-11-24 00:42:23.149 | INFO     | __main__:<module>:160 - Step34980, Loss: 3.4535765647888184, Grad L2 Norm: 0.02166861854493618
2025-11-24 00:42:25.184 | INFO     | __main__:<module>:160 - Step34990, Loss: 3.526646614074707, Grad L2 Norm: 0.022694235667586327
2025-11-24 00:42:27.209 | INFO     | __main__:<module>:160 - Step35000, Loss: 3.6010453701019287, Grad L2 Norm: 0.025221282616257668
2025-11-24 00:42:29.243 | INFO     | __main__:<module>:160 - Step35010, Loss: 3.4920477867126465, Grad L2 Norm: 0.020130766555666924
2025-11-24 00:42:31.273 | INFO     | __main__:<module>:160 - Step35020, Loss: 3.4870493412017822, Grad L2 Norm: 0.021234704181551933
2025-11-24 00:42:33.301 | INFO     | __main__:<module>:160 - Step35030, Loss: 3.5669171810150146, Grad L2 Norm: 0.022002538666129112
2025-11-24 00:42:35.327 | INFO     | __main__:<module>:160 - Step35040, Loss: 3.5729117393493652, Grad L2 Norm: 0.02213907241821289
2025-11-24 00:42:37.356 | INFO     | __main__:<module>:160 - Step35050, Loss: 3.4609603881835938, Grad L2 Norm: 0.021819952875375748
2025-11-24 00:42:39.379 | INFO     | __main__:<module>:160 - Step35060, Loss: 3.5773282051086426, Grad L2 Norm: 0.020846206694841385
2025-11-24 00:42:41.401 | INFO     | __main__:<module>:160 - Step35070, Loss: 3.455458879470825, Grad L2 Norm: 0.021335171535611153
2025-11-24 00:42:43.429 | INFO     | __main__:<module>:160 - Step35080, Loss: 3.59285044670105, Grad L2 Norm: 0.022271936759352684
2025-11-24 00:42:45.449 | INFO     | __main__:<module>:160 - Step35090, Loss: 3.570833444595337, Grad L2 Norm: 0.02485678717494011
2025-11-24 00:42:47.474 | INFO     | __main__:<module>:160 - Step35100, Loss: 3.555202007293701, Grad L2 Norm: 0.019615348428487778
2025-11-24 00:42:49.496 | INFO     | __main__:<module>:160 - Step35110, Loss: 3.442214012145996, Grad L2 Norm: 0.024007387459278107
2025-11-24 00:42:51.515 | INFO     | __main__:<module>:160 - Step35120, Loss: 3.6434221267700195, Grad L2 Norm: 0.023689348250627518
2025-11-24 00:42:53.535 | INFO     | __main__:<module>:160 - Step35130, Loss: 3.678309917449951, Grad L2 Norm: 0.02411872148513794
2025-11-24 00:42:55.555 | INFO     | __main__:<module>:160 - Step35140, Loss: 3.5002548694610596, Grad L2 Norm: 0.023112259805202484
2025-11-24 00:42:57.568 | INFO     | __main__:<module>:160 - Step35150, Loss: 3.730980396270752, Grad L2 Norm: 0.023917704820632935
2025-11-24 00:42:59.581 | INFO     | __main__:<module>:160 - Step35160, Loss: 3.7358896732330322, Grad L2 Norm: 0.022144554182887077
2025-11-24 00:43:01.595 | INFO     | __main__:<module>:160 - Step35170, Loss: 3.6874828338623047, Grad L2 Norm: 0.025404546409845352
2025-11-24 00:43:03.616 | INFO     | __main__:<module>:160 - Step35180, Loss: 3.5461747646331787, Grad L2 Norm: 0.02267044223845005
2025-11-24 00:43:05.631 | INFO     | __main__:<module>:160 - Step35190, Loss: 3.6996231079101562, Grad L2 Norm: 0.02244875393807888
2025-11-24 00:43:07.639 | INFO     | __main__:<module>:160 - Step35200, Loss: 3.5504746437072754, Grad L2 Norm: 0.02138664200901985
2025-11-24 00:43:07.640 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:43:08.922 | INFO     | __main__:<module>:181 - validation loss: 3.5691790103912355
2025-11-24 00:43:10.940 | INFO     | __main__:<module>:160 - Step35210, Loss: 3.672964334487915, Grad L2 Norm: 0.0232430100440979
2025-11-24 00:43:12.953 | INFO     | __main__:<module>:160 - Step35220, Loss: 3.57810640335083, Grad L2 Norm: 0.02181250974535942
2025-11-24 00:43:14.966 | INFO     | __main__:<module>:160 - Step35230, Loss: 3.4640321731567383, Grad L2 Norm: 0.021966783329844475
2025-11-24 00:43:16.975 | INFO     | __main__:<module>:160 - Step35240, Loss: 3.48581600189209, Grad L2 Norm: 0.022730251774191856
2025-11-24 00:43:18.985 | INFO     | __main__:<module>:160 - Step35250, Loss: 3.601895570755005, Grad L2 Norm: 0.02209720015525818
2025-11-24 00:43:20.994 | INFO     | __main__:<module>:160 - Step35260, Loss: 3.5156707763671875, Grad L2 Norm: 0.02106558531522751
2025-11-24 00:43:23.008 | INFO     | __main__:<module>:160 - Step35270, Loss: 3.6709022521972656, Grad L2 Norm: 0.023303868249058723
2025-11-24 00:43:25.017 | INFO     | __main__:<module>:160 - Step35280, Loss: 3.595292091369629, Grad L2 Norm: 0.02327735722064972
2025-11-24 00:43:27.029 | INFO     | __main__:<module>:160 - Step35290, Loss: 3.6583545207977295, Grad L2 Norm: 0.024067215621471405
2025-11-24 00:43:29.032 | INFO     | __main__:<module>:160 - Step35300, Loss: 3.6987104415893555, Grad L2 Norm: 0.023830872029066086
2025-11-24 00:43:31.044 | INFO     | __main__:<module>:160 - Step35310, Loss: 3.6130285263061523, Grad L2 Norm: 0.022458435967564583
2025-11-24 00:43:33.053 | INFO     | __main__:<module>:160 - Step35320, Loss: 3.6930980682373047, Grad L2 Norm: 0.024208154529333115
2025-11-24 00:43:35.066 | INFO     | __main__:<module>:160 - Step35330, Loss: 3.606055736541748, Grad L2 Norm: 0.02094843238592148
2025-11-24 00:43:37.078 | INFO     | __main__:<module>:160 - Step35340, Loss: 3.615171194076538, Grad L2 Norm: 0.022923361510038376
2025-11-24 00:43:39.088 | INFO     | __main__:<module>:160 - Step35350, Loss: 3.503135919570923, Grad L2 Norm: 0.022988086566329002
2025-11-24 00:43:41.102 | INFO     | __main__:<module>:160 - Step35360, Loss: 3.5254034996032715, Grad L2 Norm: 0.021464277058839798
2025-11-24 00:43:43.112 | INFO     | __main__:<module>:160 - Step35370, Loss: 3.5941600799560547, Grad L2 Norm: 0.022363023832440376
2025-11-24 00:43:45.123 | INFO     | __main__:<module>:160 - Step35380, Loss: 3.393868923187256, Grad L2 Norm: 0.02400478720664978
2025-11-24 00:43:47.136 | INFO     | __main__:<module>:160 - Step35390, Loss: 3.5720372200012207, Grad L2 Norm: 0.02287556603550911
2025-11-24 00:43:49.141 | INFO     | __main__:<module>:160 - Step35400, Loss: 3.47727632522583, Grad L2 Norm: 0.021572625264525414
2025-11-24 00:43:51.147 | INFO     | __main__:<module>:160 - Step35410, Loss: 3.639446258544922, Grad L2 Norm: 0.02263508550822735
2025-11-24 00:43:53.157 | INFO     | __main__:<module>:160 - Step35420, Loss: 3.602137327194214, Grad L2 Norm: 0.02165757119655609
2025-11-24 00:43:55.160 | INFO     | __main__:<module>:160 - Step35430, Loss: 3.6037912368774414, Grad L2 Norm: 0.02316359430551529
2025-11-24 00:43:57.166 | INFO     | __main__:<module>:160 - Step35440, Loss: 3.496009349822998, Grad L2 Norm: 0.02106577344238758
2025-11-24 00:43:59.176 | INFO     | __main__:<module>:160 - Step35450, Loss: 3.696204662322998, Grad L2 Norm: 0.022288355976343155
2025-11-24 00:44:01.177 | INFO     | __main__:<module>:160 - Step35460, Loss: 3.5727550983428955, Grad L2 Norm: 0.020793268457055092
2025-11-24 00:44:03.180 | INFO     | __main__:<module>:160 - Step35470, Loss: 3.6693778038024902, Grad L2 Norm: 0.022256527096033096
2025-11-24 00:44:05.183 | INFO     | __main__:<module>:160 - Step35480, Loss: 3.4584953784942627, Grad L2 Norm: 0.021184995770454407
2025-11-24 00:44:07.193 | INFO     | __main__:<module>:160 - Step35490, Loss: 3.6841018199920654, Grad L2 Norm: 0.0223882757127285
2025-11-24 00:44:09.198 | INFO     | __main__:<module>:160 - Step35500, Loss: 3.557339906692505, Grad L2 Norm: 0.022038087248802185
2025-11-24 00:44:11.207 | INFO     | __main__:<module>:160 - Step35510, Loss: 3.6361942291259766, Grad L2 Norm: 0.021382175385951996
2025-11-24 00:44:13.214 | INFO     | __main__:<module>:160 - Step35520, Loss: 3.5024759769439697, Grad L2 Norm: 0.02386217750608921
2025-11-24 00:44:15.215 | INFO     | __main__:<module>:160 - Step35530, Loss: 3.581474542617798, Grad L2 Norm: 0.02361993119120598
2025-11-24 00:44:17.213 | INFO     | __main__:<module>:160 - Step35540, Loss: 3.601789951324463, Grad L2 Norm: 0.021299399435520172
2025-11-24 00:44:19.216 | INFO     | __main__:<module>:160 - Step35550, Loss: 3.464938163757324, Grad L2 Norm: 0.02210971899330616
2025-11-24 00:44:21.229 | INFO     | __main__:<module>:160 - Step35560, Loss: 3.57499361038208, Grad L2 Norm: 0.02535090781748295
2025-11-24 00:44:23.235 | INFO     | __main__:<module>:160 - Step35570, Loss: 3.525688648223877, Grad L2 Norm: 0.02374887280166149
2025-11-24 00:44:25.249 | INFO     | __main__:<module>:160 - Step35580, Loss: 3.4704830646514893, Grad L2 Norm: 0.021554965525865555
2025-11-24 00:44:27.255 | INFO     | __main__:<module>:160 - Step35590, Loss: 3.5442044734954834, Grad L2 Norm: 0.02137245610356331
2025-11-24 00:44:29.270 | INFO     | __main__:<module>:160 - Step35600, Loss: 3.6037638187408447, Grad L2 Norm: 0.022760141640901566
2025-11-24 00:44:29.270 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:44:30.551 | INFO     | __main__:<module>:181 - validation loss: 3.5608664989471435
2025-11-24 00:44:32.571 | INFO     | __main__:<module>:160 - Step35610, Loss: 3.7091290950775146, Grad L2 Norm: 0.0226679015904665
2025-11-24 00:44:34.586 | INFO     | __main__:<module>:160 - Step35620, Loss: 3.545058488845825, Grad L2 Norm: 0.02205156534910202
2025-11-24 00:44:36.600 | INFO     | __main__:<module>:160 - Step35630, Loss: 3.675337553024292, Grad L2 Norm: 0.022994261234998703
2025-11-24 00:44:38.608 | INFO     | __main__:<module>:160 - Step35640, Loss: 3.558971643447876, Grad L2 Norm: 0.024124709889292717
2025-11-24 00:44:40.621 | INFO     | __main__:<module>:160 - Step35650, Loss: 3.5716302394866943, Grad L2 Norm: 0.0216537956148386
2025-11-24 00:44:42.628 | INFO     | __main__:<module>:160 - Step35660, Loss: 3.5538787841796875, Grad L2 Norm: 0.02268999256193638
2025-11-24 00:44:44.639 | INFO     | __main__:<module>:160 - Step35670, Loss: 3.690305709838867, Grad L2 Norm: 0.02614196389913559
2025-11-24 00:44:46.646 | INFO     | __main__:<module>:160 - Step35680, Loss: 3.5215272903442383, Grad L2 Norm: 0.02253996767103672
2025-11-24 00:44:48.657 | INFO     | __main__:<module>:160 - Step35690, Loss: 3.55784273147583, Grad L2 Norm: 0.022277450188994408
2025-11-24 00:44:50.662 | INFO     | __main__:<module>:160 - Step35700, Loss: 3.5291216373443604, Grad L2 Norm: 0.023738373070955276
2025-11-24 00:44:52.664 | INFO     | __main__:<module>:160 - Step35710, Loss: 3.5911343097686768, Grad L2 Norm: 0.02455008774995804
2025-11-24 00:44:54.675 | INFO     | __main__:<module>:160 - Step35720, Loss: 3.456760883331299, Grad L2 Norm: 0.021759172901511192
2025-11-24 00:44:56.681 | INFO     | __main__:<module>:160 - Step35730, Loss: 3.556730270385742, Grad L2 Norm: 0.022184865549206734
2025-11-24 00:44:58.690 | INFO     | __main__:<module>:160 - Step35740, Loss: 3.5273733139038086, Grad L2 Norm: 0.022649548947811127
2025-11-24 00:45:00.698 | INFO     | __main__:<module>:160 - Step35750, Loss: 3.658231019973755, Grad L2 Norm: 0.023058898746967316
2025-11-24 00:45:02.710 | INFO     | __main__:<module>:160 - Step35760, Loss: 3.492166042327881, Grad L2 Norm: 0.02176837995648384
2025-11-24 00:45:04.717 | INFO     | __main__:<module>:160 - Step35770, Loss: 3.5972795486450195, Grad L2 Norm: 0.02123679406940937
2025-11-24 00:45:06.720 | INFO     | __main__:<module>:160 - Step35780, Loss: 3.5428266525268555, Grad L2 Norm: 0.020734626799821854
2025-11-24 00:45:08.725 | INFO     | __main__:<module>:160 - Step35790, Loss: 3.5366692543029785, Grad L2 Norm: 0.022695891559123993
2025-11-24 00:45:10.732 | INFO     | __main__:<module>:160 - Step35800, Loss: 3.7254719734191895, Grad L2 Norm: 0.0252360999584198
2025-11-24 00:45:12.739 | INFO     | __main__:<module>:160 - Step35810, Loss: 3.536548137664795, Grad L2 Norm: 0.022455407306551933
2025-11-24 00:45:14.749 | INFO     | __main__:<module>:160 - Step35820, Loss: 3.5910491943359375, Grad L2 Norm: 0.021702298894524574
2025-11-24 00:45:16.758 | INFO     | __main__:<module>:160 - Step35830, Loss: 3.5537474155426025, Grad L2 Norm: 0.021415382623672485
2025-11-24 00:45:18.771 | INFO     | __main__:<module>:160 - Step35840, Loss: 3.598681688308716, Grad L2 Norm: 0.022323789075016975
2025-11-24 00:45:20.778 | INFO     | __main__:<module>:160 - Step35850, Loss: 3.5524168014526367, Grad L2 Norm: 0.023040693253278732
2025-11-24 00:45:22.791 | INFO     | __main__:<module>:160 - Step35860, Loss: 3.466994524002075, Grad L2 Norm: 0.02040642499923706
2025-11-24 00:45:24.803 | INFO     | __main__:<module>:160 - Step35870, Loss: 3.525726556777954, Grad L2 Norm: 0.0225796140730381
2025-11-24 00:45:26.811 | INFO     | __main__:<module>:160 - Step35880, Loss: 3.4499363899230957, Grad L2 Norm: 0.022962292656302452
2025-11-24 00:45:28.816 | INFO     | __main__:<module>:160 - Step35890, Loss: 3.5435562133789062, Grad L2 Norm: 0.02145637758076191
2025-11-24 00:45:30.829 | INFO     | __main__:<module>:160 - Step35900, Loss: 3.6597328186035156, Grad L2 Norm: 0.023113984614610672
2025-11-24 00:45:32.837 | INFO     | __main__:<module>:160 - Step35910, Loss: 3.575321674346924, Grad L2 Norm: 0.02390875481069088
2025-11-24 00:45:34.849 | INFO     | __main__:<module>:160 - Step35920, Loss: 3.4387381076812744, Grad L2 Norm: 0.024104993790388107
2025-11-24 00:45:36.860 | INFO     | __main__:<module>:160 - Step35930, Loss: 3.530461072921753, Grad L2 Norm: 0.022218821570277214
2025-11-24 00:45:38.868 | INFO     | __main__:<module>:160 - Step35940, Loss: 3.4805121421813965, Grad L2 Norm: 0.02286446839570999
2025-11-24 00:45:40.870 | INFO     | __main__:<module>:160 - Step35950, Loss: 3.6711418628692627, Grad L2 Norm: 0.023534633219242096
2025-11-24 00:45:42.883 | INFO     | __main__:<module>:160 - Step35960, Loss: 3.4067416191101074, Grad L2 Norm: 0.022716373205184937
2025-11-24 00:45:44.889 | INFO     | __main__:<module>:160 - Step35970, Loss: 3.574117660522461, Grad L2 Norm: 0.022393591701984406
2025-11-24 00:45:46.903 | INFO     | __main__:<module>:160 - Step35980, Loss: 3.498622417449951, Grad L2 Norm: 0.021124640479683876
2025-11-24 00:45:48.909 | INFO     | __main__:<module>:160 - Step35990, Loss: 3.4707813262939453, Grad L2 Norm: 0.021141987293958664
2025-11-24 00:45:50.922 | INFO     | __main__:<module>:160 - Step36000, Loss: 3.630035400390625, Grad L2 Norm: 0.022097688168287277
2025-11-24 00:45:50.922 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:45:52.204 | INFO     | __main__:<module>:181 - validation loss: 3.5532957315444946
2025-11-24 00:45:52.204 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_36000.pt
2025-11-24 00:45:53.964 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 00:45:55.951 | INFO     | __main__:<module>:160 - Step36010, Loss: 3.665257215499878, Grad L2 Norm: 0.0222257599234581
2025-11-24 00:45:57.957 | INFO     | __main__:<module>:160 - Step36020, Loss: 3.6975533962249756, Grad L2 Norm: 0.02278411202132702
2025-11-24 00:45:59.963 | INFO     | __main__:<module>:160 - Step36030, Loss: 3.4402780532836914, Grad L2 Norm: 0.021916020661592484
2025-11-24 00:46:01.974 | INFO     | __main__:<module>:160 - Step36040, Loss: 3.5989673137664795, Grad L2 Norm: 0.021401653066277504
2025-11-24 00:46:03.984 | INFO     | __main__:<module>:160 - Step36050, Loss: 3.50510573387146, Grad L2 Norm: 0.02402007393538952
2025-11-24 00:46:05.998 | INFO     | __main__:<module>:160 - Step36060, Loss: 3.585334300994873, Grad L2 Norm: 0.021408013999462128
2025-11-24 00:46:08.007 | INFO     | __main__:<module>:160 - Step36070, Loss: 3.530902624130249, Grad L2 Norm: 0.022487284615635872
2025-11-24 00:46:10.017 | INFO     | __main__:<module>:160 - Step36080, Loss: 3.544813871383667, Grad L2 Norm: 0.023509899154305458
2025-11-24 00:46:12.030 | INFO     | __main__:<module>:160 - Step36090, Loss: 3.5746054649353027, Grad L2 Norm: 0.021796146407723427
2025-11-24 00:46:14.039 | INFO     | __main__:<module>:160 - Step36100, Loss: 3.5441133975982666, Grad L2 Norm: 0.02259301207959652
2025-11-24 00:46:16.049 | INFO     | __main__:<module>:160 - Step36110, Loss: 3.5796968936920166, Grad L2 Norm: 0.023151125758886337
2025-11-24 00:46:18.058 | INFO     | __main__:<module>:160 - Step36120, Loss: 3.5992977619171143, Grad L2 Norm: 0.022603558376431465
2025-11-24 00:46:20.072 | INFO     | __main__:<module>:160 - Step36130, Loss: 3.553034782409668, Grad L2 Norm: 0.02396848425269127
2025-11-24 00:46:22.080 | INFO     | __main__:<module>:160 - Step36140, Loss: 3.528055191040039, Grad L2 Norm: 0.022951465100049973
2025-11-24 00:46:24.094 | INFO     | __main__:<module>:160 - Step36150, Loss: 3.4975247383117676, Grad L2 Norm: 0.02125667966902256
2025-11-24 00:46:26.107 | INFO     | __main__:<module>:160 - Step36160, Loss: 3.572037696838379, Grad L2 Norm: 0.021769268438220024
2025-11-24 00:46:28.118 | INFO     | __main__:<module>:160 - Step36170, Loss: 3.5529518127441406, Grad L2 Norm: 0.02101157233119011
2025-11-24 00:46:30.133 | INFO     | __main__:<module>:160 - Step36180, Loss: 3.644092559814453, Grad L2 Norm: 0.02280079945921898
2025-11-24 00:46:32.155 | INFO     | __main__:<module>:160 - Step36190, Loss: 3.4654524326324463, Grad L2 Norm: 0.022647468373179436
2025-11-24 00:46:34.174 | INFO     | __main__:<module>:160 - Step36200, Loss: 3.761214256286621, Grad L2 Norm: 0.024770788848400116
2025-11-24 00:46:36.195 | INFO     | __main__:<module>:160 - Step36210, Loss: 3.519035577774048, Grad L2 Norm: 0.02138335071504116
2025-11-24 00:46:38.211 | INFO     | __main__:<module>:160 - Step36220, Loss: 3.6353421211242676, Grad L2 Norm: 0.021184127777814865
2025-11-24 00:46:40.227 | INFO     | __main__:<module>:160 - Step36230, Loss: 3.6352481842041016, Grad L2 Norm: 0.022679528221488
2025-11-24 00:46:42.246 | INFO     | __main__:<module>:160 - Step36240, Loss: 3.6558101177215576, Grad L2 Norm: 0.022344445809721947
2025-11-24 00:46:44.262 | INFO     | __main__:<module>:160 - Step36250, Loss: 3.571382522583008, Grad L2 Norm: 0.0216680895537138
2025-11-24 00:46:46.285 | INFO     | __main__:<module>:160 - Step36260, Loss: 3.5368528366088867, Grad L2 Norm: 0.021288003772497177
2025-11-24 00:46:48.311 | INFO     | __main__:<module>:160 - Step36270, Loss: 3.5999999046325684, Grad L2 Norm: 0.02256622724235058
2025-11-24 00:46:50.339 | INFO     | __main__:<module>:160 - Step36280, Loss: 3.600212574005127, Grad L2 Norm: 0.023757407441735268
2025-11-24 00:46:52.359 | INFO     | __main__:<module>:160 - Step36290, Loss: 3.670535087585449, Grad L2 Norm: 0.02411380410194397
2025-11-24 00:46:54.378 | INFO     | __main__:<module>:160 - Step36300, Loss: 3.572474718093872, Grad L2 Norm: 0.022242911159992218
2025-11-24 00:46:56.401 | INFO     | __main__:<module>:160 - Step36310, Loss: 3.6107420921325684, Grad L2 Norm: 0.022523287683725357
2025-11-24 00:46:58.430 | INFO     | __main__:<module>:160 - Step36320, Loss: 3.5810179710388184, Grad L2 Norm: 0.02018839679658413
2025-11-24 00:47:00.459 | INFO     | __main__:<module>:160 - Step36330, Loss: 3.5233960151672363, Grad L2 Norm: 0.020774737000465393
2025-11-24 00:47:02.488 | INFO     | __main__:<module>:160 - Step36340, Loss: 3.480430841445923, Grad L2 Norm: 0.021964645013213158
2025-11-24 00:47:04.516 | INFO     | __main__:<module>:160 - Step36350, Loss: 3.5336966514587402, Grad L2 Norm: 0.02199512906372547
2025-11-24 00:47:06.554 | INFO     | __main__:<module>:160 - Step36360, Loss: 3.5791945457458496, Grad L2 Norm: 0.02367168851196766
2025-11-24 00:47:08.585 | INFO     | __main__:<module>:160 - Step36370, Loss: 3.608351230621338, Grad L2 Norm: 0.022151881828904152
2025-11-24 00:47:10.614 | INFO     | __main__:<module>:160 - Step36380, Loss: 3.6172542572021484, Grad L2 Norm: 0.02229183167219162
2025-11-24 00:47:12.651 | INFO     | __main__:<module>:160 - Step36390, Loss: 3.60476016998291, Grad L2 Norm: 0.023423640057444572
2025-11-24 00:47:14.677 | INFO     | __main__:<module>:160 - Step36400, Loss: 3.484266757965088, Grad L2 Norm: 0.02254682220518589
2025-11-24 00:47:14.677 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:47:15.972 | INFO     | __main__:<module>:181 - validation loss: 3.539936351776123
2025-11-24 00:47:18.013 | INFO     | __main__:<module>:160 - Step36410, Loss: 3.56646728515625, Grad L2 Norm: 0.02333451807498932
2025-11-24 00:47:20.050 | INFO     | __main__:<module>:160 - Step36420, Loss: 3.5680365562438965, Grad L2 Norm: 0.023657483980059624
2025-11-24 00:47:22.092 | INFO     | __main__:<module>:160 - Step36430, Loss: 3.6783366203308105, Grad L2 Norm: 0.02564895711839199
2025-11-24 00:47:24.131 | INFO     | __main__:<module>:160 - Step36440, Loss: 3.5130066871643066, Grad L2 Norm: 0.02151600271463394
2025-11-24 00:47:26.172 | INFO     | __main__:<module>:160 - Step36450, Loss: 3.625471353530884, Grad L2 Norm: 0.022092824801802635
2025-11-24 00:47:28.214 | INFO     | __main__:<module>:160 - Step36460, Loss: 3.647571563720703, Grad L2 Norm: 0.023711662739515305
2025-11-24 00:47:30.260 | INFO     | __main__:<module>:160 - Step36470, Loss: 3.5908327102661133, Grad L2 Norm: 0.023632965981960297
2025-11-24 00:47:32.307 | INFO     | __main__:<module>:160 - Step36480, Loss: 3.6002395153045654, Grad L2 Norm: 0.022654613479971886
2025-11-24 00:47:34.352 | INFO     | __main__:<module>:160 - Step36490, Loss: 3.490602493286133, Grad L2 Norm: 0.023515433073043823
2025-11-24 00:47:36.390 | INFO     | __main__:<module>:160 - Step36500, Loss: 3.577988624572754, Grad L2 Norm: 0.023163005709648132
2025-11-24 00:47:38.431 | INFO     | __main__:<module>:160 - Step36510, Loss: 3.499389410018921, Grad L2 Norm: 0.021591879427433014
2025-11-24 00:47:40.472 | INFO     | __main__:<module>:160 - Step36520, Loss: 3.5322654247283936, Grad L2 Norm: 0.021206805482506752
2025-11-24 00:47:42.521 | INFO     | __main__:<module>:160 - Step36530, Loss: 3.5636258125305176, Grad L2 Norm: 0.022143743932247162
2025-11-24 00:47:44.567 | INFO     | __main__:<module>:160 - Step36540, Loss: 3.582437038421631, Grad L2 Norm: 0.02217097021639347
2025-11-24 00:47:46.608 | INFO     | __main__:<module>:160 - Step36550, Loss: 3.498459577560425, Grad L2 Norm: 0.02258831448853016
2025-11-24 00:47:48.652 | INFO     | __main__:<module>:160 - Step36560, Loss: 3.5681447982788086, Grad L2 Norm: 0.021213417872786522
2025-11-24 00:47:50.698 | INFO     | __main__:<module>:160 - Step36570, Loss: 3.4552135467529297, Grad L2 Norm: 0.02334490418434143
2025-11-24 00:47:52.745 | INFO     | __main__:<module>:160 - Step36580, Loss: 3.469222068786621, Grad L2 Norm: 0.02167019620537758
2025-11-24 00:47:54.790 | INFO     | __main__:<module>:160 - Step36590, Loss: 3.6321523189544678, Grad L2 Norm: 0.022597504779696465
2025-11-24 00:47:56.842 | INFO     | __main__:<module>:160 - Step36600, Loss: 3.6000218391418457, Grad L2 Norm: 0.02282126061618328
2025-11-24 00:47:58.888 | INFO     | __main__:<module>:160 - Step36610, Loss: 3.4304049015045166, Grad L2 Norm: 0.02209368348121643
2025-11-24 00:48:00.936 | INFO     | __main__:<module>:160 - Step36620, Loss: 3.51834774017334, Grad L2 Norm: 0.022669486701488495
2025-11-24 00:48:02.983 | INFO     | __main__:<module>:160 - Step36630, Loss: 3.603994369506836, Grad L2 Norm: 0.02617805078625679
2025-11-24 00:48:05.027 | INFO     | __main__:<module>:160 - Step36640, Loss: 3.6012048721313477, Grad L2 Norm: 0.023536276072263718
2025-11-24 00:48:07.070 | INFO     | __main__:<module>:160 - Step36650, Loss: 3.5715770721435547, Grad L2 Norm: 0.022584853693842888
2025-11-24 00:48:09.115 | INFO     | __main__:<module>:160 - Step36660, Loss: 3.6032230854034424, Grad L2 Norm: 0.02167077548801899
2025-11-24 00:48:11.158 | INFO     | __main__:<module>:160 - Step36670, Loss: 3.4760732650756836, Grad L2 Norm: 0.023096367716789246
2025-11-24 00:48:13.200 | INFO     | __main__:<module>:160 - Step36680, Loss: 3.5091676712036133, Grad L2 Norm: 0.022220324724912643
2025-11-24 00:48:15.244 | INFO     | __main__:<module>:160 - Step36690, Loss: 3.546865463256836, Grad L2 Norm: 0.02200196124613285
2025-11-24 00:48:17.287 | INFO     | __main__:<module>:160 - Step36700, Loss: 3.6107254028320312, Grad L2 Norm: 0.02361438050866127
2025-11-24 00:48:19.334 | INFO     | __main__:<module>:160 - Step36710, Loss: 3.3787591457366943, Grad L2 Norm: 0.023974837735295296
2025-11-24 00:48:21.376 | INFO     | __main__:<module>:160 - Step36720, Loss: 3.564690113067627, Grad L2 Norm: 0.020152470096945763
2025-11-24 00:48:23.419 | INFO     | __main__:<module>:160 - Step36730, Loss: 3.728806495666504, Grad L2 Norm: 0.02605600655078888
2025-11-24 00:48:25.461 | INFO     | __main__:<module>:160 - Step36740, Loss: 3.5275518894195557, Grad L2 Norm: 0.022394802421331406
2025-11-24 00:48:27.508 | INFO     | __main__:<module>:160 - Step36750, Loss: 3.596923351287842, Grad L2 Norm: 0.02231910638511181
2025-11-24 00:48:29.552 | INFO     | __main__:<module>:160 - Step36760, Loss: 3.65146541595459, Grad L2 Norm: 0.022564291954040527
2025-11-24 00:48:31.595 | INFO     | __main__:<module>:160 - Step36770, Loss: 3.433732748031616, Grad L2 Norm: 0.021568110212683678
2025-11-24 00:48:33.638 | INFO     | __main__:<module>:160 - Step36780, Loss: 3.4942235946655273, Grad L2 Norm: 0.0229503121227026
2025-11-24 00:48:35.689 | INFO     | __main__:<module>:160 - Step36790, Loss: 3.6448636054992676, Grad L2 Norm: 0.02483099326491356
2025-11-24 00:48:37.736 | INFO     | __main__:<module>:160 - Step36800, Loss: 3.536867380142212, Grad L2 Norm: 0.023103883489966393
2025-11-24 00:48:37.737 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:48:39.038 | INFO     | __main__:<module>:181 - validation loss: 3.5408531665802
2025-11-24 00:48:41.100 | INFO     | __main__:<module>:160 - Step36810, Loss: 3.6391539573669434, Grad L2 Norm: 0.02336455136537552
2025-11-24 00:48:43.147 | INFO     | __main__:<module>:160 - Step36820, Loss: 3.4557087421417236, Grad L2 Norm: 0.021497666835784912
2025-11-24 00:48:45.186 | INFO     | __main__:<module>:160 - Step36830, Loss: 3.6634697914123535, Grad L2 Norm: 0.022417746484279633
2025-11-24 00:48:47.229 | INFO     | __main__:<module>:160 - Step36840, Loss: 3.5871527194976807, Grad L2 Norm: 0.02191036567091942
2025-11-24 00:48:49.272 | INFO     | __main__:<module>:160 - Step36850, Loss: 3.567471742630005, Grad L2 Norm: 0.023653849959373474
2025-11-24 00:48:51.322 | INFO     | __main__:<module>:160 - Step36860, Loss: 3.4477012157440186, Grad L2 Norm: 0.022019121795892715
2025-11-24 00:48:53.369 | INFO     | __main__:<module>:160 - Step36870, Loss: 3.556612253189087, Grad L2 Norm: 0.022331787273287773
2025-11-24 00:48:55.423 | INFO     | __main__:<module>:160 - Step36880, Loss: 3.5709288120269775, Grad L2 Norm: 0.02341320738196373
2025-11-24 00:48:57.477 | INFO     | __main__:<module>:160 - Step36890, Loss: 3.5722532272338867, Grad L2 Norm: 0.02140362747013569
2025-11-24 00:48:59.523 | INFO     | __main__:<module>:160 - Step36900, Loss: 3.471503257751465, Grad L2 Norm: 0.02162814699113369
2025-11-24 00:49:01.570 | INFO     | __main__:<module>:160 - Step36910, Loss: 3.6250102519989014, Grad L2 Norm: 0.02211015298962593
2025-11-24 00:49:03.618 | INFO     | __main__:<module>:160 - Step36920, Loss: 3.696800708770752, Grad L2 Norm: 0.02312597632408142
2025-11-24 00:49:05.665 | INFO     | __main__:<module>:160 - Step36930, Loss: 3.5404410362243652, Grad L2 Norm: 0.021651901304721832
2025-11-24 00:49:07.719 | INFO     | __main__:<module>:160 - Step36940, Loss: 3.5359108448028564, Grad L2 Norm: 0.02188403531908989
2025-11-24 00:49:09.766 | INFO     | __main__:<module>:160 - Step36950, Loss: 3.5923657417297363, Grad L2 Norm: 0.021474679931998253
2025-11-24 00:49:11.816 | INFO     | __main__:<module>:160 - Step36960, Loss: 3.56278657913208, Grad L2 Norm: 0.021024376153945923
2025-11-24 00:49:13.866 | INFO     | __main__:<module>:160 - Step36970, Loss: 3.529881238937378, Grad L2 Norm: 0.02169070765376091
2025-11-24 00:49:15.915 | INFO     | __main__:<module>:160 - Step36980, Loss: 3.630666732788086, Grad L2 Norm: 0.023321833461523056
2025-11-24 00:49:17.965 | INFO     | __main__:<module>:160 - Step36990, Loss: 3.5814592838287354, Grad L2 Norm: 0.02343258261680603
2025-11-24 00:49:20.016 | INFO     | __main__:<module>:160 - Step37000, Loss: 3.522569417953491, Grad L2 Norm: 0.023017793893814087
2025-11-24 00:49:22.064 | INFO     | __main__:<module>:160 - Step37010, Loss: 3.668923854827881, Grad L2 Norm: 0.022886771708726883
2025-11-24 00:49:24.115 | INFO     | __main__:<module>:160 - Step37020, Loss: 3.764430522918701, Grad L2 Norm: 0.022952202707529068
2025-11-24 00:49:26.169 | INFO     | __main__:<module>:160 - Step37030, Loss: 3.6521644592285156, Grad L2 Norm: 0.02194995805621147
2025-11-24 00:49:28.213 | INFO     | __main__:<module>:160 - Step37040, Loss: 3.5760135650634766, Grad L2 Norm: 0.023404259234666824
2025-11-24 00:49:30.265 | INFO     | __main__:<module>:160 - Step37050, Loss: 3.521766185760498, Grad L2 Norm: 0.021438756957650185
2025-11-24 00:49:32.315 | INFO     | __main__:<module>:160 - Step37060, Loss: 3.4575419425964355, Grad L2 Norm: 0.021800389513373375
2025-11-24 00:49:34.366 | INFO     | __main__:<module>:160 - Step37070, Loss: 3.6187758445739746, Grad L2 Norm: 0.022887922823429108
2025-11-24 00:49:36.415 | INFO     | __main__:<module>:160 - Step37080, Loss: 3.6381163597106934, Grad L2 Norm: 0.021636033430695534
2025-11-24 00:49:38.463 | INFO     | __main__:<module>:160 - Step37090, Loss: 3.551011562347412, Grad L2 Norm: 0.021380122750997543
2025-11-24 00:49:40.512 | INFO     | __main__:<module>:160 - Step37100, Loss: 3.478285789489746, Grad L2 Norm: 0.023181824013590813
2025-11-24 00:49:42.563 | INFO     | __main__:<module>:160 - Step37110, Loss: 3.6530814170837402, Grad L2 Norm: 0.024058643728494644
2025-11-24 00:49:44.615 | INFO     | __main__:<module>:160 - Step37120, Loss: 3.5843470096588135, Grad L2 Norm: 0.021599899977445602
2025-11-24 00:49:46.665 | INFO     | __main__:<module>:160 - Step37130, Loss: 3.5858473777770996, Grad L2 Norm: 0.022037658840417862
2025-11-24 00:49:48.722 | INFO     | __main__:<module>:160 - Step37140, Loss: 3.476696014404297, Grad L2 Norm: 0.021493608132004738
2025-11-24 00:49:50.772 | INFO     | __main__:<module>:160 - Step37150, Loss: 3.547386646270752, Grad L2 Norm: 0.022976268082857132
2025-11-24 00:49:52.826 | INFO     | __main__:<module>:160 - Step37160, Loss: 3.560969829559326, Grad L2 Norm: 0.02344343438744545
2025-11-24 00:49:54.880 | INFO     | __main__:<module>:160 - Step37170, Loss: 3.48663330078125, Grad L2 Norm: 0.020172113552689552
2025-11-24 00:49:56.929 | INFO     | __main__:<module>:160 - Step37180, Loss: 3.533310890197754, Grad L2 Norm: 0.022347591817378998
2025-11-24 00:49:58.981 | INFO     | __main__:<module>:160 - Step37190, Loss: 3.640655517578125, Grad L2 Norm: 0.022763362154364586
2025-11-24 00:50:01.031 | INFO     | __main__:<module>:160 - Step37200, Loss: 3.5649170875549316, Grad L2 Norm: 0.02226526290178299
2025-11-24 00:50:01.031 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:50:02.348 | INFO     | __main__:<module>:181 - validation loss: 3.5806134700775147
2025-11-24 00:50:04.407 | INFO     | __main__:<module>:160 - Step37210, Loss: 3.4584403038024902, Grad L2 Norm: 0.021229207515716553
2025-11-24 00:50:06.461 | INFO     | __main__:<module>:160 - Step37220, Loss: 3.5702199935913086, Grad L2 Norm: 0.02257978543639183
2025-11-24 00:50:08.508 | INFO     | __main__:<module>:160 - Step37230, Loss: 3.5725908279418945, Grad L2 Norm: 0.02269032970070839
2025-11-24 00:50:10.563 | INFO     | __main__:<module>:160 - Step37240, Loss: 3.690314292907715, Grad L2 Norm: 0.021925073117017746
2025-11-24 00:50:12.611 | INFO     | __main__:<module>:160 - Step37250, Loss: 3.6109554767608643, Grad L2 Norm: 0.02293112501502037
2025-11-24 00:50:14.661 | INFO     | __main__:<module>:160 - Step37260, Loss: 3.634967565536499, Grad L2 Norm: 0.023085324093699455
2025-11-24 00:50:16.708 | INFO     | __main__:<module>:160 - Step37270, Loss: 3.560943126678467, Grad L2 Norm: 0.022506626322865486
2025-11-24 00:50:18.752 | INFO     | __main__:<module>:160 - Step37280, Loss: 3.4833133220672607, Grad L2 Norm: 0.021222693845629692
2025-11-24 00:50:20.798 | INFO     | __main__:<module>:160 - Step37290, Loss: 3.6332640647888184, Grad L2 Norm: 0.02430388145148754
2025-11-24 00:50:22.841 | INFO     | __main__:<module>:160 - Step37300, Loss: 3.5455315113067627, Grad L2 Norm: 0.02094659022986889
2025-11-24 00:50:24.885 | INFO     | __main__:<module>:160 - Step37310, Loss: 3.58658504486084, Grad L2 Norm: 0.021700674667954445
2025-11-24 00:50:26.928 | INFO     | __main__:<module>:160 - Step37320, Loss: 3.4636454582214355, Grad L2 Norm: 0.0226766187697649
2025-11-24 00:50:28.963 | INFO     | __main__:<module>:160 - Step37330, Loss: 3.546553373336792, Grad L2 Norm: 0.023870447650551796
2025-11-24 00:50:31.000 | INFO     | __main__:<module>:160 - Step37340, Loss: 3.6909091472625732, Grad L2 Norm: 0.024165300652384758
2025-11-24 00:50:33.036 | INFO     | __main__:<module>:160 - Step37350, Loss: 3.655510902404785, Grad L2 Norm: 0.021705731749534607
2025-11-24 00:50:35.075 | INFO     | __main__:<module>:160 - Step37360, Loss: 3.641413450241089, Grad L2 Norm: 0.021886898204684258
2025-11-24 00:50:37.114 | INFO     | __main__:<module>:160 - Step37370, Loss: 3.600696563720703, Grad L2 Norm: 0.022205593064427376
2025-11-24 00:50:39.150 | INFO     | __main__:<module>:160 - Step37380, Loss: 3.528454065322876, Grad L2 Norm: 0.022772617638111115
2025-11-24 00:50:41.190 | INFO     | __main__:<module>:160 - Step37390, Loss: 3.439781665802002, Grad L2 Norm: 0.02216494455933571
2025-11-24 00:50:43.227 | INFO     | __main__:<module>:160 - Step37400, Loss: 3.628354549407959, Grad L2 Norm: 0.02417321689426899
2025-11-24 00:50:45.259 | INFO     | __main__:<module>:160 - Step37410, Loss: 3.518765449523926, Grad L2 Norm: 0.021532682701945305
2025-11-24 00:50:47.290 | INFO     | __main__:<module>:160 - Step37420, Loss: 3.7342727184295654, Grad L2 Norm: 0.0262751504778862
2025-11-24 00:50:49.327 | INFO     | __main__:<module>:160 - Step37430, Loss: 3.607483386993408, Grad L2 Norm: 0.022157257422804832
2025-11-24 00:50:51.367 | INFO     | __main__:<module>:160 - Step37440, Loss: 3.49855899810791, Grad L2 Norm: 0.022774772718548775
2025-11-24 00:50:53.403 | INFO     | __main__:<module>:160 - Step37450, Loss: 3.5148465633392334, Grad L2 Norm: 0.022201523184776306
2025-11-24 00:50:55.433 | INFO     | __main__:<module>:160 - Step37460, Loss: 3.626847743988037, Grad L2 Norm: 0.021944085136055946
2025-11-24 00:50:57.466 | INFO     | __main__:<module>:160 - Step37470, Loss: 3.6200060844421387, Grad L2 Norm: 0.023107578977942467
2025-11-24 00:50:59.503 | INFO     | __main__:<module>:160 - Step37480, Loss: 3.4543328285217285, Grad L2 Norm: 0.022013608366250992
2025-11-24 00:51:01.537 | INFO     | __main__:<module>:160 - Step37490, Loss: 3.4793107509613037, Grad L2 Norm: 0.020806729793548584
2025-11-24 00:51:03.565 | INFO     | __main__:<module>:160 - Step37500, Loss: 3.5942158699035645, Grad L2 Norm: 0.021976836025714874
2025-11-24 00:51:05.598 | INFO     | __main__:<module>:160 - Step37510, Loss: 3.485051155090332, Grad L2 Norm: 0.02202025055885315
2025-11-24 00:51:07.623 | INFO     | __main__:<module>:160 - Step37520, Loss: 3.5255768299102783, Grad L2 Norm: 0.021449798718094826
2025-11-24 00:51:09.656 | INFO     | __main__:<module>:160 - Step37530, Loss: 3.6194417476654053, Grad L2 Norm: 0.022273914888501167
2025-11-24 00:51:11.684 | INFO     | __main__:<module>:160 - Step37540, Loss: 3.547987461090088, Grad L2 Norm: 0.022431474179029465
2025-11-24 00:51:13.716 | INFO     | __main__:<module>:160 - Step37550, Loss: 3.5800061225891113, Grad L2 Norm: 0.02352670580148697
2025-11-24 00:51:15.746 | INFO     | __main__:<module>:160 - Step37560, Loss: 3.513716220855713, Grad L2 Norm: 0.021059218794107437
2025-11-24 00:51:17.775 | INFO     | __main__:<module>:160 - Step37570, Loss: 3.536034107208252, Grad L2 Norm: 0.02258799411356449
2025-11-24 00:51:19.809 | INFO     | __main__:<module>:160 - Step37580, Loss: 3.579000234603882, Grad L2 Norm: 0.020649129524827003
2025-11-24 00:51:21.839 | INFO     | __main__:<module>:160 - Step37590, Loss: 3.41843318939209, Grad L2 Norm: 0.02231464721262455
2025-11-24 00:51:23.870 | INFO     | __main__:<module>:160 - Step37600, Loss: 3.4055681228637695, Grad L2 Norm: 0.0240614116191864
2025-11-24 00:51:23.871 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:51:25.157 | INFO     | __main__:<module>:181 - validation loss: 3.5789254784584044
2025-11-24 00:51:27.193 | INFO     | __main__:<module>:160 - Step37610, Loss: 3.531324863433838, Grad L2 Norm: 0.024393856525421143
2025-11-24 00:51:29.219 | INFO     | __main__:<module>:160 - Step37620, Loss: 3.6903936862945557, Grad L2 Norm: 0.022742627188563347
2025-11-24 00:51:31.244 | INFO     | __main__:<module>:160 - Step37630, Loss: 3.486971855163574, Grad L2 Norm: 0.02178369089961052
2025-11-24 00:51:33.269 | INFO     | __main__:<module>:160 - Step37640, Loss: 3.6027636528015137, Grad L2 Norm: 0.022287674248218536
2025-11-24 00:51:35.294 | INFO     | __main__:<module>:160 - Step37650, Loss: 3.6613306999206543, Grad L2 Norm: 0.022153547033667564
2025-11-24 00:51:37.321 | INFO     | __main__:<module>:160 - Step37660, Loss: 3.569237232208252, Grad L2 Norm: 0.02294418402016163
2025-11-24 00:51:39.349 | INFO     | __main__:<module>:160 - Step37670, Loss: 3.5479788780212402, Grad L2 Norm: 0.021762436255812645
2025-11-24 00:51:41.376 | INFO     | __main__:<module>:160 - Step37680, Loss: 3.5242972373962402, Grad L2 Norm: 0.020931227132678032
2025-11-24 00:51:43.406 | INFO     | __main__:<module>:160 - Step37690, Loss: 3.5479607582092285, Grad L2 Norm: 0.020773574709892273
2025-11-24 00:51:45.431 | INFO     | __main__:<module>:160 - Step37700, Loss: 3.5718483924865723, Grad L2 Norm: 0.022875037044286728
2025-11-24 00:51:47.457 | INFO     | __main__:<module>:160 - Step37710, Loss: 3.608665943145752, Grad L2 Norm: 0.02162747271358967
2025-11-24 00:51:49.482 | INFO     | __main__:<module>:160 - Step37720, Loss: 3.4580137729644775, Grad L2 Norm: 0.021483296528458595
2025-11-24 00:51:51.506 | INFO     | __main__:<module>:160 - Step37730, Loss: 3.5612168312072754, Grad L2 Norm: 0.02258448861539364
2025-11-24 00:51:53.530 | INFO     | __main__:<module>:160 - Step37740, Loss: 3.5061328411102295, Grad L2 Norm: 0.022540690377354622
2025-11-24 00:51:55.555 | INFO     | __main__:<module>:160 - Step37750, Loss: 3.52492094039917, Grad L2 Norm: 0.02259114384651184
2025-11-24 00:51:57.582 | INFO     | __main__:<module>:160 - Step37760, Loss: 3.5290517807006836, Grad L2 Norm: 0.021974695846438408
2025-11-24 00:51:59.604 | INFO     | __main__:<module>:160 - Step37770, Loss: 3.571359634399414, Grad L2 Norm: 0.02236960642039776
2025-11-24 00:52:01.628 | INFO     | __main__:<module>:160 - Step37780, Loss: 3.6502063274383545, Grad L2 Norm: 0.02226436138153076
2025-11-24 00:52:03.651 | INFO     | __main__:<module>:160 - Step37790, Loss: 3.493870735168457, Grad L2 Norm: 0.021703585982322693
2025-11-24 00:52:05.672 | INFO     | __main__:<module>:160 - Step37800, Loss: 3.5748205184936523, Grad L2 Norm: 0.020425481721758842
2025-11-24 00:52:07.689 | INFO     | __main__:<module>:160 - Step37810, Loss: 3.5364887714385986, Grad L2 Norm: 0.02255094237625599
2025-11-24 00:52:09.706 | INFO     | __main__:<module>:160 - Step37820, Loss: 3.6145741939544678, Grad L2 Norm: 0.022668296471238136
2025-11-24 00:52:11.728 | INFO     | __main__:<module>:160 - Step37830, Loss: 3.483419179916382, Grad L2 Norm: 0.023378748446702957
2025-11-24 00:52:13.755 | INFO     | __main__:<module>:160 - Step37840, Loss: 3.5746214389801025, Grad L2 Norm: 0.02173769846558571
2025-11-24 00:52:15.777 | INFO     | __main__:<module>:160 - Step37850, Loss: 3.620562791824341, Grad L2 Norm: 0.02136523276567459
2025-11-24 00:52:17.797 | INFO     | __main__:<module>:160 - Step37860, Loss: 3.6197900772094727, Grad L2 Norm: 0.022394051775336266
2025-11-24 00:52:19.817 | INFO     | __main__:<module>:160 - Step37870, Loss: 3.591618061065674, Grad L2 Norm: 0.02148018404841423
2025-11-24 00:52:21.832 | INFO     | __main__:<module>:160 - Step37880, Loss: 3.4776525497436523, Grad L2 Norm: 0.024614164605736732
2025-11-24 00:52:23.844 | INFO     | __main__:<module>:160 - Step37890, Loss: 3.596912384033203, Grad L2 Norm: 0.023658521473407745
2025-11-24 00:52:25.860 | INFO     | __main__:<module>:160 - Step37900, Loss: 3.6524856090545654, Grad L2 Norm: 0.02223762311041355
2025-11-24 00:52:27.875 | INFO     | __main__:<module>:160 - Step37910, Loss: 3.4492721557617188, Grad L2 Norm: 0.022499840706586838
2025-11-24 00:52:29.887 | INFO     | __main__:<module>:160 - Step37920, Loss: 3.6223578453063965, Grad L2 Norm: 0.0247571412473917
2025-11-24 00:52:31.897 | INFO     | __main__:<module>:160 - Step37930, Loss: 3.4985902309417725, Grad L2 Norm: 0.021304918453097343
2025-11-24 00:52:33.910 | INFO     | __main__:<module>:160 - Step37940, Loss: 3.411414861679077, Grad L2 Norm: 0.02233210578560829
2025-11-24 00:52:35.925 | INFO     | __main__:<module>:160 - Step37950, Loss: 3.5351614952087402, Grad L2 Norm: 0.02202894538640976
2025-11-24 00:52:37.940 | INFO     | __main__:<module>:160 - Step37960, Loss: 3.6636455059051514, Grad L2 Norm: 0.02317664958536625
2025-11-24 00:52:39.957 | INFO     | __main__:<module>:160 - Step37970, Loss: 3.4946584701538086, Grad L2 Norm: 0.022488519549369812
2025-11-24 00:52:41.977 | INFO     | __main__:<module>:160 - Step37980, Loss: 3.5700931549072266, Grad L2 Norm: 0.023357996717095375
2025-11-24 00:52:43.989 | INFO     | __main__:<module>:160 - Step37990, Loss: 3.6257119178771973, Grad L2 Norm: 0.0233293566852808
2025-11-24 00:52:46.004 | INFO     | __main__:<module>:160 - Step38000, Loss: 3.4843835830688477, Grad L2 Norm: 0.022854765877127647
2025-11-24 00:52:46.004 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:52:47.290 | INFO     | __main__:<module>:181 - validation loss: 3.588969326019287
2025-11-24 00:52:47.291 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_38000.pt
2025-11-24 00:52:48.958 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 00:52:50.949 | INFO     | __main__:<module>:160 - Step38010, Loss: 3.636094808578491, Grad L2 Norm: 0.024237632751464844
2025-11-24 00:52:52.954 | INFO     | __main__:<module>:160 - Step38020, Loss: 3.5781750679016113, Grad L2 Norm: 0.02233090065419674
2025-11-24 00:52:54.964 | INFO     | __main__:<module>:160 - Step38030, Loss: 3.6127803325653076, Grad L2 Norm: 0.02483053132891655
2025-11-24 00:52:56.972 | INFO     | __main__:<module>:160 - Step38040, Loss: 3.4726455211639404, Grad L2 Norm: 0.022816183045506477
2025-11-24 00:52:58.978 | INFO     | __main__:<module>:160 - Step38050, Loss: 3.5282135009765625, Grad L2 Norm: 0.02260948158800602
2025-11-24 00:53:00.985 | INFO     | __main__:<module>:160 - Step38060, Loss: 3.5636000633239746, Grad L2 Norm: 0.022944364696741104
2025-11-24 00:53:02.992 | INFO     | __main__:<module>:160 - Step38070, Loss: 3.5296688079833984, Grad L2 Norm: 0.022496746852993965
2025-11-24 00:53:05.003 | INFO     | __main__:<module>:160 - Step38080, Loss: 3.566962718963623, Grad L2 Norm: 0.023155396804213524
2025-11-24 00:53:07.010 | INFO     | __main__:<module>:160 - Step38090, Loss: 3.4883832931518555, Grad L2 Norm: 0.02070583775639534
2025-11-24 00:53:09.024 | INFO     | __main__:<module>:160 - Step38100, Loss: 3.629704475402832, Grad L2 Norm: 0.02216673083603382
2025-11-24 00:53:11.034 | INFO     | __main__:<module>:160 - Step38110, Loss: 3.629786491394043, Grad L2 Norm: 0.022855151444673538
2025-11-24 00:53:13.046 | INFO     | __main__:<module>:160 - Step38120, Loss: 3.511532783508301, Grad L2 Norm: 0.02154061757028103
2025-11-24 00:53:15.058 | INFO     | __main__:<module>:160 - Step38130, Loss: 3.5488100051879883, Grad L2 Norm: 0.022068381309509277
2025-11-24 00:53:17.069 | INFO     | __main__:<module>:160 - Step38140, Loss: 3.5904252529144287, Grad L2 Norm: 0.02200954779982567
2025-11-24 00:53:19.081 | INFO     | __main__:<module>:160 - Step38150, Loss: 3.654325485229492, Grad L2 Norm: 0.022595835849642754
2025-11-24 00:53:21.090 | INFO     | __main__:<module>:160 - Step38160, Loss: 3.4478330612182617, Grad L2 Norm: 0.023034177720546722
2025-11-24 00:53:23.104 | INFO     | __main__:<module>:160 - Step38170, Loss: 3.6483845710754395, Grad L2 Norm: 0.022482525557279587
2025-11-24 00:53:25.115 | INFO     | __main__:<module>:160 - Step38180, Loss: 3.590578079223633, Grad L2 Norm: 0.0219158623367548
2025-11-24 00:53:27.125 | INFO     | __main__:<module>:160 - Step38190, Loss: 3.4728732109069824, Grad L2 Norm: 0.02534445933997631
2025-11-24 00:53:29.138 | INFO     | __main__:<module>:160 - Step38200, Loss: 3.6289563179016113, Grad L2 Norm: 0.023763738572597504
2025-11-24 00:53:31.144 | INFO     | __main__:<module>:160 - Step38210, Loss: 3.4798152446746826, Grad L2 Norm: 0.023020945489406586
2025-11-24 00:53:33.155 | INFO     | __main__:<module>:160 - Step38220, Loss: 3.5576000213623047, Grad L2 Norm: 0.022867588326334953
2025-11-24 00:53:35.160 | INFO     | __main__:<module>:160 - Step38230, Loss: 3.6345207691192627, Grad L2 Norm: 0.024431871250271797
2025-11-24 00:53:37.165 | INFO     | __main__:<module>:160 - Step38240, Loss: 3.5416760444641113, Grad L2 Norm: 0.02265591360628605
2025-11-24 00:53:39.175 | INFO     | __main__:<module>:160 - Step38250, Loss: 3.570434808731079, Grad L2 Norm: 0.021224528551101685
2025-11-24 00:53:41.181 | INFO     | __main__:<module>:160 - Step38260, Loss: 3.5040383338928223, Grad L2 Norm: 0.02282710000872612
2025-11-24 00:53:43.194 | INFO     | __main__:<module>:160 - Step38270, Loss: 3.5013716220855713, Grad L2 Norm: 0.022930005565285683
2025-11-24 00:53:45.198 | INFO     | __main__:<module>:160 - Step38280, Loss: 3.435912847518921, Grad L2 Norm: 0.022095778957009315
2025-11-24 00:53:47.208 | INFO     | __main__:<module>:160 - Step38290, Loss: 3.5964016914367676, Grad L2 Norm: 0.023713411763310432
2025-11-24 00:53:49.217 | INFO     | __main__:<module>:160 - Step38300, Loss: 3.5386722087860107, Grad L2 Norm: 0.021468788385391235
2025-11-24 00:53:51.232 | INFO     | __main__:<module>:160 - Step38310, Loss: 3.4767513275146484, Grad L2 Norm: 0.023016715422272682
2025-11-24 00:53:53.243 | INFO     | __main__:<module>:160 - Step38320, Loss: 3.6418004035949707, Grad L2 Norm: 0.022739198058843613
2025-11-24 00:53:55.253 | INFO     | __main__:<module>:160 - Step38330, Loss: 3.6178364753723145, Grad L2 Norm: 0.022089384496212006
2025-11-24 00:53:57.254 | INFO     | __main__:<module>:160 - Step38340, Loss: 3.6807851791381836, Grad L2 Norm: 0.02469303086400032
2025-11-24 00:53:59.261 | INFO     | __main__:<module>:160 - Step38350, Loss: 3.4781956672668457, Grad L2 Norm: 0.022664932534098625
2025-11-24 00:54:01.268 | INFO     | __main__:<module>:160 - Step38360, Loss: 3.604842185974121, Grad L2 Norm: 0.023628313094377518
2025-11-24 00:54:03.271 | INFO     | __main__:<module>:160 - Step38370, Loss: 3.4921882152557373, Grad L2 Norm: 0.021739397197961807
2025-11-24 00:54:05.274 | INFO     | __main__:<module>:160 - Step38380, Loss: 3.5133419036865234, Grad L2 Norm: 0.022775420919060707
2025-11-24 00:54:07.281 | INFO     | __main__:<module>:160 - Step38390, Loss: 3.509331226348877, Grad L2 Norm: 0.021031763404607773
2025-11-24 00:54:09.284 | INFO     | __main__:<module>:160 - Step38400, Loss: 3.6596131324768066, Grad L2 Norm: 0.021954823285341263
2025-11-24 00:54:09.285 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:54:10.555 | INFO     | __main__:<module>:181 - validation loss: 3.5466267228126527
2025-11-24 00:54:12.564 | INFO     | __main__:<module>:160 - Step38410, Loss: 3.6267905235290527, Grad L2 Norm: 0.022392580285668373
2025-11-24 00:54:14.564 | INFO     | __main__:<module>:160 - Step38420, Loss: 3.5840635299682617, Grad L2 Norm: 0.023093922063708305
2025-11-24 00:54:16.563 | INFO     | __main__:<module>:160 - Step38430, Loss: 3.553811550140381, Grad L2 Norm: 0.02263827621936798
2025-11-24 00:54:18.563 | INFO     | __main__:<module>:160 - Step38440, Loss: 3.571568489074707, Grad L2 Norm: 0.024091780185699463
2025-11-24 00:54:20.561 | INFO     | __main__:<module>:160 - Step38450, Loss: 3.62131404876709, Grad L2 Norm: 0.022516906261444092
2025-11-24 00:54:22.557 | INFO     | __main__:<module>:160 - Step38460, Loss: 3.5644171237945557, Grad L2 Norm: 0.025297539308667183
2025-11-24 00:54:24.558 | INFO     | __main__:<module>:160 - Step38470, Loss: 3.584660053253174, Grad L2 Norm: 0.023944688960909843
2025-11-24 00:54:26.558 | INFO     | __main__:<module>:160 - Step38480, Loss: 3.7274725437164307, Grad L2 Norm: 0.026080619543790817
2025-11-24 00:54:28.560 | INFO     | __main__:<module>:160 - Step38490, Loss: 3.545665740966797, Grad L2 Norm: 0.021694673225283623
2025-11-24 00:54:30.558 | INFO     | __main__:<module>:160 - Step38500, Loss: 3.5067734718322754, Grad L2 Norm: 0.02320018596947193
2025-11-24 00:54:32.556 | INFO     | __main__:<module>:160 - Step38510, Loss: 3.515530586242676, Grad L2 Norm: 0.02298635244369507
2025-11-24 00:54:34.558 | INFO     | __main__:<module>:160 - Step38520, Loss: 3.4442999362945557, Grad L2 Norm: 0.02281413972377777
2025-11-24 00:54:36.556 | INFO     | __main__:<module>:160 - Step38530, Loss: 3.6178200244903564, Grad L2 Norm: 0.024573208764195442
2025-11-24 00:54:38.553 | INFO     | __main__:<module>:160 - Step38540, Loss: 3.527902841567993, Grad L2 Norm: 0.022129520773887634
2025-11-24 00:54:40.549 | INFO     | __main__:<module>:160 - Step38550, Loss: 3.4897775650024414, Grad L2 Norm: 0.022288983687758446
2025-11-24 00:54:42.544 | INFO     | __main__:<module>:160 - Step38560, Loss: 3.470250129699707, Grad L2 Norm: 0.021938282996416092
2025-11-24 00:54:44.534 | INFO     | __main__:<module>:160 - Step38570, Loss: 3.548156261444092, Grad L2 Norm: 0.022841185331344604
2025-11-24 00:54:46.527 | INFO     | __main__:<module>:160 - Step38580, Loss: 3.5263049602508545, Grad L2 Norm: 0.02274051308631897
2025-11-24 00:54:48.526 | INFO     | __main__:<module>:160 - Step38590, Loss: 3.552856922149658, Grad L2 Norm: 0.022336412221193314
2025-11-24 00:54:50.527 | INFO     | __main__:<module>:160 - Step38600, Loss: 3.526352882385254, Grad L2 Norm: 0.0226126741617918
2025-11-24 00:54:52.521 | INFO     | __main__:<module>:160 - Step38610, Loss: 3.559515953063965, Grad L2 Norm: 0.021055730059742928
2025-11-24 00:54:54.511 | INFO     | __main__:<module>:160 - Step38620, Loss: 3.6251673698425293, Grad L2 Norm: 0.02335742674767971
2025-11-24 00:54:56.506 | INFO     | __main__:<module>:160 - Step38630, Loss: 3.6279406547546387, Grad L2 Norm: 0.022633139044046402
2025-11-24 00:54:58.497 | INFO     | __main__:<module>:160 - Step38640, Loss: 3.57065486907959, Grad L2 Norm: 0.022988826036453247
2025-11-24 00:55:00.484 | INFO     | __main__:<module>:160 - Step38650, Loss: 3.707639694213867, Grad L2 Norm: 0.024540258571505547
2025-11-24 00:55:02.482 | INFO     | __main__:<module>:160 - Step38660, Loss: 3.6573946475982666, Grad L2 Norm: 0.02192884497344494
2025-11-24 00:55:04.481 | INFO     | __main__:<module>:160 - Step38670, Loss: 3.5684518814086914, Grad L2 Norm: 0.02258157730102539
2025-11-24 00:55:06.483 | INFO     | __main__:<module>:160 - Step38680, Loss: 3.6633458137512207, Grad L2 Norm: 0.02179907076060772
2025-11-24 00:55:08.481 | INFO     | __main__:<module>:160 - Step38690, Loss: 3.619086265563965, Grad L2 Norm: 0.02320259064435959
2025-11-24 00:55:10.480 | INFO     | __main__:<module>:160 - Step38700, Loss: 3.5804316997528076, Grad L2 Norm: 0.02393408864736557
2025-11-24 00:55:12.479 | INFO     | __main__:<module>:160 - Step38710, Loss: 3.7127628326416016, Grad L2 Norm: 0.02402561902999878
2025-11-24 00:55:14.479 | INFO     | __main__:<module>:160 - Step38720, Loss: 3.53086519241333, Grad L2 Norm: 0.0224690493196249
2025-11-24 00:55:16.479 | INFO     | __main__:<module>:160 - Step38730, Loss: 3.52462100982666, Grad L2 Norm: 0.02331681363284588
2025-11-24 00:55:18.477 | INFO     | __main__:<module>:160 - Step38740, Loss: 3.7185161113739014, Grad L2 Norm: 0.025384875014424324
2025-11-24 00:55:20.477 | INFO     | __main__:<module>:160 - Step38750, Loss: 3.706892251968384, Grad L2 Norm: 0.024539822712540627
2025-11-24 00:55:22.475 | INFO     | __main__:<module>:160 - Step38760, Loss: 3.6912312507629395, Grad L2 Norm: 0.02336021512746811
2025-11-24 00:55:24.476 | INFO     | __main__:<module>:160 - Step38770, Loss: 3.5215463638305664, Grad L2 Norm: 0.022850895300507545
2025-11-24 00:55:26.475 | INFO     | __main__:<module>:160 - Step38780, Loss: 3.5303845405578613, Grad L2 Norm: 0.02266291342675686
2025-11-24 00:55:28.472 | INFO     | __main__:<module>:160 - Step38790, Loss: 3.456428050994873, Grad L2 Norm: 0.022942060604691505
2025-11-24 00:55:30.460 | INFO     | __main__:<module>:160 - Step38800, Loss: 3.606186628341675, Grad L2 Norm: 0.0233409833163023
2025-11-24 00:55:30.461 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:55:31.725 | INFO     | __main__:<module>:181 - validation loss: 3.5668567419052124
2025-11-24 00:55:33.721 | INFO     | __main__:<module>:160 - Step38810, Loss: 3.51859188079834, Grad L2 Norm: 0.022312946617603302
2025-11-24 00:55:35.713 | INFO     | __main__:<module>:160 - Step38820, Loss: 3.6304686069488525, Grad L2 Norm: 0.02091042324900627
2025-11-24 00:55:37.709 | INFO     | __main__:<module>:160 - Step38830, Loss: 3.642652988433838, Grad L2 Norm: 0.022383777424693108
2025-11-24 00:55:39.692 | INFO     | __main__:<module>:160 - Step38840, Loss: 3.622872829437256, Grad L2 Norm: 0.025289660319685936
2025-11-24 00:55:41.674 | INFO     | __main__:<module>:160 - Step38850, Loss: 3.5285305976867676, Grad L2 Norm: 0.02507694996893406
2025-11-24 00:55:43.653 | INFO     | __main__:<module>:160 - Step38860, Loss: 3.5187175273895264, Grad L2 Norm: 0.02456430345773697
2025-11-24 00:55:45.638 | INFO     | __main__:<module>:160 - Step38870, Loss: 3.440424680709839, Grad L2 Norm: 0.02235768362879753
2025-11-24 00:55:47.627 | INFO     | __main__:<module>:160 - Step38880, Loss: 3.4434518814086914, Grad L2 Norm: 0.021165432408452034
2025-11-24 00:55:49.611 | INFO     | __main__:<module>:160 - Step38890, Loss: 3.593783378601074, Grad L2 Norm: 0.023628342896699905
2025-11-24 00:55:51.598 | INFO     | __main__:<module>:160 - Step38900, Loss: 3.517167806625366, Grad L2 Norm: 0.022602561861276627
2025-11-24 00:55:53.588 | INFO     | __main__:<module>:160 - Step38910, Loss: 3.5593857765197754, Grad L2 Norm: 0.026050280779600143
2025-11-24 00:55:55.583 | INFO     | __main__:<module>:160 - Step38920, Loss: 3.574892997741699, Grad L2 Norm: 0.023123936727643013
2025-11-24 00:55:57.579 | INFO     | __main__:<module>:160 - Step38930, Loss: 3.5566611289978027, Grad L2 Norm: 0.02258220501244068
2025-11-24 00:55:59.570 | INFO     | __main__:<module>:160 - Step38940, Loss: 3.561450242996216, Grad L2 Norm: 0.02150631509721279
2025-11-24 00:56:01.568 | INFO     | __main__:<module>:160 - Step38950, Loss: 3.516906261444092, Grad L2 Norm: 0.023484840989112854
2025-11-24 00:56:03.564 | INFO     | __main__:<module>:160 - Step38960, Loss: 3.6374919414520264, Grad L2 Norm: 0.021618427708745003
2025-11-24 00:56:05.563 | INFO     | __main__:<module>:160 - Step38970, Loss: 3.7169694900512695, Grad L2 Norm: 0.02257811278104782
2025-11-24 00:56:07.563 | INFO     | __main__:<module>:160 - Step38980, Loss: 3.4155867099761963, Grad L2 Norm: 0.0217586699873209
2025-11-24 00:56:09.562 | INFO     | __main__:<module>:160 - Step38990, Loss: 3.554453134536743, Grad L2 Norm: 0.022944999858736992
2025-11-24 00:56:11.559 | INFO     | __main__:<module>:160 - Step39000, Loss: 3.719991683959961, Grad L2 Norm: 0.024135928601026535
2025-11-24 00:56:13.554 | INFO     | __main__:<module>:160 - Step39010, Loss: 3.569847345352173, Grad L2 Norm: 0.024276578798890114
2025-11-24 00:56:15.549 | INFO     | __main__:<module>:160 - Step39020, Loss: 3.4700560569763184, Grad L2 Norm: 0.021382316946983337
2025-11-24 00:56:17.544 | INFO     | __main__:<module>:160 - Step39030, Loss: 3.4740302562713623, Grad L2 Norm: 0.022993525490164757
2025-11-24 00:56:19.543 | INFO     | __main__:<module>:160 - Step39040, Loss: 3.6497414112091064, Grad L2 Norm: 0.023245807737112045
2025-11-24 00:56:21.543 | INFO     | __main__:<module>:160 - Step39050, Loss: 3.5059168338775635, Grad L2 Norm: 0.024230873212218285
2025-11-24 00:56:23.540 | INFO     | __main__:<module>:160 - Step39060, Loss: 3.4795398712158203, Grad L2 Norm: 0.02256990782916546
2025-11-24 00:56:25.538 | INFO     | __main__:<module>:160 - Step39070, Loss: 3.771123170852661, Grad L2 Norm: 0.0231194905936718
2025-11-24 00:56:27.536 | INFO     | __main__:<module>:160 - Step39080, Loss: 3.5823557376861572, Grad L2 Norm: 0.022934386506676674
2025-11-24 00:56:29.536 | INFO     | __main__:<module>:160 - Step39090, Loss: 3.5167553424835205, Grad L2 Norm: 0.023368969559669495
2025-11-24 00:56:31.534 | INFO     | __main__:<module>:160 - Step39100, Loss: 3.583961009979248, Grad L2 Norm: 0.022531256079673767
2025-11-24 00:56:33.522 | INFO     | __main__:<module>:160 - Step39110, Loss: 3.615867853164673, Grad L2 Norm: 0.023276926949620247
2025-11-24 00:56:35.514 | INFO     | __main__:<module>:160 - Step39120, Loss: 3.6180806159973145, Grad L2 Norm: 0.023529784753918648
2025-11-24 00:56:37.506 | INFO     | __main__:<module>:160 - Step39130, Loss: 3.4233953952789307, Grad L2 Norm: 0.02300475724041462
2025-11-24 00:56:39.495 | INFO     | __main__:<module>:160 - Step39140, Loss: 3.483841896057129, Grad L2 Norm: 0.022350918501615524
2025-11-24 00:56:41.491 | INFO     | __main__:<module>:160 - Step39150, Loss: 3.495065689086914, Grad L2 Norm: 0.02074177749454975
2025-11-24 00:56:43.480 | INFO     | __main__:<module>:160 - Step39160, Loss: 3.5959625244140625, Grad L2 Norm: 0.022153513506054878
2025-11-24 00:56:45.472 | INFO     | __main__:<module>:160 - Step39170, Loss: 3.4628520011901855, Grad L2 Norm: 0.02296089194715023
2025-11-24 00:56:47.460 | INFO     | __main__:<module>:160 - Step39180, Loss: 3.566582202911377, Grad L2 Norm: 0.02059398591518402
2025-11-24 00:56:49.452 | INFO     | __main__:<module>:160 - Step39190, Loss: 3.5721375942230225, Grad L2 Norm: 0.022259334102272987
2025-11-24 00:56:51.448 | INFO     | __main__:<module>:160 - Step39200, Loss: 3.5853354930877686, Grad L2 Norm: 0.021382838487625122
2025-11-24 00:56:51.449 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:56:52.712 | INFO     | __main__:<module>:181 - validation loss: 3.567618429660797
2025-11-24 00:56:54.711 | INFO     | __main__:<module>:160 - Step39210, Loss: 3.611936092376709, Grad L2 Norm: 0.02231127768754959
2025-11-24 00:56:56.709 | INFO     | __main__:<module>:160 - Step39220, Loss: 3.7236719131469727, Grad L2 Norm: 0.022631213068962097
2025-11-24 00:56:58.708 | INFO     | __main__:<module>:160 - Step39230, Loss: 3.540761709213257, Grad L2 Norm: 0.02435983531177044
2025-11-24 00:57:00.705 | INFO     | __main__:<module>:160 - Step39240, Loss: 3.6892173290252686, Grad L2 Norm: 0.022534597665071487
2025-11-24 00:57:02.698 | INFO     | __main__:<module>:160 - Step39250, Loss: 3.4615964889526367, Grad L2 Norm: 0.021552540361881256
2025-11-24 00:57:04.690 | INFO     | __main__:<module>:160 - Step39260, Loss: 3.5468804836273193, Grad L2 Norm: 0.021557429805397987
2025-11-24 00:57:06.687 | INFO     | __main__:<module>:160 - Step39270, Loss: 3.7205519676208496, Grad L2 Norm: 0.02214679680764675
2025-11-24 00:57:08.684 | INFO     | __main__:<module>:160 - Step39280, Loss: 3.5872902870178223, Grad L2 Norm: 0.02294602431356907
2025-11-24 00:57:10.683 | INFO     | __main__:<module>:160 - Step39290, Loss: 3.5584254264831543, Grad L2 Norm: 0.024226143956184387
2025-11-24 00:57:12.682 | INFO     | __main__:<module>:160 - Step39300, Loss: 3.623213291168213, Grad L2 Norm: 0.021514425054192543
2025-11-24 00:57:14.681 | INFO     | __main__:<module>:160 - Step39310, Loss: 3.725520372390747, Grad L2 Norm: 0.02400076389312744
2025-11-24 00:57:16.682 | INFO     | __main__:<module>:160 - Step39320, Loss: 3.547100782394409, Grad L2 Norm: 0.025130413472652435
2025-11-24 00:57:18.683 | INFO     | __main__:<module>:160 - Step39330, Loss: 3.544506072998047, Grad L2 Norm: 0.023051433265209198
2025-11-24 00:57:20.681 | INFO     | __main__:<module>:160 - Step39340, Loss: 3.627621650695801, Grad L2 Norm: 0.02311849221587181
2025-11-24 00:57:22.679 | INFO     | __main__:<module>:160 - Step39350, Loss: 3.4648778438568115, Grad L2 Norm: 0.02169293724000454
2025-11-24 00:57:24.679 | INFO     | __main__:<module>:160 - Step39360, Loss: 3.638631582260132, Grad L2 Norm: 0.022692566737532616
2025-11-24 00:57:26.679 | INFO     | __main__:<module>:160 - Step39370, Loss: 3.5376968383789062, Grad L2 Norm: 0.022125093266367912
2025-11-24 00:57:28.678 | INFO     | __main__:<module>:160 - Step39380, Loss: 3.61185359954834, Grad L2 Norm: 0.021265288814902306
2025-11-24 00:57:30.679 | INFO     | __main__:<module>:160 - Step39390, Loss: 3.6407623291015625, Grad L2 Norm: 0.021581873297691345
2025-11-24 00:57:32.679 | INFO     | __main__:<module>:160 - Step39400, Loss: 3.4681148529052734, Grad L2 Norm: 0.02239913120865822
2025-11-24 00:57:34.680 | INFO     | __main__:<module>:160 - Step39410, Loss: 3.712656259536743, Grad L2 Norm: 0.026807231828570366
2025-11-24 00:57:36.679 | INFO     | __main__:<module>:160 - Step39420, Loss: 3.5585129261016846, Grad L2 Norm: 0.022491350769996643
2025-11-24 00:57:38.679 | INFO     | __main__:<module>:160 - Step39430, Loss: 3.5976457595825195, Grad L2 Norm: 0.02266456000506878
2025-11-24 00:57:40.676 | INFO     | __main__:<module>:160 - Step39440, Loss: 3.7466986179351807, Grad L2 Norm: 0.022886402904987335
2025-11-24 00:57:42.673 | INFO     | __main__:<module>:160 - Step39450, Loss: 3.5657005310058594, Grad L2 Norm: 0.022911150008440018
2025-11-24 00:57:44.671 | INFO     | __main__:<module>:160 - Step39460, Loss: 3.6561591625213623, Grad L2 Norm: 0.02155051752924919
2025-11-24 00:57:46.672 | INFO     | __main__:<module>:160 - Step39470, Loss: 3.6662909984588623, Grad L2 Norm: 0.024373497813940048
2025-11-24 00:57:48.671 | INFO     | __main__:<module>:160 - Step39480, Loss: 3.496856689453125, Grad L2 Norm: 0.022786496207118034
2025-11-24 00:57:50.669 | INFO     | __main__:<module>:160 - Step39490, Loss: 3.625218391418457, Grad L2 Norm: 0.02308008074760437
2025-11-24 00:57:52.668 | INFO     | __main__:<module>:160 - Step39500, Loss: 3.512120246887207, Grad L2 Norm: 0.022672617807984352
2025-11-24 00:57:54.669 | INFO     | __main__:<module>:160 - Step39510, Loss: 3.577234983444214, Grad L2 Norm: 0.022406065836548805
2025-11-24 00:57:56.669 | INFO     | __main__:<module>:160 - Step39520, Loss: 3.5359761714935303, Grad L2 Norm: 0.02660786733031273
2025-11-24 00:57:58.665 | INFO     | __main__:<module>:160 - Step39530, Loss: 3.48564076423645, Grad L2 Norm: 0.020921804010868073
2025-11-24 00:58:00.654 | INFO     | __main__:<module>:160 - Step39540, Loss: 3.7673282623291016, Grad L2 Norm: 0.02393730729818344
2025-11-24 00:58:02.645 | INFO     | __main__:<module>:160 - Step39550, Loss: 3.6635098457336426, Grad L2 Norm: 0.023801390081644058
2025-11-24 00:58:04.634 | INFO     | __main__:<module>:160 - Step39560, Loss: 3.5983214378356934, Grad L2 Norm: 0.02280208095908165
2025-11-24 00:58:06.625 | INFO     | __main__:<module>:160 - Step39570, Loss: 3.4999396800994873, Grad L2 Norm: 0.023365063592791557
2025-11-24 00:58:08.624 | INFO     | __main__:<module>:160 - Step39580, Loss: 3.6022145748138428, Grad L2 Norm: 0.023475447669625282
2025-11-24 00:58:10.611 | INFO     | __main__:<module>:160 - Step39590, Loss: 3.531904697418213, Grad L2 Norm: 0.0211536455899477
2025-11-24 00:58:12.604 | INFO     | __main__:<module>:160 - Step39600, Loss: 3.5368895530700684, Grad L2 Norm: 0.021489130333065987
2025-11-24 00:58:12.605 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:58:13.870 | INFO     | __main__:<module>:181 - validation loss: 3.550528073310852
2025-11-24 00:58:15.867 | INFO     | __main__:<module>:160 - Step39610, Loss: 3.7178382873535156, Grad L2 Norm: 0.023597126826643944
2025-11-24 00:58:17.858 | INFO     | __main__:<module>:160 - Step39620, Loss: 3.394500970840454, Grad L2 Norm: 0.025268778204917908
2025-11-24 00:58:19.845 | INFO     | __main__:<module>:160 - Step39630, Loss: 3.6381611824035645, Grad L2 Norm: 0.023761305958032608
2025-11-24 00:58:21.828 | INFO     | __main__:<module>:160 - Step39640, Loss: 3.6868295669555664, Grad L2 Norm: 0.023543760180473328
2025-11-24 00:58:23.813 | INFO     | __main__:<module>:160 - Step39650, Loss: 3.5886964797973633, Grad L2 Norm: 0.021593652665615082
2025-11-24 00:58:25.800 | INFO     | __main__:<module>:160 - Step39660, Loss: 3.451706886291504, Grad L2 Norm: 0.023506993427872658
2025-11-24 00:58:27.786 | INFO     | __main__:<module>:160 - Step39670, Loss: 3.5531327724456787, Grad L2 Norm: 0.021210825070738792
2025-11-24 00:58:29.768 | INFO     | __main__:<module>:160 - Step39680, Loss: 3.5311217308044434, Grad L2 Norm: 0.022540830075740814
2025-11-24 00:58:31.749 | INFO     | __main__:<module>:160 - Step39690, Loss: 3.486793041229248, Grad L2 Norm: 0.02370716631412506
2025-11-24 00:58:33.732 | INFO     | __main__:<module>:160 - Step39700, Loss: 3.4969706535339355, Grad L2 Norm: 0.02124212309718132
2025-11-24 00:58:35.713 | INFO     | __main__:<module>:160 - Step39710, Loss: 3.625657320022583, Grad L2 Norm: 0.023349132388830185
2025-11-24 00:58:37.697 | INFO     | __main__:<module>:160 - Step39720, Loss: 3.6368699073791504, Grad L2 Norm: 0.02233133465051651
2025-11-24 00:58:39.684 | INFO     | __main__:<module>:160 - Step39730, Loss: 3.590043544769287, Grad L2 Norm: 0.02307530865073204
2025-11-24 00:58:41.673 | INFO     | __main__:<module>:160 - Step39740, Loss: 3.5828185081481934, Grad L2 Norm: 0.02148744836449623
2025-11-24 00:58:43.656 | INFO     | __main__:<module>:160 - Step39750, Loss: 3.5672836303710938, Grad L2 Norm: 0.02331637591123581
2025-11-24 00:58:45.644 | INFO     | __main__:<module>:160 - Step39760, Loss: 3.566112518310547, Grad L2 Norm: 0.02362566441297531
2025-11-24 00:58:47.631 | INFO     | __main__:<module>:160 - Step39770, Loss: 3.5954806804656982, Grad L2 Norm: 0.024110443890094757
2025-11-24 00:58:49.620 | INFO     | __main__:<module>:160 - Step39780, Loss: 3.58490252494812, Grad L2 Norm: 0.022741898894309998
2025-11-24 00:58:51.610 | INFO     | __main__:<module>:160 - Step39790, Loss: 3.5408554077148438, Grad L2 Norm: 0.02187490090727806
2025-11-24 00:58:53.597 | INFO     | __main__:<module>:160 - Step39800, Loss: 3.490992546081543, Grad L2 Norm: 0.02250155620276928
2025-11-24 00:58:55.589 | INFO     | __main__:<module>:160 - Step39810, Loss: 3.572166681289673, Grad L2 Norm: 0.024901380762457848
2025-11-24 00:58:57.577 | INFO     | __main__:<module>:160 - Step39820, Loss: 3.5858564376831055, Grad L2 Norm: 0.022609423846006393
2025-11-24 00:58:59.569 | INFO     | __main__:<module>:160 - Step39830, Loss: 3.656097888946533, Grad L2 Norm: 0.0228278748691082
2025-11-24 00:59:01.554 | INFO     | __main__:<module>:160 - Step39840, Loss: 3.473099946975708, Grad L2 Norm: 0.02331545762717724
2025-11-24 00:59:03.545 | INFO     | __main__:<module>:160 - Step39850, Loss: 3.696470022201538, Grad L2 Norm: 0.024005044251680374
2025-11-24 00:59:05.532 | INFO     | __main__:<module>:160 - Step39860, Loss: 3.5237479209899902, Grad L2 Norm: 0.023405177518725395
2025-11-24 00:59:07.524 | INFO     | __main__:<module>:160 - Step39870, Loss: 3.474860668182373, Grad L2 Norm: 0.021765323355793953
2025-11-24 00:59:09.513 | INFO     | __main__:<module>:160 - Step39880, Loss: 3.5567169189453125, Grad L2 Norm: 0.02230112999677658
2025-11-24 00:59:11.504 | INFO     | __main__:<module>:160 - Step39890, Loss: 3.485146999359131, Grad L2 Norm: 0.023541485890746117
2025-11-24 00:59:13.493 | INFO     | __main__:<module>:160 - Step39900, Loss: 3.474165916442871, Grad L2 Norm: 0.02212120220065117
2025-11-24 00:59:15.481 | INFO     | __main__:<module>:160 - Step39910, Loss: 3.5337843894958496, Grad L2 Norm: 0.02185695990920067
2025-11-24 00:59:17.466 | INFO     | __main__:<module>:160 - Step39920, Loss: 3.527320146560669, Grad L2 Norm: 0.024890588596463203
2025-11-24 00:59:19.452 | INFO     | __main__:<module>:160 - Step39930, Loss: 3.43900465965271, Grad L2 Norm: 0.021805264055728912
2025-11-24 00:59:21.435 | INFO     | __main__:<module>:160 - Step39940, Loss: 3.59696364402771, Grad L2 Norm: 0.022573594003915787
2025-11-24 00:59:23.421 | INFO     | __main__:<module>:160 - Step39950, Loss: 3.486135244369507, Grad L2 Norm: 0.02166571654379368
2025-11-24 00:59:25.403 | INFO     | __main__:<module>:160 - Step39960, Loss: 3.612091541290283, Grad L2 Norm: 0.025368595495820045
2025-11-24 00:59:27.387 | INFO     | __main__:<module>:160 - Step39970, Loss: 3.5334558486938477, Grad L2 Norm: 0.02254013903439045
2025-11-24 00:59:29.376 | INFO     | __main__:<module>:160 - Step39980, Loss: 3.4588403701782227, Grad L2 Norm: 0.021432923153042793
2025-11-24 00:59:31.360 | INFO     | __main__:<module>:160 - Step39990, Loss: 3.4366884231567383, Grad L2 Norm: 0.022218456491827965
2025-11-24 00:59:33.349 | INFO     | __main__:<module>:160 - Step40000, Loss: 3.613910675048828, Grad L2 Norm: 0.02151624672114849
2025-11-24 00:59:33.349 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 00:59:34.609 | INFO     | __main__:<module>:181 - validation loss: 3.5576006531715394
2025-11-24 00:59:34.610 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_40000.pt
2025-11-24 00:59:36.396 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 00:59:38.362 | INFO     | __main__:<module>:160 - Step40010, Loss: 3.5008020401000977, Grad L2 Norm: 0.021354418247938156
2025-11-24 00:59:40.353 | INFO     | __main__:<module>:160 - Step40020, Loss: 3.5498743057250977, Grad L2 Norm: 0.023694975301623344
2025-11-24 00:59:42.339 | INFO     | __main__:<module>:160 - Step40030, Loss: 3.561882257461548, Grad L2 Norm: 0.022872421890497208
2025-11-24 00:59:44.329 | INFO     | __main__:<module>:160 - Step40040, Loss: 3.613996982574463, Grad L2 Norm: 0.026508457958698273
2025-11-24 00:59:46.315 | INFO     | __main__:<module>:160 - Step40050, Loss: 3.6562352180480957, Grad L2 Norm: 0.023226367309689522
2025-11-24 00:59:48.305 | INFO     | __main__:<module>:160 - Step40060, Loss: 3.62554931640625, Grad L2 Norm: 0.023482611402869225
2025-11-24 00:59:50.295 | INFO     | __main__:<module>:160 - Step40070, Loss: 3.6192679405212402, Grad L2 Norm: 0.022070733830332756
2025-11-24 00:59:52.293 | INFO     | __main__:<module>:160 - Step40080, Loss: 3.5861167907714844, Grad L2 Norm: 0.02363881841301918
2025-11-24 00:59:54.290 | INFO     | __main__:<module>:160 - Step40090, Loss: 3.6114187240600586, Grad L2 Norm: 0.022513585165143013
2025-11-24 00:59:56.289 | INFO     | __main__:<module>:160 - Step40100, Loss: 3.61452054977417, Grad L2 Norm: 0.02388313040137291
2025-11-24 00:59:58.286 | INFO     | __main__:<module>:160 - Step40110, Loss: 3.6552910804748535, Grad L2 Norm: 0.022558143362402916
2025-11-24 01:00:00.284 | INFO     | __main__:<module>:160 - Step40120, Loss: 3.601935625076294, Grad L2 Norm: 0.025150949135422707
2025-11-24 01:00:02.275 | INFO     | __main__:<module>:160 - Step40130, Loss: 3.5905704498291016, Grad L2 Norm: 0.025619782507419586
2025-11-24 01:00:04.271 | INFO     | __main__:<module>:160 - Step40140, Loss: 3.59128999710083, Grad L2 Norm: 0.022386370226740837
2025-11-24 01:00:06.268 | INFO     | __main__:<module>:160 - Step40150, Loss: 3.612898349761963, Grad L2 Norm: 0.023245669901371002
2025-11-24 01:00:08.267 | INFO     | __main__:<module>:160 - Step40160, Loss: 3.5223116874694824, Grad L2 Norm: 0.02212364226579666
2025-11-24 01:00:10.264 | INFO     | __main__:<module>:160 - Step40170, Loss: 3.5267386436462402, Grad L2 Norm: 0.023351453244686127
2025-11-24 01:00:12.266 | INFO     | __main__:<module>:160 - Step40180, Loss: 3.6987695693969727, Grad L2 Norm: 0.024154210463166237
2025-11-24 01:00:14.265 | INFO     | __main__:<module>:160 - Step40190, Loss: 3.5949249267578125, Grad L2 Norm: 0.022125335410237312
2025-11-24 01:00:16.266 | INFO     | __main__:<module>:160 - Step40200, Loss: 3.6334099769592285, Grad L2 Norm: 0.024090752005577087
2025-11-24 01:00:18.266 | INFO     | __main__:<module>:160 - Step40210, Loss: 3.6352460384368896, Grad L2 Norm: 0.024578046053647995
2025-11-24 01:00:20.265 | INFO     | __main__:<module>:160 - Step40220, Loss: 3.539358615875244, Grad L2 Norm: 0.023454878479242325
2025-11-24 01:00:22.268 | INFO     | __main__:<module>:160 - Step40230, Loss: 3.6550135612487793, Grad L2 Norm: 0.023801539093255997
2025-11-24 01:00:24.267 | INFO     | __main__:<module>:160 - Step40240, Loss: 3.5663318634033203, Grad L2 Norm: 0.021035250276327133
2025-11-24 01:00:26.266 | INFO     | __main__:<module>:160 - Step40250, Loss: 3.543606996536255, Grad L2 Norm: 0.024705467745661736
2025-11-24 01:00:28.265 | INFO     | __main__:<module>:160 - Step40260, Loss: 3.606236457824707, Grad L2 Norm: 0.02196574956178665
2025-11-24 01:00:30.265 | INFO     | __main__:<module>:160 - Step40270, Loss: 3.419510841369629, Grad L2 Norm: 0.022198285907506943
2025-11-24 01:00:32.265 | INFO     | __main__:<module>:160 - Step40280, Loss: 3.5705480575561523, Grad L2 Norm: 0.023515067994594574
2025-11-24 01:00:34.264 | INFO     | __main__:<module>:160 - Step40290, Loss: 3.6469743251800537, Grad L2 Norm: 0.024182328954339027
2025-11-24 01:00:36.262 | INFO     | __main__:<module>:160 - Step40300, Loss: 3.643922805786133, Grad L2 Norm: 0.022330762818455696
2025-11-24 01:00:38.260 | INFO     | __main__:<module>:160 - Step40310, Loss: 3.4555227756500244, Grad L2 Norm: 0.02236557938158512
2025-11-24 01:00:40.257 | INFO     | __main__:<module>:160 - Step40320, Loss: 3.550314426422119, Grad L2 Norm: 0.022530362010002136
2025-11-24 01:00:42.249 | INFO     | __main__:<module>:160 - Step40330, Loss: 3.5039849281311035, Grad L2 Norm: 0.021580785512924194
2025-11-24 01:00:44.237 | INFO     | __main__:<module>:160 - Step40340, Loss: 3.6022157669067383, Grad L2 Norm: 0.022716019302606583
2025-11-24 01:00:46.227 | INFO     | __main__:<module>:160 - Step40350, Loss: 3.631101131439209, Grad L2 Norm: 0.021779583767056465
2025-11-24 01:00:48.217 | INFO     | __main__:<module>:160 - Step40360, Loss: 3.47257661819458, Grad L2 Norm: 0.02224212884902954
2025-11-24 01:00:50.211 | INFO     | __main__:<module>:160 - Step40370, Loss: 3.530890941619873, Grad L2 Norm: 0.022026678547263145
2025-11-24 01:00:52.200 | INFO     | __main__:<module>:160 - Step40380, Loss: 3.5020313262939453, Grad L2 Norm: 0.02264351025223732
2025-11-24 01:00:54.193 | INFO     | __main__:<module>:160 - Step40390, Loss: 3.7061240673065186, Grad L2 Norm: 0.024355923756957054
2025-11-24 01:00:56.188 | INFO     | __main__:<module>:160 - Step40400, Loss: 3.5855069160461426, Grad L2 Norm: 0.021426256746053696
2025-11-24 01:00:56.188 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:00:57.454 | INFO     | __main__:<module>:181 - validation loss: 3.5578795790672304
2025-11-24 01:00:59.452 | INFO     | __main__:<module>:160 - Step40410, Loss: 3.5899925231933594, Grad L2 Norm: 0.02372952550649643
2025-11-24 01:01:01.453 | INFO     | __main__:<module>:160 - Step40420, Loss: 3.443959951400757, Grad L2 Norm: 0.021532762795686722
2025-11-24 01:01:03.446 | INFO     | __main__:<module>:160 - Step40430, Loss: 3.642458915710449, Grad L2 Norm: 0.026345444843173027
2025-11-24 01:01:05.434 | INFO     | __main__:<module>:160 - Step40440, Loss: 3.5165963172912598, Grad L2 Norm: 0.024859298020601273
2025-11-24 01:01:07.429 | INFO     | __main__:<module>:160 - Step40450, Loss: 3.56656551361084, Grad L2 Norm: 0.02224627509713173
2025-11-24 01:01:09.427 | INFO     | __main__:<module>:160 - Step40460, Loss: 3.5449588298797607, Grad L2 Norm: 0.02412394806742668
2025-11-24 01:01:11.426 | INFO     | __main__:<module>:160 - Step40470, Loss: 3.593944549560547, Grad L2 Norm: 0.022818177938461304
2025-11-24 01:01:13.420 | INFO     | __main__:<module>:160 - Step40480, Loss: 3.676560163497925, Grad L2 Norm: 0.025739215314388275
2025-11-24 01:01:15.410 | INFO     | __main__:<module>:160 - Step40490, Loss: 3.556149482727051, Grad L2 Norm: 0.023557092994451523
2025-11-24 01:01:17.409 | INFO     | __main__:<module>:160 - Step40500, Loss: 3.5490832328796387, Grad L2 Norm: 0.023110676556825638
2025-11-24 01:01:19.406 | INFO     | __main__:<module>:160 - Step40510, Loss: 3.6607704162597656, Grad L2 Norm: 0.023321952670812607
2025-11-24 01:01:21.403 | INFO     | __main__:<module>:160 - Step40520, Loss: 3.59226655960083, Grad L2 Norm: 0.021558307111263275
2025-11-24 01:01:23.403 | INFO     | __main__:<module>:160 - Step40530, Loss: 3.5493288040161133, Grad L2 Norm: 0.021857067942619324
2025-11-24 01:01:25.405 | INFO     | __main__:<module>:160 - Step40540, Loss: 3.677215576171875, Grad L2 Norm: 0.02352164499461651
2025-11-24 01:01:27.405 | INFO     | __main__:<module>:160 - Step40550, Loss: 3.491781234741211, Grad L2 Norm: 0.02234892174601555
2025-11-24 01:01:29.404 | INFO     | __main__:<module>:160 - Step40560, Loss: 3.5528013706207275, Grad L2 Norm: 0.021653885021805763
2025-11-24 01:01:31.403 | INFO     | __main__:<module>:160 - Step40570, Loss: 3.6061689853668213, Grad L2 Norm: 0.02365249954164028
2025-11-24 01:01:33.403 | INFO     | __main__:<module>:160 - Step40580, Loss: 3.645463466644287, Grad L2 Norm: 0.022484945133328438
2025-11-24 01:01:35.402 | INFO     | __main__:<module>:160 - Step40590, Loss: 3.486168622970581, Grad L2 Norm: 0.021094057708978653
2025-11-24 01:01:37.401 | INFO     | __main__:<module>:160 - Step40600, Loss: 3.5709645748138428, Grad L2 Norm: 0.02276575192809105
2025-11-24 01:01:39.402 | INFO     | __main__:<module>:160 - Step40610, Loss: 3.570970296859741, Grad L2 Norm: 0.02127894014120102
2025-11-24 01:01:41.403 | INFO     | __main__:<module>:160 - Step40620, Loss: 3.563396453857422, Grad L2 Norm: 0.022854778915643692
2025-11-24 01:01:43.402 | INFO     | __main__:<module>:160 - Step40630, Loss: 3.649935483932495, Grad L2 Norm: 0.02358054742217064
2025-11-24 01:01:45.400 | INFO     | __main__:<module>:160 - Step40640, Loss: 3.5814638137817383, Grad L2 Norm: 0.02510848641395569
2025-11-24 01:01:47.398 | INFO     | __main__:<module>:160 - Step40650, Loss: 3.4984776973724365, Grad L2 Norm: 0.021702371537685394
2025-11-24 01:01:49.397 | INFO     | __main__:<module>:160 - Step40660, Loss: 3.5787293910980225, Grad L2 Norm: 0.023214807733893394
2025-11-24 01:01:51.395 | INFO     | __main__:<module>:160 - Step40670, Loss: 3.6266121864318848, Grad L2 Norm: 0.023980792611837387
2025-11-24 01:01:53.396 | INFO     | __main__:<module>:160 - Step40680, Loss: 3.5054595470428467, Grad L2 Norm: 0.02340860292315483
2025-11-24 01:01:55.395 | INFO     | __main__:<module>:160 - Step40690, Loss: 3.5440168380737305, Grad L2 Norm: 0.023184431716799736
2025-11-24 01:01:57.393 | INFO     | __main__:<module>:160 - Step40700, Loss: 3.6988704204559326, Grad L2 Norm: 0.023073960095643997
2025-11-24 01:01:59.393 | INFO     | __main__:<module>:160 - Step40710, Loss: 3.5976552963256836, Grad L2 Norm: 0.02168026566505432
2025-11-24 01:02:01.388 | INFO     | __main__:<module>:160 - Step40720, Loss: 3.5088961124420166, Grad L2 Norm: 0.024596482515335083
2025-11-24 01:02:03.380 | INFO     | __main__:<module>:160 - Step40730, Loss: 3.439568519592285, Grad L2 Norm: 0.022544939070940018
2025-11-24 01:02:05.374 | INFO     | __main__:<module>:160 - Step40740, Loss: 3.4700074195861816, Grad L2 Norm: 0.0230516716837883
2025-11-24 01:02:07.371 | INFO     | __main__:<module>:160 - Step40750, Loss: 3.6103768348693848, Grad L2 Norm: 0.02235361561179161
2025-11-24 01:02:09.369 | INFO     | __main__:<module>:160 - Step40760, Loss: 3.492461681365967, Grad L2 Norm: 0.023325741291046143
2025-11-24 01:02:11.366 | INFO     | __main__:<module>:160 - Step40770, Loss: 3.5594770908355713, Grad L2 Norm: 0.021156365051865578
2025-11-24 01:02:13.355 | INFO     | __main__:<module>:160 - Step40780, Loss: 3.479954719543457, Grad L2 Norm: 0.02231323905289173
2025-11-24 01:02:15.351 | INFO     | __main__:<module>:160 - Step40790, Loss: 3.715982437133789, Grad L2 Norm: 0.021954039111733437
2025-11-24 01:02:17.347 | INFO     | __main__:<module>:160 - Step40800, Loss: 3.5713748931884766, Grad L2 Norm: 0.023116903379559517
2025-11-24 01:02:17.348 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:02:18.614 | INFO     | __main__:<module>:181 - validation loss: 3.541349458694458
2025-11-24 01:02:20.618 | INFO     | __main__:<module>:160 - Step40810, Loss: 3.557647228240967, Grad L2 Norm: 0.021622618660330772
2025-11-24 01:02:22.607 | INFO     | __main__:<module>:160 - Step40820, Loss: 3.515462875366211, Grad L2 Norm: 0.023145493119955063
2025-11-24 01:02:24.593 | INFO     | __main__:<module>:160 - Step40830, Loss: 3.64201021194458, Grad L2 Norm: 0.02198777161538601
2025-11-24 01:02:26.583 | INFO     | __main__:<module>:160 - Step40840, Loss: 3.472630262374878, Grad L2 Norm: 0.023415736854076385
2025-11-24 01:02:28.570 | INFO     | __main__:<module>:160 - Step40850, Loss: 3.558290958404541, Grad L2 Norm: 0.02303372137248516
2025-11-24 01:02:30.562 | INFO     | __main__:<module>:160 - Step40860, Loss: 3.508040428161621, Grad L2 Norm: 0.021466344594955444
2025-11-24 01:02:32.558 | INFO     | __main__:<module>:160 - Step40870, Loss: 3.5340394973754883, Grad L2 Norm: 0.022139903157949448
2025-11-24 01:02:34.543 | INFO     | __main__:<module>:160 - Step40880, Loss: 3.5941362380981445, Grad L2 Norm: 0.023589467629790306
2025-11-24 01:02:36.532 | INFO     | __main__:<module>:160 - Step40890, Loss: 3.5031533241271973, Grad L2 Norm: 0.022431058809161186
2025-11-24 01:02:38.520 | INFO     | __main__:<module>:160 - Step40900, Loss: 3.606285572052002, Grad L2 Norm: 0.021904069930315018
2025-11-24 01:02:40.507 | INFO     | __main__:<module>:160 - Step40910, Loss: 3.4361109733581543, Grad L2 Norm: 0.0222574882209301
2025-11-24 01:02:42.496 | INFO     | __main__:<module>:160 - Step40920, Loss: 3.772829532623291, Grad L2 Norm: 0.02500501088798046
2025-11-24 01:02:44.480 | INFO     | __main__:<module>:160 - Step40930, Loss: 3.5794262886047363, Grad L2 Norm: 0.02284349873661995
2025-11-24 01:02:46.465 | INFO     | __main__:<module>:160 - Step40940, Loss: 3.464796304702759, Grad L2 Norm: 0.022756149992346764
2025-11-24 01:02:48.451 | INFO     | __main__:<module>:160 - Step40950, Loss: 3.535914421081543, Grad L2 Norm: 0.025648079812526703
2025-11-24 01:02:50.436 | INFO     | __main__:<module>:160 - Step40960, Loss: 3.5263314247131348, Grad L2 Norm: 0.023703018203377724
2025-11-24 01:02:52.418 | INFO     | __main__:<module>:160 - Step40970, Loss: 3.518256187438965, Grad L2 Norm: 0.0236524548381567
2025-11-24 01:02:54.403 | INFO     | __main__:<module>:160 - Step40980, Loss: 3.577150344848633, Grad L2 Norm: 0.023337995633482933
2025-11-24 01:02:56.388 | INFO     | __main__:<module>:160 - Step40990, Loss: 3.5465621948242188, Grad L2 Norm: 0.0206509530544281
2025-11-24 01:02:58.374 | INFO     | __main__:<module>:160 - Step41000, Loss: 3.573418140411377, Grad L2 Norm: 0.025240184739232063
2025-11-24 01:03:00.361 | INFO     | __main__:<module>:160 - Step41010, Loss: 3.561011791229248, Grad L2 Norm: 0.023023828864097595
2025-11-24 01:03:02.351 | INFO     | __main__:<module>:160 - Step41020, Loss: 3.707909107208252, Grad L2 Norm: 0.022883515805006027
2025-11-24 01:03:04.337 | INFO     | __main__:<module>:160 - Step41030, Loss: 3.5670981407165527, Grad L2 Norm: 0.023559968918561935
2025-11-24 01:03:06.325 | INFO     | __main__:<module>:160 - Step41040, Loss: 3.4600958824157715, Grad L2 Norm: 0.02333485707640648
2025-11-24 01:03:08.314 | INFO     | __main__:<module>:160 - Step41050, Loss: 3.7649734020233154, Grad L2 Norm: 0.024102453142404556
2025-11-24 01:03:10.308 | INFO     | __main__:<module>:160 - Step41060, Loss: 3.575101137161255, Grad L2 Norm: 0.02403774857521057
2025-11-24 01:03:12.294 | INFO     | __main__:<module>:160 - Step41070, Loss: 3.620555877685547, Grad L2 Norm: 0.024088624864816666
2025-11-24 01:03:14.281 | INFO     | __main__:<module>:160 - Step41080, Loss: 3.5058298110961914, Grad L2 Norm: 0.02373959682881832
2025-11-24 01:03:16.269 | INFO     | __main__:<module>:160 - Step41090, Loss: 3.6294198036193848, Grad L2 Norm: 0.022163445129990578
2025-11-24 01:03:18.257 | INFO     | __main__:<module>:160 - Step41100, Loss: 3.4780197143554688, Grad L2 Norm: 0.022223157808184624
2025-11-24 01:03:20.248 | INFO     | __main__:<module>:160 - Step41110, Loss: 3.580045700073242, Grad L2 Norm: 0.02417830377817154
2025-11-24 01:03:22.238 | INFO     | __main__:<module>:160 - Step41120, Loss: 3.5873749256134033, Grad L2 Norm: 0.023413309827446938
2025-11-24 01:03:24.226 | INFO     | __main__:<module>:160 - Step41130, Loss: 3.561589241027832, Grad L2 Norm: 0.022671328857541084
2025-11-24 01:03:26.215 | INFO     | __main__:<module>:160 - Step41140, Loss: 3.5223679542541504, Grad L2 Norm: 0.02172999083995819
2025-11-24 01:03:28.206 | INFO     | __main__:<module>:160 - Step41150, Loss: 3.514760732650757, Grad L2 Norm: 0.02238617278635502
2025-11-24 01:03:30.196 | INFO     | __main__:<module>:160 - Step41160, Loss: 3.5584611892700195, Grad L2 Norm: 0.023160196840763092
2025-11-24 01:03:32.183 | INFO     | __main__:<module>:160 - Step41170, Loss: 3.6610827445983887, Grad L2 Norm: 0.02404678426682949
2025-11-24 01:03:34.167 | INFO     | __main__:<module>:160 - Step41180, Loss: 3.510260820388794, Grad L2 Norm: 0.02211952582001686
2025-11-24 01:03:36.156 | INFO     | __main__:<module>:160 - Step41190, Loss: 3.6846113204956055, Grad L2 Norm: 0.02432701364159584
2025-11-24 01:03:38.143 | INFO     | __main__:<module>:160 - Step41200, Loss: 3.5059707164764404, Grad L2 Norm: 0.021323326975107193
2025-11-24 01:03:38.144 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:03:39.407 | INFO     | __main__:<module>:181 - validation loss: 3.5417474508285522
2025-11-24 01:03:41.408 | INFO     | __main__:<module>:160 - Step41210, Loss: 3.5280137062072754, Grad L2 Norm: 0.021414082497358322
2025-11-24 01:03:43.398 | INFO     | __main__:<module>:160 - Step41220, Loss: 3.5535902976989746, Grad L2 Norm: 0.020884303376078606
2025-11-24 01:03:45.382 | INFO     | __main__:<module>:160 - Step41230, Loss: 3.5849924087524414, Grad L2 Norm: 0.024274170398712158
2025-11-24 01:03:47.375 | INFO     | __main__:<module>:160 - Step41240, Loss: 3.545154571533203, Grad L2 Norm: 0.022578176110982895
2025-11-24 01:03:49.361 | INFO     | __main__:<module>:160 - Step41250, Loss: 3.508683204650879, Grad L2 Norm: 0.021890249103307724
2025-11-24 01:03:51.349 | INFO     | __main__:<module>:160 - Step41260, Loss: 3.479325294494629, Grad L2 Norm: 0.021115640178322792
2025-11-24 01:03:53.337 | INFO     | __main__:<module>:160 - Step41270, Loss: 3.606118679046631, Grad L2 Norm: 0.02220800332725048
2025-11-24 01:03:55.323 | INFO     | __main__:<module>:160 - Step41280, Loss: 3.604041576385498, Grad L2 Norm: 0.02474583126604557
2025-11-24 01:03:57.312 | INFO     | __main__:<module>:160 - Step41290, Loss: 3.587474822998047, Grad L2 Norm: 0.02265649102628231
2025-11-24 01:03:59.295 | INFO     | __main__:<module>:160 - Step41300, Loss: 3.5736727714538574, Grad L2 Norm: 0.022418038919568062
2025-11-24 01:04:01.281 | INFO     | __main__:<module>:160 - Step41310, Loss: 3.565707206726074, Grad L2 Norm: 0.025572631508111954
2025-11-24 01:04:03.266 | INFO     | __main__:<module>:160 - Step41320, Loss: 3.6654558181762695, Grad L2 Norm: 0.02332982048392296
2025-11-24 01:04:05.253 | INFO     | __main__:<module>:160 - Step41330, Loss: 3.4440836906433105, Grad L2 Norm: 0.02318497747182846
2025-11-24 01:04:07.238 | INFO     | __main__:<module>:160 - Step41340, Loss: 3.4987130165100098, Grad L2 Norm: 0.021291712298989296
2025-11-24 01:04:09.223 | INFO     | __main__:<module>:160 - Step41350, Loss: 3.649980068206787, Grad L2 Norm: 0.022644339129328728
2025-11-24 01:04:11.208 | INFO     | __main__:<module>:160 - Step41360, Loss: 3.5822582244873047, Grad L2 Norm: 0.022887036204338074
2025-11-24 01:04:13.192 | INFO     | __main__:<module>:160 - Step41370, Loss: 3.59891414642334, Grad L2 Norm: 0.02343571186065674
2025-11-24 01:04:15.173 | INFO     | __main__:<module>:160 - Step41380, Loss: 3.6382124423980713, Grad L2 Norm: 0.02359970472753048
2025-11-24 01:04:17.158 | INFO     | __main__:<module>:160 - Step41390, Loss: 3.8092565536499023, Grad L2 Norm: 0.022954346612095833
2025-11-24 01:04:19.140 | INFO     | __main__:<module>:160 - Step41400, Loss: 3.5656275749206543, Grad L2 Norm: 0.025879638269543648
2025-11-24 01:04:21.122 | INFO     | __main__:<module>:160 - Step41410, Loss: 3.4519498348236084, Grad L2 Norm: 0.021903494372963905
2025-11-24 01:04:23.104 | INFO     | __main__:<module>:160 - Step41420, Loss: 3.5745534896850586, Grad L2 Norm: 0.023168403655290604
2025-11-24 01:04:25.086 | INFO     | __main__:<module>:160 - Step41430, Loss: 3.6997270584106445, Grad L2 Norm: 0.023970356211066246
2025-11-24 01:04:27.065 | INFO     | __main__:<module>:160 - Step41440, Loss: 3.631826877593994, Grad L2 Norm: 0.022118890658020973
2025-11-24 01:04:29.046 | INFO     | __main__:<module>:160 - Step41450, Loss: 3.587902069091797, Grad L2 Norm: 0.022258346900343895
2025-11-24 01:04:31.023 | INFO     | __main__:<module>:160 - Step41460, Loss: 3.6175332069396973, Grad L2 Norm: 0.022853121161460876
2025-11-24 01:04:33.006 | INFO     | __main__:<module>:160 - Step41470, Loss: 3.446460247039795, Grad L2 Norm: 0.022941013798117638
2025-11-24 01:04:34.989 | INFO     | __main__:<module>:160 - Step41480, Loss: 3.6902639865875244, Grad L2 Norm: 0.023476727306842804
2025-11-24 01:04:36.966 | INFO     | __main__:<module>:160 - Step41490, Loss: 3.4846653938293457, Grad L2 Norm: 0.025764424353837967
2025-11-24 01:04:38.947 | INFO     | __main__:<module>:160 - Step41500, Loss: 3.601001262664795, Grad L2 Norm: 0.022276608273386955
2025-11-24 01:04:40.929 | INFO     | __main__:<module>:160 - Step41510, Loss: 3.545630693435669, Grad L2 Norm: 0.021407270804047585
2025-11-24 01:04:42.911 | INFO     | __main__:<module>:160 - Step41520, Loss: 3.774885654449463, Grad L2 Norm: 0.02244972065091133
2025-11-24 01:04:44.892 | INFO     | __main__:<module>:160 - Step41530, Loss: 3.550983428955078, Grad L2 Norm: 0.023418359458446503
2025-11-24 01:04:46.874 | INFO     | __main__:<module>:160 - Step41540, Loss: 3.6057400703430176, Grad L2 Norm: 0.021360859274864197
2025-11-24 01:04:48.857 | INFO     | __main__:<module>:160 - Step41550, Loss: 3.7551207542419434, Grad L2 Norm: 0.023519424721598625
2025-11-24 01:04:50.837 | INFO     | __main__:<module>:160 - Step41560, Loss: 3.5131239891052246, Grad L2 Norm: 0.02274443954229355
2025-11-24 01:04:52.813 | INFO     | __main__:<module>:160 - Step41570, Loss: 3.566988706588745, Grad L2 Norm: 0.02233344316482544
2025-11-24 01:04:54.787 | INFO     | __main__:<module>:160 - Step41580, Loss: 3.6262502670288086, Grad L2 Norm: 0.023685581982135773
2025-11-24 01:04:56.764 | INFO     | __main__:<module>:160 - Step41590, Loss: 3.625729560852051, Grad L2 Norm: 0.022416509687900543
2025-11-24 01:04:58.743 | INFO     | __main__:<module>:160 - Step41600, Loss: 3.63006591796875, Grad L2 Norm: 0.022694384679198265
2025-11-24 01:04:58.744 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:05:00.001 | INFO     | __main__:<module>:181 - validation loss: 3.540187418460846
2025-11-24 01:05:01.987 | INFO     | __main__:<module>:160 - Step41610, Loss: 3.54994535446167, Grad L2 Norm: 0.02282891236245632
2025-11-24 01:05:03.963 | INFO     | __main__:<module>:160 - Step41620, Loss: 3.4953219890594482, Grad L2 Norm: 0.022488854825496674
2025-11-24 01:05:05.941 | INFO     | __main__:<module>:160 - Step41630, Loss: 3.588688611984253, Grad L2 Norm: 0.024650078266859055
2025-11-24 01:05:07.923 | INFO     | __main__:<module>:160 - Step41640, Loss: 3.638784408569336, Grad L2 Norm: 0.02245955914258957
2025-11-24 01:05:09.902 | INFO     | __main__:<module>:160 - Step41650, Loss: 3.7076973915100098, Grad L2 Norm: 0.024773433804512024
2025-11-24 01:05:11.883 | INFO     | __main__:<module>:160 - Step41660, Loss: 3.5858540534973145, Grad L2 Norm: 0.02352713793516159
2025-11-24 01:05:13.862 | INFO     | __main__:<module>:160 - Step41670, Loss: 3.509446144104004, Grad L2 Norm: 0.02130253240466118
2025-11-24 01:05:15.847 | INFO     | __main__:<module>:160 - Step41680, Loss: 3.538541078567505, Grad L2 Norm: 0.020206013694405556
2025-11-24 01:05:17.829 | INFO     | __main__:<module>:160 - Step41690, Loss: 3.5323352813720703, Grad L2 Norm: 0.02329779602587223
2025-11-24 01:05:19.809 | INFO     | __main__:<module>:160 - Step41700, Loss: 3.63261079788208, Grad L2 Norm: 0.025974223390221596
2025-11-24 01:05:21.791 | INFO     | __main__:<module>:160 - Step41710, Loss: 3.487520217895508, Grad L2 Norm: 0.024444911628961563
2025-11-24 01:05:23.776 | INFO     | __main__:<module>:160 - Step41720, Loss: 3.654418706893921, Grad L2 Norm: 0.024730157107114792
2025-11-24 01:05:25.759 | INFO     | __main__:<module>:160 - Step41730, Loss: 3.480464458465576, Grad L2 Norm: 0.021746806800365448
2025-11-24 01:05:27.738 | INFO     | __main__:<module>:160 - Step41740, Loss: 3.551124334335327, Grad L2 Norm: 0.02275339514017105
2025-11-24 01:05:29.714 | INFO     | __main__:<module>:160 - Step41750, Loss: 3.699556827545166, Grad L2 Norm: 0.022551661357283592
2025-11-24 01:05:31.693 | INFO     | __main__:<module>:160 - Step41760, Loss: 3.710906982421875, Grad L2 Norm: 0.022431302815675735
2025-11-24 01:05:33.673 | INFO     | __main__:<module>:160 - Step41770, Loss: 3.671121597290039, Grad L2 Norm: 0.022926224395632744
2025-11-24 01:05:35.651 | INFO     | __main__:<module>:160 - Step41780, Loss: 3.589146852493286, Grad L2 Norm: 0.021343346685171127
2025-11-24 01:05:37.631 | INFO     | __main__:<module>:160 - Step41790, Loss: 3.5029690265655518, Grad L2 Norm: 0.02391679771244526
2025-11-24 01:05:39.612 | INFO     | __main__:<module>:160 - Step41800, Loss: 3.538456916809082, Grad L2 Norm: 0.022416701540350914
2025-11-24 01:05:41.592 | INFO     | __main__:<module>:160 - Step41810, Loss: 3.5470240116119385, Grad L2 Norm: 0.022963009774684906
2025-11-24 01:05:43.574 | INFO     | __main__:<module>:160 - Step41820, Loss: 3.6067440509796143, Grad L2 Norm: 0.022048646584153175
2025-11-24 01:05:45.557 | INFO     | __main__:<module>:160 - Step41830, Loss: 3.515377998352051, Grad L2 Norm: 0.02255341224372387
2025-11-24 01:05:47.538 | INFO     | __main__:<module>:160 - Step41840, Loss: 3.6289634704589844, Grad L2 Norm: 0.024385174736380577
2025-11-24 01:05:49.518 | INFO     | __main__:<module>:160 - Step41850, Loss: 3.51104998588562, Grad L2 Norm: 0.022032158449292183
2025-11-24 01:05:51.488 | INFO     | __main__:<module>:160 - Step41860, Loss: 3.6238744258880615, Grad L2 Norm: 0.023233715444803238
2025-11-24 01:05:53.465 | INFO     | __main__:<module>:160 - Step41870, Loss: 3.585965633392334, Grad L2 Norm: 0.02209692820906639
2025-11-24 01:05:55.444 | INFO     | __main__:<module>:160 - Step41880, Loss: 3.5167956352233887, Grad L2 Norm: 0.02236686274409294
2025-11-24 01:05:57.420 | INFO     | __main__:<module>:160 - Step41890, Loss: 3.569009304046631, Grad L2 Norm: 0.02311793901026249
2025-11-24 01:05:59.397 | INFO     | __main__:<module>:160 - Step41900, Loss: 3.5178961753845215, Grad L2 Norm: 0.02216240018606186
2025-11-24 01:06:01.377 | INFO     | __main__:<module>:160 - Step41910, Loss: 3.593217372894287, Grad L2 Norm: 0.02240588888525963
2025-11-24 01:06:03.357 | INFO     | __main__:<module>:160 - Step41920, Loss: 3.67093563079834, Grad L2 Norm: 0.021699920296669006
2025-11-24 01:06:05.338 | INFO     | __main__:<module>:160 - Step41930, Loss: 3.48945689201355, Grad L2 Norm: 0.0237264521420002
2025-11-24 01:06:07.323 | INFO     | __main__:<module>:160 - Step41940, Loss: 3.616057872772217, Grad L2 Norm: 0.02372547797858715
2025-11-24 01:06:09.307 | INFO     | __main__:<module>:160 - Step41950, Loss: 3.5632567405700684, Grad L2 Norm: 0.02283674292266369
2025-11-24 01:06:11.293 | INFO     | __main__:<module>:160 - Step41960, Loss: 3.601269006729126, Grad L2 Norm: 0.023717030882835388
2025-11-24 01:06:13.273 | INFO     | __main__:<module>:160 - Step41970, Loss: 3.6787350177764893, Grad L2 Norm: 0.02231382392346859
2025-11-24 01:06:15.255 | INFO     | __main__:<module>:160 - Step41980, Loss: 3.6793618202209473, Grad L2 Norm: 0.02428026683628559
2025-11-24 01:06:17.240 | INFO     | __main__:<module>:160 - Step41990, Loss: 3.40519642829895, Grad L2 Norm: 0.022343697026371956
2025-11-24 01:06:19.223 | INFO     | __main__:<module>:160 - Step42000, Loss: 3.54074764251709, Grad L2 Norm: 0.02281865105032921
2025-11-24 01:06:19.223 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:06:20.485 | INFO     | __main__:<module>:181 - validation loss: 3.571047580242157
2025-11-24 01:06:20.486 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_42000.pt
2025-11-24 01:06:22.170 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 01:06:24.128 | INFO     | __main__:<module>:160 - Step42010, Loss: 3.6552164554595947, Grad L2 Norm: 0.022033102810382843
2025-11-24 01:06:26.108 | INFO     | __main__:<module>:160 - Step42020, Loss: 3.537863254547119, Grad L2 Norm: 0.02334170788526535
2025-11-24 01:06:28.089 | INFO     | __main__:<module>:160 - Step42030, Loss: 3.5269856452941895, Grad L2 Norm: 0.022227946668863297
2025-11-24 01:06:30.065 | INFO     | __main__:<module>:160 - Step42040, Loss: 3.5789613723754883, Grad L2 Norm: 0.022850647568702698
2025-11-24 01:06:32.043 | INFO     | __main__:<module>:160 - Step42050, Loss: 3.4971628189086914, Grad L2 Norm: 0.021822385489940643
2025-11-24 01:06:34.021 | INFO     | __main__:<module>:160 - Step42060, Loss: 3.551731586456299, Grad L2 Norm: 0.021843189373612404
2025-11-24 01:06:35.996 | INFO     | __main__:<module>:160 - Step42070, Loss: 3.6173017024993896, Grad L2 Norm: 0.02166217751801014
2025-11-24 01:06:37.967 | INFO     | __main__:<module>:160 - Step42080, Loss: 3.522630453109741, Grad L2 Norm: 0.022541135549545288
2025-11-24 01:06:39.933 | INFO     | __main__:<module>:160 - Step42090, Loss: 3.5272417068481445, Grad L2 Norm: 0.021792903542518616
2025-11-24 01:06:41.905 | INFO     | __main__:<module>:160 - Step42100, Loss: 3.606466054916382, Grad L2 Norm: 0.023263102397322655
2025-11-24 01:06:43.874 | INFO     | __main__:<module>:160 - Step42110, Loss: 3.4940240383148193, Grad L2 Norm: 0.021885301917791367
2025-11-24 01:06:45.847 | INFO     | __main__:<module>:160 - Step42120, Loss: 3.568004608154297, Grad L2 Norm: 0.025389298796653748
2025-11-24 01:06:47.823 | INFO     | __main__:<module>:160 - Step42130, Loss: 3.518768310546875, Grad L2 Norm: 0.021053435280919075
2025-11-24 01:06:49.800 | INFO     | __main__:<module>:160 - Step42140, Loss: 3.458019495010376, Grad L2 Norm: 0.023246396332979202
2025-11-24 01:06:51.778 | INFO     | __main__:<module>:160 - Step42150, Loss: 3.550692558288574, Grad L2 Norm: 0.02248598262667656
2025-11-24 01:06:53.758 | INFO     | __main__:<module>:160 - Step42160, Loss: 3.5294089317321777, Grad L2 Norm: 0.022993994876742363
2025-11-24 01:06:55.729 | INFO     | __main__:<module>:160 - Step42170, Loss: 3.5993494987487793, Grad L2 Norm: 0.023258674889802933
2025-11-24 01:06:57.704 | INFO     | __main__:<module>:160 - Step42180, Loss: 3.6306328773498535, Grad L2 Norm: 0.026785407215356827
2025-11-24 01:06:59.680 | INFO     | __main__:<module>:160 - Step42190, Loss: 3.472527265548706, Grad L2 Norm: 0.02306247130036354
2025-11-24 01:07:01.659 | INFO     | __main__:<module>:160 - Step42200, Loss: 3.5424368381500244, Grad L2 Norm: 0.023668624460697174
2025-11-24 01:07:03.643 | INFO     | __main__:<module>:160 - Step42210, Loss: 3.448148727416992, Grad L2 Norm: 0.023217948153614998
2025-11-24 01:07:05.624 | INFO     | __main__:<module>:160 - Step42220, Loss: 3.5808167457580566, Grad L2 Norm: 0.022801769897341728
2025-11-24 01:07:07.604 | INFO     | __main__:<module>:160 - Step42230, Loss: 3.571560859680176, Grad L2 Norm: 0.022147279232740402
2025-11-24 01:07:09.585 | INFO     | __main__:<module>:160 - Step42240, Loss: 3.575770854949951, Grad L2 Norm: 0.02194898948073387
2025-11-24 01:07:11.562 | INFO     | __main__:<module>:160 - Step42250, Loss: 3.584975004196167, Grad L2 Norm: 0.023381788283586502
2025-11-24 01:07:13.542 | INFO     | __main__:<module>:160 - Step42260, Loss: 3.494767189025879, Grad L2 Norm: 0.021661652252078056
2025-11-24 01:07:15.520 | INFO     | __main__:<module>:160 - Step42270, Loss: 3.519469976425171, Grad L2 Norm: 0.022877030074596405
2025-11-24 01:07:17.496 | INFO     | __main__:<module>:160 - Step42280, Loss: 3.4388837814331055, Grad L2 Norm: 0.023042675107717514
2025-11-24 01:07:19.473 | INFO     | __main__:<module>:160 - Step42290, Loss: 3.496807813644409, Grad L2 Norm: 0.02140352502465248
2025-11-24 01:07:21.452 | INFO     | __main__:<module>:160 - Step42300, Loss: 3.4485268592834473, Grad L2 Norm: 0.021993424743413925
2025-11-24 01:07:23.428 | INFO     | __main__:<module>:160 - Step42310, Loss: 3.683750629425049, Grad L2 Norm: 0.024389343336224556
2025-11-24 01:07:25.401 | INFO     | __main__:<module>:160 - Step42320, Loss: 3.4999618530273438, Grad L2 Norm: 0.022994734346866608
2025-11-24 01:07:27.377 | INFO     | __main__:<module>:160 - Step42330, Loss: 3.6949963569641113, Grad L2 Norm: 0.02236192673444748
2025-11-24 01:07:29.356 | INFO     | __main__:<module>:160 - Step42340, Loss: 3.6942286491394043, Grad L2 Norm: 0.023933885619044304
2025-11-24 01:07:31.335 | INFO     | __main__:<module>:160 - Step42350, Loss: 3.4730491638183594, Grad L2 Norm: 0.022651812061667442
2025-11-24 01:07:33.316 | INFO     | __main__:<module>:160 - Step42360, Loss: 3.5540013313293457, Grad L2 Norm: 0.022984763607382774
2025-11-24 01:07:35.291 | INFO     | __main__:<module>:160 - Step42370, Loss: 3.7068557739257812, Grad L2 Norm: 0.023188821971416473
2025-11-24 01:07:37.268 | INFO     | __main__:<module>:160 - Step42380, Loss: 3.7143449783325195, Grad L2 Norm: 0.024338819086551666
2025-11-24 01:07:39.247 | INFO     | __main__:<module>:160 - Step42390, Loss: 3.602604627609253, Grad L2 Norm: 0.021960102021694183
2025-11-24 01:07:41.230 | INFO     | __main__:<module>:160 - Step42400, Loss: 3.5594286918640137, Grad L2 Norm: 0.022345785051584244
2025-11-24 01:07:41.230 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:07:42.488 | INFO     | __main__:<module>:181 - validation loss: 3.5567519307136535
2025-11-24 01:07:44.482 | INFO     | __main__:<module>:160 - Step42410, Loss: 3.5407400131225586, Grad L2 Norm: 0.021126288920640945
2025-11-24 01:07:46.464 | INFO     | __main__:<module>:160 - Step42420, Loss: 3.4147748947143555, Grad L2 Norm: 0.022876529023051262
2025-11-24 01:07:48.445 | INFO     | __main__:<module>:160 - Step42430, Loss: 3.6450061798095703, Grad L2 Norm: 0.025474125519394875
2025-11-24 01:07:50.425 | INFO     | __main__:<module>:160 - Step42440, Loss: 3.5536551475524902, Grad L2 Norm: 0.022526100277900696
2025-11-24 01:07:52.407 | INFO     | __main__:<module>:160 - Step42450, Loss: 3.5308613777160645, Grad L2 Norm: 0.02524804323911667
2025-11-24 01:07:54.387 | INFO     | __main__:<module>:160 - Step42460, Loss: 3.5717055797576904, Grad L2 Norm: 0.02140207588672638
2025-11-24 01:07:56.366 | INFO     | __main__:<module>:160 - Step42470, Loss: 3.4175727367401123, Grad L2 Norm: 0.02214502915740013
2025-11-24 01:07:58.349 | INFO     | __main__:<module>:160 - Step42480, Loss: 3.571989059448242, Grad L2 Norm: 0.02432466670870781
2025-11-24 01:08:00.325 | INFO     | __main__:<module>:160 - Step42490, Loss: 3.5525078773498535, Grad L2 Norm: 0.02259998396039009
2025-11-24 01:08:02.302 | INFO     | __main__:<module>:160 - Step42500, Loss: 3.528792381286621, Grad L2 Norm: 0.021498627960681915
2025-11-24 01:08:04.287 | INFO     | __main__:<module>:160 - Step42510, Loss: 3.556725025177002, Grad L2 Norm: 0.023648561909794807
2025-11-24 01:08:06.268 | INFO     | __main__:<module>:160 - Step42520, Loss: 3.6394236087799072, Grad L2 Norm: 0.023324180394411087
2025-11-24 01:08:08.245 | INFO     | __main__:<module>:160 - Step42530, Loss: 3.681809186935425, Grad L2 Norm: 0.022926177829504013
2025-11-24 01:08:10.225 | INFO     | __main__:<module>:160 - Step42540, Loss: 3.7277770042419434, Grad L2 Norm: 0.02258916385471821
2025-11-24 01:08:12.204 | INFO     | __main__:<module>:160 - Step42550, Loss: 3.4124560356140137, Grad L2 Norm: 0.02331649325788021
2025-11-24 01:08:14.189 | INFO     | __main__:<module>:160 - Step42560, Loss: 3.465548038482666, Grad L2 Norm: 0.022283002734184265
2025-11-24 01:08:16.177 | INFO     | __main__:<module>:160 - Step42570, Loss: 3.5453906059265137, Grad L2 Norm: 0.024086028337478638
2025-11-24 01:08:18.157 | INFO     | __main__:<module>:160 - Step42580, Loss: 3.4826440811157227, Grad L2 Norm: 0.022154582664370537
2025-11-24 01:08:20.142 | INFO     | __main__:<module>:160 - Step42590, Loss: 3.588412284851074, Grad L2 Norm: 0.022781914100050926
2025-11-24 01:08:22.128 | INFO     | __main__:<module>:160 - Step42600, Loss: 3.608741521835327, Grad L2 Norm: 0.02383086085319519
2025-11-24 01:08:24.113 | INFO     | __main__:<module>:160 - Step42610, Loss: 3.5030510425567627, Grad L2 Norm: 0.02229701727628708
2025-11-24 01:08:26.094 | INFO     | __main__:<module>:160 - Step42620, Loss: 3.66870379447937, Grad L2 Norm: 0.025608060881495476
2025-11-24 01:08:28.073 | INFO     | __main__:<module>:160 - Step42630, Loss: 3.535494089126587, Grad L2 Norm: 0.022051457315683365
2025-11-24 01:08:30.056 | INFO     | __main__:<module>:160 - Step42640, Loss: 3.5421910285949707, Grad L2 Norm: 0.021855583414435387
2025-11-24 01:08:32.037 | INFO     | __main__:<module>:160 - Step42650, Loss: 3.568549633026123, Grad L2 Norm: 0.023364823311567307
2025-11-24 01:08:34.019 | INFO     | __main__:<module>:160 - Step42660, Loss: 3.601909637451172, Grad L2 Norm: 0.024188721552491188
2025-11-24 01:08:35.998 | INFO     | __main__:<module>:160 - Step42670, Loss: 3.5885748863220215, Grad L2 Norm: 0.02181331068277359
2025-11-24 01:08:37.979 | INFO     | __main__:<module>:160 - Step42680, Loss: 3.617766857147217, Grad L2 Norm: 0.023013152182102203
2025-11-24 01:08:39.959 | INFO     | __main__:<module>:160 - Step42690, Loss: 3.491741180419922, Grad L2 Norm: 0.023910144343972206
2025-11-24 01:08:41.944 | INFO     | __main__:<module>:160 - Step42700, Loss: 3.537140369415283, Grad L2 Norm: 0.020911753177642822
2025-11-24 01:08:43.925 | INFO     | __main__:<module>:160 - Step42710, Loss: 3.445761203765869, Grad L2 Norm: 0.023004962131381035
2025-11-24 01:08:45.903 | INFO     | __main__:<module>:160 - Step42720, Loss: 3.506180763244629, Grad L2 Norm: 0.0214668121188879
2025-11-24 01:08:47.880 | INFO     | __main__:<module>:160 - Step42730, Loss: 3.4783101081848145, Grad L2 Norm: 0.022172147408127785
2025-11-24 01:08:49.857 | INFO     | __main__:<module>:160 - Step42740, Loss: 3.4654452800750732, Grad L2 Norm: 0.02221785858273506
2025-11-24 01:08:51.835 | INFO     | __main__:<module>:160 - Step42750, Loss: 3.50361967086792, Grad L2 Norm: 0.024259353056550026
2025-11-24 01:08:53.811 | INFO     | __main__:<module>:160 - Step42760, Loss: 3.526268482208252, Grad L2 Norm: 0.021114451810717583
2025-11-24 01:08:55.787 | INFO     | __main__:<module>:160 - Step42770, Loss: 3.6268117427825928, Grad L2 Norm: 0.022636830806732178
2025-11-24 01:08:57.766 | INFO     | __main__:<module>:160 - Step42780, Loss: 3.547800064086914, Grad L2 Norm: 0.02302679233253002
2025-11-24 01:08:59.749 | INFO     | __main__:<module>:160 - Step42790, Loss: 3.5420780181884766, Grad L2 Norm: 0.02604382485151291
2025-11-24 01:09:01.732 | INFO     | __main__:<module>:160 - Step42800, Loss: 3.533783435821533, Grad L2 Norm: 0.02228986844420433
2025-11-24 01:09:01.732 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:09:02.991 | INFO     | __main__:<module>:181 - validation loss: 3.555777537822723
2025-11-24 01:09:04.979 | INFO     | __main__:<module>:160 - Step42810, Loss: 3.4887430667877197, Grad L2 Norm: 0.021590640768408775
2025-11-24 01:09:06.967 | INFO     | __main__:<module>:160 - Step42820, Loss: 3.5799317359924316, Grad L2 Norm: 0.023478109389543533
2025-11-24 01:09:08.954 | INFO     | __main__:<module>:160 - Step42830, Loss: 3.595841884613037, Grad L2 Norm: 0.02195628359913826
2025-11-24 01:09:10.937 | INFO     | __main__:<module>:160 - Step42840, Loss: 3.4044723510742188, Grad L2 Norm: 0.02301824651658535
2025-11-24 01:09:12.915 | INFO     | __main__:<module>:160 - Step42850, Loss: 3.5858397483825684, Grad L2 Norm: 0.0229992363601923
2025-11-24 01:09:14.894 | INFO     | __main__:<module>:160 - Step42860, Loss: 3.469477653503418, Grad L2 Norm: 0.021987618878483772
2025-11-24 01:09:16.875 | INFO     | __main__:<module>:160 - Step42870, Loss: 3.5945560932159424, Grad L2 Norm: 0.02210407890379429
2025-11-24 01:09:18.853 | INFO     | __main__:<module>:160 - Step42880, Loss: 3.469970941543579, Grad L2 Norm: 0.023274455219507217
2025-11-24 01:09:20.830 | INFO     | __main__:<module>:160 - Step42890, Loss: 3.5439484119415283, Grad L2 Norm: 0.022019466385245323
2025-11-24 01:09:22.808 | INFO     | __main__:<module>:160 - Step42900, Loss: 3.6476850509643555, Grad L2 Norm: 0.02472117356956005
2025-11-24 01:09:24.781 | INFO     | __main__:<module>:160 - Step42910, Loss: 3.6463589668273926, Grad L2 Norm: 0.024523690342903137
2025-11-24 01:09:26.765 | INFO     | __main__:<module>:160 - Step42920, Loss: 3.61378812789917, Grad L2 Norm: 0.023269588127732277
2025-11-24 01:09:28.749 | INFO     | __main__:<module>:160 - Step42930, Loss: 3.548922061920166, Grad L2 Norm: 0.0238215159624815
2025-11-24 01:09:30.734 | INFO     | __main__:<module>:160 - Step42940, Loss: 3.578463554382324, Grad L2 Norm: 0.022961270064115524
2025-11-24 01:09:32.714 | INFO     | __main__:<module>:160 - Step42950, Loss: 3.66377592086792, Grad L2 Norm: 0.02472018077969551
2025-11-24 01:09:34.694 | INFO     | __main__:<module>:160 - Step42960, Loss: 3.4622786045074463, Grad L2 Norm: 0.021128801628947258
2025-11-24 01:09:36.678 | INFO     | __main__:<module>:160 - Step42970, Loss: 3.6862971782684326, Grad L2 Norm: 0.024170447140932083
2025-11-24 01:09:38.663 | INFO     | __main__:<module>:160 - Step42980, Loss: 3.546809196472168, Grad L2 Norm: 0.02050335519015789
2025-11-24 01:09:40.640 | INFO     | __main__:<module>:160 - Step42990, Loss: 3.5377535820007324, Grad L2 Norm: 0.021553639322519302
2025-11-24 01:09:42.620 | INFO     | __main__:<module>:160 - Step43000, Loss: 3.4693603515625, Grad L2 Norm: 0.0217048991471529
2025-11-24 01:09:44.605 | INFO     | __main__:<module>:160 - Step43010, Loss: 3.397695541381836, Grad L2 Norm: 0.02173164300620556
2025-11-24 01:09:46.585 | INFO     | __main__:<module>:160 - Step43020, Loss: 3.7258358001708984, Grad L2 Norm: 0.02483898401260376
2025-11-24 01:09:48.561 | INFO     | __main__:<module>:160 - Step43030, Loss: 3.459564685821533, Grad L2 Norm: 0.02101406455039978
2025-11-24 01:09:50.535 | INFO     | __main__:<module>:160 - Step43040, Loss: 3.48879337310791, Grad L2 Norm: 0.02173502743244171
2025-11-24 01:09:52.512 | INFO     | __main__:<module>:160 - Step43050, Loss: 3.497894763946533, Grad L2 Norm: 0.02174077183008194
2025-11-24 01:09:54.489 | INFO     | __main__:<module>:160 - Step43060, Loss: 3.443452835083008, Grad L2 Norm: 0.0211779847741127
2025-11-24 01:09:56.468 | INFO     | __main__:<module>:160 - Step43070, Loss: 3.5760276317596436, Grad L2 Norm: 0.022622717544436455
2025-11-24 01:09:58.447 | INFO     | __main__:<module>:160 - Step43080, Loss: 3.638362169265747, Grad L2 Norm: 0.022799424827098846
2025-11-24 01:10:00.425 | INFO     | __main__:<module>:160 - Step43090, Loss: 3.6128034591674805, Grad L2 Norm: 0.022406388074159622
2025-11-24 01:10:02.407 | INFO     | __main__:<module>:160 - Step43100, Loss: 3.7485649585723877, Grad L2 Norm: 0.02401137910783291
2025-11-24 01:10:04.384 | INFO     | __main__:<module>:160 - Step43110, Loss: 3.6618800163269043, Grad L2 Norm: 0.022520260885357857
2025-11-24 01:10:06.361 | INFO     | __main__:<module>:160 - Step43120, Loss: 3.5821385383605957, Grad L2 Norm: 0.02223408967256546
2025-11-24 01:10:08.340 | INFO     | __main__:<module>:160 - Step43130, Loss: 3.4032506942749023, Grad L2 Norm: 0.021683726459741592
2025-11-24 01:10:10.315 | INFO     | __main__:<module>:160 - Step43140, Loss: 3.625016689300537, Grad L2 Norm: 0.0228450745344162
2025-11-24 01:10:12.287 | INFO     | __main__:<module>:160 - Step43150, Loss: 3.597775936126709, Grad L2 Norm: 0.023471517488360405
2025-11-24 01:10:14.262 | INFO     | __main__:<module>:160 - Step43160, Loss: 3.5278186798095703, Grad L2 Norm: 0.02452850714325905
2025-11-24 01:10:16.245 | INFO     | __main__:<module>:160 - Step43170, Loss: 3.552391767501831, Grad L2 Norm: 0.021312572062015533
2025-11-24 01:10:18.223 | INFO     | __main__:<module>:160 - Step43180, Loss: 3.568057060241699, Grad L2 Norm: 0.022160818800330162
2025-11-24 01:10:20.204 | INFO     | __main__:<module>:160 - Step43190, Loss: 3.688197135925293, Grad L2 Norm: 0.023341529071331024
2025-11-24 01:10:22.183 | INFO     | __main__:<module>:160 - Step43200, Loss: 3.635282039642334, Grad L2 Norm: 0.023270215839147568
2025-11-24 01:10:22.183 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:10:23.443 | INFO     | __main__:<module>:181 - validation loss: 3.5458315134048464
2025-11-24 01:10:25.429 | INFO     | __main__:<module>:160 - Step43210, Loss: 3.486738681793213, Grad L2 Norm: 0.022964928299188614
2025-11-24 01:10:27.408 | INFO     | __main__:<module>:160 - Step43220, Loss: 3.5546963214874268, Grad L2 Norm: 0.024237243458628654
2025-11-24 01:10:29.390 | INFO     | __main__:<module>:160 - Step43230, Loss: 3.7082653045654297, Grad L2 Norm: 0.024127274751663208
2025-11-24 01:10:31.372 | INFO     | __main__:<module>:160 - Step43240, Loss: 3.580580234527588, Grad L2 Norm: 0.022501755505800247
2025-11-24 01:10:33.352 | INFO     | __main__:<module>:160 - Step43250, Loss: 3.6082088947296143, Grad L2 Norm: 0.022617699578404427
2025-11-24 01:10:35.333 | INFO     | __main__:<module>:160 - Step43260, Loss: 3.568566083908081, Grad L2 Norm: 0.02330024167895317
2025-11-24 01:10:37.313 | INFO     | __main__:<module>:160 - Step43270, Loss: 3.580498218536377, Grad L2 Norm: 0.022137226536870003
2025-11-24 01:10:39.294 | INFO     | __main__:<module>:160 - Step43280, Loss: 3.438338279724121, Grad L2 Norm: 0.02456037513911724
2025-11-24 01:10:41.278 | INFO     | __main__:<module>:160 - Step43290, Loss: 3.3953113555908203, Grad L2 Norm: 0.023179659619927406
2025-11-24 01:10:43.256 | INFO     | __main__:<module>:160 - Step43300, Loss: 3.6334280967712402, Grad L2 Norm: 0.022921331226825714
2025-11-24 01:10:45.237 | INFO     | __main__:<module>:160 - Step43310, Loss: 3.6670949459075928, Grad L2 Norm: 0.02285417914390564
2025-11-24 01:10:47.214 | INFO     | __main__:<module>:160 - Step43320, Loss: 3.59456205368042, Grad L2 Norm: 0.022211624309420586
2025-11-24 01:10:49.192 | INFO     | __main__:<module>:160 - Step43330, Loss: 3.461754083633423, Grad L2 Norm: 0.02262655831873417
2025-11-24 01:10:51.170 | INFO     | __main__:<module>:160 - Step43340, Loss: 3.491995334625244, Grad L2 Norm: 0.021895453333854675
2025-11-24 01:10:53.145 | INFO     | __main__:<module>:160 - Step43350, Loss: 3.610340118408203, Grad L2 Norm: 0.022429972887039185
2025-11-24 01:10:55.119 | INFO     | __main__:<module>:160 - Step43360, Loss: 3.496795177459717, Grad L2 Norm: 0.02086765505373478
2025-11-24 01:10:57.101 | INFO     | __main__:<module>:160 - Step43370, Loss: 3.4284090995788574, Grad L2 Norm: 0.02487483248114586
2025-11-24 01:10:59.084 | INFO     | __main__:<module>:160 - Step43380, Loss: 3.544252395629883, Grad L2 Norm: 0.023259738460183144
2025-11-24 01:11:01.067 | INFO     | __main__:<module>:160 - Step43390, Loss: 3.5726141929626465, Grad L2 Norm: 0.02165529876947403
2025-11-24 01:11:03.050 | INFO     | __main__:<module>:160 - Step43400, Loss: 3.525233030319214, Grad L2 Norm: 0.022770538926124573
2025-11-24 01:11:05.032 | INFO     | __main__:<module>:160 - Step43410, Loss: 3.490814447402954, Grad L2 Norm: 0.02161998301744461
2025-11-24 01:11:07.018 | INFO     | __main__:<module>:160 - Step43420, Loss: 3.5677080154418945, Grad L2 Norm: 0.023716455325484276
2025-11-24 01:11:09.004 | INFO     | __main__:<module>:160 - Step43430, Loss: 3.5819456577301025, Grad L2 Norm: 0.022109193727374077
2025-11-24 01:11:10.987 | INFO     | __main__:<module>:160 - Step43440, Loss: 3.5772275924682617, Grad L2 Norm: 0.021601896733045578
2025-11-24 01:11:12.968 | INFO     | __main__:<module>:160 - Step43450, Loss: 3.6613526344299316, Grad L2 Norm: 0.022695831954479218
2025-11-24 01:11:14.947 | INFO     | __main__:<module>:160 - Step43460, Loss: 3.5130014419555664, Grad L2 Norm: 0.02242898754775524
2025-11-24 01:11:16.928 | INFO     | __main__:<module>:160 - Step43470, Loss: 3.5253751277923584, Grad L2 Norm: 0.021488232538104057
2025-11-24 01:11:18.906 | INFO     | __main__:<module>:160 - Step43480, Loss: 3.7755208015441895, Grad L2 Norm: 0.025431765243411064
2025-11-24 01:11:20.887 | INFO     | __main__:<module>:160 - Step43490, Loss: 3.4501798152923584, Grad L2 Norm: 0.022585801780223846
2025-11-24 01:11:22.870 | INFO     | __main__:<module>:160 - Step43500, Loss: 3.531095027923584, Grad L2 Norm: 0.02236192487180233
2025-11-24 01:11:24.858 | INFO     | __main__:<module>:160 - Step43510, Loss: 3.5360171794891357, Grad L2 Norm: 0.0218763817101717
2025-11-24 01:11:26.839 | INFO     | __main__:<module>:160 - Step43520, Loss: 3.4694273471832275, Grad L2 Norm: 0.024008775129914284
2025-11-24 01:11:28.821 | INFO     | __main__:<module>:160 - Step43530, Loss: 3.512784719467163, Grad L2 Norm: 0.0240385290235281
2025-11-24 01:11:30.802 | INFO     | __main__:<module>:160 - Step43540, Loss: 3.608159065246582, Grad L2 Norm: 0.0224563367664814
2025-11-24 01:11:32.782 | INFO     | __main__:<module>:160 - Step43550, Loss: 3.7426676750183105, Grad L2 Norm: 0.024429665878415108
2025-11-24 01:11:34.763 | INFO     | __main__:<module>:160 - Step43560, Loss: 3.6113758087158203, Grad L2 Norm: 0.023517675697803497
2025-11-24 01:11:36.749 | INFO     | __main__:<module>:160 - Step43570, Loss: 3.538638114929199, Grad L2 Norm: 0.022987032309174538
2025-11-24 01:11:38.734 | INFO     | __main__:<module>:160 - Step43580, Loss: 3.5255603790283203, Grad L2 Norm: 0.02194293588399887
2025-11-24 01:11:40.715 | INFO     | __main__:<module>:160 - Step43590, Loss: 3.7453672885894775, Grad L2 Norm: 0.02385607175529003
2025-11-24 01:11:42.698 | INFO     | __main__:<module>:160 - Step43600, Loss: 3.624143600463867, Grad L2 Norm: 0.022843942046165466
2025-11-24 01:11:42.699 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:11:43.962 | INFO     | __main__:<module>:181 - validation loss: 3.565669357776642
2025-11-24 01:11:45.955 | INFO     | __main__:<module>:160 - Step43610, Loss: 3.560804605484009, Grad L2 Norm: 0.024963190779089928
2025-11-24 01:11:47.939 | INFO     | __main__:<module>:160 - Step43620, Loss: 3.5685465335845947, Grad L2 Norm: 0.022630229592323303
2025-11-24 01:11:49.921 | INFO     | __main__:<module>:160 - Step43630, Loss: 3.6469674110412598, Grad L2 Norm: 0.0252090934664011
2025-11-24 01:11:51.904 | INFO     | __main__:<module>:160 - Step43640, Loss: 3.6277637481689453, Grad L2 Norm: 0.023136863484978676
2025-11-24 01:11:53.887 | INFO     | __main__:<module>:160 - Step43650, Loss: 3.6260931491851807, Grad L2 Norm: 0.021380722522735596
2025-11-24 01:11:55.870 | INFO     | __main__:<module>:160 - Step43660, Loss: 3.560727834701538, Grad L2 Norm: 0.024034962058067322
2025-11-24 01:11:57.849 | INFO     | __main__:<module>:160 - Step43670, Loss: 3.613812208175659, Grad L2 Norm: 0.024971356615424156
2025-11-24 01:11:59.829 | INFO     | __main__:<module>:160 - Step43680, Loss: 3.617380380630493, Grad L2 Norm: 0.022734081372618675
2025-11-24 01:12:01.810 | INFO     | __main__:<module>:160 - Step43690, Loss: 3.502821922302246, Grad L2 Norm: 0.021476106718182564
2025-11-24 01:12:03.792 | INFO     | __main__:<module>:160 - Step43700, Loss: 3.4829320907592773, Grad L2 Norm: 0.02364642731845379
2025-11-24 01:12:05.778 | INFO     | __main__:<module>:160 - Step43710, Loss: 3.5591888427734375, Grad L2 Norm: 0.021212434396147728
2025-11-24 01:12:07.763 | INFO     | __main__:<module>:160 - Step43720, Loss: 3.5147480964660645, Grad L2 Norm: 0.021673910319805145
2025-11-24 01:12:09.740 | INFO     | __main__:<module>:160 - Step43730, Loss: 3.6071436405181885, Grad L2 Norm: 0.021976733580231667
2025-11-24 01:12:11.719 | INFO     | __main__:<module>:160 - Step43740, Loss: 3.4267868995666504, Grad L2 Norm: 0.02205701731145382
2025-11-24 01:12:13.699 | INFO     | __main__:<module>:160 - Step43750, Loss: 3.537984609603882, Grad L2 Norm: 0.02156033366918564
2025-11-24 01:12:15.682 | INFO     | __main__:<module>:160 - Step43760, Loss: 3.617805004119873, Grad L2 Norm: 0.021795757114887238
2025-11-24 01:12:17.665 | INFO     | __main__:<module>:160 - Step43770, Loss: 3.5552749633789062, Grad L2 Norm: 0.021745622158050537
2025-11-24 01:12:19.649 | INFO     | __main__:<module>:160 - Step43780, Loss: 3.501716136932373, Grad L2 Norm: 0.021666647866368294
2025-11-24 01:12:21.633 | INFO     | __main__:<module>:160 - Step43790, Loss: 3.4691162109375, Grad L2 Norm: 0.022450953722000122
2025-11-24 01:12:23.618 | INFO     | __main__:<module>:160 - Step43800, Loss: 3.555757999420166, Grad L2 Norm: 0.022678516805171967
2025-11-24 01:12:25.600 | INFO     | __main__:<module>:160 - Step43810, Loss: 3.553968667984009, Grad L2 Norm: 0.02226262539625168
2025-11-24 01:12:27.580 | INFO     | __main__:<module>:160 - Step43820, Loss: 3.5292797088623047, Grad L2 Norm: 0.022570831701159477
2025-11-24 01:12:29.564 | INFO     | __main__:<module>:160 - Step43830, Loss: 3.3857195377349854, Grad L2 Norm: 0.021890442818403244
2025-11-24 01:12:31.548 | INFO     | __main__:<module>:160 - Step43840, Loss: 3.54914927482605, Grad L2 Norm: 0.02264014631509781
2025-11-24 01:12:33.524 | INFO     | __main__:<module>:160 - Step43850, Loss: 3.624845027923584, Grad L2 Norm: 0.021486185491085052
2025-11-24 01:12:35.502 | INFO     | __main__:<module>:160 - Step43860, Loss: 3.5155439376831055, Grad L2 Norm: 0.023584263399243355
2025-11-24 01:12:37.480 | INFO     | __main__:<module>:160 - Step43870, Loss: 3.6222095489501953, Grad L2 Norm: 0.02485026977956295
2025-11-24 01:12:39.459 | INFO     | __main__:<module>:160 - Step43880, Loss: 3.6578500270843506, Grad L2 Norm: 0.021903501823544502
2025-11-24 01:12:41.439 | INFO     | __main__:<module>:160 - Step43890, Loss: 3.6141650676727295, Grad L2 Norm: 0.02236207202076912
2025-11-24 01:12:43.421 | INFO     | __main__:<module>:160 - Step43900, Loss: 3.56843900680542, Grad L2 Norm: 0.02192053012549877
2025-11-24 01:12:45.400 | INFO     | __main__:<module>:160 - Step43910, Loss: 3.6047916412353516, Grad L2 Norm: 0.021639402955770493
2025-11-24 01:12:47.380 | INFO     | __main__:<module>:160 - Step43920, Loss: 3.626875638961792, Grad L2 Norm: 0.022193502634763718
2025-11-24 01:12:49.359 | INFO     | __main__:<module>:160 - Step43930, Loss: 3.431957721710205, Grad L2 Norm: 0.022634582594037056
2025-11-24 01:12:51.339 | INFO     | __main__:<module>:160 - Step43940, Loss: 3.4829442501068115, Grad L2 Norm: 0.02251000888645649
2025-11-24 01:12:53.317 | INFO     | __main__:<module>:160 - Step43950, Loss: 3.6058058738708496, Grad L2 Norm: 0.02361217699944973
2025-11-24 01:12:55.295 | INFO     | __main__:<module>:160 - Step43960, Loss: 3.480416774749756, Grad L2 Norm: 0.02274521067738533
2025-11-24 01:12:57.269 | INFO     | __main__:<module>:160 - Step43970, Loss: 3.5340771675109863, Grad L2 Norm: 0.022296776995062828
2025-11-24 01:12:59.248 | INFO     | __main__:<module>:160 - Step43980, Loss: 3.5089991092681885, Grad L2 Norm: 0.020698808133602142
2025-11-24 01:13:01.225 | INFO     | __main__:<module>:160 - Step43990, Loss: 3.4959661960601807, Grad L2 Norm: 0.022754937410354614
2025-11-24 01:13:03.201 | INFO     | __main__:<module>:160 - Step44000, Loss: 3.444934129714966, Grad L2 Norm: 0.02265828102827072
2025-11-24 01:13:03.202 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:13:04.453 | INFO     | __main__:<module>:181 - validation loss: 3.5600780725479124
2025-11-24 01:13:04.454 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_44000.pt
2025-11-24 01:13:06.126 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 01:13:08.073 | INFO     | __main__:<module>:160 - Step44010, Loss: 3.5580224990844727, Grad L2 Norm: 0.024275699630379677
2025-11-24 01:13:10.040 | INFO     | __main__:<module>:160 - Step44020, Loss: 3.5869576930999756, Grad L2 Norm: 0.02223074808716774
2025-11-24 01:13:12.009 | INFO     | __main__:<module>:160 - Step44030, Loss: 3.48695707321167, Grad L2 Norm: 0.02252984419465065
2025-11-24 01:13:13.979 | INFO     | __main__:<module>:160 - Step44040, Loss: 3.4990954399108887, Grad L2 Norm: 0.02250347100198269
2025-11-24 01:13:15.946 | INFO     | __main__:<module>:160 - Step44050, Loss: 3.75681734085083, Grad L2 Norm: 0.026408931240439415
2025-11-24 01:13:17.921 | INFO     | __main__:<module>:160 - Step44060, Loss: 3.5591840744018555, Grad L2 Norm: 0.022503145039081573
2025-11-24 01:13:19.895 | INFO     | __main__:<module>:160 - Step44070, Loss: 3.5494635105133057, Grad L2 Norm: 0.022267764434218407
2025-11-24 01:13:21.864 | INFO     | __main__:<module>:160 - Step44080, Loss: 3.456080436706543, Grad L2 Norm: 0.023394471034407616
2025-11-24 01:13:23.837 | INFO     | __main__:<module>:160 - Step44090, Loss: 3.5781705379486084, Grad L2 Norm: 0.022882478311657906
2025-11-24 01:13:25.805 | INFO     | __main__:<module>:160 - Step44100, Loss: 3.4388763904571533, Grad L2 Norm: 0.022165440022945404
2025-11-24 01:13:27.779 | INFO     | __main__:<module>:160 - Step44110, Loss: 3.6074929237365723, Grad L2 Norm: 0.023061834275722504
2025-11-24 01:13:29.746 | INFO     | __main__:<module>:160 - Step44120, Loss: 3.570561408996582, Grad L2 Norm: 0.023377610370516777
2025-11-24 01:13:31.717 | INFO     | __main__:<module>:160 - Step44130, Loss: 3.476379871368408, Grad L2 Norm: 0.022375639528036118
2025-11-24 01:13:33.684 | INFO     | __main__:<module>:160 - Step44140, Loss: 3.556939125061035, Grad L2 Norm: 0.02156088873744011
2025-11-24 01:13:35.648 | INFO     | __main__:<module>:160 - Step44150, Loss: 3.564286947250366, Grad L2 Norm: 0.022217677906155586
2025-11-24 01:13:37.617 | INFO     | __main__:<module>:160 - Step44160, Loss: 3.3929877281188965, Grad L2 Norm: 0.022455671802163124
2025-11-24 01:13:39.589 | INFO     | __main__:<module>:160 - Step44170, Loss: 3.5821638107299805, Grad L2 Norm: 0.024943212047219276
2025-11-24 01:13:41.558 | INFO     | __main__:<module>:160 - Step44180, Loss: 3.5431952476501465, Grad L2 Norm: 0.023058291524648666
2025-11-24 01:13:43.531 | INFO     | __main__:<module>:160 - Step44190, Loss: 3.6780481338500977, Grad L2 Norm: 0.024533364921808243
2025-11-24 01:13:45.509 | INFO     | __main__:<module>:160 - Step44200, Loss: 3.5379390716552734, Grad L2 Norm: 0.021388733759522438
2025-11-24 01:13:47.483 | INFO     | __main__:<module>:160 - Step44210, Loss: 3.56158447265625, Grad L2 Norm: 0.021436922252178192
2025-11-24 01:13:49.459 | INFO     | __main__:<module>:160 - Step44220, Loss: 3.4762017726898193, Grad L2 Norm: 0.022097352892160416
2025-11-24 01:13:51.436 | INFO     | __main__:<module>:160 - Step44230, Loss: 3.6066131591796875, Grad L2 Norm: 0.022185662761330605
2025-11-24 01:13:53.415 | INFO     | __main__:<module>:160 - Step44240, Loss: 3.4204554557800293, Grad L2 Norm: 0.023476341739296913
2025-11-24 01:13:55.394 | INFO     | __main__:<module>:160 - Step44250, Loss: 3.694460868835449, Grad L2 Norm: 0.022596603259444237
2025-11-24 01:13:57.368 | INFO     | __main__:<module>:160 - Step44260, Loss: 3.458976984024048, Grad L2 Norm: 0.021503765136003494
2025-11-24 01:13:59.338 | INFO     | __main__:<module>:160 - Step44270, Loss: 3.7068512439727783, Grad L2 Norm: 0.02251921407878399
2025-11-24 01:14:01.309 | INFO     | __main__:<module>:160 - Step44280, Loss: 3.6425271034240723, Grad L2 Norm: 0.022502895444631577
2025-11-24 01:14:03.280 | INFO     | __main__:<module>:160 - Step44290, Loss: 3.659961700439453, Grad L2 Norm: 0.023804716765880585
2025-11-24 01:14:05.254 | INFO     | __main__:<module>:160 - Step44300, Loss: 3.6406333446502686, Grad L2 Norm: 0.022703707218170166
2025-11-24 01:14:07.231 | INFO     | __main__:<module>:160 - Step44310, Loss: 3.615736484527588, Grad L2 Norm: 0.02185472659766674
2025-11-24 01:14:09.207 | INFO     | __main__:<module>:160 - Step44320, Loss: 3.6237635612487793, Grad L2 Norm: 0.02333563193678856
2025-11-24 01:14:11.176 | INFO     | __main__:<module>:160 - Step44330, Loss: 3.5022153854370117, Grad L2 Norm: 0.023446783423423767
2025-11-24 01:14:13.146 | INFO     | __main__:<module>:160 - Step44340, Loss: 3.6999778747558594, Grad L2 Norm: 0.023990077897906303
2025-11-24 01:14:15.115 | INFO     | __main__:<module>:160 - Step44350, Loss: 3.46976375579834, Grad L2 Norm: 0.022251833230257034
2025-11-24 01:14:17.087 | INFO     | __main__:<module>:160 - Step44360, Loss: 3.753431797027588, Grad L2 Norm: 0.023573124781250954
2025-11-24 01:14:19.054 | INFO     | __main__:<module>:160 - Step44370, Loss: 3.7548763751983643, Grad L2 Norm: 0.0238035935908556
2025-11-24 01:14:21.026 | INFO     | __main__:<module>:160 - Step44380, Loss: 3.4529380798339844, Grad L2 Norm: 0.023488417267799377
2025-11-24 01:14:22.998 | INFO     | __main__:<module>:160 - Step44390, Loss: 3.667391061782837, Grad L2 Norm: 0.024162692949175835
2025-11-24 01:14:24.967 | INFO     | __main__:<module>:160 - Step44400, Loss: 3.7247235774993896, Grad L2 Norm: 0.02527780830860138
2025-11-24 01:14:24.968 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:14:26.221 | INFO     | __main__:<module>:181 - validation loss: 3.565260648727417
2025-11-24 01:14:28.202 | INFO     | __main__:<module>:160 - Step44410, Loss: 3.6358232498168945, Grad L2 Norm: 0.023247869685292244
2025-11-24 01:14:30.171 | INFO     | __main__:<module>:160 - Step44420, Loss: 3.6011133193969727, Grad L2 Norm: 0.023354891687631607
2025-11-24 01:14:32.144 | INFO     | __main__:<module>:160 - Step44430, Loss: 3.5388054847717285, Grad L2 Norm: 0.022502228617668152
2025-11-24 01:14:34.114 | INFO     | __main__:<module>:160 - Step44440, Loss: 3.468776226043701, Grad L2 Norm: 0.023289009928703308
2025-11-24 01:14:36.091 | INFO     | __main__:<module>:160 - Step44450, Loss: 3.6029443740844727, Grad L2 Norm: 0.021728210151195526
2025-11-24 01:14:38.065 | INFO     | __main__:<module>:160 - Step44460, Loss: 3.4809465408325195, Grad L2 Norm: 0.021727748215198517
2025-11-24 01:14:40.040 | INFO     | __main__:<module>:160 - Step44470, Loss: 3.7729315757751465, Grad L2 Norm: 0.02374028041958809
2025-11-24 01:14:42.016 | INFO     | __main__:<module>:160 - Step44480, Loss: 3.655595541000366, Grad L2 Norm: 0.023836351931095123
2025-11-24 01:14:43.993 | INFO     | __main__:<module>:160 - Step44490, Loss: 3.634413719177246, Grad L2 Norm: 0.02377878502011299
2025-11-24 01:14:45.963 | INFO     | __main__:<module>:160 - Step44500, Loss: 3.5913028717041016, Grad L2 Norm: 0.025158604606986046
2025-11-24 01:14:47.936 | INFO     | __main__:<module>:160 - Step44510, Loss: 3.5499558448791504, Grad L2 Norm: 0.02178303152322769
2025-11-24 01:14:49.913 | INFO     | __main__:<module>:160 - Step44520, Loss: 3.470947265625, Grad L2 Norm: 0.02189120650291443
2025-11-24 01:14:51.891 | INFO     | __main__:<module>:160 - Step44530, Loss: 3.5457496643066406, Grad L2 Norm: 0.02115527167916298
2025-11-24 01:14:53.868 | INFO     | __main__:<module>:160 - Step44540, Loss: 3.7310009002685547, Grad L2 Norm: 0.026992755010724068
2025-11-24 01:14:55.841 | INFO     | __main__:<module>:160 - Step44550, Loss: 3.4289400577545166, Grad L2 Norm: 0.02338721975684166
2025-11-24 01:14:57.817 | INFO     | __main__:<module>:160 - Step44560, Loss: 3.5049357414245605, Grad L2 Norm: 0.02249859645962715
2025-11-24 01:14:59.792 | INFO     | __main__:<module>:160 - Step44570, Loss: 3.369715452194214, Grad L2 Norm: 0.02228960394859314
2025-11-24 01:15:01.760 | INFO     | __main__:<module>:160 - Step44580, Loss: 3.408447265625, Grad L2 Norm: 0.023453762754797935
2025-11-24 01:15:03.733 | INFO     | __main__:<module>:160 - Step44590, Loss: 3.5541200637817383, Grad L2 Norm: 0.02378176338970661
2025-11-24 01:15:05.704 | INFO     | __main__:<module>:160 - Step44600, Loss: 3.499871253967285, Grad L2 Norm: 0.02348925918340683
2025-11-24 01:15:07.672 | INFO     | __main__:<module>:160 - Step44610, Loss: 3.4825339317321777, Grad L2 Norm: 0.025158774107694626
2025-11-24 01:15:09.639 | INFO     | __main__:<module>:160 - Step44620, Loss: 3.5618174076080322, Grad L2 Norm: 0.023194149136543274
2025-11-24 01:15:11.612 | INFO     | __main__:<module>:160 - Step44630, Loss: 3.535271167755127, Grad L2 Norm: 0.022023817524313927
2025-11-24 01:15:13.586 | INFO     | __main__:<module>:160 - Step44640, Loss: 3.5095455646514893, Grad L2 Norm: 0.022791964933276176
2025-11-24 01:15:15.553 | INFO     | __main__:<module>:160 - Step44650, Loss: 3.5451014041900635, Grad L2 Norm: 0.021210432052612305
2025-11-24 01:15:17.527 | INFO     | __main__:<module>:160 - Step44660, Loss: 3.507167100906372, Grad L2 Norm: 0.022485749796032906
2025-11-24 01:15:19.493 | INFO     | __main__:<module>:160 - Step44670, Loss: 3.547252655029297, Grad L2 Norm: 0.022245967760682106
2025-11-24 01:15:21.465 | INFO     | __main__:<module>:160 - Step44680, Loss: 3.5939157009124756, Grad L2 Norm: 0.024381166324019432
2025-11-24 01:15:23.436 | INFO     | __main__:<module>:160 - Step44690, Loss: 3.557328939437866, Grad L2 Norm: 0.02077752910554409
2025-11-24 01:15:25.408 | INFO     | __main__:<module>:160 - Step44700, Loss: 3.643228054046631, Grad L2 Norm: 0.023715700954198837
2025-11-24 01:15:27.382 | INFO     | __main__:<module>:160 - Step44710, Loss: 3.527434825897217, Grad L2 Norm: 0.02413509599864483
2025-11-24 01:15:29.351 | INFO     | __main__:<module>:160 - Step44720, Loss: 3.607987403869629, Grad L2 Norm: 0.025113636627793312
2025-11-24 01:15:31.327 | INFO     | __main__:<module>:160 - Step44730, Loss: 3.4486374855041504, Grad L2 Norm: 0.021727431565523148
2025-11-24 01:15:33.300 | INFO     | __main__:<module>:160 - Step44740, Loss: 3.468029260635376, Grad L2 Norm: 0.02258889749646187
2025-11-24 01:15:35.277 | INFO     | __main__:<module>:160 - Step44750, Loss: 3.6855921745300293, Grad L2 Norm: 0.023960670456290245
2025-11-24 01:15:37.250 | INFO     | __main__:<module>:160 - Step44760, Loss: 3.7404332160949707, Grad L2 Norm: 0.023677358403801918
2025-11-24 01:15:39.223 | INFO     | __main__:<module>:160 - Step44770, Loss: 3.5728116035461426, Grad L2 Norm: 0.02340392768383026
2025-11-24 01:15:41.198 | INFO     | __main__:<module>:160 - Step44780, Loss: 3.764171600341797, Grad L2 Norm: 0.023892728611826897
2025-11-24 01:15:43.176 | INFO     | __main__:<module>:160 - Step44790, Loss: 3.534071207046509, Grad L2 Norm: 0.023018352687358856
2025-11-24 01:15:45.147 | INFO     | __main__:<module>:160 - Step44800, Loss: 3.579925775527954, Grad L2 Norm: 0.020595846697688103
2025-11-24 01:15:45.148 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:15:46.401 | INFO     | __main__:<module>:181 - validation loss: 3.5643097162246704
2025-11-24 01:15:48.379 | INFO     | __main__:<module>:160 - Step44810, Loss: 3.464815139770508, Grad L2 Norm: 0.022359970957040787
2025-11-24 01:15:50.350 | INFO     | __main__:<module>:160 - Step44820, Loss: 3.7072153091430664, Grad L2 Norm: 0.0227726548910141
2025-11-24 01:15:52.319 | INFO     | __main__:<module>:160 - Step44830, Loss: 3.5870699882507324, Grad L2 Norm: 0.02307191677391529
2025-11-24 01:15:54.291 | INFO     | __main__:<module>:160 - Step44840, Loss: 3.5763561725616455, Grad L2 Norm: 0.021839609369635582
2025-11-24 01:15:56.259 | INFO     | __main__:<module>:160 - Step44850, Loss: 3.579770088195801, Grad L2 Norm: 0.02416042424738407
2025-11-24 01:15:58.228 | INFO     | __main__:<module>:160 - Step44860, Loss: 3.48506760597229, Grad L2 Norm: 0.02237125113606453
2025-11-24 01:16:00.199 | INFO     | __main__:<module>:160 - Step44870, Loss: 3.569091320037842, Grad L2 Norm: 0.023889632895588875
2025-11-24 01:16:02.170 | INFO     | __main__:<module>:160 - Step44880, Loss: 3.5288047790527344, Grad L2 Norm: 0.02115417644381523
2025-11-24 01:16:04.139 | INFO     | __main__:<module>:160 - Step44890, Loss: 3.4565587043762207, Grad L2 Norm: 0.021631823852658272
2025-11-24 01:16:06.114 | INFO     | __main__:<module>:160 - Step44900, Loss: 3.611790895462036, Grad L2 Norm: 0.02210460603237152
2025-11-24 01:16:08.088 | INFO     | __main__:<module>:160 - Step44910, Loss: 3.465585231781006, Grad L2 Norm: 0.02360304445028305
2025-11-24 01:16:10.061 | INFO     | __main__:<module>:160 - Step44920, Loss: 3.5862507820129395, Grad L2 Norm: 0.02161424420773983
2025-11-24 01:16:12.033 | INFO     | __main__:<module>:160 - Step44930, Loss: 3.6107797622680664, Grad L2 Norm: 0.023701732978224754
2025-11-24 01:16:14.005 | INFO     | __main__:<module>:160 - Step44940, Loss: 3.697206974029541, Grad L2 Norm: 0.025053445249795914
2025-11-24 01:16:15.975 | INFO     | __main__:<module>:160 - Step44950, Loss: 3.6810717582702637, Grad L2 Norm: 0.02442985773086548
2025-11-24 01:16:17.949 | INFO     | __main__:<module>:160 - Step44960, Loss: 3.5886969566345215, Grad L2 Norm: 0.02338111773133278
2025-11-24 01:16:19.919 | INFO     | __main__:<module>:160 - Step44970, Loss: 3.6044344902038574, Grad L2 Norm: 0.022353315725922585
2025-11-24 01:16:21.893 | INFO     | __main__:<module>:160 - Step44980, Loss: 3.438373327255249, Grad L2 Norm: 0.022328335791826248
2025-11-24 01:16:23.868 | INFO     | __main__:<module>:160 - Step44990, Loss: 3.463792085647583, Grad L2 Norm: 0.023535702377557755
2025-11-24 01:16:25.842 | INFO     | __main__:<module>:160 - Step45000, Loss: 3.5629429817199707, Grad L2 Norm: 0.021248409524559975
2025-11-24 01:16:27.814 | INFO     | __main__:<module>:160 - Step45010, Loss: 3.5631258487701416, Grad L2 Norm: 0.023549478501081467
2025-11-24 01:16:29.794 | INFO     | __main__:<module>:160 - Step45020, Loss: 3.4790422916412354, Grad L2 Norm: 0.02417454682290554
2025-11-24 01:16:31.772 | INFO     | __main__:<module>:160 - Step45030, Loss: 3.6247854232788086, Grad L2 Norm: 0.02176669053733349
2025-11-24 01:16:33.750 | INFO     | __main__:<module>:160 - Step45040, Loss: 3.6991961002349854, Grad L2 Norm: 0.02426832728087902
2025-11-24 01:16:35.724 | INFO     | __main__:<module>:160 - Step45050, Loss: 3.4988832473754883, Grad L2 Norm: 0.023055575788021088
2025-11-24 01:16:37.701 | INFO     | __main__:<module>:160 - Step45060, Loss: 3.7350516319274902, Grad L2 Norm: 0.02367076277732849
2025-11-24 01:16:39.678 | INFO     | __main__:<module>:160 - Step45070, Loss: 3.538267135620117, Grad L2 Norm: 0.022422034293413162
2025-11-24 01:16:41.651 | INFO     | __main__:<module>:160 - Step45080, Loss: 3.625718593597412, Grad L2 Norm: 0.02314663492143154
2025-11-24 01:16:43.626 | INFO     | __main__:<module>:160 - Step45090, Loss: 3.486556053161621, Grad L2 Norm: 0.022417698055505753
2025-11-24 01:16:45.602 | INFO     | __main__:<module>:160 - Step45100, Loss: 3.5539846420288086, Grad L2 Norm: 0.022732770070433617
2025-11-24 01:16:47.576 | INFO     | __main__:<module>:160 - Step45110, Loss: 3.6573545932769775, Grad L2 Norm: 0.02287895977497101
2025-11-24 01:16:49.547 | INFO     | __main__:<module>:160 - Step45120, Loss: 3.5444514751434326, Grad L2 Norm: 0.023143526166677475
2025-11-24 01:16:51.521 | INFO     | __main__:<module>:160 - Step45130, Loss: 3.4661636352539062, Grad L2 Norm: 0.02185329794883728
2025-11-24 01:16:53.497 | INFO     | __main__:<module>:160 - Step45140, Loss: 3.601290464401245, Grad L2 Norm: 0.023648463189601898
2025-11-24 01:16:55.474 | INFO     | __main__:<module>:160 - Step45150, Loss: 3.5622482299804688, Grad L2 Norm: 0.02089819498360157
2025-11-24 01:16:57.445 | INFO     | __main__:<module>:160 - Step45160, Loss: 3.5065855979919434, Grad L2 Norm: 0.023739848285913467
2025-11-24 01:16:59.420 | INFO     | __main__:<module>:160 - Step45170, Loss: 3.479401111602783, Grad L2 Norm: 0.021604685112833977
2025-11-24 01:17:01.395 | INFO     | __main__:<module>:160 - Step45180, Loss: 3.470690965652466, Grad L2 Norm: 0.022315258160233498
2025-11-24 01:17:03.366 | INFO     | __main__:<module>:160 - Step45190, Loss: 3.509080410003662, Grad L2 Norm: 0.02349982038140297
2025-11-24 01:17:05.336 | INFO     | __main__:<module>:160 - Step45200, Loss: 3.6208815574645996, Grad L2 Norm: 0.0224777702242136
2025-11-24 01:17:05.337 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:17:06.587 | INFO     | __main__:<module>:181 - validation loss: 3.583612525463104
2025-11-24 01:17:08.572 | INFO     | __main__:<module>:160 - Step45210, Loss: 3.500068187713623, Grad L2 Norm: 0.023212667554616928
2025-11-24 01:17:10.538 | INFO     | __main__:<module>:160 - Step45220, Loss: 3.5892486572265625, Grad L2 Norm: 0.022274035960435867
2025-11-24 01:17:12.507 | INFO     | __main__:<module>:160 - Step45230, Loss: 3.5823206901550293, Grad L2 Norm: 0.0263187475502491
2025-11-24 01:17:14.475 | INFO     | __main__:<module>:160 - Step45240, Loss: 3.6167874336242676, Grad L2 Norm: 0.023757243528962135
2025-11-24 01:17:16.440 | INFO     | __main__:<module>:160 - Step45250, Loss: 3.5891711711883545, Grad L2 Norm: 0.023351939395070076
2025-11-24 01:17:18.412 | INFO     | __main__:<module>:160 - Step45260, Loss: 3.4946699142456055, Grad L2 Norm: 0.021835489198565483
2025-11-24 01:17:20.380 | INFO     | __main__:<module>:160 - Step45270, Loss: 3.6352379322052, Grad L2 Norm: 0.022182920947670937
2025-11-24 01:17:22.351 | INFO     | __main__:<module>:160 - Step45280, Loss: 3.525733232498169, Grad L2 Norm: 0.022536855190992355
2025-11-24 01:17:24.315 | INFO     | __main__:<module>:160 - Step45290, Loss: 3.637298345565796, Grad L2 Norm: 0.022853132337331772
2025-11-24 01:17:26.278 | INFO     | __main__:<module>:160 - Step45300, Loss: 3.605889081954956, Grad L2 Norm: 0.022524265572428703
2025-11-24 01:17:28.247 | INFO     | __main__:<module>:160 - Step45310, Loss: 3.4860172271728516, Grad L2 Norm: 0.022384559735655785
2025-11-24 01:17:30.216 | INFO     | __main__:<module>:160 - Step45320, Loss: 3.6509604454040527, Grad L2 Norm: 0.0247728880494833
2025-11-24 01:17:32.184 | INFO     | __main__:<module>:160 - Step45330, Loss: 3.531665086746216, Grad L2 Norm: 0.023974711075425148
2025-11-24 01:17:34.149 | INFO     | __main__:<module>:160 - Step45340, Loss: 3.544764518737793, Grad L2 Norm: 0.022250138223171234
2025-11-24 01:17:36.116 | INFO     | __main__:<module>:160 - Step45350, Loss: 3.573375701904297, Grad L2 Norm: 0.02177581563591957
2025-11-24 01:17:38.082 | INFO     | __main__:<module>:160 - Step45360, Loss: 3.465498924255371, Grad L2 Norm: 0.022486796602606773
2025-11-24 01:17:40.044 | INFO     | __main__:<module>:160 - Step45370, Loss: 3.4790401458740234, Grad L2 Norm: 0.023334410041570663
2025-11-24 01:17:42.006 | INFO     | __main__:<module>:160 - Step45380, Loss: 3.5098729133605957, Grad L2 Norm: 0.022211477160453796
2025-11-24 01:17:43.969 | INFO     | __main__:<module>:160 - Step45390, Loss: 3.62882137298584, Grad L2 Norm: 0.022998612374067307
2025-11-24 01:17:45.930 | INFO     | __main__:<module>:160 - Step45400, Loss: 3.5303282737731934, Grad L2 Norm: 0.022751977667212486
2025-11-24 01:17:47.892 | INFO     | __main__:<module>:160 - Step45410, Loss: 3.496002197265625, Grad L2 Norm: 0.022710327059030533
2025-11-24 01:17:49.859 | INFO     | __main__:<module>:160 - Step45420, Loss: 3.5678913593292236, Grad L2 Norm: 0.022212442010641098
2025-11-24 01:17:51.822 | INFO     | __main__:<module>:160 - Step45430, Loss: 3.4931259155273438, Grad L2 Norm: 0.02240622602403164
2025-11-24 01:17:53.785 | INFO     | __main__:<module>:160 - Step45440, Loss: 3.5713841915130615, Grad L2 Norm: 0.027619434520602226
2025-11-24 01:17:55.744 | INFO     | __main__:<module>:160 - Step45450, Loss: 3.6122500896453857, Grad L2 Norm: 0.023017754778265953
2025-11-24 01:17:57.709 | INFO     | __main__:<module>:160 - Step45460, Loss: 3.607579469680786, Grad L2 Norm: 0.022432664409279823
2025-11-24 01:17:59.676 | INFO     | __main__:<module>:160 - Step45470, Loss: 3.40061616897583, Grad L2 Norm: 0.02270091511309147
2025-11-24 01:18:01.637 | INFO     | __main__:<module>:160 - Step45480, Loss: 3.4739484786987305, Grad L2 Norm: 0.023500114679336548
2025-11-24 01:18:03.602 | INFO     | __main__:<module>:160 - Step45490, Loss: 3.4857425689697266, Grad L2 Norm: 0.021669402718544006
2025-11-24 01:18:05.572 | INFO     | __main__:<module>:160 - Step45500, Loss: 3.5828752517700195, Grad L2 Norm: 0.022417711094021797
2025-11-24 01:18:07.535 | INFO     | __main__:<module>:160 - Step45510, Loss: 3.529606819152832, Grad L2 Norm: 0.02249518595635891
2025-11-24 01:18:09.487 | INFO     | __main__:<module>:160 - Step45520, Loss: 3.5443239212036133, Grad L2 Norm: 0.02258881740272045
2025-11-24 01:18:11.439 | INFO     | __main__:<module>:160 - Step45530, Loss: 3.4636383056640625, Grad L2 Norm: 0.021887416020035744
2025-11-24 01:18:13.394 | INFO     | __main__:<module>:160 - Step45540, Loss: 3.494131565093994, Grad L2 Norm: 0.022256789728999138
2025-11-24 01:18:15.353 | INFO     | __main__:<module>:160 - Step45550, Loss: 3.4858431816101074, Grad L2 Norm: 0.0227871872484684
2025-11-24 01:18:17.306 | INFO     | __main__:<module>:160 - Step45560, Loss: 3.5036418437957764, Grad L2 Norm: 0.023543929681181908
2025-11-24 01:18:19.266 | INFO     | __main__:<module>:160 - Step45570, Loss: 3.5403904914855957, Grad L2 Norm: 0.023212695494294167
2025-11-24 01:18:21.225 | INFO     | __main__:<module>:160 - Step45580, Loss: 3.4344894886016846, Grad L2 Norm: 0.022749004885554314
2025-11-24 01:18:23.176 | INFO     | __main__:<module>:160 - Step45590, Loss: 3.554164409637451, Grad L2 Norm: 0.02284608781337738
2025-11-24 01:18:25.130 | INFO     | __main__:<module>:160 - Step45600, Loss: 3.487703323364258, Grad L2 Norm: 0.023596514016389847
2025-11-24 01:18:25.131 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:18:26.373 | INFO     | __main__:<module>:181 - validation loss: 3.5816797375679017
2025-11-24 01:18:28.341 | INFO     | __main__:<module>:160 - Step45610, Loss: 3.6211721897125244, Grad L2 Norm: 0.027168208733201027
2025-11-24 01:18:30.299 | INFO     | __main__:<module>:160 - Step45620, Loss: 3.521024703979492, Grad L2 Norm: 0.022434260696172714
2025-11-24 01:18:32.251 | INFO     | __main__:<module>:160 - Step45630, Loss: 3.612213611602783, Grad L2 Norm: 0.022360140457749367
2025-11-24 01:18:34.209 | INFO     | __main__:<module>:160 - Step45640, Loss: 3.5680198669433594, Grad L2 Norm: 0.02306944876909256
2025-11-24 01:18:36.169 | INFO     | __main__:<module>:160 - Step45650, Loss: 3.574141263961792, Grad L2 Norm: 0.022112678736448288
2025-11-24 01:18:38.121 | INFO     | __main__:<module>:160 - Step45660, Loss: 3.6103265285491943, Grad L2 Norm: 0.022803375497460365
2025-11-24 01:18:40.073 | INFO     | __main__:<module>:160 - Step45670, Loss: 3.4428300857543945, Grad L2 Norm: 0.023329010233283043
2025-11-24 01:18:42.029 | INFO     | __main__:<module>:160 - Step45680, Loss: 3.667642116546631, Grad L2 Norm: 0.024101467803120613
2025-11-24 01:18:43.979 | INFO     | __main__:<module>:160 - Step45690, Loss: 3.5484859943389893, Grad L2 Norm: 0.024325737729668617
2025-11-24 01:18:45.932 | INFO     | __main__:<module>:160 - Step45700, Loss: 3.50362229347229, Grad L2 Norm: 0.021973658353090286
2025-11-24 01:18:47.882 | INFO     | __main__:<module>:160 - Step45710, Loss: 3.546973705291748, Grad L2 Norm: 0.021819649264216423
2025-11-24 01:18:49.841 | INFO     | __main__:<module>:160 - Step45720, Loss: 3.6565146446228027, Grad L2 Norm: 0.023128816857933998
2025-11-24 01:18:51.794 | INFO     | __main__:<module>:160 - Step45730, Loss: 3.5918703079223633, Grad L2 Norm: 0.024937540292739868
2025-11-24 01:18:53.750 | INFO     | __main__:<module>:160 - Step45740, Loss: 3.5725865364074707, Grad L2 Norm: 0.023277148604393005
2025-11-24 01:18:55.717 | INFO     | __main__:<module>:160 - Step45750, Loss: 3.452108144760132, Grad L2 Norm: 0.02261381968855858
2025-11-24 01:18:57.682 | INFO     | __main__:<module>:160 - Step45760, Loss: 3.548154354095459, Grad L2 Norm: 0.02209686115384102
2025-11-24 01:18:59.642 | INFO     | __main__:<module>:160 - Step45770, Loss: 3.7856693267822266, Grad L2 Norm: 0.02238755114376545
2025-11-24 01:19:01.605 | INFO     | __main__:<module>:160 - Step45780, Loss: 3.600318670272827, Grad L2 Norm: 0.024204468354582787
2025-11-24 01:19:03.565 | INFO     | __main__:<module>:160 - Step45790, Loss: 3.6882972717285156, Grad L2 Norm: 0.02242712490260601
2025-11-24 01:19:05.528 | INFO     | __main__:<module>:160 - Step45800, Loss: 3.560664176940918, Grad L2 Norm: 0.024279078468680382
2025-11-24 01:19:07.494 | INFO     | __main__:<module>:160 - Step45810, Loss: 3.5278513431549072, Grad L2 Norm: 0.022190192714333534
2025-11-24 01:19:09.455 | INFO     | __main__:<module>:160 - Step45820, Loss: 3.5346481800079346, Grad L2 Norm: 0.02181498520076275
2025-11-24 01:19:11.416 | INFO     | __main__:<module>:160 - Step45830, Loss: 3.607386827468872, Grad L2 Norm: 0.020578427240252495
2025-11-24 01:19:13.372 | INFO     | __main__:<module>:160 - Step45840, Loss: 3.4865052700042725, Grad L2 Norm: 0.02219058759510517
2025-11-24 01:19:15.331 | INFO     | __main__:<module>:160 - Step45850, Loss: 3.5075509548187256, Grad L2 Norm: 0.022167488932609558
2025-11-24 01:19:17.291 | INFO     | __main__:<module>:160 - Step45860, Loss: 3.5834641456604004, Grad L2 Norm: 0.024350591003894806
2025-11-24 01:19:19.252 | INFO     | __main__:<module>:160 - Step45870, Loss: 3.4809303283691406, Grad L2 Norm: 0.023096270859241486
2025-11-24 01:19:21.210 | INFO     | __main__:<module>:160 - Step45880, Loss: 3.465649127960205, Grad L2 Norm: 0.02271309681236744
2025-11-24 01:19:23.166 | INFO     | __main__:<module>:160 - Step45890, Loss: 3.4698314666748047, Grad L2 Norm: 0.02667393907904625
2025-11-24 01:19:25.130 | INFO     | __main__:<module>:160 - Step45900, Loss: 3.602973461151123, Grad L2 Norm: 0.02203008532524109
2025-11-24 01:19:27.094 | INFO     | __main__:<module>:160 - Step45910, Loss: 3.523155689239502, Grad L2 Norm: 0.02287784032523632
2025-11-24 01:19:29.056 | INFO     | __main__:<module>:160 - Step45920, Loss: 3.551353693008423, Grad L2 Norm: 0.02249600738286972
2025-11-24 01:19:31.023 | INFO     | __main__:<module>:160 - Step45930, Loss: 3.469261407852173, Grad L2 Norm: 0.022353941574692726
2025-11-24 01:19:32.989 | INFO     | __main__:<module>:160 - Step45940, Loss: 3.5987372398376465, Grad L2 Norm: 0.021154578775167465
2025-11-24 01:19:34.952 | INFO     | __main__:<module>:160 - Step45950, Loss: 3.599418878555298, Grad L2 Norm: 0.022380171343684196
2025-11-24 01:19:36.919 | INFO     | __main__:<module>:160 - Step45960, Loss: 3.5174546241760254, Grad L2 Norm: 0.022344017401337624
2025-11-24 01:19:38.887 | INFO     | __main__:<module>:160 - Step45970, Loss: 3.4727916717529297, Grad L2 Norm: 0.022452721372246742
2025-11-24 01:19:40.852 | INFO     | __main__:<module>:160 - Step45980, Loss: 3.4781153202056885, Grad L2 Norm: 0.024592110887169838
2025-11-24 01:19:42.825 | INFO     | __main__:<module>:160 - Step45990, Loss: 3.620209217071533, Grad L2 Norm: 0.023701444268226624
2025-11-24 01:19:44.794 | INFO     | __main__:<module>:160 - Step46000, Loss: 3.6188671588897705, Grad L2 Norm: 0.021488485857844353
2025-11-24 01:19:44.795 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:19:46.046 | INFO     | __main__:<module>:181 - validation loss: 3.567049539089203
2025-11-24 01:19:46.047 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_46000.pt
2025-11-24 01:19:47.746 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 01:19:49.152 | INFO     | __main__:<module>:160 - Step46010, Loss: 3.5845143795013428, Grad L2 Norm: 0.024124959483742714
2025-11-24 01:19:50.558 | INFO     | __main__:<module>:160 - Step46020, Loss: 3.535078525543213, Grad L2 Norm: 0.02159302867949009
2025-11-24 01:19:51.965 | INFO     | __main__:<module>:160 - Step46030, Loss: 3.5365285873413086, Grad L2 Norm: 0.022751126438379288
2025-11-24 01:19:53.371 | INFO     | __main__:<module>:160 - Step46040, Loss: 3.580467462539673, Grad L2 Norm: 0.022870168089866638
2025-11-24 01:19:54.812 | INFO     | __main__:<module>:160 - Step46050, Loss: 3.545072317123413, Grad L2 Norm: 0.021370835602283478
2025-11-24 01:19:56.317 | INFO     | __main__:<module>:160 - Step46060, Loss: 3.5558111667633057, Grad L2 Norm: 0.023767728358507156
2025-11-24 01:19:57.771 | INFO     | __main__:<module>:160 - Step46070, Loss: 3.5651614665985107, Grad L2 Norm: 0.02318614348769188
2025-11-24 01:19:59.252 | INFO     | __main__:<module>:160 - Step46080, Loss: 3.600738286972046, Grad L2 Norm: 0.026669513434171677
2025-11-24 01:20:00.833 | INFO     | __main__:<module>:160 - Step46090, Loss: 3.478309154510498, Grad L2 Norm: 0.023022091016173363
2025-11-24 01:20:02.383 | INFO     | __main__:<module>:160 - Step46100, Loss: 3.4867513179779053, Grad L2 Norm: 0.02143050916492939
2025-11-24 01:20:03.940 | INFO     | __main__:<module>:160 - Step46110, Loss: 3.644042491912842, Grad L2 Norm: 0.02337559498846531
2025-11-24 01:20:05.494 | INFO     | __main__:<module>:160 - Step46120, Loss: 3.5057501792907715, Grad L2 Norm: 0.022305406630039215
2025-11-24 01:20:07.044 | INFO     | __main__:<module>:160 - Step46130, Loss: 3.562819719314575, Grad L2 Norm: 0.024541517719626427
2025-11-24 01:20:08.598 | INFO     | __main__:<module>:160 - Step46140, Loss: 3.5908401012420654, Grad L2 Norm: 0.02260083146393299
2025-11-24 01:20:10.151 | INFO     | __main__:<module>:160 - Step46150, Loss: 3.608234405517578, Grad L2 Norm: 0.025639597326517105
2025-11-24 01:20:11.703 | INFO     | __main__:<module>:160 - Step46160, Loss: 3.4741878509521484, Grad L2 Norm: 0.02126535400748253
2025-11-24 01:20:13.254 | INFO     | __main__:<module>:160 - Step46170, Loss: 3.5064759254455566, Grad L2 Norm: 0.023707278072834015
2025-11-24 01:20:14.806 | INFO     | __main__:<module>:160 - Step46180, Loss: 3.751826047897339, Grad L2 Norm: 0.02368742972612381
2025-11-24 01:20:16.436 | INFO     | __main__:<module>:160 - Step46190, Loss: 3.438237190246582, Grad L2 Norm: 0.02160920575261116
2025-11-24 01:20:18.172 | INFO     | __main__:<module>:160 - Step46200, Loss: 3.469144821166992, Grad L2 Norm: 0.021994514390826225
2025-11-24 01:20:19.907 | INFO     | __main__:<module>:160 - Step46210, Loss: 3.6810474395751953, Grad L2 Norm: 0.0242291372269392
2025-11-24 01:20:21.595 | INFO     | __main__:<module>:160 - Step46220, Loss: 3.522928476333618, Grad L2 Norm: 0.022332999855279922
2025-11-24 01:20:23.235 | INFO     | __main__:<module>:160 - Step46230, Loss: 3.469383478164673, Grad L2 Norm: 0.021341988816857338
2025-11-24 01:20:24.875 | INFO     | __main__:<module>:160 - Step46240, Loss: 3.501281261444092, Grad L2 Norm: 0.02130642533302307
2025-11-24 01:20:26.517 | INFO     | __main__:<module>:160 - Step46250, Loss: 3.5270042419433594, Grad L2 Norm: 0.022077711299061775
2025-11-24 01:20:28.160 | INFO     | __main__:<module>:160 - Step46260, Loss: 3.484255313873291, Grad L2 Norm: 0.02292901836335659
2025-11-24 01:20:29.801 | INFO     | __main__:<module>:160 - Step46270, Loss: 3.5547432899475098, Grad L2 Norm: 0.022405607625842094
2025-11-24 01:20:31.442 | INFO     | __main__:<module>:160 - Step46280, Loss: 3.5863773822784424, Grad L2 Norm: 0.02263532765209675
2025-11-24 01:20:33.079 | INFO     | __main__:<module>:160 - Step46290, Loss: 3.494213581085205, Grad L2 Norm: 0.0226457342505455
2025-11-24 01:20:34.717 | INFO     | __main__:<module>:160 - Step46300, Loss: 3.574925422668457, Grad L2 Norm: 0.020972594618797302
2025-11-24 01:20:36.356 | INFO     | __main__:<module>:160 - Step46310, Loss: 3.63275146484375, Grad L2 Norm: 0.025402387604117393
2025-11-24 01:20:37.999 | INFO     | __main__:<module>:160 - Step46320, Loss: 3.6210365295410156, Grad L2 Norm: 0.02223014645278454
2025-11-24 01:20:39.638 | INFO     | __main__:<module>:160 - Step46330, Loss: 3.4579527378082275, Grad L2 Norm: 0.02458352968096733
2025-11-24 01:20:41.278 | INFO     | __main__:<module>:160 - Step46340, Loss: 3.6053786277770996, Grad L2 Norm: 0.022741874679923058
2025-11-24 01:20:42.920 | INFO     | __main__:<module>:160 - Step46350, Loss: 3.5435447692871094, Grad L2 Norm: 0.024795610457658768
2025-11-24 01:20:44.561 | INFO     | __main__:<module>:160 - Step46360, Loss: 3.534902811050415, Grad L2 Norm: 0.022169960662722588
2025-11-24 01:20:46.203 | INFO     | __main__:<module>:160 - Step46370, Loss: 3.488241195678711, Grad L2 Norm: 0.023516956716775894
2025-11-24 01:20:47.845 | INFO     | __main__:<module>:160 - Step46380, Loss: 3.5217039585113525, Grad L2 Norm: 0.022654017433524132
2025-11-24 01:20:49.485 | INFO     | __main__:<module>:160 - Step46390, Loss: 3.5183229446411133, Grad L2 Norm: 0.02482420951128006
2025-11-24 01:20:51.128 | INFO     | __main__:<module>:160 - Step46400, Loss: 3.5372679233551025, Grad L2 Norm: 0.02136044390499592
2025-11-24 01:20:51.129 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:20:52.139 | INFO     | __main__:<module>:181 - validation loss: 3.591873621940613
2025-11-24 01:20:53.791 | INFO     | __main__:<module>:160 - Step46410, Loss: 3.5622618198394775, Grad L2 Norm: 0.021654194220900536
2025-11-24 01:20:55.521 | INFO     | __main__:<module>:160 - Step46420, Loss: 3.6359453201293945, Grad L2 Norm: 0.024184133857488632
2025-11-24 01:20:57.252 | INFO     | __main__:<module>:160 - Step46430, Loss: 3.622755527496338, Grad L2 Norm: 0.023212525993585587
2025-11-24 01:20:58.981 | INFO     | __main__:<module>:160 - Step46440, Loss: 3.56404447555542, Grad L2 Norm: 0.02415493130683899
2025-11-24 01:21:00.713 | INFO     | __main__:<module>:160 - Step46450, Loss: 3.699845790863037, Grad L2 Norm: 0.02360098622739315
2025-11-24 01:21:02.445 | INFO     | __main__:<module>:160 - Step46460, Loss: 3.517207145690918, Grad L2 Norm: 0.024826647713780403
2025-11-24 01:21:04.175 | INFO     | __main__:<module>:160 - Step46470, Loss: 3.442456007003784, Grad L2 Norm: 0.022424103692173958
2025-11-24 01:21:05.906 | INFO     | __main__:<module>:160 - Step46480, Loss: 3.6853933334350586, Grad L2 Norm: 0.02505463734269142
2025-11-24 01:21:07.636 | INFO     | __main__:<module>:160 - Step46490, Loss: 3.5733485221862793, Grad L2 Norm: 0.022861190140247345
2025-11-24 01:21:09.367 | INFO     | __main__:<module>:160 - Step46500, Loss: 3.492244005203247, Grad L2 Norm: 0.02195451781153679
2025-11-24 01:21:11.099 | INFO     | __main__:<module>:160 - Step46510, Loss: 3.4131908416748047, Grad L2 Norm: 0.023310136049985886
2025-11-24 01:21:12.829 | INFO     | __main__:<module>:160 - Step46520, Loss: 3.4547901153564453, Grad L2 Norm: 0.024015387520194054
2025-11-24 01:21:14.560 | INFO     | __main__:<module>:160 - Step46530, Loss: 3.3856663703918457, Grad L2 Norm: 0.022809915244579315
2025-11-24 01:21:16.290 | INFO     | __main__:<module>:160 - Step46540, Loss: 3.6449975967407227, Grad L2 Norm: 0.025121545419096947
2025-11-24 01:21:18.020 | INFO     | __main__:<module>:160 - Step46550, Loss: 3.4484055042266846, Grad L2 Norm: 0.022105395793914795
2025-11-24 01:21:19.748 | INFO     | __main__:<module>:160 - Step46560, Loss: 3.598928451538086, Grad L2 Norm: 0.02363535389304161
2025-11-24 01:21:21.479 | INFO     | __main__:<module>:160 - Step46570, Loss: 3.492659091949463, Grad L2 Norm: 0.022586362436413765
2025-11-24 01:21:23.208 | INFO     | __main__:<module>:160 - Step46580, Loss: 3.5292491912841797, Grad L2 Norm: 0.021572157740592957
2025-11-24 01:21:24.938 | INFO     | __main__:<module>:160 - Step46590, Loss: 3.6621313095092773, Grad L2 Norm: 0.0225139819085598
2025-11-24 01:21:26.668 | INFO     | __main__:<module>:160 - Step46600, Loss: 3.564371109008789, Grad L2 Norm: 0.02260175347328186
2025-11-24 01:21:28.398 | INFO     | __main__:<module>:160 - Step46610, Loss: 3.7325615882873535, Grad L2 Norm: 0.024088852107524872
2025-11-24 01:21:30.129 | INFO     | __main__:<module>:160 - Step46620, Loss: 3.510744333267212, Grad L2 Norm: 0.024275342002511024
2025-11-24 01:21:31.858 | INFO     | __main__:<module>:160 - Step46630, Loss: 3.5080161094665527, Grad L2 Norm: 0.023204071447253227
2025-11-24 01:21:33.590 | INFO     | __main__:<module>:160 - Step46640, Loss: 3.5659751892089844, Grad L2 Norm: 0.02426162362098694
2025-11-24 01:21:35.323 | INFO     | __main__:<module>:160 - Step46650, Loss: 3.5502281188964844, Grad L2 Norm: 0.02356046997010708
2025-11-24 01:21:37.054 | INFO     | __main__:<module>:160 - Step46660, Loss: 3.625791311264038, Grad L2 Norm: 0.02321254462003708
2025-11-24 01:21:38.784 | INFO     | __main__:<module>:160 - Step46670, Loss: 3.5229883193969727, Grad L2 Norm: 0.022911032661795616
2025-11-24 01:21:40.514 | INFO     | __main__:<module>:160 - Step46680, Loss: 3.4388790130615234, Grad L2 Norm: 0.021524040028452873
2025-11-24 01:21:42.245 | INFO     | __main__:<module>:160 - Step46690, Loss: 3.5078647136688232, Grad L2 Norm: 0.02295011468231678
2025-11-24 01:21:43.977 | INFO     | __main__:<module>:160 - Step46700, Loss: 3.5568368434906006, Grad L2 Norm: 0.020753873512148857
2025-11-24 01:21:45.706 | INFO     | __main__:<module>:160 - Step46710, Loss: 3.653165817260742, Grad L2 Norm: 0.02181169018149376
2025-11-24 01:21:47.437 | INFO     | __main__:<module>:160 - Step46720, Loss: 3.4881861209869385, Grad L2 Norm: 0.022080691531300545
2025-11-24 01:21:49.167 | INFO     | __main__:<module>:160 - Step46730, Loss: 3.571035861968994, Grad L2 Norm: 0.023238440975546837
2025-11-24 01:21:50.897 | INFO     | __main__:<module>:160 - Step46740, Loss: 3.4877676963806152, Grad L2 Norm: 0.022069355472922325
2025-11-24 01:21:52.628 | INFO     | __main__:<module>:160 - Step46750, Loss: 3.4732038974761963, Grad L2 Norm: 0.02298857644200325
2025-11-24 01:21:54.357 | INFO     | __main__:<module>:160 - Step46760, Loss: 3.57517147064209, Grad L2 Norm: 0.020876767113804817
2025-11-24 01:21:56.088 | INFO     | __main__:<module>:160 - Step46770, Loss: 3.501498222351074, Grad L2 Norm: 0.022714322432875633
2025-11-24 01:21:57.819 | INFO     | __main__:<module>:160 - Step46780, Loss: 3.598182201385498, Grad L2 Norm: 0.02251378260552883
2025-11-24 01:21:59.549 | INFO     | __main__:<module>:160 - Step46790, Loss: 3.576329469680786, Grad L2 Norm: 0.0228474959731102
2025-11-24 01:22:01.278 | INFO     | __main__:<module>:160 - Step46800, Loss: 3.6818861961364746, Grad L2 Norm: 0.024644430726766586
2025-11-24 01:22:01.279 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:22:02.296 | INFO     | __main__:<module>:181 - validation loss: 3.572709345817566
2025-11-24 01:22:04.025 | INFO     | __main__:<module>:160 - Step46810, Loss: 3.4785666465759277, Grad L2 Norm: 0.02340397611260414
2025-11-24 01:22:05.761 | INFO     | __main__:<module>:160 - Step46820, Loss: 3.7515869140625, Grad L2 Norm: 0.023902030661702156
2025-11-24 01:22:07.500 | INFO     | __main__:<module>:160 - Step46830, Loss: 3.4775137901306152, Grad L2 Norm: 0.023433292284607887
2025-11-24 01:22:09.237 | INFO     | __main__:<module>:160 - Step46840, Loss: 3.5456440448760986, Grad L2 Norm: 0.02201332338154316
2025-11-24 01:22:10.972 | INFO     | __main__:<module>:160 - Step46850, Loss: 3.5568981170654297, Grad L2 Norm: 0.022537710145115852
2025-11-24 01:22:12.709 | INFO     | __main__:<module>:160 - Step46860, Loss: 3.5755577087402344, Grad L2 Norm: 0.023130159825086594
2025-11-24 01:22:14.445 | INFO     | __main__:<module>:160 - Step46870, Loss: 3.552689552307129, Grad L2 Norm: 0.022754685953259468
2025-11-24 01:22:16.182 | INFO     | __main__:<module>:160 - Step46880, Loss: 3.570298194885254, Grad L2 Norm: 0.02352428436279297
2025-11-24 01:22:17.919 | INFO     | __main__:<module>:160 - Step46890, Loss: 3.430471897125244, Grad L2 Norm: 0.02170184813439846
2025-11-24 01:22:19.655 | INFO     | __main__:<module>:160 - Step46900, Loss: 3.439370632171631, Grad L2 Norm: 0.022300712764263153
2025-11-24 01:22:21.391 | INFO     | __main__:<module>:160 - Step46910, Loss: 3.6808834075927734, Grad L2 Norm: 0.02312733419239521
2025-11-24 01:22:23.127 | INFO     | __main__:<module>:160 - Step46920, Loss: 3.6044411659240723, Grad L2 Norm: 0.02331085503101349
2025-11-24 01:22:24.862 | INFO     | __main__:<module>:160 - Step46930, Loss: 3.6215968132019043, Grad L2 Norm: 0.026683488860726357
2025-11-24 01:22:26.598 | INFO     | __main__:<module>:160 - Step46940, Loss: 3.6143102645874023, Grad L2 Norm: 0.023813936859369278
2025-11-24 01:22:28.334 | INFO     | __main__:<module>:160 - Step46950, Loss: 3.5328619480133057, Grad L2 Norm: 0.02251669019460678
2025-11-24 01:22:30.069 | INFO     | __main__:<module>:160 - Step46960, Loss: 3.7860186100006104, Grad L2 Norm: 0.03857223689556122
2025-11-24 01:22:31.813 | INFO     | __main__:<module>:160 - Step46970, Loss: 3.523362874984741, Grad L2 Norm: 0.022424640133976936
2025-11-24 01:22:33.549 | INFO     | __main__:<module>:160 - Step46980, Loss: 3.547593116760254, Grad L2 Norm: 0.02192566730082035
2025-11-24 01:22:35.286 | INFO     | __main__:<module>:160 - Step46990, Loss: 3.472825527191162, Grad L2 Norm: 0.022813627496361732
2025-11-24 01:22:37.021 | INFO     | __main__:<module>:160 - Step47000, Loss: 3.54905104637146, Grad L2 Norm: 0.023063190281391144
2025-11-24 01:22:38.757 | INFO     | __main__:<module>:160 - Step47010, Loss: 3.5739479064941406, Grad L2 Norm: 0.023531021550297737
2025-11-24 01:22:40.496 | INFO     | __main__:<module>:160 - Step47020, Loss: 3.47326397895813, Grad L2 Norm: 0.024013519287109375
2025-11-24 01:22:42.231 | INFO     | __main__:<module>:160 - Step47030, Loss: 3.623220205307007, Grad L2 Norm: 0.024208221584558487
2025-11-24 01:22:43.967 | INFO     | __main__:<module>:160 - Step47040, Loss: 3.556915044784546, Grad L2 Norm: 0.021900825202465057
2025-11-24 01:22:45.702 | INFO     | __main__:<module>:160 - Step47050, Loss: 3.608285427093506, Grad L2 Norm: 0.022059176117181778
2025-11-24 01:22:47.438 | INFO     | __main__:<module>:160 - Step47060, Loss: 3.493565559387207, Grad L2 Norm: 0.022990407422184944
2025-11-24 01:22:49.174 | INFO     | __main__:<module>:160 - Step47070, Loss: 3.634953022003174, Grad L2 Norm: 0.023009885102510452
2025-11-24 01:22:50.910 | INFO     | __main__:<module>:160 - Step47080, Loss: 3.5390067100524902, Grad L2 Norm: 0.02339516580104828
2025-11-24 01:22:52.645 | INFO     | __main__:<module>:160 - Step47090, Loss: 3.491483449935913, Grad L2 Norm: 0.021989721804857254
2025-11-24 01:22:54.380 | INFO     | __main__:<module>:160 - Step47100, Loss: 3.50038480758667, Grad L2 Norm: 0.022445037961006165
2025-11-24 01:22:56.116 | INFO     | __main__:<module>:160 - Step47110, Loss: 3.5749893188476562, Grad L2 Norm: 0.02263922616839409
2025-11-24 01:22:57.852 | INFO     | __main__:<module>:160 - Step47120, Loss: 3.5312163829803467, Grad L2 Norm: 0.025096220895648003
2025-11-24 01:22:59.588 | INFO     | __main__:<module>:160 - Step47130, Loss: 3.5705935955047607, Grad L2 Norm: 0.022483738139271736
2025-11-24 01:23:01.323 | INFO     | __main__:<module>:160 - Step47140, Loss: 3.6587677001953125, Grad L2 Norm: 0.02388213574886322
2025-11-24 01:23:03.058 | INFO     | __main__:<module>:160 - Step47150, Loss: 3.6573410034179688, Grad L2 Norm: 0.025147201493382454
2025-11-24 01:23:04.794 | INFO     | __main__:<module>:160 - Step47160, Loss: 3.6511118412017822, Grad L2 Norm: 0.02339346893131733
2025-11-24 01:23:06.529 | INFO     | __main__:<module>:160 - Step47170, Loss: 3.642117977142334, Grad L2 Norm: 0.021851466968655586
2025-11-24 01:23:08.263 | INFO     | __main__:<module>:160 - Step47180, Loss: 3.620854139328003, Grad L2 Norm: 0.023045415058732033
2025-11-24 01:23:09.998 | INFO     | __main__:<module>:160 - Step47190, Loss: 3.5836286544799805, Grad L2 Norm: 0.025872675701975822
2025-11-24 01:23:11.734 | INFO     | __main__:<module>:160 - Step47200, Loss: 3.563304901123047, Grad L2 Norm: 0.02234296314418316
2025-11-24 01:23:11.735 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:23:12.758 | INFO     | __main__:<module>:181 - validation loss: 3.5378114700317385
2025-11-24 01:23:14.483 | INFO     | __main__:<module>:160 - Step47210, Loss: 3.7981083393096924, Grad L2 Norm: 0.024311412125825882
2025-11-24 01:23:16.208 | INFO     | __main__:<module>:160 - Step47220, Loss: 3.5414693355560303, Grad L2 Norm: 0.022112123668193817
2025-11-24 01:23:17.928 | INFO     | __main__:<module>:160 - Step47230, Loss: 3.672933578491211, Grad L2 Norm: 0.023453328758478165
2025-11-24 01:23:19.664 | INFO     | __main__:<module>:160 - Step47240, Loss: 3.3818411827087402, Grad L2 Norm: 0.02230747602880001
2025-11-24 01:23:21.399 | INFO     | __main__:<module>:160 - Step47250, Loss: 3.5370311737060547, Grad L2 Norm: 0.022231828421354294
2025-11-24 01:23:23.138 | INFO     | __main__:<module>:160 - Step47260, Loss: 3.6016736030578613, Grad L2 Norm: 0.02310829982161522
2025-11-24 01:23:24.874 | INFO     | __main__:<module>:160 - Step47270, Loss: 3.712841510772705, Grad L2 Norm: 0.02318265475332737
2025-11-24 01:23:26.610 | INFO     | __main__:<module>:160 - Step47280, Loss: 3.5752274990081787, Grad L2 Norm: 0.02311249077320099
2025-11-24 01:23:28.347 | INFO     | __main__:<module>:160 - Step47290, Loss: 3.6553757190704346, Grad L2 Norm: 0.024111906066536903
2025-11-24 01:23:30.082 | INFO     | __main__:<module>:160 - Step47300, Loss: 3.5026118755340576, Grad L2 Norm: 0.0219112578779459
2025-11-24 01:23:31.818 | INFO     | __main__:<module>:160 - Step47310, Loss: 3.528331756591797, Grad L2 Norm: 0.022081883624196053
2025-11-24 01:23:33.554 | INFO     | __main__:<module>:160 - Step47320, Loss: 3.540097951889038, Grad L2 Norm: 0.02197279967367649
2025-11-24 01:23:35.290 | INFO     | __main__:<module>:160 - Step47330, Loss: 3.5560667514801025, Grad L2 Norm: 0.023367810994386673
2025-11-24 01:23:37.026 | INFO     | __main__:<module>:160 - Step47340, Loss: 3.6865458488464355, Grad L2 Norm: 0.023354561999440193
2025-11-24 01:23:38.762 | INFO     | __main__:<module>:160 - Step47350, Loss: 3.541044235229492, Grad L2 Norm: 0.02208474464714527
2025-11-24 01:23:40.497 | INFO     | __main__:<module>:160 - Step47360, Loss: 3.6205692291259766, Grad L2 Norm: 0.02203921601176262
2025-11-24 01:23:42.233 | INFO     | __main__:<module>:160 - Step47370, Loss: 3.5841329097747803, Grad L2 Norm: 0.022943923249840736
2025-11-24 01:23:43.969 | INFO     | __main__:<module>:160 - Step47380, Loss: 3.581634044647217, Grad L2 Norm: 0.02181227132678032
2025-11-24 01:23:45.708 | INFO     | __main__:<module>:160 - Step47390, Loss: 3.503638744354248, Grad L2 Norm: 0.02063339576125145
2025-11-24 01:23:47.446 | INFO     | __main__:<module>:160 - Step47400, Loss: 3.56736421585083, Grad L2 Norm: 0.023822376504540443
2025-11-24 01:23:49.182 | INFO     | __main__:<module>:160 - Step47410, Loss: 3.6648433208465576, Grad L2 Norm: 0.02296912670135498
2025-11-24 01:23:50.918 | INFO     | __main__:<module>:160 - Step47420, Loss: 3.5712780952453613, Grad L2 Norm: 0.024821043014526367
2025-11-24 01:23:52.653 | INFO     | __main__:<module>:160 - Step47430, Loss: 3.477814197540283, Grad L2 Norm: 0.021240953356027603
2025-11-24 01:23:54.389 | INFO     | __main__:<module>:160 - Step47440, Loss: 3.5047473907470703, Grad L2 Norm: 0.022446278482675552
2025-11-24 01:23:56.126 | INFO     | __main__:<module>:160 - Step47450, Loss: 3.54327392578125, Grad L2 Norm: 0.023031964898109436
2025-11-24 01:23:57.862 | INFO     | __main__:<module>:160 - Step47460, Loss: 3.6383166313171387, Grad L2 Norm: 0.023519448935985565
2025-11-24 01:23:59.596 | INFO     | __main__:<module>:160 - Step47470, Loss: 3.519718647003174, Grad L2 Norm: 0.022184943780303
2025-11-24 01:24:01.333 | INFO     | __main__:<module>:160 - Step47480, Loss: 3.6190624237060547, Grad L2 Norm: 0.02293255180120468
2025-11-24 01:24:03.069 | INFO     | __main__:<module>:160 - Step47490, Loss: 3.574178695678711, Grad L2 Norm: 0.021799011155962944
2025-11-24 01:24:04.804 | INFO     | __main__:<module>:160 - Step47500, Loss: 3.5458617210388184, Grad L2 Norm: 0.021515589207410812
2025-11-24 01:24:06.540 | INFO     | __main__:<module>:160 - Step47510, Loss: 3.611687421798706, Grad L2 Norm: 0.02267465740442276
2025-11-24 01:24:08.275 | INFO     | __main__:<module>:160 - Step47520, Loss: 3.509931802749634, Grad L2 Norm: 0.02260659821331501
2025-11-24 01:24:10.009 | INFO     | __main__:<module>:160 - Step47530, Loss: 3.607668876647949, Grad L2 Norm: 0.02378074638545513
2025-11-24 01:24:11.744 | INFO     | __main__:<module>:160 - Step47540, Loss: 3.414011001586914, Grad L2 Norm: 0.02254539355635643
2025-11-24 01:24:13.480 | INFO     | __main__:<module>:160 - Step47550, Loss: 3.5651097297668457, Grad L2 Norm: 0.022500816732645035
2025-11-24 01:24:15.216 | INFO     | __main__:<module>:160 - Step47560, Loss: 3.461092472076416, Grad L2 Norm: 0.02363506890833378
2025-11-24 01:24:16.952 | INFO     | __main__:<module>:160 - Step47570, Loss: 3.5399608612060547, Grad L2 Norm: 0.02266504243016243
2025-11-24 01:24:18.690 | INFO     | __main__:<module>:160 - Step47580, Loss: 3.681605339050293, Grad L2 Norm: 0.02310357615351677
2025-11-24 01:24:20.427 | INFO     | __main__:<module>:160 - Step47590, Loss: 3.5805349349975586, Grad L2 Norm: 0.02338659018278122
2025-11-24 01:24:22.163 | INFO     | __main__:<module>:160 - Step47600, Loss: 3.6048736572265625, Grad L2 Norm: 0.022944645956158638
2025-11-24 01:24:22.163 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:24:23.181 | INFO     | __main__:<module>:181 - validation loss: 3.543527376651764
2025-11-24 01:24:24.916 | INFO     | __main__:<module>:160 - Step47610, Loss: 3.5109477043151855, Grad L2 Norm: 0.02279753051698208
2025-11-24 01:24:26.651 | INFO     | __main__:<module>:160 - Step47620, Loss: 3.511530876159668, Grad L2 Norm: 0.023142626509070396
2025-11-24 01:24:28.389 | INFO     | __main__:<module>:160 - Step47630, Loss: 3.454704999923706, Grad L2 Norm: 0.021829433739185333
2025-11-24 01:24:30.124 | INFO     | __main__:<module>:160 - Step47640, Loss: 3.601469039916992, Grad L2 Norm: 0.025051718577742577
2025-11-24 01:24:31.859 | INFO     | __main__:<module>:160 - Step47650, Loss: 3.564472198486328, Grad L2 Norm: 0.02400989830493927
2025-11-24 01:24:33.595 | INFO     | __main__:<module>:160 - Step47660, Loss: 3.5398526191711426, Grad L2 Norm: 0.02283177524805069
2025-11-24 01:24:35.330 | INFO     | __main__:<module>:160 - Step47670, Loss: 3.5040292739868164, Grad L2 Norm: 0.022434726357460022
2025-11-24 01:24:37.065 | INFO     | __main__:<module>:160 - Step47680, Loss: 3.477227210998535, Grad L2 Norm: 0.022489028051495552
2025-11-24 01:24:38.800 | INFO     | __main__:<module>:160 - Step47690, Loss: 3.488548755645752, Grad L2 Norm: 0.022239692509174347
2025-11-24 01:24:40.534 | INFO     | __main__:<module>:160 - Step47700, Loss: 3.4394426345825195, Grad L2 Norm: 0.02518017403781414
2025-11-24 01:24:42.269 | INFO     | __main__:<module>:160 - Step47710, Loss: 3.8627257347106934, Grad L2 Norm: 0.02483323961496353
2025-11-24 01:24:43.999 | INFO     | __main__:<module>:160 - Step47720, Loss: 3.6433358192443848, Grad L2 Norm: 0.024142732843756676
2025-11-24 01:24:45.730 | INFO     | __main__:<module>:160 - Step47730, Loss: 3.6042237281799316, Grad L2 Norm: 0.02520151250064373
2025-11-24 01:24:47.459 | INFO     | __main__:<module>:160 - Step47740, Loss: 3.465102434158325, Grad L2 Norm: 0.02369464375078678
2025-11-24 01:24:49.190 | INFO     | __main__:<module>:160 - Step47750, Loss: 3.467179298400879, Grad L2 Norm: 0.021933672949671745
2025-11-24 01:24:50.921 | INFO     | __main__:<module>:160 - Step47760, Loss: 3.5404815673828125, Grad L2 Norm: 0.024211794137954712
2025-11-24 01:24:52.653 | INFO     | __main__:<module>:160 - Step47770, Loss: 3.575216293334961, Grad L2 Norm: 0.024398036301136017
2025-11-24 01:24:54.383 | INFO     | __main__:<module>:160 - Step47780, Loss: 3.4022538661956787, Grad L2 Norm: 0.022808661684393883
2025-11-24 01:24:56.113 | INFO     | __main__:<module>:160 - Step47790, Loss: 3.746710777282715, Grad L2 Norm: 0.024148568511009216
2025-11-24 01:24:57.842 | INFO     | __main__:<module>:160 - Step47800, Loss: 3.675551414489746, Grad L2 Norm: 0.022563068196177483
2025-11-24 01:24:59.572 | INFO     | __main__:<module>:160 - Step47810, Loss: 3.477506399154663, Grad L2 Norm: 0.021832985803484917
2025-11-24 01:25:01.302 | INFO     | __main__:<module>:160 - Step47820, Loss: 3.63710618019104, Grad L2 Norm: 0.02232881262898445
2025-11-24 01:25:03.036 | INFO     | __main__:<module>:160 - Step47830, Loss: 3.4551265239715576, Grad L2 Norm: 0.0222097709774971
2025-11-24 01:25:04.757 | INFO     | __main__:<module>:160 - Step47840, Loss: 3.569718360900879, Grad L2 Norm: 0.023351628333330154
2025-11-24 01:25:06.474 | INFO     | __main__:<module>:160 - Step47850, Loss: 3.515160083770752, Grad L2 Norm: 0.021222472190856934
2025-11-24 01:25:08.190 | INFO     | __main__:<module>:160 - Step47860, Loss: 3.570667028427124, Grad L2 Norm: 0.022469008341431618
2025-11-24 01:25:09.925 | INFO     | __main__:<module>:160 - Step47870, Loss: 3.7783873081207275, Grad L2 Norm: 0.02387668751180172
2025-11-24 01:25:11.654 | INFO     | __main__:<module>:160 - Step47880, Loss: 3.509491205215454, Grad L2 Norm: 0.022585248574614525
2025-11-24 01:25:13.390 | INFO     | __main__:<module>:160 - Step47890, Loss: 3.6600568294525146, Grad L2 Norm: 0.023825617507100105
2025-11-24 01:25:15.125 | INFO     | __main__:<module>:160 - Step47900, Loss: 3.6086511611938477, Grad L2 Norm: 0.022154470905661583
2025-11-24 01:25:16.861 | INFO     | __main__:<module>:160 - Step47910, Loss: 3.628164768218994, Grad L2 Norm: 0.024386748671531677
2025-11-24 01:25:18.596 | INFO     | __main__:<module>:160 - Step47920, Loss: 3.4706130027770996, Grad L2 Norm: 0.021490933373570442
2025-11-24 01:25:20.332 | INFO     | __main__:<module>:160 - Step47930, Loss: 3.5748367309570312, Grad L2 Norm: 0.021970581263303757
2025-11-24 01:25:22.067 | INFO     | __main__:<module>:160 - Step47940, Loss: 3.598083972930908, Grad L2 Norm: 0.022360866889357567
2025-11-24 01:25:23.803 | INFO     | __main__:<module>:160 - Step47950, Loss: 3.4952383041381836, Grad L2 Norm: 0.02469579130411148
2025-11-24 01:25:25.542 | INFO     | __main__:<module>:160 - Step47960, Loss: 3.4385452270507812, Grad L2 Norm: 0.022846078500151634
2025-11-24 01:25:27.279 | INFO     | __main__:<module>:160 - Step47970, Loss: 3.6031808853149414, Grad L2 Norm: 0.021899927407503128
2025-11-24 01:25:29.014 | INFO     | __main__:<module>:160 - Step47980, Loss: 3.4955010414123535, Grad L2 Norm: 0.023106714710593224
2025-11-24 01:25:30.749 | INFO     | __main__:<module>:160 - Step47990, Loss: 3.4975461959838867, Grad L2 Norm: 0.02368137799203396
2025-11-24 01:25:32.483 | INFO     | __main__:<module>:160 - Step48000, Loss: 3.5559144020080566, Grad L2 Norm: 0.02488967403769493
2025-11-24 01:25:32.484 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:25:33.502 | INFO     | __main__:<module>:181 - validation loss: 3.542420172691345
2025-11-24 01:25:33.503 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_48000.pt
2025-11-24 01:25:35.257 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 01:25:36.851 | INFO     | __main__:<module>:160 - Step48010, Loss: 3.5616989135742188, Grad L2 Norm: 0.02192072942852974
2025-11-24 01:25:38.586 | INFO     | __main__:<module>:160 - Step48020, Loss: 3.414249897003174, Grad L2 Norm: 0.02375093847513199
2025-11-24 01:25:40.322 | INFO     | __main__:<module>:160 - Step48030, Loss: 3.520876169204712, Grad L2 Norm: 0.022558577358722687
2025-11-24 01:25:42.058 | INFO     | __main__:<module>:160 - Step48040, Loss: 3.5395185947418213, Grad L2 Norm: 0.020524833351373672
2025-11-24 01:25:43.794 | INFO     | __main__:<module>:160 - Step48050, Loss: 3.499671459197998, Grad L2 Norm: 0.02210984379053116
2025-11-24 01:25:45.530 | INFO     | __main__:<module>:160 - Step48060, Loss: 3.609802722930908, Grad L2 Norm: 0.024322915822267532
2025-11-24 01:25:47.266 | INFO     | __main__:<module>:160 - Step48070, Loss: 3.5692684650421143, Grad L2 Norm: 0.025284385308623314
2025-11-24 01:25:49.002 | INFO     | __main__:<module>:160 - Step48080, Loss: 3.6025280952453613, Grad L2 Norm: 0.022384125739336014
2025-11-24 01:25:50.737 | INFO     | __main__:<module>:160 - Step48090, Loss: 3.6030421257019043, Grad L2 Norm: 0.021195560693740845
2025-11-24 01:25:52.473 | INFO     | __main__:<module>:160 - Step48100, Loss: 3.60575532913208, Grad L2 Norm: 0.02257889322936535
2025-11-24 01:25:54.208 | INFO     | __main__:<module>:160 - Step48110, Loss: 3.5441317558288574, Grad L2 Norm: 0.024750258773565292
2025-11-24 01:25:55.944 | INFO     | __main__:<module>:160 - Step48120, Loss: 3.6352956295013428, Grad L2 Norm: 0.023378416895866394
2025-11-24 01:25:57.681 | INFO     | __main__:<module>:160 - Step48130, Loss: 3.590972661972046, Grad L2 Norm: 0.021635448560118675
2025-11-24 01:25:59.419 | INFO     | __main__:<module>:160 - Step48140, Loss: 3.565908908843994, Grad L2 Norm: 0.02149922028183937
2025-11-24 01:26:01.155 | INFO     | __main__:<module>:160 - Step48150, Loss: 3.456886053085327, Grad L2 Norm: 0.022371146827936172
2025-11-24 01:26:02.892 | INFO     | __main__:<module>:160 - Step48160, Loss: 3.565485954284668, Grad L2 Norm: 0.026316925883293152
2025-11-24 01:26:04.628 | INFO     | __main__:<module>:160 - Step48170, Loss: 3.6283421516418457, Grad L2 Norm: 0.024388698861002922
2025-11-24 01:26:06.363 | INFO     | __main__:<module>:160 - Step48180, Loss: 3.446711540222168, Grad L2 Norm: 0.022913740947842598
2025-11-24 01:26:08.101 | INFO     | __main__:<module>:160 - Step48190, Loss: 3.420748233795166, Grad L2 Norm: 0.02159561775624752
2025-11-24 01:26:09.837 | INFO     | __main__:<module>:160 - Step48200, Loss: 3.6066489219665527, Grad L2 Norm: 0.023856980726122856
2025-11-24 01:26:11.574 | INFO     | __main__:<module>:160 - Step48210, Loss: 3.5999810695648193, Grad L2 Norm: 0.02282158099114895
2025-11-24 01:26:13.309 | INFO     | __main__:<module>:160 - Step48220, Loss: 3.5431880950927734, Grad L2 Norm: 0.023376524448394775
2025-11-24 01:26:15.045 | INFO     | __main__:<module>:160 - Step48230, Loss: 3.5856592655181885, Grad L2 Norm: 0.022151542827486992
2025-11-24 01:26:16.780 | INFO     | __main__:<module>:160 - Step48240, Loss: 3.533940315246582, Grad L2 Norm: 0.022199664264917374
2025-11-24 01:26:18.517 | INFO     | __main__:<module>:160 - Step48250, Loss: 3.519618034362793, Grad L2 Norm: 0.025003936141729355
2025-11-24 01:26:20.252 | INFO     | __main__:<module>:160 - Step48260, Loss: 3.5597076416015625, Grad L2 Norm: 0.022664224728941917
2025-11-24 01:26:21.990 | INFO     | __main__:<module>:160 - Step48270, Loss: 3.7128748893737793, Grad L2 Norm: 0.022892847657203674
2025-11-24 01:26:23.732 | INFO     | __main__:<module>:160 - Step48280, Loss: 3.418174982070923, Grad L2 Norm: 0.022992048412561417
2025-11-24 01:26:25.467 | INFO     | __main__:<module>:160 - Step48290, Loss: 3.5264506340026855, Grad L2 Norm: 0.022301221266388893
2025-11-24 01:26:27.203 | INFO     | __main__:<module>:160 - Step48300, Loss: 3.520831823348999, Grad L2 Norm: 0.022196978330612183
2025-11-24 01:26:28.938 | INFO     | __main__:<module>:160 - Step48310, Loss: 3.505446434020996, Grad L2 Norm: 0.02331978641450405
2025-11-24 01:26:30.677 | INFO     | __main__:<module>:160 - Step48320, Loss: 3.55029296875, Grad L2 Norm: 0.022567443549633026
2025-11-24 01:26:32.414 | INFO     | __main__:<module>:160 - Step48330, Loss: 3.53841495513916, Grad L2 Norm: 0.02259957417845726
2025-11-24 01:26:34.149 | INFO     | __main__:<module>:160 - Step48340, Loss: 3.574157238006592, Grad L2 Norm: 0.02224677987396717
2025-11-24 01:26:35.884 | INFO     | __main__:<module>:160 - Step48350, Loss: 3.6962890625, Grad L2 Norm: 0.026686593890190125
2025-11-24 01:26:37.620 | INFO     | __main__:<module>:160 - Step48360, Loss: 3.479201555252075, Grad L2 Norm: 0.022359007969498634
2025-11-24 01:26:39.355 | INFO     | __main__:<module>:160 - Step48370, Loss: 3.626150369644165, Grad L2 Norm: 0.02182406187057495
2025-11-24 01:26:41.093 | INFO     | __main__:<module>:160 - Step48380, Loss: 3.624605417251587, Grad L2 Norm: 0.02201850898563862
2025-11-24 01:26:42.829 | INFO     | __main__:<module>:160 - Step48390, Loss: 3.5674667358398438, Grad L2 Norm: 0.02217828296124935
2025-11-24 01:26:44.566 | INFO     | __main__:<module>:160 - Step48400, Loss: 3.448690891265869, Grad L2 Norm: 0.022697342559695244
2025-11-24 01:26:44.566 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:26:45.584 | INFO     | __main__:<module>:181 - validation loss: 3.5388741374015806
2025-11-24 01:26:47.316 | INFO     | __main__:<module>:160 - Step48410, Loss: 3.5322628021240234, Grad L2 Norm: 0.02281336672604084
2025-11-24 01:26:49.047 | INFO     | __main__:<module>:160 - Step48420, Loss: 3.5204806327819824, Grad L2 Norm: 0.02222207933664322
2025-11-24 01:26:50.779 | INFO     | __main__:<module>:160 - Step48430, Loss: 3.570228099822998, Grad L2 Norm: 0.022344661876559258
2025-11-24 01:26:52.512 | INFO     | __main__:<module>:160 - Step48440, Loss: 3.4963440895080566, Grad L2 Norm: 0.02351890504360199
2025-11-24 01:26:54.244 | INFO     | __main__:<module>:160 - Step48450, Loss: 3.5722389221191406, Grad L2 Norm: 0.025422653183341026
2025-11-24 01:26:55.975 | INFO     | __main__:<module>:160 - Step48460, Loss: 3.666252613067627, Grad L2 Norm: 0.024621807038784027
2025-11-24 01:26:57.706 | INFO     | __main__:<module>:160 - Step48470, Loss: 3.653202533721924, Grad L2 Norm: 0.02325170859694481
2025-11-24 01:26:59.438 | INFO     | __main__:<module>:160 - Step48480, Loss: 3.7319259643554688, Grad L2 Norm: 0.0235978402197361
2025-11-24 01:27:01.170 | INFO     | __main__:<module>:160 - Step48490, Loss: 3.5695719718933105, Grad L2 Norm: 0.02170247957110405
2025-11-24 01:27:02.903 | INFO     | __main__:<module>:160 - Step48500, Loss: 3.593385934829712, Grad L2 Norm: 0.023680102080106735
2025-11-24 01:27:04.638 | INFO     | __main__:<module>:160 - Step48510, Loss: 3.565138578414917, Grad L2 Norm: 0.02653331868350506
2025-11-24 01:27:06.370 | INFO     | __main__:<module>:160 - Step48520, Loss: 3.5353002548217773, Grad L2 Norm: 0.022244004532694817
2025-11-24 01:27:08.102 | INFO     | __main__:<module>:160 - Step48530, Loss: 3.5288803577423096, Grad L2 Norm: 0.02384926751255989
2025-11-24 01:27:09.834 | INFO     | __main__:<module>:160 - Step48540, Loss: 3.4670896530151367, Grad L2 Norm: 0.022538136690855026
2025-11-24 01:27:11.567 | INFO     | __main__:<module>:160 - Step48550, Loss: 3.4830398559570312, Grad L2 Norm: 0.021915409713983536
2025-11-24 01:27:13.300 | INFO     | __main__:<module>:160 - Step48560, Loss: 3.7187252044677734, Grad L2 Norm: 0.022826697677373886
2025-11-24 01:27:15.032 | INFO     | __main__:<module>:160 - Step48570, Loss: 3.5134663581848145, Grad L2 Norm: 0.022006157785654068
2025-11-24 01:27:16.765 | INFO     | __main__:<module>:160 - Step48580, Loss: 3.5175070762634277, Grad L2 Norm: 0.022064577788114548
2025-11-24 01:27:18.497 | INFO     | __main__:<module>:160 - Step48590, Loss: 3.4435718059539795, Grad L2 Norm: 0.025387192144989967
2025-11-24 01:27:20.232 | INFO     | __main__:<module>:160 - Step48600, Loss: 3.574477195739746, Grad L2 Norm: 0.023181280121207237
2025-11-24 01:27:21.967 | INFO     | __main__:<module>:160 - Step48610, Loss: 3.5976829528808594, Grad L2 Norm: 0.023117350414395332
2025-11-24 01:27:23.702 | INFO     | __main__:<module>:160 - Step48620, Loss: 3.573380947113037, Grad L2 Norm: 0.02219981513917446
2025-11-24 01:27:25.427 | INFO     | __main__:<module>:160 - Step48630, Loss: 3.621622085571289, Grad L2 Norm: 0.025364883244037628
2025-11-24 01:27:27.161 | INFO     | __main__:<module>:160 - Step48640, Loss: 3.6176514625549316, Grad L2 Norm: 0.02219090424478054
2025-11-24 01:27:28.886 | INFO     | __main__:<module>:160 - Step48650, Loss: 3.580576181411743, Grad L2 Norm: 0.024564029648900032
2025-11-24 01:27:30.610 | INFO     | __main__:<module>:160 - Step48660, Loss: 3.5609564781188965, Grad L2 Norm: 0.022815391421318054
2025-11-24 01:27:32.328 | INFO     | __main__:<module>:160 - Step48670, Loss: 3.459327459335327, Grad L2 Norm: 0.024006113409996033
2025-11-24 01:27:34.000 | INFO     | __main__:<module>:160 - Step48680, Loss: 3.5639214515686035, Grad L2 Norm: 0.021398432552814484
2025-11-24 01:27:35.733 | INFO     | __main__:<module>:160 - Step48690, Loss: 3.6548588275909424, Grad L2 Norm: 0.023259425535798073
2025-11-24 01:27:37.450 | INFO     | __main__:<module>:160 - Step48700, Loss: 3.5875043869018555, Grad L2 Norm: 0.022541593760252
2025-11-24 01:27:39.183 | INFO     | __main__:<module>:160 - Step48710, Loss: 3.513347625732422, Grad L2 Norm: 0.023190155625343323
2025-11-24 01:27:40.902 | INFO     | __main__:<module>:160 - Step48720, Loss: 3.4805047512054443, Grad L2 Norm: 0.022108668461441994
2025-11-24 01:27:42.636 | INFO     | __main__:<module>:160 - Step48730, Loss: 3.520585536956787, Grad L2 Norm: 0.02220228873193264
2025-11-24 01:27:44.365 | INFO     | __main__:<module>:160 - Step48740, Loss: 3.6257641315460205, Grad L2 Norm: 0.02366580069065094
2025-11-24 01:27:46.092 | INFO     | __main__:<module>:160 - Step48750, Loss: 3.5140538215637207, Grad L2 Norm: 0.02116316370666027
2025-11-24 01:27:47.818 | INFO     | __main__:<module>:160 - Step48760, Loss: 3.6649107933044434, Grad L2 Norm: 0.021985244005918503
2025-11-24 01:27:49.545 | INFO     | __main__:<module>:160 - Step48770, Loss: 3.643970012664795, Grad L2 Norm: 0.023227520287036896
2025-11-24 01:27:51.267 | INFO     | __main__:<module>:160 - Step48780, Loss: 3.54410719871521, Grad L2 Norm: 0.0234171524643898
2025-11-24 01:27:52.996 | INFO     | __main__:<module>:160 - Step48790, Loss: 3.5876893997192383, Grad L2 Norm: 0.023499753326177597
2025-11-24 01:27:54.713 | INFO     | __main__:<module>:160 - Step48800, Loss: 3.458740711212158, Grad L2 Norm: 0.023863233625888824
2025-11-24 01:27:54.714 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:27:55.731 | INFO     | __main__:<module>:181 - validation loss: 3.552440845966339
2025-11-24 01:27:57.454 | INFO     | __main__:<module>:160 - Step48810, Loss: 3.5200490951538086, Grad L2 Norm: 0.023559534922242165
2025-11-24 01:27:59.173 | INFO     | __main__:<module>:160 - Step48820, Loss: 3.621039390563965, Grad L2 Norm: 0.022871971130371094
2025-11-24 01:28:00.898 | INFO     | __main__:<module>:160 - Step48830, Loss: 3.4957292079925537, Grad L2 Norm: 0.022472389042377472
2025-11-24 01:28:02.614 | INFO     | __main__:<module>:160 - Step48840, Loss: 3.6294381618499756, Grad L2 Norm: 0.02275872603058815
2025-11-24 01:28:04.328 | INFO     | __main__:<module>:160 - Step48850, Loss: 3.62422776222229, Grad L2 Norm: 0.022277524694800377
2025-11-24 01:28:06.052 | INFO     | __main__:<module>:160 - Step48860, Loss: 3.593066692352295, Grad L2 Norm: 0.023243358358740807
2025-11-24 01:28:07.769 | INFO     | __main__:<module>:160 - Step48870, Loss: 3.5982728004455566, Grad L2 Norm: 0.023601491004228592
2025-11-24 01:28:09.493 | INFO     | __main__:<module>:160 - Step48880, Loss: 3.713252067565918, Grad L2 Norm: 0.02724020928144455
2025-11-24 01:28:11.212 | INFO     | __main__:<module>:160 - Step48890, Loss: 3.5752973556518555, Grad L2 Norm: 0.02366260625422001
2025-11-24 01:28:12.936 | INFO     | __main__:<module>:160 - Step48900, Loss: 3.454118251800537, Grad L2 Norm: 0.02297305315732956
2025-11-24 01:28:14.664 | INFO     | __main__:<module>:160 - Step48910, Loss: 3.575186252593994, Grad L2 Norm: 0.02303355745971203
2025-11-24 01:28:16.377 | INFO     | __main__:<module>:160 - Step48920, Loss: 3.456366539001465, Grad L2 Norm: 0.023424118757247925
2025-11-24 01:28:18.099 | INFO     | __main__:<module>:160 - Step48930, Loss: 3.4915733337402344, Grad L2 Norm: 0.024477321654558182
2025-11-24 01:28:19.830 | INFO     | __main__:<module>:160 - Step48940, Loss: 3.5868959426879883, Grad L2 Norm: 0.02234731614589691
2025-11-24 01:28:21.546 | INFO     | __main__:<module>:160 - Step48950, Loss: 3.6077382564544678, Grad L2 Norm: 0.023334674537181854
2025-11-24 01:28:23.271 | INFO     | __main__:<module>:160 - Step48960, Loss: 3.6599977016448975, Grad L2 Norm: 0.02223464660346508
2025-11-24 01:28:24.984 | INFO     | __main__:<module>:160 - Step48970, Loss: 3.6744906902313232, Grad L2 Norm: 0.024609971791505814
2025-11-24 01:28:26.712 | INFO     | __main__:<module>:160 - Step48980, Loss: 3.4741768836975098, Grad L2 Norm: 0.022367535158991814
2025-11-24 01:28:28.436 | INFO     | __main__:<module>:160 - Step48990, Loss: 3.6080098152160645, Grad L2 Norm: 0.024021314457058907
2025-11-24 01:28:30.163 | INFO     | __main__:<module>:160 - Step49000, Loss: 3.507389545440674, Grad L2 Norm: 0.02251916006207466
2025-11-24 01:28:31.882 | INFO     | __main__:<module>:160 - Step49010, Loss: 3.370511531829834, Grad L2 Norm: 0.023369794711470604
2025-11-24 01:28:33.598 | INFO     | __main__:<module>:160 - Step49020, Loss: 3.572683572769165, Grad L2 Norm: 0.022416550666093826
2025-11-24 01:28:35.332 | INFO     | __main__:<module>:160 - Step49030, Loss: 3.4085330963134766, Grad L2 Norm: 0.021382374688982964
2025-11-24 01:28:37.059 | INFO     | __main__:<module>:160 - Step49040, Loss: 3.4893953800201416, Grad L2 Norm: 0.021387210115790367
2025-11-24 01:28:38.785 | INFO     | __main__:<module>:160 - Step49050, Loss: 3.6521718502044678, Grad L2 Norm: 0.023617614060640335
2025-11-24 01:28:40.512 | INFO     | __main__:<module>:160 - Step49060, Loss: 3.5709919929504395, Grad L2 Norm: 0.023351270705461502
2025-11-24 01:28:42.227 | INFO     | __main__:<module>:160 - Step49070, Loss: 3.4140238761901855, Grad L2 Norm: 0.022567281499505043
2025-11-24 01:28:43.957 | INFO     | __main__:<module>:160 - Step49080, Loss: 3.4864988327026367, Grad L2 Norm: 0.021648304536938667
2025-11-24 01:28:45.672 | INFO     | __main__:<module>:160 - Step49090, Loss: 3.58095645904541, Grad L2 Norm: 0.020508751273155212
2025-11-24 01:28:47.408 | INFO     | __main__:<module>:160 - Step49100, Loss: 3.471393585205078, Grad L2 Norm: 0.021654387935996056
2025-11-24 01:28:49.132 | INFO     | __main__:<module>:160 - Step49110, Loss: 3.5116655826568604, Grad L2 Norm: 0.022656328976154327
2025-11-24 01:28:50.868 | INFO     | __main__:<module>:160 - Step49120, Loss: 3.4519855976104736, Grad L2 Norm: 0.023049669340252876
2025-11-24 01:28:52.605 | INFO     | __main__:<module>:160 - Step49130, Loss: 3.5798180103302, Grad L2 Norm: 0.02352236770093441
2025-11-24 01:28:54.332 | INFO     | __main__:<module>:160 - Step49140, Loss: 3.5338215827941895, Grad L2 Norm: 0.027907870709896088
2025-11-24 01:28:56.061 | INFO     | __main__:<module>:160 - Step49150, Loss: 3.5056934356689453, Grad L2 Norm: 0.024177245795726776
2025-11-24 01:28:57.797 | INFO     | __main__:<module>:160 - Step49160, Loss: 3.5654196739196777, Grad L2 Norm: 0.024185452610254288
2025-11-24 01:28:59.532 | INFO     | __main__:<module>:160 - Step49170, Loss: 3.448714017868042, Grad L2 Norm: 0.021562466397881508
2025-11-24 01:29:01.267 | INFO     | __main__:<module>:160 - Step49180, Loss: 3.5531039237976074, Grad L2 Norm: 0.02075517550110817
2025-11-24 01:29:03.004 | INFO     | __main__:<module>:160 - Step49190, Loss: 3.6065595149993896, Grad L2 Norm: 0.021847423166036606
2025-11-24 01:29:04.740 | INFO     | __main__:<module>:160 - Step49200, Loss: 3.536257743835449, Grad L2 Norm: 0.026268156245350838
2025-11-24 01:29:04.741 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:29:05.758 | INFO     | __main__:<module>:181 - validation loss: 3.544651913642883
2025-11-24 01:29:07.489 | INFO     | __main__:<module>:160 - Step49210, Loss: 3.4496588706970215, Grad L2 Norm: 0.021546298637986183
2025-11-24 01:29:09.225 | INFO     | __main__:<module>:160 - Step49220, Loss: 3.4356417655944824, Grad L2 Norm: 0.02155631221830845
2025-11-24 01:29:10.961 | INFO     | __main__:<module>:160 - Step49230, Loss: 3.592134475708008, Grad L2 Norm: 0.022143224254250526
2025-11-24 01:29:12.696 | INFO     | __main__:<module>:160 - Step49240, Loss: 3.4905333518981934, Grad L2 Norm: 0.02353954315185547
2025-11-24 01:29:14.432 | INFO     | __main__:<module>:160 - Step49250, Loss: 3.6192574501037598, Grad L2 Norm: 0.024838227778673172
2025-11-24 01:29:16.171 | INFO     | __main__:<module>:160 - Step49260, Loss: 3.5624194145202637, Grad L2 Norm: 0.023068074136972427
2025-11-24 01:29:17.907 | INFO     | __main__:<module>:160 - Step49270, Loss: 3.5900440216064453, Grad L2 Norm: 0.023914817720651627
2025-11-24 01:29:19.642 | INFO     | __main__:<module>:160 - Step49280, Loss: 3.48720645904541, Grad L2 Norm: 0.022428344935178757
2025-11-24 01:29:21.377 | INFO     | __main__:<module>:160 - Step49290, Loss: 3.54142165184021, Grad L2 Norm: 0.022838592529296875
2025-11-24 01:29:23.112 | INFO     | __main__:<module>:160 - Step49300, Loss: 3.579751968383789, Grad L2 Norm: 0.02307494357228279
2025-11-24 01:29:24.848 | INFO     | __main__:<module>:160 - Step49310, Loss: 3.5863871574401855, Grad L2 Norm: 0.022636188194155693
2025-11-24 01:29:26.574 | INFO     | __main__:<module>:160 - Step49320, Loss: 3.4576401710510254, Grad L2 Norm: 0.022155888378620148
2025-11-24 01:29:28.291 | INFO     | __main__:<module>:160 - Step49330, Loss: 3.56817364692688, Grad L2 Norm: 0.025574538856744766
2025-11-24 01:29:30.018 | INFO     | __main__:<module>:160 - Step49340, Loss: 3.6053569316864014, Grad L2 Norm: 0.022864321246743202
2025-11-24 01:29:31.754 | INFO     | __main__:<module>:160 - Step49350, Loss: 3.4436163902282715, Grad L2 Norm: 0.02268351800739765
2025-11-24 01:29:33.491 | INFO     | __main__:<module>:160 - Step49360, Loss: 3.519312858581543, Grad L2 Norm: 0.023269271478056908
2025-11-24 01:29:35.226 | INFO     | __main__:<module>:160 - Step49370, Loss: 3.5481762886047363, Grad L2 Norm: 0.022727930918335915
2025-11-24 01:29:36.962 | INFO     | __main__:<module>:160 - Step49380, Loss: 3.4664130210876465, Grad L2 Norm: 0.024083001539111137
2025-11-24 01:29:38.697 | INFO     | __main__:<module>:160 - Step49390, Loss: 3.4057674407958984, Grad L2 Norm: 0.021942857652902603
2025-11-24 01:29:40.433 | INFO     | __main__:<module>:160 - Step49400, Loss: 3.5474038124084473, Grad L2 Norm: 0.02245810441672802
2025-11-24 01:29:42.169 | INFO     | __main__:<module>:160 - Step49410, Loss: 3.5793356895446777, Grad L2 Norm: 0.02210473082959652
2025-11-24 01:29:43.905 | INFO     | __main__:<module>:160 - Step49420, Loss: 3.570563793182373, Grad L2 Norm: 0.02125350944697857
2025-11-24 01:29:45.640 | INFO     | __main__:<module>:160 - Step49430, Loss: 3.5097904205322266, Grad L2 Norm: 0.022222688421607018
2025-11-24 01:29:47.377 | INFO     | __main__:<module>:160 - Step49440, Loss: 3.6294174194335938, Grad L2 Norm: 0.023532267659902573
2025-11-24 01:29:49.115 | INFO     | __main__:<module>:160 - Step49450, Loss: 3.53379487991333, Grad L2 Norm: 0.02312060259282589
2025-11-24 01:29:50.852 | INFO     | __main__:<module>:160 - Step49460, Loss: 3.426978588104248, Grad L2 Norm: 0.021308457478880882
2025-11-24 01:29:52.577 | INFO     | __main__:<module>:160 - Step49470, Loss: 3.584796905517578, Grad L2 Norm: 0.022552672773599625
2025-11-24 01:29:54.304 | INFO     | __main__:<module>:160 - Step49480, Loss: 3.532898426055908, Grad L2 Norm: 0.02275206334888935
2025-11-24 01:29:56.038 | INFO     | __main__:<module>:160 - Step49490, Loss: 3.721127986907959, Grad L2 Norm: 0.023754507303237915
2025-11-24 01:29:57.768 | INFO     | __main__:<module>:160 - Step49500, Loss: 3.4948983192443848, Grad L2 Norm: 0.023265786468982697
2025-11-24 01:29:59.506 | INFO     | __main__:<module>:160 - Step49510, Loss: 3.730149984359741, Grad L2 Norm: 0.025270601734519005
2025-11-24 01:30:01.233 | INFO     | __main__:<module>:160 - Step49520, Loss: 3.5798628330230713, Grad L2 Norm: 0.023358602076768875
2025-11-24 01:30:02.970 | INFO     | __main__:<module>:160 - Step49530, Loss: 3.5934503078460693, Grad L2 Norm: 0.023217910900712013
2025-11-24 01:30:04.689 | INFO     | __main__:<module>:160 - Step49540, Loss: 3.4958620071411133, Grad L2 Norm: 0.02127712033689022
2025-11-24 01:30:06.423 | INFO     | __main__:<module>:160 - Step49550, Loss: 3.4409308433532715, Grad L2 Norm: 0.023934802040457726
2025-11-24 01:30:08.141 | INFO     | __main__:<module>:160 - Step49560, Loss: 3.4266281127929688, Grad L2 Norm: 0.02368590049445629
2025-11-24 01:30:09.868 | INFO     | __main__:<module>:160 - Step49570, Loss: 3.5777969360351562, Grad L2 Norm: 0.02341713197529316
2025-11-24 01:30:11.593 | INFO     | __main__:<module>:160 - Step49580, Loss: 3.4821624755859375, Grad L2 Norm: 0.0216919407248497
2025-11-24 01:30:13.321 | INFO     | __main__:<module>:160 - Step49590, Loss: 3.5607075691223145, Grad L2 Norm: 0.022422540932893753
2025-11-24 01:30:15.044 | INFO     | __main__:<module>:160 - Step49600, Loss: 3.532356023788452, Grad L2 Norm: 0.021394189447164536
2025-11-24 01:30:15.045 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:30:16.057 | INFO     | __main__:<module>:181 - validation loss: 3.5436033248901366
2025-11-24 01:30:17.793 | INFO     | __main__:<module>:160 - Step49610, Loss: 3.539151191711426, Grad L2 Norm: 0.022504063323140144
2025-11-24 01:30:19.518 | INFO     | __main__:<module>:160 - Step49620, Loss: 3.690011501312256, Grad L2 Norm: 0.023275181651115417
2025-11-24 01:30:21.242 | INFO     | __main__:<module>:160 - Step49630, Loss: 3.5700466632843018, Grad L2 Norm: 0.023620080202817917
2025-11-24 01:30:22.960 | INFO     | __main__:<module>:160 - Step49640, Loss: 3.582955837249756, Grad L2 Norm: 0.023797105997800827
2025-11-24 01:30:24.686 | INFO     | __main__:<module>:160 - Step49650, Loss: 3.4948534965515137, Grad L2 Norm: 0.02293582260608673
2025-11-24 01:30:26.402 | INFO     | __main__:<module>:160 - Step49660, Loss: 3.6857266426086426, Grad L2 Norm: 0.024430064484477043
2025-11-24 01:30:28.130 | INFO     | __main__:<module>:160 - Step49670, Loss: 3.539809226989746, Grad L2 Norm: 0.02204618975520134
2025-11-24 01:30:29.866 | INFO     | __main__:<module>:160 - Step49680, Loss: 3.559152126312256, Grad L2 Norm: 0.021840566769242287
2025-11-24 01:30:31.603 | INFO     | __main__:<module>:160 - Step49690, Loss: 3.5466465950012207, Grad L2 Norm: 0.021511776372790337
2025-11-24 01:30:33.339 | INFO     | __main__:<module>:160 - Step49700, Loss: 3.709275245666504, Grad L2 Norm: 0.022566018626093864
2025-11-24 01:30:35.077 | INFO     | __main__:<module>:160 - Step49710, Loss: 3.465287446975708, Grad L2 Norm: 0.02397502027451992
2025-11-24 01:30:36.811 | INFO     | __main__:<module>:160 - Step49720, Loss: 3.7092843055725098, Grad L2 Norm: 0.02337511256337166
2025-11-24 01:30:38.546 | INFO     | __main__:<module>:160 - Step49730, Loss: 3.504687547683716, Grad L2 Norm: 0.022973760962486267
2025-11-24 01:30:40.279 | INFO     | __main__:<module>:160 - Step49740, Loss: 3.582256317138672, Grad L2 Norm: 0.024204973131418228
2025-11-24 01:30:41.992 | INFO     | __main__:<module>:160 - Step49750, Loss: 3.7777514457702637, Grad L2 Norm: 0.024983642622828484
2025-11-24 01:30:43.727 | INFO     | __main__:<module>:160 - Step49760, Loss: 3.540027618408203, Grad L2 Norm: 0.02238299325108528
2025-11-24 01:30:45.445 | INFO     | __main__:<module>:160 - Step49770, Loss: 3.642033100128174, Grad L2 Norm: 0.021982422098517418
2025-11-24 01:30:47.169 | INFO     | __main__:<module>:160 - Step49780, Loss: 3.5035455226898193, Grad L2 Norm: 0.021956423297524452
2025-11-24 01:30:48.888 | INFO     | __main__:<module>:160 - Step49790, Loss: 3.470674991607666, Grad L2 Norm: 0.021127020940184593
2025-11-24 01:30:50.602 | INFO     | __main__:<module>:160 - Step49800, Loss: 3.4601492881774902, Grad L2 Norm: 0.023029785603284836
2025-11-24 01:30:52.329 | INFO     | __main__:<module>:160 - Step49810, Loss: 3.6494784355163574, Grad L2 Norm: 0.022221410647034645
2025-11-24 01:30:54.053 | INFO     | __main__:<module>:160 - Step49820, Loss: 3.590773582458496, Grad L2 Norm: 0.02392739988863468
2025-11-24 01:30:55.782 | INFO     | __main__:<module>:160 - Step49830, Loss: 3.516180992126465, Grad L2 Norm: 0.02120186574757099
2025-11-24 01:30:57.498 | INFO     | __main__:<module>:160 - Step49840, Loss: 3.545020580291748, Grad L2 Norm: 0.021932421252131462
2025-11-24 01:30:59.213 | INFO     | __main__:<module>:160 - Step49850, Loss: 3.4478759765625, Grad L2 Norm: 0.021265273913741112
2025-11-24 01:31:00.948 | INFO     | __main__:<module>:160 - Step49860, Loss: 3.62349009513855, Grad L2 Norm: 0.0227308738976717
2025-11-24 01:31:02.663 | INFO     | __main__:<module>:160 - Step49870, Loss: 3.464573860168457, Grad L2 Norm: 0.022660257294774055
2025-11-24 01:31:04.386 | INFO     | __main__:<module>:160 - Step49880, Loss: 3.6432690620422363, Grad L2 Norm: 0.024256175383925438
2025-11-24 01:31:06.103 | INFO     | __main__:<module>:160 - Step49890, Loss: 3.6827802658081055, Grad L2 Norm: 0.0253299567848444
2025-11-24 01:31:07.830 | INFO     | __main__:<module>:160 - Step49900, Loss: 3.514369487762451, Grad L2 Norm: 0.022537490352988243
2025-11-24 01:31:09.555 | INFO     | __main__:<module>:160 - Step49910, Loss: 3.604550361633301, Grad L2 Norm: 0.022362716495990753
2025-11-24 01:31:11.272 | INFO     | __main__:<module>:160 - Step49920, Loss: 3.4666666984558105, Grad L2 Norm: 0.022711703553795815
2025-11-24 01:31:12.994 | INFO     | __main__:<module>:160 - Step49930, Loss: 3.5819880962371826, Grad L2 Norm: 0.02434547245502472
2025-11-24 01:31:14.715 | INFO     | __main__:<module>:160 - Step49940, Loss: 3.5172696113586426, Grad L2 Norm: 0.022515593096613884
2025-11-24 01:31:16.439 | INFO     | __main__:<module>:160 - Step49950, Loss: 3.648310899734497, Grad L2 Norm: 0.02277788333594799
2025-11-24 01:31:18.167 | INFO     | __main__:<module>:160 - Step49960, Loss: 3.529449462890625, Grad L2 Norm: 0.021726200357079506
2025-11-24 01:31:19.881 | INFO     | __main__:<module>:160 - Step49970, Loss: 3.425045967102051, Grad L2 Norm: 0.0224187932908535
2025-11-24 01:31:21.603 | INFO     | __main__:<module>:160 - Step49980, Loss: 3.5072975158691406, Grad L2 Norm: 0.022204885259270668
2025-11-24 01:31:23.331 | INFO     | __main__:<module>:160 - Step49990, Loss: 3.551312208175659, Grad L2 Norm: 0.02331715263426304
2025-11-24 01:31:25.048 | INFO     | __main__:<module>:160 - Step50000, Loss: 3.5294580459594727, Grad L2 Norm: 0.02217293344438076
2025-11-24 01:31:25.049 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:31:26.066 | INFO     | __main__:<module>:181 - validation loss: 3.5347681879997253
2025-11-24 01:31:26.067 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_50000.pt
2025-11-24 01:31:27.864 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 01:31:29.510 | INFO     | __main__:<module>:160 - Step50010, Loss: 3.546267032623291, Grad L2 Norm: 0.025239916518330574
2025-11-24 01:31:31.235 | INFO     | __main__:<module>:160 - Step50020, Loss: 3.7004690170288086, Grad L2 Norm: 0.02338007278740406
2025-11-24 01:31:32.950 | INFO     | __main__:<module>:160 - Step50030, Loss: 3.526494026184082, Grad L2 Norm: 0.02200198546051979
2025-11-24 01:31:34.669 | INFO     | __main__:<module>:160 - Step50040, Loss: 3.6587181091308594, Grad L2 Norm: 0.024740321561694145
2025-11-24 01:31:36.396 | INFO     | __main__:<module>:160 - Step50050, Loss: 3.428354024887085, Grad L2 Norm: 0.022309066727757454
2025-11-24 01:31:38.118 | INFO     | __main__:<module>:160 - Step50060, Loss: 3.561706781387329, Grad L2 Norm: 0.022541416808962822
2025-11-24 01:31:39.840 | INFO     | __main__:<module>:160 - Step50070, Loss: 3.5842432975769043, Grad L2 Norm: 0.022201981395483017
2025-11-24 01:31:41.560 | INFO     | __main__:<module>:160 - Step50080, Loss: 3.6372947692871094, Grad L2 Norm: 0.022325314581394196
2025-11-24 01:31:43.295 | INFO     | __main__:<module>:160 - Step50090, Loss: 3.564310073852539, Grad L2 Norm: 0.02279939502477646
2025-11-24 01:31:45.013 | INFO     | __main__:<module>:160 - Step50100, Loss: 3.609886884689331, Grad L2 Norm: 0.024674013257026672
2025-11-24 01:31:46.740 | INFO     | __main__:<module>:160 - Step50110, Loss: 3.652390956878662, Grad L2 Norm: 0.022279981523752213
2025-11-24 01:31:48.465 | INFO     | __main__:<module>:160 - Step50120, Loss: 3.7929718494415283, Grad L2 Norm: 0.023503225296735764
2025-11-24 01:31:50.193 | INFO     | __main__:<module>:160 - Step50130, Loss: 3.605616331100464, Grad L2 Norm: 0.025205854326486588
2025-11-24 01:31:51.916 | INFO     | __main__:<module>:160 - Step50140, Loss: 3.6671388149261475, Grad L2 Norm: 0.025723345577716827
2025-11-24 01:31:53.646 | INFO     | __main__:<module>:160 - Step50150, Loss: 3.5270016193389893, Grad L2 Norm: 0.022659726440906525
2025-11-24 01:31:55.369 | INFO     | __main__:<module>:160 - Step50160, Loss: 3.4498724937438965, Grad L2 Norm: 0.023018037900328636
2025-11-24 01:31:57.086 | INFO     | __main__:<module>:160 - Step50170, Loss: 3.4412312507629395, Grad L2 Norm: 0.022009726613759995
2025-11-24 01:31:58.811 | INFO     | __main__:<module>:160 - Step50180, Loss: 3.485215187072754, Grad L2 Norm: 0.02224252186715603
2025-11-24 01:32:00.539 | INFO     | __main__:<module>:160 - Step50190, Loss: 3.527963161468506, Grad L2 Norm: 0.024052007123827934
2025-11-24 01:32:02.261 | INFO     | __main__:<module>:160 - Step50200, Loss: 3.5647149085998535, Grad L2 Norm: 0.022651877254247665
2025-11-24 01:32:03.988 | INFO     | __main__:<module>:160 - Step50210, Loss: 3.3990373611450195, Grad L2 Norm: 0.02315731905400753
2025-11-24 01:32:05.705 | INFO     | __main__:<module>:160 - Step50220, Loss: 3.5372304916381836, Grad L2 Norm: 0.02332509495317936
2025-11-24 01:32:07.424 | INFO     | __main__:<module>:160 - Step50230, Loss: 3.528684139251709, Grad L2 Norm: 0.022837553173303604
2025-11-24 01:32:09.151 | INFO     | __main__:<module>:160 - Step50240, Loss: 3.5780115127563477, Grad L2 Norm: 0.023278620094060898
2025-11-24 01:32:10.870 | INFO     | __main__:<module>:160 - Step50250, Loss: 3.5557143688201904, Grad L2 Norm: 0.02258983440697193
2025-11-24 01:32:12.595 | INFO     | __main__:<module>:160 - Step50260, Loss: 3.6283843517303467, Grad L2 Norm: 0.024272916838526726
2025-11-24 01:32:14.314 | INFO     | __main__:<module>:160 - Step50270, Loss: 3.544497013092041, Grad L2 Norm: 0.023792069405317307
2025-11-24 01:32:16.030 | INFO     | __main__:<module>:160 - Step50280, Loss: 3.562776565551758, Grad L2 Norm: 0.0225864015519619
2025-11-24 01:32:17.754 | INFO     | __main__:<module>:160 - Step50290, Loss: 3.5652616024017334, Grad L2 Norm: 0.02461455762386322
2025-11-24 01:32:19.471 | INFO     | __main__:<module>:160 - Step50300, Loss: 3.5838942527770996, Grad L2 Norm: 0.024617500603199005
2025-11-24 01:32:21.194 | INFO     | __main__:<module>:160 - Step50310, Loss: 3.529078960418701, Grad L2 Norm: 0.022294875234365463
2025-11-24 01:32:22.912 | INFO     | __main__:<module>:160 - Step50320, Loss: 3.52150297164917, Grad L2 Norm: 0.022174065932631493
2025-11-24 01:32:24.638 | INFO     | __main__:<module>:160 - Step50330, Loss: 3.3908421993255615, Grad L2 Norm: 0.02112516015768051
2025-11-24 01:32:26.366 | INFO     | __main__:<module>:160 - Step50340, Loss: 3.488739013671875, Grad L2 Norm: 0.022205423563718796
2025-11-24 01:32:28.079 | INFO     | __main__:<module>:160 - Step50350, Loss: 3.557694435119629, Grad L2 Norm: 0.023198716342449188
2025-11-24 01:32:29.801 | INFO     | __main__:<module>:160 - Step50360, Loss: 3.4711945056915283, Grad L2 Norm: 0.02237514965236187
2025-11-24 01:32:31.533 | INFO     | __main__:<module>:160 - Step50370, Loss: 3.7236592769622803, Grad L2 Norm: 0.023221435025334358
2025-11-24 01:32:33.249 | INFO     | __main__:<module>:160 - Step50380, Loss: 3.4893109798431396, Grad L2 Norm: 0.022707810625433922
2025-11-24 01:32:34.977 | INFO     | __main__:<module>:160 - Step50390, Loss: 3.5747740268707275, Grad L2 Norm: 0.02207779884338379
2025-11-24 01:32:36.691 | INFO     | __main__:<module>:160 - Step50400, Loss: 3.5923168659210205, Grad L2 Norm: 0.022837871685624123
2025-11-24 01:32:36.691 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:32:37.708 | INFO     | __main__:<module>:181 - validation loss: 3.529939329624176
2025-11-24 01:32:39.431 | INFO     | __main__:<module>:160 - Step50410, Loss: 3.6411523818969727, Grad L2 Norm: 0.022941669449210167
2025-11-24 01:32:41.149 | INFO     | __main__:<module>:160 - Step50420, Loss: 3.559480905532837, Grad L2 Norm: 0.022695405408740044
2025-11-24 01:32:42.864 | INFO     | __main__:<module>:160 - Step50430, Loss: 3.6366569995880127, Grad L2 Norm: 0.02440096065402031
2025-11-24 01:32:44.590 | INFO     | __main__:<module>:160 - Step50440, Loss: 3.4591188430786133, Grad L2 Norm: 0.0213466826826334
2025-11-24 01:32:46.304 | INFO     | __main__:<module>:160 - Step50450, Loss: 3.5557074546813965, Grad L2 Norm: 0.022085227072238922
2025-11-24 01:32:48.026 | INFO     | __main__:<module>:160 - Step50460, Loss: 3.47540283203125, Grad L2 Norm: 0.02337873913347721
2025-11-24 01:32:49.744 | INFO     | __main__:<module>:160 - Step50470, Loss: 3.499342918395996, Grad L2 Norm: 0.023308612406253815
2025-11-24 01:32:51.459 | INFO     | __main__:<module>:160 - Step50480, Loss: 3.604387044906616, Grad L2 Norm: 0.023289619013667107
2025-11-24 01:32:53.183 | INFO     | __main__:<module>:160 - Step50490, Loss: 3.5136921405792236, Grad L2 Norm: 0.02223932184278965
2025-11-24 01:32:54.909 | INFO     | __main__:<module>:160 - Step50500, Loss: 3.45287823677063, Grad L2 Norm: 0.024898143485188484
2025-11-24 01:32:56.633 | INFO     | __main__:<module>:160 - Step50510, Loss: 3.5607223510742188, Grad L2 Norm: 0.023057030513882637
2025-11-24 01:32:58.352 | INFO     | __main__:<module>:160 - Step50520, Loss: 3.6077637672424316, Grad L2 Norm: 0.024640018120408058
2025-11-24 01:33:00.066 | INFO     | __main__:<module>:160 - Step50530, Loss: 3.5465803146362305, Grad L2 Norm: 0.02328389137983322
2025-11-24 01:33:01.794 | INFO     | __main__:<module>:160 - Step50540, Loss: 3.4904303550720215, Grad L2 Norm: 0.021577635779976845
2025-11-24 01:33:03.519 | INFO     | __main__:<module>:160 - Step50550, Loss: 3.633104085922241, Grad L2 Norm: 0.02227615937590599
2025-11-24 01:33:05.246 | INFO     | __main__:<module>:160 - Step50560, Loss: 3.478898525238037, Grad L2 Norm: 0.02458316646516323
2025-11-24 01:33:06.963 | INFO     | __main__:<module>:160 - Step50570, Loss: 3.4977214336395264, Grad L2 Norm: 0.02261616289615631
2025-11-24 01:33:08.681 | INFO     | __main__:<module>:160 - Step50580, Loss: 3.578131675720215, Grad L2 Norm: 0.02236473746597767
2025-11-24 01:33:10.415 | INFO     | __main__:<module>:160 - Step50590, Loss: 3.5081944465637207, Grad L2 Norm: 0.022067908197641373
2025-11-24 01:33:12.130 | INFO     | __main__:<module>:160 - Step50600, Loss: 3.7363698482513428, Grad L2 Norm: 0.02550099603831768
2025-11-24 01:33:13.854 | INFO     | __main__:<module>:160 - Step50610, Loss: 3.5791103839874268, Grad L2 Norm: 0.023757513612508774
2025-11-24 01:33:15.569 | INFO     | __main__:<module>:160 - Step50620, Loss: 3.6226749420166016, Grad L2 Norm: 0.023169927299022675
2025-11-24 01:33:17.297 | INFO     | __main__:<module>:160 - Step50630, Loss: 3.519735336303711, Grad L2 Norm: 0.024303298443555832
2025-11-24 01:33:19.021 | INFO     | __main__:<module>:160 - Step50640, Loss: 3.6147139072418213, Grad L2 Norm: 0.026003075763583183
2025-11-24 01:33:20.739 | INFO     | __main__:<module>:160 - Step50650, Loss: 3.5617423057556152, Grad L2 Norm: 0.024697301909327507
2025-11-24 01:33:22.463 | INFO     | __main__:<module>:160 - Step50660, Loss: 3.7365596294403076, Grad L2 Norm: 0.02518434263765812
2025-11-24 01:33:24.179 | INFO     | __main__:<module>:160 - Step50670, Loss: 3.6966476440429688, Grad L2 Norm: 0.02310929447412491
2025-11-24 01:33:25.913 | INFO     | __main__:<module>:160 - Step50680, Loss: 3.4621005058288574, Grad L2 Norm: 0.023210354149341583
2025-11-24 01:33:27.633 | INFO     | __main__:<module>:160 - Step50690, Loss: 3.4581117630004883, Grad L2 Norm: 0.022202974185347557
2025-11-24 01:33:29.348 | INFO     | __main__:<module>:160 - Step50700, Loss: 3.523111343383789, Grad L2 Norm: 0.02250768430531025
2025-11-24 01:33:31.072 | INFO     | __main__:<module>:160 - Step50710, Loss: 3.5475165843963623, Grad L2 Norm: 0.022073104977607727
2025-11-24 01:33:32.799 | INFO     | __main__:<module>:160 - Step50720, Loss: 3.7214269638061523, Grad L2 Norm: 0.0232679583132267
2025-11-24 01:33:34.522 | INFO     | __main__:<module>:160 - Step50730, Loss: 3.4705913066864014, Grad L2 Norm: 0.022395364940166473
2025-11-24 01:33:36.240 | INFO     | __main__:<module>:160 - Step50740, Loss: 3.5369977951049805, Grad L2 Norm: 0.023488689213991165
2025-11-24 01:33:37.955 | INFO     | __main__:<module>:160 - Step50750, Loss: 3.5212454795837402, Grad L2 Norm: 0.022779537364840508
2025-11-24 01:33:39.684 | INFO     | __main__:<module>:160 - Step50760, Loss: 3.4281015396118164, Grad L2 Norm: 0.026160860434174538
2025-11-24 01:33:41.409 | INFO     | __main__:<module>:160 - Step50770, Loss: 3.5486178398132324, Grad L2 Norm: 0.021839844062924385
2025-11-24 01:33:43.137 | INFO     | __main__:<module>:160 - Step50780, Loss: 3.641227960586548, Grad L2 Norm: 0.02390495501458645
2025-11-24 01:33:44.850 | INFO     | __main__:<module>:160 - Step50790, Loss: 3.5307717323303223, Grad L2 Norm: 0.022270243614912033
2025-11-24 01:33:46.567 | INFO     | __main__:<module>:160 - Step50800, Loss: 3.510021448135376, Grad L2 Norm: 0.021555868908762932
2025-11-24 01:33:46.567 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:33:47.585 | INFO     | __main__:<module>:181 - validation loss: 3.5442577958106996
2025-11-24 01:33:49.311 | INFO     | __main__:<module>:160 - Step50810, Loss: 3.511235475540161, Grad L2 Norm: 0.023279763758182526
2025-11-24 01:33:51.025 | INFO     | __main__:<module>:160 - Step50820, Loss: 3.557239532470703, Grad L2 Norm: 0.02433290332555771
2025-11-24 01:33:52.750 | INFO     | __main__:<module>:160 - Step50830, Loss: 3.641326665878296, Grad L2 Norm: 0.022731604054570198
2025-11-24 01:33:54.467 | INFO     | __main__:<module>:160 - Step50840, Loss: 3.7139320373535156, Grad L2 Norm: 0.02342013642191887
2025-11-24 01:33:56.179 | INFO     | __main__:<module>:160 - Step50850, Loss: 3.5797119140625, Grad L2 Norm: 0.02198401838541031
2025-11-24 01:33:57.904 | INFO     | __main__:<module>:160 - Step50860, Loss: 3.5503876209259033, Grad L2 Norm: 0.024221887812018394
2025-11-24 01:33:59.621 | INFO     | __main__:<module>:160 - Step50870, Loss: 3.6939697265625, Grad L2 Norm: 0.02370840311050415
2025-11-24 01:34:01.343 | INFO     | __main__:<module>:160 - Step50880, Loss: 3.5988855361938477, Grad L2 Norm: 0.023569030687212944
2025-11-24 01:34:03.061 | INFO     | __main__:<module>:160 - Step50890, Loss: 3.4168806076049805, Grad L2 Norm: 0.023396790027618408
2025-11-24 01:34:04.787 | INFO     | __main__:<module>:160 - Step50900, Loss: 3.6461105346679688, Grad L2 Norm: 0.024246085435152054
2025-11-24 01:34:06.514 | INFO     | __main__:<module>:160 - Step50910, Loss: 3.51132869720459, Grad L2 Norm: 0.02199370227754116
2025-11-24 01:34:08.229 | INFO     | __main__:<module>:160 - Step50920, Loss: 3.551624298095703, Grad L2 Norm: 0.02327224425971508
2025-11-24 01:34:09.950 | INFO     | __main__:<module>:160 - Step50930, Loss: 3.598519802093506, Grad L2 Norm: 0.023193515837192535
2025-11-24 01:34:11.680 | INFO     | __main__:<module>:160 - Step50940, Loss: 3.620457172393799, Grad L2 Norm: 0.021891247481107712
2025-11-24 01:34:13.401 | INFO     | __main__:<module>:160 - Step50950, Loss: 3.620361804962158, Grad L2 Norm: 0.022813687101006508
2025-11-24 01:34:15.124 | INFO     | __main__:<module>:160 - Step50960, Loss: 3.4370064735412598, Grad L2 Norm: 0.021860355511307716
2025-11-24 01:34:16.837 | INFO     | __main__:<module>:160 - Step50970, Loss: 3.5853934288024902, Grad L2 Norm: 0.022621527314186096
2025-11-24 01:34:18.565 | INFO     | __main__:<module>:160 - Step50980, Loss: 3.461483955383301, Grad L2 Norm: 0.020810944959521294
2025-11-24 01:34:20.289 | INFO     | __main__:<module>:160 - Step50990, Loss: 3.5926332473754883, Grad L2 Norm: 0.023160623386502266
2025-11-24 01:34:22.016 | INFO     | __main__:<module>:160 - Step51000, Loss: 3.591519355773926, Grad L2 Norm: 0.022901592776179314
2025-11-24 01:34:23.736 | INFO     | __main__:<module>:160 - Step51010, Loss: 3.4718830585479736, Grad L2 Norm: 0.02115785703063011
2025-11-24 01:34:25.450 | INFO     | __main__:<module>:160 - Step51020, Loss: 3.562403440475464, Grad L2 Norm: 0.02286701090633869
2025-11-24 01:34:27.185 | INFO     | __main__:<module>:160 - Step51030, Loss: 3.595083236694336, Grad L2 Norm: 0.022467033937573433
2025-11-24 01:34:28.900 | INFO     | __main__:<module>:160 - Step51040, Loss: 3.6946239471435547, Grad L2 Norm: 0.022753987461328506
2025-11-24 01:34:30.623 | INFO     | __main__:<module>:160 - Step51050, Loss: 3.548713207244873, Grad L2 Norm: 0.024709299206733704
2025-11-24 01:34:32.341 | INFO     | __main__:<module>:160 - Step51060, Loss: 3.5383663177490234, Grad L2 Norm: 0.02167675830423832
2025-11-24 01:34:34.069 | INFO     | __main__:<module>:160 - Step51070, Loss: 3.505089282989502, Grad L2 Norm: 0.02190045453608036
2025-11-24 01:34:35.791 | INFO     | __main__:<module>:160 - Step51080, Loss: 3.5271718502044678, Grad L2 Norm: 0.023862702772021294
2025-11-24 01:34:37.509 | INFO     | __main__:<module>:160 - Step51090, Loss: 3.5083916187286377, Grad L2 Norm: 0.02367718145251274
2025-11-24 01:34:39.231 | INFO     | __main__:<module>:160 - Step51100, Loss: 3.546597957611084, Grad L2 Norm: 0.022648965939879417
2025-11-24 01:34:40.950 | INFO     | __main__:<module>:160 - Step51110, Loss: 3.448401689529419, Grad L2 Norm: 0.023099234327673912
2025-11-24 01:34:42.676 | INFO     | __main__:<module>:160 - Step51120, Loss: 3.513733386993408, Grad L2 Norm: 0.02314666472375393
2025-11-24 01:34:44.404 | INFO     | __main__:<module>:160 - Step51130, Loss: 3.568075656890869, Grad L2 Norm: 0.022616732865571976
2025-11-24 01:34:46.121 | INFO     | __main__:<module>:160 - Step51140, Loss: 3.5421299934387207, Grad L2 Norm: 0.023257629945874214
2025-11-24 01:34:47.843 | INFO     | __main__:<module>:160 - Step51150, Loss: 3.610032081604004, Grad L2 Norm: 0.021931074559688568
2025-11-24 01:34:49.571 | INFO     | __main__:<module>:160 - Step51160, Loss: 3.5397274494171143, Grad L2 Norm: 0.02348962612450123
2025-11-24 01:34:51.287 | INFO     | __main__:<module>:160 - Step51170, Loss: 3.6099414825439453, Grad L2 Norm: 0.023765165358781815
2025-11-24 01:34:53.011 | INFO     | __main__:<module>:160 - Step51180, Loss: 3.489042043685913, Grad L2 Norm: 0.02338714338839054
2025-11-24 01:34:54.725 | INFO     | __main__:<module>:160 - Step51190, Loss: 3.7128491401672363, Grad L2 Norm: 0.022368893027305603
2025-11-24 01:34:56.454 | INFO     | __main__:<module>:160 - Step51200, Loss: 3.5947682857513428, Grad L2 Norm: 0.02342453971505165
2025-11-24 01:34:56.455 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:34:57.471 | INFO     | __main__:<module>:181 - validation loss: 3.5693620562553408
2025-11-24 01:34:59.196 | INFO     | __main__:<module>:160 - Step51210, Loss: 3.4393882751464844, Grad L2 Norm: 0.024078698828816414
2025-11-24 01:35:00.922 | INFO     | __main__:<module>:160 - Step51220, Loss: 3.590501546859741, Grad L2 Norm: 0.022985011339187622
2025-11-24 01:35:02.648 | INFO     | __main__:<module>:160 - Step51230, Loss: 3.495283842086792, Grad L2 Norm: 0.023045623674988747
2025-11-24 01:35:04.373 | INFO     | __main__:<module>:160 - Step51240, Loss: 3.688880443572998, Grad L2 Norm: 0.024644844233989716
2025-11-24 01:35:06.097 | INFO     | __main__:<module>:160 - Step51250, Loss: 3.559246301651001, Grad L2 Norm: 0.02233341708779335
2025-11-24 01:35:07.811 | INFO     | __main__:<module>:160 - Step51260, Loss: 3.5764849185943604, Grad L2 Norm: 0.024764511734247208
2025-11-24 01:35:09.544 | INFO     | __main__:<module>:160 - Step51270, Loss: 3.5198464393615723, Grad L2 Norm: 0.023431885987520218
2025-11-24 01:35:11.261 | INFO     | __main__:<module>:160 - Step51280, Loss: 3.6710686683654785, Grad L2 Norm: 0.02461974322795868
2025-11-24 01:35:12.986 | INFO     | __main__:<module>:160 - Step51290, Loss: 3.6078596115112305, Grad L2 Norm: 0.025384074077010155
2025-11-24 01:35:14.712 | INFO     | __main__:<module>:160 - Step51300, Loss: 3.4938805103302, Grad L2 Norm: 0.023388797417283058
2025-11-24 01:35:16.428 | INFO     | __main__:<module>:160 - Step51310, Loss: 3.5073180198669434, Grad L2 Norm: 0.02187199331820011
2025-11-24 01:35:18.151 | INFO     | __main__:<module>:160 - Step51320, Loss: 3.6311261653900146, Grad L2 Norm: 0.02234586700797081
2025-11-24 01:35:19.883 | INFO     | __main__:<module>:160 - Step51330, Loss: 3.582106590270996, Grad L2 Norm: 0.022536296397447586
2025-11-24 01:35:21.598 | INFO     | __main__:<module>:160 - Step51340, Loss: 3.5731329917907715, Grad L2 Norm: 0.022849369794130325
2025-11-24 01:35:23.323 | INFO     | __main__:<module>:160 - Step51350, Loss: 3.4673025608062744, Grad L2 Norm: 0.02298666536808014
2025-11-24 01:35:25.037 | INFO     | __main__:<module>:160 - Step51360, Loss: 3.538931369781494, Grad L2 Norm: 0.02335665374994278
2025-11-24 01:35:26.765 | INFO     | __main__:<module>:160 - Step51370, Loss: 3.5758490562438965, Grad L2 Norm: 0.022653786465525627
2025-11-24 01:35:28.490 | INFO     | __main__:<module>:160 - Step51380, Loss: 3.4942920207977295, Grad L2 Norm: 0.02327284961938858
2025-11-24 01:35:30.217 | INFO     | __main__:<module>:160 - Step51390, Loss: 3.5463528633117676, Grad L2 Norm: 0.02249986119568348
2025-11-24 01:35:31.932 | INFO     | __main__:<module>:160 - Step51400, Loss: 3.543351173400879, Grad L2 Norm: 0.021677644923329353
2025-11-24 01:35:33.646 | INFO     | __main__:<module>:160 - Step51410, Loss: 3.660301446914673, Grad L2 Norm: 0.024089977145195007
2025-11-24 01:35:35.382 | INFO     | __main__:<module>:160 - Step51420, Loss: 3.4773201942443848, Grad L2 Norm: 0.023860206827521324
2025-11-24 01:35:37.098 | INFO     | __main__:<module>:160 - Step51430, Loss: 3.5663957595825195, Grad L2 Norm: 0.022376475855708122
2025-11-24 01:35:38.822 | INFO     | __main__:<module>:160 - Step51440, Loss: 3.568460702896118, Grad L2 Norm: 0.023225335404276848
2025-11-24 01:35:40.539 | INFO     | __main__:<module>:160 - Step51450, Loss: 3.5631630420684814, Grad L2 Norm: 0.023153137415647507
2025-11-24 01:35:42.266 | INFO     | __main__:<module>:160 - Step51460, Loss: 3.5991811752319336, Grad L2 Norm: 0.022624414414167404
2025-11-24 01:35:43.991 | INFO     | __main__:<module>:160 - Step51470, Loss: 3.59598445892334, Grad L2 Norm: 0.023367803543806076
2025-11-24 01:35:45.708 | INFO     | __main__:<module>:160 - Step51480, Loss: 3.5270891189575195, Grad L2 Norm: 0.025244150310754776
2025-11-24 01:35:47.430 | INFO     | __main__:<module>:160 - Step51490, Loss: 3.5307064056396484, Grad L2 Norm: 0.023715341463685036
2025-11-24 01:35:49.148 | INFO     | __main__:<module>:160 - Step51500, Loss: 3.4557080268859863, Grad L2 Norm: 0.023034540936350822
2025-11-24 01:35:50.874 | INFO     | __main__:<module>:160 - Step51510, Loss: 3.6409144401550293, Grad L2 Norm: 0.02384188026189804
2025-11-24 01:35:52.605 | INFO     | __main__:<module>:160 - Step51520, Loss: 3.5957939624786377, Grad L2 Norm: 0.02398904599249363
2025-11-24 01:35:54.316 | INFO     | __main__:<module>:160 - Step51530, Loss: 3.615037441253662, Grad L2 Norm: 0.02387833222746849
2025-11-24 01:35:56.039 | INFO     | __main__:<module>:160 - Step51540, Loss: 3.564027786254883, Grad L2 Norm: 0.022077975794672966
2025-11-24 01:35:57.768 | INFO     | __main__:<module>:160 - Step51550, Loss: 3.5733144283294678, Grad L2 Norm: 0.022413088008761406
2025-11-24 01:35:59.486 | INFO     | __main__:<module>:160 - Step51560, Loss: 3.5110247135162354, Grad L2 Norm: 0.022835493087768555
2025-11-24 01:36:01.211 | INFO     | __main__:<module>:160 - Step51570, Loss: 3.47802734375, Grad L2 Norm: 0.023781917989253998
2025-11-24 01:36:02.926 | INFO     | __main__:<module>:160 - Step51580, Loss: 3.467689037322998, Grad L2 Norm: 0.022655941545963287
2025-11-24 01:36:04.655 | INFO     | __main__:<module>:160 - Step51590, Loss: 3.5688564777374268, Grad L2 Norm: 0.027196915820240974
2025-11-24 01:36:06.379 | INFO     | __main__:<module>:160 - Step51600, Loss: 3.547288417816162, Grad L2 Norm: 0.022545645013451576
2025-11-24 01:36:06.380 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:36:07.408 | INFO     | __main__:<module>:181 - validation loss: 3.5382538080215453
2025-11-24 01:36:09.132 | INFO     | __main__:<module>:160 - Step51610, Loss: 3.5204949378967285, Grad L2 Norm: 0.024701422080397606
2025-11-24 01:36:10.850 | INFO     | __main__:<module>:160 - Step51620, Loss: 3.5185179710388184, Grad L2 Norm: 0.02183559164404869
2025-11-24 01:36:12.578 | INFO     | __main__:<module>:160 - Step51630, Loss: 3.530776023864746, Grad L2 Norm: 0.024517759680747986
2025-11-24 01:36:14.303 | INFO     | __main__:<module>:160 - Step51640, Loss: 3.523710250854492, Grad L2 Norm: 0.023584559559822083
2025-11-24 01:36:16.019 | INFO     | __main__:<module>:160 - Step51650, Loss: 3.519052028656006, Grad L2 Norm: 0.021948548033833504
2025-11-24 01:36:17.743 | INFO     | __main__:<module>:160 - Step51660, Loss: 3.591299057006836, Grad L2 Norm: 0.022233137860894203
2025-11-24 01:36:19.461 | INFO     | __main__:<module>:160 - Step51670, Loss: 3.6054630279541016, Grad L2 Norm: 0.02365252748131752
2025-11-24 01:36:21.186 | INFO     | __main__:<module>:160 - Step51680, Loss: 3.640350341796875, Grad L2 Norm: 0.023037636652588844
2025-11-24 01:36:22.915 | INFO     | __main__:<module>:160 - Step51690, Loss: 3.602421283721924, Grad L2 Norm: 0.022491639479994774
2025-11-24 01:36:24.629 | INFO     | __main__:<module>:160 - Step51700, Loss: 3.5891225337982178, Grad L2 Norm: 0.021236877888441086
2025-11-24 01:36:26.352 | INFO     | __main__:<module>:160 - Step51710, Loss: 3.489110231399536, Grad L2 Norm: 0.02322751097381115
2025-11-24 01:36:28.082 | INFO     | __main__:<module>:160 - Step51720, Loss: 3.599529266357422, Grad L2 Norm: 0.02166910283267498
2025-11-24 01:36:29.795 | INFO     | __main__:<module>:160 - Step51730, Loss: 3.60575008392334, Grad L2 Norm: 0.023785216733813286
2025-11-24 01:36:31.521 | INFO     | __main__:<module>:160 - Step51740, Loss: 3.590522050857544, Grad L2 Norm: 0.023965556174516678
2025-11-24 01:36:33.236 | INFO     | __main__:<module>:160 - Step51750, Loss: 3.3361191749572754, Grad L2 Norm: 0.021840842440724373
2025-11-24 01:36:34.966 | INFO     | __main__:<module>:160 - Step51760, Loss: 3.5926198959350586, Grad L2 Norm: 0.02202857844531536
2025-11-24 01:36:36.689 | INFO     | __main__:<module>:160 - Step51770, Loss: 3.4840145111083984, Grad L2 Norm: 0.021976687014102936
2025-11-24 01:36:38.415 | INFO     | __main__:<module>:160 - Step51780, Loss: 3.6383023262023926, Grad L2 Norm: 0.022174067795276642
2025-11-24 01:36:40.131 | INFO     | __main__:<module>:160 - Step51790, Loss: 3.4438064098358154, Grad L2 Norm: 0.022212082520127296
2025-11-24 01:36:41.847 | INFO     | __main__:<module>:160 - Step51800, Loss: 3.6320152282714844, Grad L2 Norm: 0.023986708372831345
2025-11-24 01:36:43.582 | INFO     | __main__:<module>:160 - Step51810, Loss: 3.5314087867736816, Grad L2 Norm: 0.023333033546805382
2025-11-24 01:36:45.297 | INFO     | __main__:<module>:160 - Step51820, Loss: 3.5250115394592285, Grad L2 Norm: 0.02292746864259243
2025-11-24 01:36:47.021 | INFO     | __main__:<module>:160 - Step51830, Loss: 3.5754759311676025, Grad L2 Norm: 0.023101532831788063
2025-11-24 01:36:48.737 | INFO     | __main__:<module>:160 - Step51840, Loss: 3.5684704780578613, Grad L2 Norm: 0.023198705166578293
2025-11-24 01:36:50.464 | INFO     | __main__:<module>:160 - Step51850, Loss: 3.6406431198120117, Grad L2 Norm: 0.022859007120132446
2025-11-24 01:36:52.190 | INFO     | __main__:<module>:160 - Step51860, Loss: 3.4650020599365234, Grad L2 Norm: 0.022894790396094322
2025-11-24 01:36:53.907 | INFO     | __main__:<module>:160 - Step51870, Loss: 3.64021635055542, Grad L2 Norm: 0.022198567166924477
2025-11-24 01:36:55.630 | INFO     | __main__:<module>:160 - Step51880, Loss: 3.566005229949951, Grad L2 Norm: 0.022158123552799225
2025-11-24 01:36:57.349 | INFO     | __main__:<module>:160 - Step51890, Loss: 3.543496608734131, Grad L2 Norm: 0.021919747814536095
2025-11-24 01:36:59.076 | INFO     | __main__:<module>:160 - Step51900, Loss: 3.5516977310180664, Grad L2 Norm: 0.023305844515562057
2025-11-24 01:37:00.803 | INFO     | __main__:<module>:160 - Step51910, Loss: 3.594517707824707, Grad L2 Norm: 0.02368173934519291
2025-11-24 01:37:02.516 | INFO     | __main__:<module>:160 - Step51920, Loss: 3.5187442302703857, Grad L2 Norm: 0.021962914615869522
2025-11-24 01:37:04.239 | INFO     | __main__:<module>:160 - Step51930, Loss: 3.551042079925537, Grad L2 Norm: 0.025086821988224983
2025-11-24 01:37:05.967 | INFO     | __main__:<module>:160 - Step51940, Loss: 3.427541971206665, Grad L2 Norm: 0.020786520093679428
2025-11-24 01:37:07.687 | INFO     | __main__:<module>:160 - Step51950, Loss: 3.5352773666381836, Grad L2 Norm: 0.025027012452483177
2025-11-24 01:37:09.411 | INFO     | __main__:<module>:160 - Step51960, Loss: 3.5148468017578125, Grad L2 Norm: 0.021683307364583015
2025-11-24 01:37:11.124 | INFO     | __main__:<module>:160 - Step51970, Loss: 3.4644663333892822, Grad L2 Norm: 0.021306345239281654
2025-11-24 01:37:12.853 | INFO     | __main__:<module>:160 - Step51980, Loss: 3.4379684925079346, Grad L2 Norm: 0.022328218445181847
2025-11-24 01:37:14.577 | INFO     | __main__:<module>:160 - Step51990, Loss: 3.7165398597717285, Grad L2 Norm: 0.02278517559170723
2025-11-24 01:37:16.302 | INFO     | __main__:<module>:160 - Step52000, Loss: 3.624161958694458, Grad L2 Norm: 0.02105654776096344
2025-11-24 01:37:16.303 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:37:17.313 | INFO     | __main__:<module>:181 - validation loss: 3.5261422038078307
2025-11-24 01:37:17.313 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_52000.pt
2025-11-24 01:37:19.024 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 01:37:20.651 | INFO     | __main__:<module>:160 - Step52010, Loss: 3.4789819717407227, Grad L2 Norm: 0.022821277379989624
2025-11-24 01:37:22.366 | INFO     | __main__:<module>:160 - Step52020, Loss: 3.5007128715515137, Grad L2 Norm: 0.022001953795552254
2025-11-24 01:37:24.089 | INFO     | __main__:<module>:160 - Step52030, Loss: 3.472133159637451, Grad L2 Norm: 0.022686339914798737
2025-11-24 01:37:25.806 | INFO     | __main__:<module>:160 - Step52040, Loss: 3.5595736503601074, Grad L2 Norm: 0.023294683545827866
2025-11-24 01:37:27.534 | INFO     | __main__:<module>:160 - Step52050, Loss: 3.52827787399292, Grad L2 Norm: 0.022513411939144135
2025-11-24 01:37:29.259 | INFO     | __main__:<module>:160 - Step52060, Loss: 3.495683193206787, Grad L2 Norm: 0.02365407533943653
2025-11-24 01:37:30.978 | INFO     | __main__:<module>:160 - Step52070, Loss: 3.48983097076416, Grad L2 Norm: 0.021273232996463776
2025-11-24 01:37:32.705 | INFO     | __main__:<module>:160 - Step52080, Loss: 3.6461997032165527, Grad L2 Norm: 0.022032152861356735
2025-11-24 01:37:34.417 | INFO     | __main__:<module>:160 - Step52090, Loss: 3.5498046875, Grad L2 Norm: 0.024264570325613022
2025-11-24 01:37:36.143 | INFO     | __main__:<module>:160 - Step52100, Loss: 3.6045708656311035, Grad L2 Norm: 0.02229599468410015
2025-11-24 01:37:37.872 | INFO     | __main__:<module>:160 - Step52110, Loss: 3.670217514038086, Grad L2 Norm: 0.02328627184033394
2025-11-24 01:37:39.586 | INFO     | __main__:<module>:160 - Step52120, Loss: 3.597999334335327, Grad L2 Norm: 0.025214239954948425
2025-11-24 01:37:41.309 | INFO     | __main__:<module>:160 - Step52130, Loss: 3.441746950149536, Grad L2 Norm: 0.023259708657860756
2025-11-24 01:37:43.038 | INFO     | __main__:<module>:160 - Step52140, Loss: 3.5191550254821777, Grad L2 Norm: 0.02196158468723297
2025-11-24 01:37:44.755 | INFO     | __main__:<module>:160 - Step52150, Loss: 3.559293270111084, Grad L2 Norm: 0.02439507283270359
2025-11-24 01:37:46.479 | INFO     | __main__:<module>:160 - Step52160, Loss: 3.550717830657959, Grad L2 Norm: 0.025165436789393425
2025-11-24 01:37:48.193 | INFO     | __main__:<module>:160 - Step52170, Loss: 3.4909791946411133, Grad L2 Norm: 0.02397208660840988
2025-11-24 01:37:49.919 | INFO     | __main__:<module>:160 - Step52180, Loss: 3.5177104473114014, Grad L2 Norm: 0.020620642229914665
2025-11-24 01:37:51.645 | INFO     | __main__:<module>:160 - Step52190, Loss: 3.457946538925171, Grad L2 Norm: 0.02403329685330391
2025-11-24 01:37:53.370 | INFO     | __main__:<module>:160 - Step52200, Loss: 3.656730890274048, Grad L2 Norm: 0.026838600635528564
2025-11-24 01:37:55.086 | INFO     | __main__:<module>:160 - Step52210, Loss: 3.6842856407165527, Grad L2 Norm: 0.023160386830568314
2025-11-24 01:37:56.803 | INFO     | __main__:<module>:160 - Step52220, Loss: 3.5944318771362305, Grad L2 Norm: 0.024768205359578133
2025-11-24 01:37:58.538 | INFO     | __main__:<module>:160 - Step52230, Loss: 3.553586959838867, Grad L2 Norm: 0.02317184954881668
2025-11-24 01:38:00.255 | INFO     | __main__:<module>:160 - Step52240, Loss: 3.5939207077026367, Grad L2 Norm: 0.02393372729420662
2025-11-24 01:38:01.978 | INFO     | __main__:<module>:160 - Step52250, Loss: 3.5090675354003906, Grad L2 Norm: 0.02235737442970276
2025-11-24 01:38:03.697 | INFO     | __main__:<module>:160 - Step52260, Loss: 3.554780960083008, Grad L2 Norm: 0.023579904809594154
2025-11-24 01:38:05.426 | INFO     | __main__:<module>:160 - Step52270, Loss: 3.445991277694702, Grad L2 Norm: 0.02279658056795597
2025-11-24 01:38:07.147 | INFO     | __main__:<module>:160 - Step52280, Loss: 3.541076183319092, Grad L2 Norm: 0.02253688871860504
2025-11-24 01:38:08.863 | INFO     | __main__:<module>:160 - Step52290, Loss: 3.618988275527954, Grad L2 Norm: 0.022946398705244064
2025-11-24 01:38:10.587 | INFO     | __main__:<module>:160 - Step52300, Loss: 3.705733060836792, Grad L2 Norm: 0.022978773340582848
2025-11-24 01:38:12.305 | INFO     | __main__:<module>:160 - Step52310, Loss: 3.501403331756592, Grad L2 Norm: 0.022798588499426842
2025-11-24 01:38:14.031 | INFO     | __main__:<module>:160 - Step52320, Loss: 3.531026840209961, Grad L2 Norm: 0.024705616757273674
2025-11-24 01:38:15.760 | INFO     | __main__:<module>:160 - Step52330, Loss: 3.4696314334869385, Grad L2 Norm: 0.021656259894371033
2025-11-24 01:38:17.473 | INFO     | __main__:<module>:160 - Step52340, Loss: 3.534990072250366, Grad L2 Norm: 0.023222682997584343
2025-11-24 01:38:19.195 | INFO     | __main__:<module>:160 - Step52350, Loss: 3.6462831497192383, Grad L2 Norm: 0.02482631988823414
2025-11-24 01:38:20.923 | INFO     | __main__:<module>:160 - Step52360, Loss: 3.5408782958984375, Grad L2 Norm: 0.02231484279036522
2025-11-24 01:38:22.642 | INFO     | __main__:<module>:160 - Step52370, Loss: 3.6756372451782227, Grad L2 Norm: 0.0228203684091568
2025-11-24 01:38:24.366 | INFO     | __main__:<module>:160 - Step52380, Loss: 3.4285330772399902, Grad L2 Norm: 0.022841686382889748
2025-11-24 01:38:26.081 | INFO     | __main__:<module>:160 - Step52390, Loss: 3.599731206893921, Grad L2 Norm: 0.024391254410147667
2025-11-24 01:38:27.809 | INFO     | __main__:<module>:160 - Step52400, Loss: 3.582489013671875, Grad L2 Norm: 0.02217409387230873
2025-11-24 01:38:27.810 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:38:28.826 | INFO     | __main__:<module>:181 - validation loss: 3.5673455476760862
2025-11-24 01:38:30.553 | INFO     | __main__:<module>:160 - Step52410, Loss: 3.639063835144043, Grad L2 Norm: 0.02418752759695053
2025-11-24 01:38:32.279 | INFO     | __main__:<module>:160 - Step52420, Loss: 3.6277425289154053, Grad L2 Norm: 0.02149442583322525
2025-11-24 01:38:34.004 | INFO     | __main__:<module>:160 - Step52430, Loss: 3.488572120666504, Grad L2 Norm: 0.022171368822455406
2025-11-24 01:38:35.732 | INFO     | __main__:<module>:160 - Step52440, Loss: 3.570727825164795, Grad L2 Norm: 0.021685611456632614
2025-11-24 01:38:37.460 | INFO     | __main__:<module>:160 - Step52450, Loss: 3.4794158935546875, Grad L2 Norm: 0.021865123882889748
2025-11-24 01:38:39.176 | INFO     | __main__:<module>:160 - Step52460, Loss: 3.5948941707611084, Grad L2 Norm: 0.0223335362970829
2025-11-24 01:38:40.899 | INFO     | __main__:<module>:160 - Step52470, Loss: 3.674262285232544, Grad L2 Norm: 0.02336721308529377
2025-11-24 01:38:42.617 | INFO     | __main__:<module>:160 - Step52480, Loss: 3.571748971939087, Grad L2 Norm: 0.0216324795037508
2025-11-24 01:38:44.341 | INFO     | __main__:<module>:160 - Step52490, Loss: 3.5070786476135254, Grad L2 Norm: 0.022121889516711235
2025-11-24 01:38:46.069 | INFO     | __main__:<module>:160 - Step52500, Loss: 3.5257229804992676, Grad L2 Norm: 0.022037774324417114
2025-11-24 01:38:47.786 | INFO     | __main__:<module>:160 - Step52510, Loss: 3.5872151851654053, Grad L2 Norm: 0.02330642193555832
2025-11-24 01:38:49.506 | INFO     | __main__:<module>:160 - Step52520, Loss: 3.465365409851074, Grad L2 Norm: 0.021301783621311188
2025-11-24 01:38:51.234 | INFO     | __main__:<module>:160 - Step52530, Loss: 3.5637705326080322, Grad L2 Norm: 0.022550685331225395
2025-11-24 01:38:52.952 | INFO     | __main__:<module>:160 - Step52540, Loss: 3.432720184326172, Grad L2 Norm: 0.02264793962240219
2025-11-24 01:38:54.677 | INFO     | __main__:<module>:160 - Step52550, Loss: 3.573284149169922, Grad L2 Norm: 0.02214990183711052
2025-11-24 01:38:56.392 | INFO     | __main__:<module>:160 - Step52560, Loss: 3.575368881225586, Grad L2 Norm: 0.02409142628312111
2025-11-24 01:38:58.120 | INFO     | __main__:<module>:160 - Step52570, Loss: 3.611234426498413, Grad L2 Norm: 0.022817932069301605
2025-11-24 01:38:59.844 | INFO     | __main__:<module>:160 - Step52580, Loss: 3.555624485015869, Grad L2 Norm: 0.023718176409602165
2025-11-24 01:39:01.570 | INFO     | __main__:<module>:160 - Step52590, Loss: 3.6073484420776367, Grad L2 Norm: 0.022675946354866028
2025-11-24 01:39:03.287 | INFO     | __main__:<module>:160 - Step52600, Loss: 3.6971371173858643, Grad L2 Norm: 0.025673285126686096
2025-11-24 01:39:05.002 | INFO     | __main__:<module>:160 - Step52610, Loss: 3.58912992477417, Grad L2 Norm: 0.023207491263747215
2025-11-24 01:39:06.738 | INFO     | __main__:<module>:160 - Step52620, Loss: 3.6822471618652344, Grad L2 Norm: 0.02412997931241989
2025-11-24 01:39:08.455 | INFO     | __main__:<module>:160 - Step52630, Loss: 3.548391342163086, Grad L2 Norm: 0.02204270288348198
2025-11-24 01:39:10.180 | INFO     | __main__:<module>:160 - Step52640, Loss: 3.5788397789001465, Grad L2 Norm: 0.02230185642838478
2025-11-24 01:39:11.898 | INFO     | __main__:<module>:160 - Step52650, Loss: 3.6163699626922607, Grad L2 Norm: 0.02277511917054653
2025-11-24 01:39:13.623 | INFO     | __main__:<module>:160 - Step52660, Loss: 3.574213981628418, Grad L2 Norm: 0.02273004874587059
2025-11-24 01:39:15.347 | INFO     | __main__:<module>:160 - Step52670, Loss: 3.584700107574463, Grad L2 Norm: 0.023168250918388367
2025-11-24 01:39:17.062 | INFO     | __main__:<module>:160 - Step52680, Loss: 3.6262388229370117, Grad L2 Norm: 0.02262597717344761
2025-11-24 01:39:18.786 | INFO     | __main__:<module>:160 - Step52690, Loss: 3.51808762550354, Grad L2 Norm: 0.021450374275445938
2025-11-24 01:39:20.508 | INFO     | __main__:<module>:160 - Step52700, Loss: 3.551455020904541, Grad L2 Norm: 0.023052159696817398
2025-11-24 01:39:22.231 | INFO     | __main__:<module>:160 - Step52710, Loss: 3.62345027923584, Grad L2 Norm: 0.023480653762817383
2025-11-24 01:39:23.958 | INFO     | __main__:<module>:160 - Step52720, Loss: 3.749525308609009, Grad L2 Norm: 0.025036362931132317
2025-11-24 01:39:25.672 | INFO     | __main__:<module>:160 - Step52730, Loss: 3.4669833183288574, Grad L2 Norm: 0.022882429882884026
2025-11-24 01:39:27.395 | INFO     | __main__:<module>:160 - Step52740, Loss: 3.6551308631896973, Grad L2 Norm: 0.022475218400359154
2025-11-24 01:39:29.125 | INFO     | __main__:<module>:160 - Step52750, Loss: 3.6735236644744873, Grad L2 Norm: 0.025849927216768265
2025-11-24 01:39:30.841 | INFO     | __main__:<module>:160 - Step52760, Loss: 3.5798604488372803, Grad L2 Norm: 0.022643662989139557
2025-11-24 01:39:32.565 | INFO     | __main__:<module>:160 - Step52770, Loss: 3.3884925842285156, Grad L2 Norm: 0.02260972373187542
2025-11-24 01:39:34.279 | INFO     | __main__:<module>:160 - Step52780, Loss: 3.610159397125244, Grad L2 Norm: 0.02261105738580227
2025-11-24 01:39:36.006 | INFO     | __main__:<module>:160 - Step52790, Loss: 3.627997398376465, Grad L2 Norm: 0.021825261414051056
2025-11-24 01:39:37.729 | INFO     | __main__:<module>:160 - Step52800, Loss: 3.5777225494384766, Grad L2 Norm: 0.022128911688923836
2025-11-24 01:39:37.730 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:39:38.747 | INFO     | __main__:<module>:181 - validation loss: 3.580989956855774
2025-11-24 01:39:40.456 | INFO     | __main__:<module>:160 - Step52810, Loss: 3.507449150085449, Grad L2 Norm: 0.02344985492527485
2025-11-24 01:39:42.180 | INFO     | __main__:<module>:160 - Step52820, Loss: 3.7869882583618164, Grad L2 Norm: 0.028720781207084656
2025-11-24 01:39:43.898 | INFO     | __main__:<module>:160 - Step52830, Loss: 3.5766196250915527, Grad L2 Norm: 0.02340993657708168
2025-11-24 01:39:45.626 | INFO     | __main__:<module>:160 - Step52840, Loss: 3.547558307647705, Grad L2 Norm: 0.023188581690192223
2025-11-24 01:39:47.341 | INFO     | __main__:<module>:160 - Step52850, Loss: 3.6008756160736084, Grad L2 Norm: 0.024241870269179344
2025-11-24 01:39:49.052 | INFO     | __main__:<module>:160 - Step52860, Loss: 3.5314669609069824, Grad L2 Norm: 0.022239331156015396
2025-11-24 01:39:50.776 | INFO     | __main__:<module>:160 - Step52870, Loss: 3.6172142028808594, Grad L2 Norm: 0.023314567282795906
2025-11-24 01:39:52.505 | INFO     | __main__:<module>:160 - Step52880, Loss: 3.5796217918395996, Grad L2 Norm: 0.02221597731113434
2025-11-24 01:39:54.226 | INFO     | __main__:<module>:160 - Step52890, Loss: 3.695390224456787, Grad L2 Norm: 0.02383175492286682
2025-11-24 01:39:55.946 | INFO     | __main__:<module>:160 - Step52900, Loss: 3.5540804862976074, Grad L2 Norm: 0.022137831896543503
2025-11-24 01:39:57.660 | INFO     | __main__:<module>:160 - Step52910, Loss: 3.51412034034729, Grad L2 Norm: 0.02522612363100052
2025-11-24 01:39:59.388 | INFO     | __main__:<module>:160 - Step52920, Loss: 3.4747538566589355, Grad L2 Norm: 0.022149184718728065
2025-11-24 01:40:01.112 | INFO     | __main__:<module>:160 - Step52930, Loss: 3.4292781352996826, Grad L2 Norm: 0.021556001156568527
2025-11-24 01:40:02.840 | INFO     | __main__:<module>:160 - Step52940, Loss: 3.5656328201293945, Grad L2 Norm: 0.022080902010202408
2025-11-24 01:40:04.554 | INFO     | __main__:<module>:160 - Step52950, Loss: 3.707561492919922, Grad L2 Norm: 0.024151833727955818
2025-11-24 01:40:06.270 | INFO     | __main__:<module>:160 - Step52960, Loss: 3.4386773109436035, Grad L2 Norm: 0.022981200367212296
2025-11-24 01:40:08.006 | INFO     | __main__:<module>:160 - Step52970, Loss: 3.4956777095794678, Grad L2 Norm: 0.022625265643000603
2025-11-24 01:40:09.723 | INFO     | __main__:<module>:160 - Step52980, Loss: 3.320370674133301, Grad L2 Norm: 0.02067391760647297
2025-11-24 01:40:11.449 | INFO     | __main__:<module>:160 - Step52990, Loss: 3.4713096618652344, Grad L2 Norm: 0.022885428741574287
2025-11-24 01:40:13.165 | INFO     | __main__:<module>:160 - Step53000, Loss: 3.5278375148773193, Grad L2 Norm: 0.02206495776772499
2025-11-24 01:40:14.892 | INFO     | __main__:<module>:160 - Step53010, Loss: 3.5846304893493652, Grad L2 Norm: 0.024440422654151917
2025-11-24 01:40:16.617 | INFO     | __main__:<module>:160 - Step53020, Loss: 3.5567855834960938, Grad L2 Norm: 0.02387406677007675
2025-11-24 01:40:18.332 | INFO     | __main__:<module>:160 - Step53030, Loss: 3.5657405853271484, Grad L2 Norm: 0.022913917899131775
2025-11-24 01:40:20.057 | INFO     | __main__:<module>:160 - Step53040, Loss: 3.4628114700317383, Grad L2 Norm: 0.02285650186240673
2025-11-24 01:40:21.772 | INFO     | __main__:<module>:160 - Step53050, Loss: 3.6402745246887207, Grad L2 Norm: 0.025402365252375603
2025-11-24 01:40:23.505 | INFO     | __main__:<module>:160 - Step53060, Loss: 3.472057819366455, Grad L2 Norm: 0.023494048044085503
2025-11-24 01:40:25.224 | INFO     | __main__:<module>:160 - Step53070, Loss: 3.5606038570404053, Grad L2 Norm: 0.022571217268705368
2025-11-24 01:40:26.941 | INFO     | __main__:<module>:160 - Step53080, Loss: 3.6530163288116455, Grad L2 Norm: 0.02421945333480835
2025-11-24 01:40:28.666 | INFO     | __main__:<module>:160 - Step53090, Loss: 3.727825880050659, Grad L2 Norm: 0.024805264547467232
2025-11-24 01:40:30.394 | INFO     | __main__:<module>:160 - Step53100, Loss: 3.4942853450775146, Grad L2 Norm: 0.023417741060256958
2025-11-24 01:40:32.116 | INFO     | __main__:<module>:160 - Step53110, Loss: 3.647679328918457, Grad L2 Norm: 0.024653896689414978
2025-11-24 01:40:33.835 | INFO     | __main__:<module>:160 - Step53120, Loss: 3.48164701461792, Grad L2 Norm: 0.0225620586425066
2025-11-24 01:40:35.549 | INFO     | __main__:<module>:160 - Step53130, Loss: 3.661746025085449, Grad L2 Norm: 0.024999866262078285
2025-11-24 01:40:37.277 | INFO     | __main__:<module>:160 - Step53140, Loss: 3.7189888954162598, Grad L2 Norm: 0.024554241448640823
2025-11-24 01:40:39.001 | INFO     | __main__:<module>:160 - Step53150, Loss: 3.6318135261535645, Grad L2 Norm: 0.023272981867194176
2025-11-24 01:40:40.727 | INFO     | __main__:<module>:160 - Step53160, Loss: 3.6712958812713623, Grad L2 Norm: 0.022995660081505775
2025-11-24 01:40:42.442 | INFO     | __main__:<module>:160 - Step53170, Loss: 3.455327033996582, Grad L2 Norm: 0.0219548512250185
2025-11-24 01:40:44.158 | INFO     | __main__:<module>:160 - Step53180, Loss: 3.768925666809082, Grad L2 Norm: 0.02683097869157791
2025-11-24 01:40:45.894 | INFO     | __main__:<module>:160 - Step53190, Loss: 3.477800130844116, Grad L2 Norm: 0.023963553830981255
2025-11-24 01:40:47.611 | INFO     | __main__:<module>:160 - Step53200, Loss: 3.4301207065582275, Grad L2 Norm: 0.024214960634708405
2025-11-24 01:40:47.611 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:40:48.632 | INFO     | __main__:<module>:181 - validation loss: 3.5770985960960386
2025-11-24 01:40:50.370 | INFO     | __main__:<module>:160 - Step53210, Loss: 3.479875087738037, Grad L2 Norm: 0.0232525747269392
2025-11-24 01:40:52.085 | INFO     | __main__:<module>:160 - Step53220, Loss: 3.5118472576141357, Grad L2 Norm: 0.022200558334589005
2025-11-24 01:40:53.819 | INFO     | __main__:<module>:160 - Step53230, Loss: 3.669124126434326, Grad L2 Norm: 0.024280767887830734
2025-11-24 01:40:55.538 | INFO     | __main__:<module>:160 - Step53240, Loss: 3.6349711418151855, Grad L2 Norm: 0.027637246996164322
2025-11-24 01:40:57.251 | INFO     | __main__:<module>:160 - Step53250, Loss: 3.5616636276245117, Grad L2 Norm: 0.023795664310455322
2025-11-24 01:40:58.977 | INFO     | __main__:<module>:160 - Step53260, Loss: 3.5998501777648926, Grad L2 Norm: 0.025204073637723923
2025-11-24 01:41:00.705 | INFO     | __main__:<module>:160 - Step53270, Loss: 3.478022336959839, Grad L2 Norm: 0.02339436113834381
2025-11-24 01:41:02.427 | INFO     | __main__:<module>:160 - Step53280, Loss: 3.669847011566162, Grad L2 Norm: 0.024787522852420807
2025-11-24 01:41:04.146 | INFO     | __main__:<module>:160 - Step53290, Loss: 3.5554592609405518, Grad L2 Norm: 0.025335662066936493
2025-11-24 01:41:05.861 | INFO     | __main__:<module>:160 - Step53300, Loss: 3.5814318656921387, Grad L2 Norm: 0.022306522354483604
2025-11-24 01:41:07.587 | INFO     | __main__:<module>:160 - Step53310, Loss: 3.6598963737487793, Grad L2 Norm: 0.02352989837527275
2025-11-24 01:41:09.323 | INFO     | __main__:<module>:160 - Step53320, Loss: 3.6484391689300537, Grad L2 Norm: 0.024075619876384735
2025-11-24 01:41:11.049 | INFO     | __main__:<module>:160 - Step53330, Loss: 3.437709331512451, Grad L2 Norm: 0.022989556193351746
2025-11-24 01:41:12.781 | INFO     | __main__:<module>:160 - Step53340, Loss: 3.607193946838379, Grad L2 Norm: 0.024032317101955414
2025-11-24 01:41:14.517 | INFO     | __main__:<module>:160 - Step53350, Loss: 3.6288204193115234, Grad L2 Norm: 0.022175129503011703
2025-11-24 01:41:16.250 | INFO     | __main__:<module>:160 - Step53360, Loss: 3.544926166534424, Grad L2 Norm: 0.02071869559586048
2025-11-24 01:41:17.975 | INFO     | __main__:<module>:160 - Step53370, Loss: 3.542931079864502, Grad L2 Norm: 0.024694329127669334
2025-11-24 01:41:19.697 | INFO     | __main__:<module>:160 - Step53380, Loss: 3.64253568649292, Grad L2 Norm: 0.022803248837590218
2025-11-24 01:41:21.413 | INFO     | __main__:<module>:160 - Step53390, Loss: 3.5417661666870117, Grad L2 Norm: 0.023247869685292244
2025-11-24 01:41:23.144 | INFO     | __main__:<module>:160 - Step53400, Loss: 3.499359607696533, Grad L2 Norm: 0.021456439048051834
2025-11-24 01:41:24.863 | INFO     | __main__:<module>:160 - Step53410, Loss: 3.48363995552063, Grad L2 Norm: 0.023773837834596634
2025-11-24 01:41:26.590 | INFO     | __main__:<module>:160 - Step53420, Loss: 3.578887939453125, Grad L2 Norm: 0.024071302264928818
2025-11-24 01:41:28.318 | INFO     | __main__:<module>:160 - Step53430, Loss: 3.4738035202026367, Grad L2 Norm: 0.021070489659905434
2025-11-24 01:41:30.046 | INFO     | __main__:<module>:160 - Step53440, Loss: 3.437495231628418, Grad L2 Norm: 0.021725142374634743
2025-11-24 01:41:31.784 | INFO     | __main__:<module>:160 - Step53450, Loss: 3.5918216705322266, Grad L2 Norm: 0.022514812648296356
2025-11-24 01:41:33.511 | INFO     | __main__:<module>:160 - Step53460, Loss: 3.450839042663574, Grad L2 Norm: 0.022176844999194145
2025-11-24 01:41:35.247 | INFO     | __main__:<module>:160 - Step53470, Loss: 3.476301431655884, Grad L2 Norm: 0.02252494916319847
2025-11-24 01:41:36.975 | INFO     | __main__:<module>:160 - Step53480, Loss: 3.607517719268799, Grad L2 Norm: 0.023694248870015144
2025-11-24 01:41:38.703 | INFO     | __main__:<module>:160 - Step53490, Loss: 3.5330982208251953, Grad L2 Norm: 0.023309634998440742
2025-11-24 01:41:40.431 | INFO     | __main__:<module>:160 - Step53500, Loss: 3.466794967651367, Grad L2 Norm: 0.023457417264580727
2025-11-24 01:41:42.154 | INFO     | __main__:<module>:160 - Step53510, Loss: 3.5292298793792725, Grad L2 Norm: 0.023541413247585297
2025-11-24 01:41:43.883 | INFO     | __main__:<module>:160 - Step53520, Loss: 3.6431314945220947, Grad L2 Norm: 0.0233868807554245
2025-11-24 01:41:45.607 | INFO     | __main__:<module>:160 - Step53530, Loss: 3.489611864089966, Grad L2 Norm: 0.021209953352808952
2025-11-24 01:41:47.339 | INFO     | __main__:<module>:160 - Step53540, Loss: 3.5925607681274414, Grad L2 Norm: 0.023271063342690468
2025-11-24 01:41:49.065 | INFO     | __main__:<module>:160 - Step53550, Loss: 3.5584311485290527, Grad L2 Norm: 0.024259302765130997
2025-11-24 01:41:50.792 | INFO     | __main__:<module>:160 - Step53560, Loss: 3.762603521347046, Grad L2 Norm: 0.023915208876132965
2025-11-24 01:41:52.508 | INFO     | __main__:<module>:160 - Step53570, Loss: 3.5994114875793457, Grad L2 Norm: 0.02205103076994419
2025-11-24 01:41:54.229 | INFO     | __main__:<module>:160 - Step53580, Loss: 3.6204590797424316, Grad L2 Norm: 0.022792069241404533
2025-11-24 01:41:55.945 | INFO     | __main__:<module>:160 - Step53590, Loss: 3.4504942893981934, Grad L2 Norm: 0.02129833586513996
2025-11-24 01:41:57.662 | INFO     | __main__:<module>:160 - Step53600, Loss: 3.5105512142181396, Grad L2 Norm: 0.021663034334778786
2025-11-24 01:41:57.663 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:41:58.679 | INFO     | __main__:<module>:181 - validation loss: 3.552489721775055
2025-11-24 01:42:00.401 | INFO     | __main__:<module>:160 - Step53610, Loss: 3.408912181854248, Grad L2 Norm: 0.021760601550340652
2025-11-24 01:42:02.116 | INFO     | __main__:<module>:160 - Step53620, Loss: 3.4637885093688965, Grad L2 Norm: 0.02224409580230713
2025-11-24 01:42:03.833 | INFO     | __main__:<module>:160 - Step53630, Loss: 3.6225438117980957, Grad L2 Norm: 0.022683914750814438
2025-11-24 01:42:05.561 | INFO     | __main__:<module>:160 - Step53640, Loss: 3.6054883003234863, Grad L2 Norm: 0.022034576162695885
2025-11-24 01:42:07.275 | INFO     | __main__:<module>:160 - Step53650, Loss: 3.4807662963867188, Grad L2 Norm: 0.02167755924165249
2025-11-24 01:42:09.002 | INFO     | __main__:<module>:160 - Step53660, Loss: 3.6230502128601074, Grad L2 Norm: 0.025045914575457573
2025-11-24 01:42:10.715 | INFO     | __main__:<module>:160 - Step53670, Loss: 3.633016586303711, Grad L2 Norm: 0.024140246212482452
2025-11-24 01:42:12.431 | INFO     | __main__:<module>:160 - Step53680, Loss: 3.5201053619384766, Grad L2 Norm: 0.020998327061533928
2025-11-24 01:42:14.156 | INFO     | __main__:<module>:160 - Step53690, Loss: 3.664435386657715, Grad L2 Norm: 0.023178815841674805
2025-11-24 01:42:15.871 | INFO     | __main__:<module>:160 - Step53700, Loss: 3.563323497772217, Grad L2 Norm: 0.02214326523244381
2025-11-24 01:42:17.597 | INFO     | __main__:<module>:160 - Step53710, Loss: 3.5395796298980713, Grad L2 Norm: 0.021815050393342972
2025-11-24 01:42:19.323 | INFO     | __main__:<module>:160 - Step53720, Loss: 3.5907721519470215, Grad L2 Norm: 0.02447918988764286
2025-11-24 01:42:21.047 | INFO     | __main__:<module>:160 - Step53730, Loss: 3.485170364379883, Grad L2 Norm: 0.021860701963305473
2025-11-24 01:42:22.766 | INFO     | __main__:<module>:160 - Step53740, Loss: 3.5108234882354736, Grad L2 Norm: 0.02217199094593525
2025-11-24 01:42:24.481 | INFO     | __main__:<module>:160 - Step53750, Loss: 3.5844130516052246, Grad L2 Norm: 0.022632163017988205
2025-11-24 01:42:26.216 | INFO     | __main__:<module>:160 - Step53760, Loss: 3.689822196960449, Grad L2 Norm: 0.02446272037923336
2025-11-24 01:42:27.934 | INFO     | __main__:<module>:160 - Step53770, Loss: 3.465165138244629, Grad L2 Norm: 0.023307736963033676
2025-11-24 01:42:29.656 | INFO     | __main__:<module>:160 - Step53780, Loss: 3.5223164558410645, Grad L2 Norm: 0.02263661101460457
2025-11-24 01:42:31.373 | INFO     | __main__:<module>:160 - Step53790, Loss: 3.6211111545562744, Grad L2 Norm: 0.021993406116962433
2025-11-24 01:42:33.101 | INFO     | __main__:<module>:160 - Step53800, Loss: 3.456846237182617, Grad L2 Norm: 0.02239249087870121
2025-11-24 01:42:34.825 | INFO     | __main__:<module>:160 - Step53810, Loss: 3.530212879180908, Grad L2 Norm: 0.021529503166675568
2025-11-24 01:42:36.542 | INFO     | __main__:<module>:160 - Step53820, Loss: 3.734556198120117, Grad L2 Norm: 0.02362527884542942
2025-11-24 01:42:38.268 | INFO     | __main__:<module>:160 - Step53830, Loss: 3.5794568061828613, Grad L2 Norm: 0.02373257651925087
2025-11-24 01:42:39.985 | INFO     | __main__:<module>:160 - Step53840, Loss: 3.572965145111084, Grad L2 Norm: 0.02241060696542263
2025-11-24 01:42:41.709 | INFO     | __main__:<module>:160 - Step53850, Loss: 3.5469791889190674, Grad L2 Norm: 0.023086728528141975
2025-11-24 01:42:43.437 | INFO     | __main__:<module>:160 - Step53860, Loss: 3.656243085861206, Grad L2 Norm: 0.024707864969968796
2025-11-24 01:42:45.151 | INFO     | __main__:<module>:160 - Step53870, Loss: 3.4758286476135254, Grad L2 Norm: 0.022674037143588066
2025-11-24 01:42:46.872 | INFO     | __main__:<module>:160 - Step53880, Loss: 3.324517250061035, Grad L2 Norm: 0.021531328558921814
2025-11-24 01:42:48.602 | INFO     | __main__:<module>:160 - Step53890, Loss: 3.410633087158203, Grad L2 Norm: 0.024153465405106544
2025-11-24 01:42:50.318 | INFO     | __main__:<module>:160 - Step53900, Loss: 3.5226447582244873, Grad L2 Norm: 0.0228357445448637
2025-11-24 01:42:52.045 | INFO     | __main__:<module>:160 - Step53910, Loss: 3.5409491062164307, Grad L2 Norm: 0.024056466296315193
2025-11-24 01:42:53.760 | INFO     | __main__:<module>:160 - Step53920, Loss: 3.6755590438842773, Grad L2 Norm: 0.02314232662320137
2025-11-24 01:42:55.487 | INFO     | __main__:<module>:160 - Step53930, Loss: 3.6288938522338867, Grad L2 Norm: 0.02625308558344841
2025-11-24 01:42:57.212 | INFO     | __main__:<module>:160 - Step53940, Loss: 3.559937000274658, Grad L2 Norm: 0.021586382761597633
2025-11-24 01:42:58.937 | INFO     | __main__:<module>:160 - Step53950, Loss: 3.553112030029297, Grad L2 Norm: 0.022507963702082634
2025-11-24 01:43:00.655 | INFO     | __main__:<module>:160 - Step53960, Loss: 3.772862434387207, Grad L2 Norm: 0.02450825832784176
2025-11-24 01:43:02.373 | INFO     | __main__:<module>:160 - Step53970, Loss: 3.510225534439087, Grad L2 Norm: 0.02227018028497696
2025-11-24 01:43:04.108 | INFO     | __main__:<module>:160 - Step53980, Loss: 3.4540467262268066, Grad L2 Norm: 0.024562176316976547
2025-11-24 01:43:05.822 | INFO     | __main__:<module>:160 - Step53990, Loss: 3.5607151985168457, Grad L2 Norm: 0.022443709895014763
2025-11-24 01:43:07.546 | INFO     | __main__:<module>:160 - Step54000, Loss: 3.552861213684082, Grad L2 Norm: 0.022919129580259323
2025-11-24 01:43:07.547 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:43:08.555 | INFO     | __main__:<module>:181 - validation loss: 3.5373997926712035
2025-11-24 01:43:08.556 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_54000.pt
2025-11-24 01:43:10.278 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 01:43:11.927 | INFO     | __main__:<module>:160 - Step54010, Loss: 3.7317519187927246, Grad L2 Norm: 0.023665331304073334
2025-11-24 01:43:13.647 | INFO     | __main__:<module>:160 - Step54020, Loss: 3.5632190704345703, Grad L2 Norm: 0.023515138775110245
2025-11-24 01:43:15.372 | INFO     | __main__:<module>:160 - Step54030, Loss: 3.5075490474700928, Grad L2 Norm: 0.021620966494083405
2025-11-24 01:43:17.098 | INFO     | __main__:<module>:160 - Step54040, Loss: 3.60038161277771, Grad L2 Norm: 0.023036250844597816
2025-11-24 01:43:18.823 | INFO     | __main__:<module>:160 - Step54050, Loss: 3.6309378147125244, Grad L2 Norm: 0.022389760240912437
2025-11-24 01:43:20.542 | INFO     | __main__:<module>:160 - Step54060, Loss: 3.637559413909912, Grad L2 Norm: 0.022600797936320305
2025-11-24 01:43:22.257 | INFO     | __main__:<module>:160 - Step54070, Loss: 3.532792329788208, Grad L2 Norm: 0.022954361513257027
2025-11-24 01:43:23.986 | INFO     | __main__:<module>:160 - Step54080, Loss: 3.5496692657470703, Grad L2 Norm: 0.022873029112815857
2025-11-24 01:43:25.710 | INFO     | __main__:<module>:160 - Step54090, Loss: 3.555598497390747, Grad L2 Norm: 0.022024080157279968
2025-11-24 01:43:27.439 | INFO     | __main__:<module>:160 - Step54100, Loss: 3.5170698165893555, Grad L2 Norm: 0.02347453683614731
2025-11-24 01:43:29.163 | INFO     | __main__:<module>:160 - Step54110, Loss: 3.618394374847412, Grad L2 Norm: 0.023655718192458153
2025-11-24 01:43:30.892 | INFO     | __main__:<module>:160 - Step54120, Loss: 3.4686057567596436, Grad L2 Norm: 0.023990128189325333
2025-11-24 01:43:32.608 | INFO     | __main__:<module>:160 - Step54130, Loss: 3.5929462909698486, Grad L2 Norm: 0.02297167107462883
2025-11-24 01:43:34.334 | INFO     | __main__:<module>:160 - Step54140, Loss: 3.501107692718506, Grad L2 Norm: 0.022420842200517654
2025-11-24 01:43:36.065 | INFO     | __main__:<module>:160 - Step54150, Loss: 3.483588457107544, Grad L2 Norm: 0.02283870242536068
2025-11-24 01:43:37.786 | INFO     | __main__:<module>:160 - Step54160, Loss: 3.609809398651123, Grad L2 Norm: 0.024401837959885597
2025-11-24 01:43:39.512 | INFO     | __main__:<module>:160 - Step54170, Loss: 3.5788893699645996, Grad L2 Norm: 0.024408865720033646
2025-11-24 01:43:41.230 | INFO     | __main__:<module>:160 - Step54180, Loss: 3.532865285873413, Grad L2 Norm: 0.02320910058915615
2025-11-24 01:43:42.942 | INFO     | __main__:<module>:160 - Step54190, Loss: 3.515972137451172, Grad L2 Norm: 0.02204103022813797
2025-11-24 01:43:44.664 | INFO     | __main__:<module>:160 - Step54200, Loss: 3.620731830596924, Grad L2 Norm: 0.021746722981333733
2025-11-24 01:43:46.383 | INFO     | __main__:<module>:160 - Step54210, Loss: 3.4878525733947754, Grad L2 Norm: 0.022942151874303818
2025-11-24 01:43:48.119 | INFO     | __main__:<module>:160 - Step54220, Loss: 3.402745008468628, Grad L2 Norm: 0.022801216691732407
2025-11-24 01:43:49.847 | INFO     | __main__:<module>:160 - Step54230, Loss: 3.5905134677886963, Grad L2 Norm: 0.02292734570801258
2025-11-24 01:43:51.563 | INFO     | __main__:<module>:160 - Step54240, Loss: 3.6206040382385254, Grad L2 Norm: 0.022818205878138542
2025-11-24 01:43:53.288 | INFO     | __main__:<module>:160 - Step54250, Loss: 3.7093822956085205, Grad L2 Norm: 0.026724301278591156
2025-11-24 01:43:55.001 | INFO     | __main__:<module>:160 - Step54260, Loss: 3.592133045196533, Grad L2 Norm: 0.023260444402694702
2025-11-24 01:43:56.731 | INFO     | __main__:<module>:160 - Step54270, Loss: 3.5982208251953125, Grad L2 Norm: 0.021730968728661537
2025-11-24 01:43:58.443 | INFO     | __main__:<module>:160 - Step54280, Loss: 3.6513452529907227, Grad L2 Norm: 0.022498849779367447
2025-11-24 01:44:00.177 | INFO     | __main__:<module>:160 - Step54290, Loss: 3.5122244358062744, Grad L2 Norm: 0.024920988827943802
2025-11-24 01:44:01.905 | INFO     | __main__:<module>:160 - Step54300, Loss: 3.4728832244873047, Grad L2 Norm: 0.021527905017137527
2025-11-24 01:44:03.624 | INFO     | __main__:<module>:160 - Step54310, Loss: 3.566676616668701, Grad L2 Norm: 0.024176297709345818
2025-11-24 01:44:05.351 | INFO     | __main__:<module>:160 - Step54320, Loss: 3.5470731258392334, Grad L2 Norm: 0.022076671943068504
2025-11-24 01:44:07.067 | INFO     | __main__:<module>:160 - Step54330, Loss: 3.5454635620117188, Grad L2 Norm: 0.02439672313630581
2025-11-24 01:44:08.791 | INFO     | __main__:<module>:160 - Step54340, Loss: 3.6187851428985596, Grad L2 Norm: 0.023268166929483414
2025-11-24 01:44:10.515 | INFO     | __main__:<module>:160 - Step54350, Loss: 3.4972586631774902, Grad L2 Norm: 0.02222009189426899
2025-11-24 01:44:12.234 | INFO     | __main__:<module>:160 - Step54360, Loss: 3.588813304901123, Grad L2 Norm: 0.023915352299809456
2025-11-24 01:44:13.970 | INFO     | __main__:<module>:160 - Step54370, Loss: 3.638820171356201, Grad L2 Norm: 0.024902256205677986
2025-11-24 01:44:15.692 | INFO     | __main__:<module>:160 - Step54380, Loss: 3.6676435470581055, Grad L2 Norm: 0.02399105206131935
2025-11-24 01:44:17.427 | INFO     | __main__:<module>:160 - Step54390, Loss: 3.474435567855835, Grad L2 Norm: 0.02127118594944477
2025-11-24 01:44:19.153 | INFO     | __main__:<module>:160 - Step54400, Loss: 3.4822821617126465, Grad L2 Norm: 0.02256391942501068
2025-11-24 01:44:19.154 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:44:20.171 | INFO     | __main__:<module>:181 - validation loss: 3.5397815823554994
2025-11-24 01:44:21.895 | INFO     | __main__:<module>:160 - Step54410, Loss: 3.61724591255188, Grad L2 Norm: 0.024179818108677864
2025-11-24 01:44:23.615 | INFO     | __main__:<module>:160 - Step54420, Loss: 3.5810861587524414, Grad L2 Norm: 0.022762369364500046
2025-11-24 01:44:25.339 | INFO     | __main__:<module>:160 - Step54430, Loss: 3.4767837524414062, Grad L2 Norm: 0.022870011627674103
2025-11-24 01:44:27.068 | INFO     | __main__:<module>:160 - Step54440, Loss: 3.6737513542175293, Grad L2 Norm: 0.022644540295004845
2025-11-24 01:44:28.803 | INFO     | __main__:<module>:160 - Step54450, Loss: 3.441242218017578, Grad L2 Norm: 0.02284051664173603
2025-11-24 01:44:30.539 | INFO     | __main__:<module>:160 - Step54460, Loss: 3.6062841415405273, Grad L2 Norm: 0.024511100724339485
2025-11-24 01:44:32.275 | INFO     | __main__:<module>:160 - Step54470, Loss: 3.5672755241394043, Grad L2 Norm: 0.02309451624751091
2025-11-24 01:44:34.011 | INFO     | __main__:<module>:160 - Step54480, Loss: 3.604768753051758, Grad L2 Norm: 0.025198016315698624
2025-11-24 01:44:35.747 | INFO     | __main__:<module>:160 - Step54490, Loss: 3.5522522926330566, Grad L2 Norm: 0.024212772026658058
2025-11-24 01:44:37.483 | INFO     | __main__:<module>:160 - Step54500, Loss: 3.7076029777526855, Grad L2 Norm: 0.023390868678689003
2025-11-24 01:44:39.219 | INFO     | __main__:<module>:160 - Step54510, Loss: 3.516356945037842, Grad L2 Norm: 0.021507035940885544
2025-11-24 01:44:40.957 | INFO     | __main__:<module>:160 - Step54520, Loss: 3.657864809036255, Grad L2 Norm: 0.02409469336271286
2025-11-24 01:44:42.694 | INFO     | __main__:<module>:160 - Step54530, Loss: 3.5975611209869385, Grad L2 Norm: 0.023699287325143814
2025-11-24 01:44:44.430 | INFO     | __main__:<module>:160 - Step54540, Loss: 3.5634217262268066, Grad L2 Norm: 0.022779202088713646
2025-11-24 01:44:46.141 | INFO     | __main__:<module>:160 - Step54550, Loss: 3.5634114742279053, Grad L2 Norm: 0.02298274077475071
2025-11-24 01:44:47.827 | INFO     | __main__:<module>:160 - Step54560, Loss: 3.567518711090088, Grad L2 Norm: 0.022541310638189316
2025-11-24 01:44:49.562 | INFO     | __main__:<module>:160 - Step54570, Loss: 3.5796914100646973, Grad L2 Norm: 0.023587210103869438
2025-11-24 01:44:51.276 | INFO     | __main__:<module>:160 - Step54580, Loss: 3.5706698894500732, Grad L2 Norm: 0.022807814180850983
2025-11-24 01:44:52.991 | INFO     | __main__:<module>:160 - Step54590, Loss: 3.4976024627685547, Grad L2 Norm: 0.023274138569831848
2025-11-24 01:44:54.718 | INFO     | __main__:<module>:160 - Step54600, Loss: 3.5658226013183594, Grad L2 Norm: 0.021538376808166504
2025-11-24 01:44:56.433 | INFO     | __main__:<module>:160 - Step54610, Loss: 3.461118698120117, Grad L2 Norm: 0.022429319098591805
2025-11-24 01:44:58.153 | INFO     | __main__:<module>:160 - Step54620, Loss: 3.519808292388916, Grad L2 Norm: 0.022290971130132675
2025-11-24 01:44:59.872 | INFO     | __main__:<module>:160 - Step54630, Loss: 3.417642593383789, Grad L2 Norm: 0.02358129806816578
2025-11-24 01:45:01.586 | INFO     | __main__:<module>:160 - Step54640, Loss: 3.565319538116455, Grad L2 Norm: 0.022449521347880363
2025-11-24 01:45:03.313 | INFO     | __main__:<module>:160 - Step54650, Loss: 3.604578971862793, Grad L2 Norm: 0.021970320492982864
2025-11-24 01:45:05.039 | INFO     | __main__:<module>:160 - Step54660, Loss: 3.6058712005615234, Grad L2 Norm: 0.024671996012330055
2025-11-24 01:45:06.767 | INFO     | __main__:<module>:160 - Step54670, Loss: 3.6033663749694824, Grad L2 Norm: 0.0245527271181345
2025-11-24 01:45:08.480 | INFO     | __main__:<module>:160 - Step54680, Loss: 3.5230321884155273, Grad L2 Norm: 0.0237484909594059
2025-11-24 01:45:10.196 | INFO     | __main__:<module>:160 - Step54690, Loss: 3.638275384902954, Grad L2 Norm: 0.028009066358208656
2025-11-24 01:45:11.931 | INFO     | __main__:<module>:160 - Step54700, Loss: 3.4092466831207275, Grad L2 Norm: 0.023722345009446144
2025-11-24 01:45:13.650 | INFO     | __main__:<module>:160 - Step54710, Loss: 3.5570130348205566, Grad L2 Norm: 0.023021439090371132
2025-11-24 01:45:15.377 | INFO     | __main__:<module>:160 - Step54720, Loss: 3.4909863471984863, Grad L2 Norm: 0.02237812802195549
2025-11-24 01:45:17.099 | INFO     | __main__:<module>:160 - Step54730, Loss: 3.5638651847839355, Grad L2 Norm: 0.021461747586727142
2025-11-24 01:45:18.820 | INFO     | __main__:<module>:160 - Step54740, Loss: 3.5593576431274414, Grad L2 Norm: 0.02241440862417221
2025-11-24 01:45:20.542 | INFO     | __main__:<module>:160 - Step54750, Loss: 3.7509427070617676, Grad L2 Norm: 0.02511429786682129
2025-11-24 01:45:22.259 | INFO     | __main__:<module>:160 - Step54760, Loss: 3.4892077445983887, Grad L2 Norm: 0.02350037731230259
2025-11-24 01:45:23.986 | INFO     | __main__:<module>:160 - Step54770, Loss: 3.5233020782470703, Grad L2 Norm: 0.02370181679725647
2025-11-24 01:45:25.703 | INFO     | __main__:<module>:160 - Step54780, Loss: 3.691763401031494, Grad L2 Norm: 0.023507704958319664
2025-11-24 01:45:27.434 | INFO     | __main__:<module>:160 - Step54790, Loss: 3.5143702030181885, Grad L2 Norm: 0.023856909945607185
2025-11-24 01:45:29.155 | INFO     | __main__:<module>:160 - Step54800, Loss: 3.622619867324829, Grad L2 Norm: 0.023039309307932854
2025-11-24 01:45:29.156 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:45:30.172 | INFO     | __main__:<module>:181 - validation loss: 3.5323822140693664
2025-11-24 01:45:31.897 | INFO     | __main__:<module>:160 - Step54810, Loss: 3.595247268676758, Grad L2 Norm: 0.023189639672636986
2025-11-24 01:45:33.625 | INFO     | __main__:<module>:160 - Step54820, Loss: 3.539354085922241, Grad L2 Norm: 0.02254854515194893
2025-11-24 01:45:35.351 | INFO     | __main__:<module>:160 - Step54830, Loss: 3.4533591270446777, Grad L2 Norm: 0.022324256598949432
2025-11-24 01:45:37.081 | INFO     | __main__:<module>:160 - Step54840, Loss: 3.671557903289795, Grad L2 Norm: 0.02542613446712494
2025-11-24 01:45:38.792 | INFO     | __main__:<module>:160 - Step54850, Loss: 3.799516201019287, Grad L2 Norm: 0.02604130282998085
2025-11-24 01:45:40.517 | INFO     | __main__:<module>:160 - Step54860, Loss: 3.5708961486816406, Grad L2 Norm: 0.022101016715168953
2025-11-24 01:45:42.246 | INFO     | __main__:<module>:160 - Step54870, Loss: 3.636775493621826, Grad L2 Norm: 0.023997977375984192
2025-11-24 01:45:43.961 | INFO     | __main__:<module>:160 - Step54880, Loss: 3.4182183742523193, Grad L2 Norm: 0.022664858028292656
2025-11-24 01:45:45.686 | INFO     | __main__:<module>:160 - Step54890, Loss: 3.429934024810791, Grad L2 Norm: 0.022206760942935944
2025-11-24 01:45:47.401 | INFO     | __main__:<module>:160 - Step54900, Loss: 3.685337781906128, Grad L2 Norm: 0.024274485185742378
2025-11-24 01:45:49.132 | INFO     | __main__:<module>:160 - Step54910, Loss: 3.6273040771484375, Grad L2 Norm: 0.023930564522743225
2025-11-24 01:45:50.854 | INFO     | __main__:<module>:160 - Step54920, Loss: 3.566418409347534, Grad L2 Norm: 0.024276141077280045
2025-11-24 01:45:52.570 | INFO     | __main__:<module>:160 - Step54930, Loss: 3.5090599060058594, Grad L2 Norm: 0.021906306967139244
2025-11-24 01:45:54.295 | INFO     | __main__:<module>:160 - Step54940, Loss: 3.5995006561279297, Grad L2 Norm: 0.023042717948555946
2025-11-24 01:45:56.010 | INFO     | __main__:<module>:160 - Step54950, Loss: 3.602377414703369, Grad L2 Norm: 0.024559736251831055
2025-11-24 01:45:57.745 | INFO     | __main__:<module>:160 - Step54960, Loss: 3.5310134887695312, Grad L2 Norm: 0.023961985483765602
2025-11-24 01:45:59.464 | INFO     | __main__:<module>:160 - Step54970, Loss: 3.602543592453003, Grad L2 Norm: 0.02209245227277279
2025-11-24 01:46:01.178 | INFO     | __main__:<module>:160 - Step54980, Loss: 3.693779945373535, Grad L2 Norm: 0.023929113522171974
2025-11-24 01:46:02.902 | INFO     | __main__:<module>:160 - Step54990, Loss: 3.475922107696533, Grad L2 Norm: 0.022966573014855385
2025-11-24 01:46:04.630 | INFO     | __main__:<module>:160 - Step55000, Loss: 3.5810632705688477, Grad L2 Norm: 0.02464943192899227
2025-11-24 01:46:06.354 | INFO     | __main__:<module>:160 - Step55010, Loss: 3.6784791946411133, Grad L2 Norm: 0.024616185575723648
2025-11-24 01:46:08.084 | INFO     | __main__:<module>:160 - Step55020, Loss: 3.631246566772461, Grad L2 Norm: 0.023522641509771347
2025-11-24 01:46:09.802 | INFO     | __main__:<module>:160 - Step55030, Loss: 3.550917625427246, Grad L2 Norm: 0.022405866533517838
2025-11-24 01:46:11.527 | INFO     | __main__:<module>:160 - Step55040, Loss: 3.5861034393310547, Grad L2 Norm: 0.02308296225965023
2025-11-24 01:46:13.247 | INFO     | __main__:<module>:160 - Step55050, Loss: 3.625300884246826, Grad L2 Norm: 0.02463199570775032
2025-11-24 01:46:14.974 | INFO     | __main__:<module>:160 - Step55060, Loss: 3.5372824668884277, Grad L2 Norm: 0.02261560782790184
2025-11-24 01:46:16.691 | INFO     | __main__:<module>:160 - Step55070, Loss: 3.5744824409484863, Grad L2 Norm: 0.022284742444753647
2025-11-24 01:46:18.417 | INFO     | __main__:<module>:160 - Step55080, Loss: 3.627953052520752, Grad L2 Norm: 0.022428393363952637
2025-11-24 01:46:20.134 | INFO     | __main__:<module>:160 - Step55090, Loss: 3.498990774154663, Grad L2 Norm: 0.024787379428744316
2025-11-24 01:46:21.852 | INFO     | __main__:<module>:160 - Step55100, Loss: 3.545691967010498, Grad L2 Norm: 0.021665826439857483
2025-11-24 01:46:23.587 | INFO     | __main__:<module>:160 - Step55110, Loss: 3.514880657196045, Grad L2 Norm: 0.02221132256090641
2025-11-24 01:46:25.300 | INFO     | __main__:<module>:160 - Step55120, Loss: 3.519963502883911, Grad L2 Norm: 0.024033846333622932
2025-11-24 01:46:27.024 | INFO     | __main__:<module>:160 - Step55130, Loss: 3.5187392234802246, Grad L2 Norm: 0.021847208961844444
2025-11-24 01:46:28.741 | INFO     | __main__:<module>:160 - Step55140, Loss: 3.546588659286499, Grad L2 Norm: 0.022980593144893646
2025-11-24 01:46:30.470 | INFO     | __main__:<module>:160 - Step55150, Loss: 3.54980731010437, Grad L2 Norm: 0.022076938301324844
2025-11-24 01:46:32.207 | INFO     | __main__:<module>:160 - Step55160, Loss: 3.674581527709961, Grad L2 Norm: 0.02322027087211609
2025-11-24 01:46:33.943 | INFO     | __main__:<module>:160 - Step55170, Loss: 3.5342650413513184, Grad L2 Norm: 0.020603643730282784
2025-11-24 01:46:35.679 | INFO     | __main__:<module>:160 - Step55180, Loss: 3.5369367599487305, Grad L2 Norm: 0.022999435663223267
2025-11-24 01:46:37.415 | INFO     | __main__:<module>:160 - Step55190, Loss: 3.4921114444732666, Grad L2 Norm: 0.022441459819674492
2025-11-24 01:46:39.150 | INFO     | __main__:<module>:160 - Step55200, Loss: 3.5897021293640137, Grad L2 Norm: 0.02212175354361534
2025-11-24 01:46:39.151 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:46:40.169 | INFO     | __main__:<module>:181 - validation loss: 3.575550353527069
2025-11-24 01:46:41.884 | INFO     | __main__:<module>:160 - Step55210, Loss: 3.482814073562622, Grad L2 Norm: 0.021544309332966805
2025-11-24 01:46:43.620 | INFO     | __main__:<module>:160 - Step55220, Loss: 3.484877586364746, Grad L2 Norm: 0.023429708555340767
2025-11-24 01:46:45.356 | INFO     | __main__:<module>:160 - Step55230, Loss: 3.567087173461914, Grad L2 Norm: 0.02370232716202736
2025-11-24 01:46:47.093 | INFO     | __main__:<module>:160 - Step55240, Loss: 3.5908689498901367, Grad L2 Norm: 0.02435930259525776
2025-11-24 01:46:48.830 | INFO     | __main__:<module>:160 - Step55250, Loss: 3.614441394805908, Grad L2 Norm: 0.02526138350367546
2025-11-24 01:46:50.565 | INFO     | __main__:<module>:160 - Step55260, Loss: 3.574774742126465, Grad L2 Norm: 0.022617146372795105
2025-11-24 01:46:52.301 | INFO     | __main__:<module>:160 - Step55270, Loss: 3.5989129543304443, Grad L2 Norm: 0.02410127967596054
2025-11-24 01:46:54.038 | INFO     | __main__:<module>:160 - Step55280, Loss: 3.665444850921631, Grad L2 Norm: 0.02278776466846466
2025-11-24 01:46:55.778 | INFO     | __main__:<module>:160 - Step55290, Loss: 3.6298792362213135, Grad L2 Norm: 0.023674048483371735
2025-11-24 01:46:57.503 | INFO     | __main__:<module>:160 - Step55300, Loss: 3.4636402130126953, Grad L2 Norm: 0.02169015444815159
2025-11-24 01:46:59.238 | INFO     | __main__:<module>:160 - Step55310, Loss: 3.5946972370147705, Grad L2 Norm: 0.02317817136645317
2025-11-24 01:47:00.973 | INFO     | __main__:<module>:160 - Step55320, Loss: 3.5991249084472656, Grad L2 Norm: 0.021870454773306847
2025-11-24 01:47:02.709 | INFO     | __main__:<module>:160 - Step55330, Loss: 3.5233688354492188, Grad L2 Norm: 0.023043612018227577
2025-11-24 01:47:04.440 | INFO     | __main__:<module>:160 - Step55340, Loss: 3.7273776531219482, Grad L2 Norm: 0.024720823392271996
2025-11-24 01:47:06.168 | INFO     | __main__:<module>:160 - Step55350, Loss: 3.460866928100586, Grad L2 Norm: 0.021619895473122597
2025-11-24 01:47:07.885 | INFO     | __main__:<module>:160 - Step55360, Loss: 3.457308292388916, Grad L2 Norm: 0.02079811319708824
2025-11-24 01:47:09.619 | INFO     | __main__:<module>:160 - Step55370, Loss: 3.5493252277374268, Grad L2 Norm: 0.023953551426529884
2025-11-24 01:47:11.294 | INFO     | __main__:<module>:160 - Step55380, Loss: 3.5244193077087402, Grad L2 Norm: 0.02311023324728012
2025-11-24 01:47:13.030 | INFO     | __main__:<module>:160 - Step55390, Loss: 3.6257972717285156, Grad L2 Norm: 0.02232980728149414
2025-11-24 01:47:14.764 | INFO     | __main__:<module>:160 - Step55400, Loss: 3.5040760040283203, Grad L2 Norm: 0.02403753623366356
2025-11-24 01:47:16.500 | INFO     | __main__:<module>:160 - Step55410, Loss: 3.5916028022766113, Grad L2 Norm: 0.023697590455412865
2025-11-24 01:47:18.234 | INFO     | __main__:<module>:160 - Step55420, Loss: 3.4713728427886963, Grad L2 Norm: 0.023688865825533867
2025-11-24 01:47:19.953 | INFO     | __main__:<module>:160 - Step55430, Loss: 3.50059175491333, Grad L2 Norm: 0.02372075617313385
2025-11-24 01:47:21.671 | INFO     | __main__:<module>:160 - Step55440, Loss: 3.5877480506896973, Grad L2 Norm: 0.022555261850357056
2025-11-24 01:47:23.396 | INFO     | __main__:<module>:160 - Step55450, Loss: 3.529691219329834, Grad L2 Norm: 0.023471202701330185
2025-11-24 01:47:25.118 | INFO     | __main__:<module>:160 - Step55460, Loss: 3.683145761489868, Grad L2 Norm: 0.024227891117334366
2025-11-24 01:47:26.847 | INFO     | __main__:<module>:160 - Step55470, Loss: 3.6244335174560547, Grad L2 Norm: 0.022867422550916672
2025-11-24 01:47:28.571 | INFO     | __main__:<module>:160 - Step55480, Loss: 3.4279537200927734, Grad L2 Norm: 0.02185196988284588
2025-11-24 01:47:30.298 | INFO     | __main__:<module>:160 - Step55490, Loss: 3.6099133491516113, Grad L2 Norm: 0.025673506781458855
2025-11-24 01:47:32.022 | INFO     | __main__:<module>:160 - Step55500, Loss: 3.4893851280212402, Grad L2 Norm: 0.023855820298194885
2025-11-24 01:47:33.749 | INFO     | __main__:<module>:160 - Step55510, Loss: 3.4306530952453613, Grad L2 Norm: 0.021878425031900406
2025-11-24 01:47:35.473 | INFO     | __main__:<module>:160 - Step55520, Loss: 3.6841013431549072, Grad L2 Norm: 0.02273457497358322
2025-11-24 01:47:37.203 | INFO     | __main__:<module>:160 - Step55530, Loss: 3.545138120651245, Grad L2 Norm: 0.024064581841230392
2025-11-24 01:47:38.924 | INFO     | __main__:<module>:160 - Step55540, Loss: 3.5362720489501953, Grad L2 Norm: 0.022884389385581017
2025-11-24 01:47:40.642 | INFO     | __main__:<module>:160 - Step55550, Loss: 3.5300283432006836, Grad L2 Norm: 0.023000897839665413
2025-11-24 01:47:42.357 | INFO     | __main__:<module>:160 - Step55560, Loss: 3.4949684143066406, Grad L2 Norm: 0.023875683546066284
2025-11-24 01:47:44.085 | INFO     | __main__:<module>:160 - Step55570, Loss: 3.554698944091797, Grad L2 Norm: 0.02197127975523472
2025-11-24 01:47:45.810 | INFO     | __main__:<module>:160 - Step55580, Loss: 3.644706964492798, Grad L2 Norm: 0.02413734421133995
2025-11-24 01:47:47.537 | INFO     | __main__:<module>:160 - Step55590, Loss: 3.466094970703125, Grad L2 Norm: 0.022580072283744812
2025-11-24 01:47:49.251 | INFO     | __main__:<module>:160 - Step55600, Loss: 3.5438733100891113, Grad L2 Norm: 0.022579021751880646
2025-11-24 01:47:49.252 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:47:50.269 | INFO     | __main__:<module>:181 - validation loss: 3.524360167980194
2025-11-24 01:47:51.985 | INFO     | __main__:<module>:160 - Step55610, Loss: 3.4723455905914307, Grad L2 Norm: 0.023372715339064598
2025-11-24 01:47:53.709 | INFO     | __main__:<module>:160 - Step55620, Loss: 3.5165629386901855, Grad L2 Norm: 0.02246277779340744
2025-11-24 01:47:55.426 | INFO     | __main__:<module>:160 - Step55630, Loss: 3.5687179565429688, Grad L2 Norm: 0.022209273651242256
2025-11-24 01:47:57.150 | INFO     | __main__:<module>:160 - Step55640, Loss: 3.562911033630371, Grad L2 Norm: 0.022739853709936142
2025-11-24 01:47:58.867 | INFO     | __main__:<module>:160 - Step55650, Loss: 3.476999282836914, Grad L2 Norm: 0.021843571215867996
2025-11-24 01:48:00.585 | INFO     | __main__:<module>:160 - Step55660, Loss: 3.511240243911743, Grad L2 Norm: 0.02308804728090763
2025-11-24 01:48:02.313 | INFO     | __main__:<module>:160 - Step55670, Loss: 3.532566547393799, Grad L2 Norm: 0.02340671420097351
2025-11-24 01:48:04.022 | INFO     | __main__:<module>:160 - Step55680, Loss: 3.566701889038086, Grad L2 Norm: 0.025224337354302406
2025-11-24 01:48:05.745 | INFO     | __main__:<module>:160 - Step55690, Loss: 3.456118106842041, Grad L2 Norm: 0.021337509155273438
2025-11-24 01:48:07.464 | INFO     | __main__:<module>:160 - Step55700, Loss: 3.6047024726867676, Grad L2 Norm: 0.022210542112588882
2025-11-24 01:48:09.189 | INFO     | __main__:<module>:160 - Step55710, Loss: 3.5369229316711426, Grad L2 Norm: 0.024953171610832214
2025-11-24 01:48:10.918 | INFO     | __main__:<module>:160 - Step55720, Loss: 3.59236216545105, Grad L2 Norm: 0.023171503096818924
2025-11-24 01:48:12.631 | INFO     | __main__:<module>:160 - Step55730, Loss: 3.595294952392578, Grad L2 Norm: 0.021468140184879303
2025-11-24 01:48:14.352 | INFO     | __main__:<module>:160 - Step55740, Loss: 3.4637691974639893, Grad L2 Norm: 0.02176266722381115
2025-11-24 01:48:16.081 | INFO     | __main__:<module>:160 - Step55750, Loss: 3.5127949714660645, Grad L2 Norm: 0.022762615233659744
2025-11-24 01:48:17.798 | INFO     | __main__:<module>:160 - Step55760, Loss: 3.478036403656006, Grad L2 Norm: 0.02373039536178112
2025-11-24 01:48:19.523 | INFO     | __main__:<module>:160 - Step55770, Loss: 3.4496703147888184, Grad L2 Norm: 0.022229675203561783
2025-11-24 01:48:21.238 | INFO     | __main__:<module>:160 - Step55780, Loss: 3.5784754753112793, Grad L2 Norm: 0.02251037210226059
2025-11-24 01:48:22.965 | INFO     | __main__:<module>:160 - Step55790, Loss: 3.5208663940429688, Grad L2 Norm: 0.021805284544825554
2025-11-24 01:48:24.690 | INFO     | __main__:<module>:160 - Step55800, Loss: 3.580601453781128, Grad L2 Norm: 0.02214912511408329
2025-11-24 01:48:26.415 | INFO     | __main__:<module>:160 - Step55810, Loss: 3.4484472274780273, Grad L2 Norm: 0.023587817326188087
2025-11-24 01:48:28.132 | INFO     | __main__:<module>:160 - Step55820, Loss: 3.4818356037139893, Grad L2 Norm: 0.023182298988103867
2025-11-24 01:48:29.848 | INFO     | __main__:<module>:160 - Step55830, Loss: 3.551870822906494, Grad L2 Norm: 0.02324320375919342
2025-11-24 01:48:31.583 | INFO     | __main__:<module>:160 - Step55840, Loss: 3.6432433128356934, Grad L2 Norm: 0.027305297553539276
2025-11-24 01:48:33.303 | INFO     | __main__:<module>:160 - Step55850, Loss: 3.5442862510681152, Grad L2 Norm: 0.02448183484375477
2025-11-24 01:48:35.026 | INFO     | __main__:<module>:160 - Step55860, Loss: 3.6438798904418945, Grad L2 Norm: 0.02220734767615795
2025-11-24 01:48:36.740 | INFO     | __main__:<module>:160 - Step55870, Loss: 3.6025052070617676, Grad L2 Norm: 0.022666798904538155
2025-11-24 01:48:38.467 | INFO     | __main__:<module>:160 - Step55880, Loss: 3.6705667972564697, Grad L2 Norm: 0.023578766733407974
2025-11-24 01:48:40.192 | INFO     | __main__:<module>:160 - Step55890, Loss: 3.496739625930786, Grad L2 Norm: 0.022973142564296722
2025-11-24 01:48:41.909 | INFO     | __main__:<module>:160 - Step55900, Loss: 3.606074094772339, Grad L2 Norm: 0.024096325039863586
2025-11-24 01:48:43.635 | INFO     | __main__:<module>:160 - Step55910, Loss: 3.5558366775512695, Grad L2 Norm: 0.021947873756289482
2025-11-24 01:48:45.351 | INFO     | __main__:<module>:160 - Step55920, Loss: 3.5952868461608887, Grad L2 Norm: 0.023181241005659103
2025-11-24 01:48:47.076 | INFO     | __main__:<module>:160 - Step55930, Loss: 3.5582189559936523, Grad L2 Norm: 0.023517288267612457
2025-11-24 01:48:48.803 | INFO     | __main__:<module>:160 - Step55940, Loss: 3.6551156044006348, Grad L2 Norm: 0.023211559280753136
2025-11-24 01:48:50.518 | INFO     | __main__:<module>:160 - Step55950, Loss: 3.6796200275421143, Grad L2 Norm: 0.02335381507873535
2025-11-24 01:48:52.241 | INFO     | __main__:<module>:160 - Step55960, Loss: 3.624678611755371, Grad L2 Norm: 0.02440938912332058
2025-11-24 01:48:53.969 | INFO     | __main__:<module>:160 - Step55970, Loss: 3.5646989345550537, Grad L2 Norm: 0.022559475153684616
2025-11-24 01:48:55.685 | INFO     | __main__:<module>:160 - Step55980, Loss: 3.6395230293273926, Grad L2 Norm: 0.021901791915297508
2025-11-24 01:48:57.412 | INFO     | __main__:<module>:160 - Step55990, Loss: 3.580824136734009, Grad L2 Norm: 0.02192968875169754
2025-11-24 01:48:59.126 | INFO     | __main__:<module>:160 - Step56000, Loss: 3.6574649810791016, Grad L2 Norm: 0.024696193635463715
2025-11-24 01:48:59.127 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:49:00.143 | INFO     | __main__:<module>:181 - validation loss: 3.5526432275772093
2025-11-24 01:49:00.144 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_56000.pt
2025-11-24 01:49:01.854 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 01:49:03.570 | INFO     | __main__:<module>:160 - Step56010, Loss: 3.5670228004455566, Grad L2 Norm: 0.021426985040307045
2025-11-24 01:49:05.287 | INFO     | __main__:<module>:160 - Step56020, Loss: 3.6004109382629395, Grad L2 Norm: 0.022322101518511772
2025-11-24 01:49:07.015 | INFO     | __main__:<module>:160 - Step56030, Loss: 3.536745548248291, Grad L2 Norm: 0.022573934867978096
2025-11-24 01:49:08.730 | INFO     | __main__:<module>:160 - Step56040, Loss: 3.6028852462768555, Grad L2 Norm: 0.027418481186032295
2025-11-24 01:49:10.463 | INFO     | __main__:<module>:160 - Step56050, Loss: 3.559630870819092, Grad L2 Norm: 0.021756570786237717
2025-11-24 01:49:12.182 | INFO     | __main__:<module>:160 - Step56060, Loss: 3.5498194694519043, Grad L2 Norm: 0.02372124418616295
2025-11-24 01:49:13.897 | INFO     | __main__:<module>:160 - Step56070, Loss: 3.462867259979248, Grad L2 Norm: 0.022623471915721893
2025-11-24 01:49:15.623 | INFO     | __main__:<module>:160 - Step56080, Loss: 3.4990057945251465, Grad L2 Norm: 0.02340678684413433
2025-11-24 01:49:17.350 | INFO     | __main__:<module>:160 - Step56090, Loss: 3.540132999420166, Grad L2 Norm: 0.0249343104660511
2025-11-24 01:49:19.087 | INFO     | __main__:<module>:160 - Step56100, Loss: 3.511326313018799, Grad L2 Norm: 0.023886533454060555
2025-11-24 01:49:20.813 | INFO     | __main__:<module>:160 - Step56110, Loss: 3.5306694507598877, Grad L2 Norm: 0.021159937605261803
2025-11-24 01:49:22.541 | INFO     | __main__:<module>:160 - Step56120, Loss: 3.440662384033203, Grad L2 Norm: 0.026758087798953056
2025-11-24 01:49:24.268 | INFO     | __main__:<module>:160 - Step56130, Loss: 3.6520450115203857, Grad L2 Norm: 0.02556229755282402
2025-11-24 01:49:25.983 | INFO     | __main__:<module>:160 - Step56140, Loss: 3.527921438217163, Grad L2 Norm: 0.023044513538479805
2025-11-24 01:49:27.710 | INFO     | __main__:<module>:160 - Step56150, Loss: 3.5362396240234375, Grad L2 Norm: 0.023586129769682884
2025-11-24 01:49:29.435 | INFO     | __main__:<module>:160 - Step56160, Loss: 3.5057263374328613, Grad L2 Norm: 0.023307735100388527
2025-11-24 01:49:31.163 | INFO     | __main__:<module>:160 - Step56170, Loss: 3.579801082611084, Grad L2 Norm: 0.0233051385730505
2025-11-24 01:49:32.889 | INFO     | __main__:<module>:160 - Step56180, Loss: 3.5333051681518555, Grad L2 Norm: 0.022686997428536415
2025-11-24 01:49:34.617 | INFO     | __main__:<module>:160 - Step56190, Loss: 3.5357656478881836, Grad L2 Norm: 0.02325482666492462
2025-11-24 01:49:36.334 | INFO     | __main__:<module>:160 - Step56200, Loss: 3.7173874378204346, Grad L2 Norm: 0.02444741502404213
2025-11-24 01:49:38.059 | INFO     | __main__:<module>:160 - Step56210, Loss: 3.5328598022460938, Grad L2 Norm: 0.022145487368106842
2025-11-24 01:49:39.789 | INFO     | __main__:<module>:160 - Step56220, Loss: 3.4566800594329834, Grad L2 Norm: 0.022020919248461723
2025-11-24 01:49:41.500 | INFO     | __main__:<module>:160 - Step56230, Loss: 3.5666253566741943, Grad L2 Norm: 0.022104082629084587
2025-11-24 01:49:43.223 | INFO     | __main__:<module>:160 - Step56240, Loss: 3.7264652252197266, Grad L2 Norm: 0.024048922583460808
2025-11-24 01:49:44.939 | INFO     | __main__:<module>:160 - Step56250, Loss: 3.5245983600616455, Grad L2 Norm: 0.023398105055093765
2025-11-24 01:49:46.669 | INFO     | __main__:<module>:160 - Step56260, Loss: 3.642469882965088, Grad L2 Norm: 0.02180520072579384
2025-11-24 01:49:48.405 | INFO     | __main__:<module>:160 - Step56270, Loss: 3.599454641342163, Grad L2 Norm: 0.022927606478333473
2025-11-24 01:49:50.125 | INFO     | __main__:<module>:160 - Step56280, Loss: 3.6528196334838867, Grad L2 Norm: 0.02579847164452076
2025-11-24 01:49:51.860 | INFO     | __main__:<module>:160 - Step56290, Loss: 3.48427152633667, Grad L2 Norm: 0.02167852595448494
2025-11-24 01:49:53.576 | INFO     | __main__:<module>:160 - Step56300, Loss: 3.3839540481567383, Grad L2 Norm: 0.02027297019958496
2025-11-24 01:49:55.290 | INFO     | __main__:<module>:160 - Step56310, Loss: 3.4776852130889893, Grad L2 Norm: 0.02263891138136387
2025-11-24 01:49:57.015 | INFO     | __main__:<module>:160 - Step56320, Loss: 3.6059863567352295, Grad L2 Norm: 0.023367850109934807
2025-11-24 01:49:58.731 | INFO     | __main__:<module>:160 - Step56330, Loss: 3.5277392864227295, Grad L2 Norm: 0.022200947627425194
2025-11-24 01:50:00.457 | INFO     | __main__:<module>:160 - Step56340, Loss: 3.6264657974243164, Grad L2 Norm: 0.022832388058304787
2025-11-24 01:50:02.169 | INFO     | __main__:<module>:160 - Step56350, Loss: 3.4965438842773438, Grad L2 Norm: 0.02109549008309841
2025-11-24 01:50:03.884 | INFO     | __main__:<module>:160 - Step56360, Loss: 3.563904285430908, Grad L2 Norm: 0.022885620594024658
2025-11-24 01:50:05.609 | INFO     | __main__:<module>:160 - Step56370, Loss: 3.5311977863311768, Grad L2 Norm: 0.024220936000347137
2025-11-24 01:50:07.324 | INFO     | __main__:<module>:160 - Step56380, Loss: 3.55253267288208, Grad L2 Norm: 0.02147517539560795
2025-11-24 01:50:09.053 | INFO     | __main__:<module>:160 - Step56390, Loss: 3.6533374786376953, Grad L2 Norm: 0.023098990321159363
2025-11-24 01:50:10.777 | INFO     | __main__:<module>:160 - Step56400, Loss: 3.5103182792663574, Grad L2 Norm: 0.022282257676124573
2025-11-24 01:50:10.778 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:50:11.800 | INFO     | __main__:<module>:181 - validation loss: 3.559316396713257
2025-11-24 01:50:13.494 | INFO     | __main__:<module>:160 - Step56410, Loss: 3.4538049697875977, Grad L2 Norm: 0.02521892450749874
2025-11-24 01:50:15.222 | INFO     | __main__:<module>:160 - Step56420, Loss: 3.589794158935547, Grad L2 Norm: 0.02680014632642269
2025-11-24 01:50:16.939 | INFO     | __main__:<module>:160 - Step56430, Loss: 3.542879581451416, Grad L2 Norm: 0.024549851194024086
2025-11-24 01:50:18.663 | INFO     | __main__:<module>:160 - Step56440, Loss: 3.516502857208252, Grad L2 Norm: 0.022112330421805382
2025-11-24 01:50:20.381 | INFO     | __main__:<module>:160 - Step56450, Loss: 3.5341219902038574, Grad L2 Norm: 0.022787855938076973
2025-11-24 01:50:22.096 | INFO     | __main__:<module>:160 - Step56460, Loss: 3.626422882080078, Grad L2 Norm: 0.02350722812116146
2025-11-24 01:50:23.822 | INFO     | __main__:<module>:160 - Step56470, Loss: 3.618067502975464, Grad L2 Norm: 0.023579303175210953
2025-11-24 01:50:25.547 | INFO     | __main__:<module>:160 - Step56480, Loss: 3.495204210281372, Grad L2 Norm: 0.02456657588481903
2025-11-24 01:50:27.282 | INFO     | __main__:<module>:160 - Step56490, Loss: 3.524268627166748, Grad L2 Norm: 0.021655043587088585
2025-11-24 01:50:28.989 | INFO     | __main__:<module>:160 - Step56500, Loss: 3.6535122394561768, Grad L2 Norm: 0.021994933485984802
2025-11-24 01:50:30.703 | INFO     | __main__:<module>:160 - Step56510, Loss: 3.5580573081970215, Grad L2 Norm: 0.02177014946937561
2025-11-24 01:50:32.429 | INFO     | __main__:<module>:160 - Step56520, Loss: 3.5710906982421875, Grad L2 Norm: 0.023799246177077293
2025-11-24 01:50:34.155 | INFO     | __main__:<module>:160 - Step56530, Loss: 3.5860939025878906, Grad L2 Norm: 0.022316185757517815
2025-11-24 01:50:35.883 | INFO     | __main__:<module>:160 - Step56540, Loss: 3.5532281398773193, Grad L2 Norm: 0.022725079208612442
2025-11-24 01:50:37.598 | INFO     | __main__:<module>:160 - Step56550, Loss: 3.4758379459381104, Grad L2 Norm: 0.02204292267560959
2025-11-24 01:50:39.333 | INFO     | __main__:<module>:160 - Step56560, Loss: 3.5248544216156006, Grad L2 Norm: 0.023774528875947
2025-11-24 01:50:41.052 | INFO     | __main__:<module>:160 - Step56570, Loss: 3.548532485961914, Grad L2 Norm: 0.02292083203792572
2025-11-24 01:50:42.767 | INFO     | __main__:<module>:160 - Step56580, Loss: 3.424130916595459, Grad L2 Norm: 0.022453879937529564
2025-11-24 01:50:44.492 | INFO     | __main__:<module>:160 - Step56590, Loss: 3.607909679412842, Grad L2 Norm: 0.02257583662867546
2025-11-24 01:50:46.208 | INFO     | __main__:<module>:160 - Step56600, Loss: 3.525247097015381, Grad L2 Norm: 0.02175247110426426
2025-11-24 01:50:47.934 | INFO     | __main__:<module>:160 - Step56610, Loss: 3.606743812561035, Grad L2 Norm: 0.0217747800052166
2025-11-24 01:50:49.657 | INFO     | __main__:<module>:160 - Step56620, Loss: 3.7118935585021973, Grad L2 Norm: 0.02352561429142952
2025-11-24 01:50:51.374 | INFO     | __main__:<module>:160 - Step56630, Loss: 3.7251322269439697, Grad L2 Norm: 0.024337105453014374
2025-11-24 01:50:53.100 | INFO     | __main__:<module>:160 - Step56640, Loss: 3.587934732437134, Grad L2 Norm: 0.021481594070792198
2025-11-24 01:50:54.814 | INFO     | __main__:<module>:160 - Step56650, Loss: 3.6018013954162598, Grad L2 Norm: 0.022772980853915215
2025-11-24 01:50:56.548 | INFO     | __main__:<module>:160 - Step56660, Loss: 3.476822853088379, Grad L2 Norm: 0.02273024432361126
2025-11-24 01:50:58.268 | INFO     | __main__:<module>:160 - Step56670, Loss: 3.514667272567749, Grad L2 Norm: 0.021705016493797302
2025-11-24 01:50:59.984 | INFO     | __main__:<module>:160 - Step56680, Loss: 3.6603851318359375, Grad L2 Norm: 0.02307303063571453
2025-11-24 01:51:01.707 | INFO     | __main__:<module>:160 - Step56690, Loss: 3.5076630115509033, Grad L2 Norm: 0.025112200528383255
2025-11-24 01:51:03.434 | INFO     | __main__:<module>:160 - Step56700, Loss: 3.669466733932495, Grad L2 Norm: 0.02231815829873085
2025-11-24 01:51:05.157 | INFO     | __main__:<module>:160 - Step56710, Loss: 3.449032783508301, Grad L2 Norm: 0.02166215516626835
2025-11-24 01:51:06.876 | INFO     | __main__:<module>:160 - Step56720, Loss: 3.552555561065674, Grad L2 Norm: 0.022398047149181366
2025-11-24 01:51:08.591 | INFO     | __main__:<module>:160 - Step56730, Loss: 3.6178159713745117, Grad L2 Norm: 0.023510152474045753
2025-11-24 01:51:10.319 | INFO     | __main__:<module>:160 - Step56740, Loss: 3.528731346130371, Grad L2 Norm: 0.02137300930917263
2025-11-24 01:51:12.044 | INFO     | __main__:<module>:160 - Step56750, Loss: 3.6236863136291504, Grad L2 Norm: 0.022494308650493622
2025-11-24 01:51:13.770 | INFO     | __main__:<module>:160 - Step56760, Loss: 3.6704211235046387, Grad L2 Norm: 0.023821724578738213
2025-11-24 01:51:15.485 | INFO     | __main__:<module>:160 - Step56770, Loss: 3.617671012878418, Grad L2 Norm: 0.022314848378300667
2025-11-24 01:51:17.200 | INFO     | __main__:<module>:160 - Step56780, Loss: 3.5298550128936768, Grad L2 Norm: 0.023030487820506096
2025-11-24 01:51:18.937 | INFO     | __main__:<module>:160 - Step56790, Loss: 3.6057991981506348, Grad L2 Norm: 0.02444719523191452
2025-11-24 01:51:20.655 | INFO     | __main__:<module>:160 - Step56800, Loss: 3.3844122886657715, Grad L2 Norm: 0.024462468922138214
2025-11-24 01:51:20.656 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:51:21.673 | INFO     | __main__:<module>:181 - validation loss: 3.5500957369804382
2025-11-24 01:51:23.407 | INFO     | __main__:<module>:160 - Step56810, Loss: 3.382404327392578, Grad L2 Norm: 0.024225376546382904
2025-11-24 01:51:25.124 | INFO     | __main__:<module>:160 - Step56820, Loss: 3.5325136184692383, Grad L2 Norm: 0.0236735288053751
2025-11-24 01:51:26.858 | INFO     | __main__:<module>:160 - Step56830, Loss: 3.6344382762908936, Grad L2 Norm: 0.02339901030063629
2025-11-24 01:51:28.581 | INFO     | __main__:<module>:160 - Step56840, Loss: 3.5846705436706543, Grad L2 Norm: 0.023789651691913605
2025-11-24 01:51:30.294 | INFO     | __main__:<module>:160 - Step56850, Loss: 3.5059986114501953, Grad L2 Norm: 0.02148902229964733
2025-11-24 01:51:32.018 | INFO     | __main__:<module>:160 - Step56860, Loss: 3.6692569255828857, Grad L2 Norm: 0.024156861007213593
2025-11-24 01:51:33.745 | INFO     | __main__:<module>:160 - Step56870, Loss: 3.503303289413452, Grad L2 Norm: 0.020900549367070198
2025-11-24 01:51:35.467 | INFO     | __main__:<module>:160 - Step56880, Loss: 3.6270692348480225, Grad L2 Norm: 0.02386181242763996
2025-11-24 01:51:37.185 | INFO     | __main__:<module>:160 - Step56890, Loss: 3.4703011512756348, Grad L2 Norm: 0.022730888798832893
2025-11-24 01:51:38.901 | INFO     | __main__:<module>:160 - Step56900, Loss: 3.6244120597839355, Grad L2 Norm: 0.022530561313033104
2025-11-24 01:51:40.627 | INFO     | __main__:<module>:160 - Step56910, Loss: 3.489030599594116, Grad L2 Norm: 0.02203940972685814
2025-11-24 01:51:42.353 | INFO     | __main__:<module>:160 - Step56920, Loss: 3.595550060272217, Grad L2 Norm: 0.02318667434155941
2025-11-24 01:51:44.081 | INFO     | __main__:<module>:160 - Step56930, Loss: 3.533691644668579, Grad L2 Norm: 0.021614722907543182
2025-11-24 01:51:45.795 | INFO     | __main__:<module>:160 - Step56940, Loss: 3.6126887798309326, Grad L2 Norm: 0.02516629546880722
2025-11-24 01:51:47.511 | INFO     | __main__:<module>:160 - Step56950, Loss: 3.515436887741089, Grad L2 Norm: 0.023356568068265915
2025-11-24 01:51:49.246 | INFO     | __main__:<module>:160 - Step56960, Loss: 3.6597366333007812, Grad L2 Norm: 0.02368410862982273
2025-11-24 01:51:50.963 | INFO     | __main__:<module>:160 - Step56970, Loss: 3.5943539142608643, Grad L2 Norm: 0.02594284899532795
2025-11-24 01:51:52.690 | INFO     | __main__:<module>:160 - Step56980, Loss: 3.4999332427978516, Grad L2 Norm: 0.022837789729237556
2025-11-24 01:51:54.404 | INFO     | __main__:<module>:160 - Step56990, Loss: 3.5482921600341797, Grad L2 Norm: 0.024465225636959076
2025-11-24 01:51:56.131 | INFO     | __main__:<module>:160 - Step57000, Loss: 3.5224900245666504, Grad L2 Norm: 0.022815505042672157
2025-11-24 01:51:57.855 | INFO     | __main__:<module>:160 - Step57010, Loss: 3.5669121742248535, Grad L2 Norm: 0.02287326194345951
2025-11-24 01:51:59.570 | INFO     | __main__:<module>:160 - Step57020, Loss: 3.5465264320373535, Grad L2 Norm: 0.025362523272633553
2025-11-24 01:52:01.299 | INFO     | __main__:<module>:160 - Step57030, Loss: 3.5480685234069824, Grad L2 Norm: 0.02265009842813015
2025-11-24 01:52:03.015 | INFO     | __main__:<module>:160 - Step57040, Loss: 3.6426010131835938, Grad L2 Norm: 0.023218505084514618
2025-11-24 01:52:04.748 | INFO     | __main__:<module>:160 - Step57050, Loss: 3.500715494155884, Grad L2 Norm: 0.023232560604810715
2025-11-24 01:52:06.466 | INFO     | __main__:<module>:160 - Step57060, Loss: 3.691559314727783, Grad L2 Norm: 0.021882716566324234
2025-11-24 01:52:08.183 | INFO     | __main__:<module>:160 - Step57070, Loss: 3.569918632507324, Grad L2 Norm: 0.023186450824141502
2025-11-24 01:52:09.906 | INFO     | __main__:<module>:160 - Step57080, Loss: 3.501075267791748, Grad L2 Norm: 0.021246274933218956
2025-11-24 01:52:11.632 | INFO     | __main__:<module>:160 - Step57090, Loss: 3.489579916000366, Grad L2 Norm: 0.022359978407621384
2025-11-24 01:52:13.355 | INFO     | __main__:<module>:160 - Step57100, Loss: 3.632072687149048, Grad L2 Norm: 0.023535387590527534
2025-11-24 01:52:15.075 | INFO     | __main__:<module>:160 - Step57110, Loss: 3.5416712760925293, Grad L2 Norm: 0.02303936518728733
2025-11-24 01:52:16.789 | INFO     | __main__:<module>:160 - Step57120, Loss: 3.537631034851074, Grad L2 Norm: 0.022821182385087013
2025-11-24 01:52:18.517 | INFO     | __main__:<module>:160 - Step57130, Loss: 3.5593082904815674, Grad L2 Norm: 0.022704996168613434
2025-11-24 01:52:20.241 | INFO     | __main__:<module>:160 - Step57140, Loss: 3.596104860305786, Grad L2 Norm: 0.021975422278046608
2025-11-24 01:52:21.969 | INFO     | __main__:<module>:160 - Step57150, Loss: 3.5578255653381348, Grad L2 Norm: 0.022958993911743164
2025-11-24 01:52:23.683 | INFO     | __main__:<module>:160 - Step57160, Loss: 3.6193151473999023, Grad L2 Norm: 0.023590276017785072
2025-11-24 01:52:25.400 | INFO     | __main__:<module>:160 - Step57170, Loss: 3.6320817470550537, Grad L2 Norm: 0.022837555035948753
2025-11-24 01:52:27.138 | INFO     | __main__:<module>:160 - Step57180, Loss: 3.6122536659240723, Grad L2 Norm: 0.022968176752328873
2025-11-24 01:52:28.853 | INFO     | __main__:<module>:160 - Step57190, Loss: 3.66743803024292, Grad L2 Norm: 0.024220431223511696
2025-11-24 01:52:30.577 | INFO     | __main__:<module>:160 - Step57200, Loss: 3.652988910675049, Grad L2 Norm: 0.024011798202991486
2025-11-24 01:52:30.578 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:52:31.594 | INFO     | __main__:<module>:181 - validation loss: 3.5735676646232606
2025-11-24 01:52:33.310 | INFO     | __main__:<module>:160 - Step57210, Loss: 3.5752408504486084, Grad L2 Norm: 0.022942952811717987
2025-11-24 01:52:35.025 | INFO     | __main__:<module>:160 - Step57220, Loss: 3.6304500102996826, Grad L2 Norm: 0.02148098312318325
2025-11-24 01:52:36.754 | INFO     | __main__:<module>:160 - Step57230, Loss: 3.512925148010254, Grad L2 Norm: 0.02324913814663887
2025-11-24 01:52:38.467 | INFO     | __main__:<module>:160 - Step57240, Loss: 3.56994366645813, Grad L2 Norm: 0.024799896404147148
2025-11-24 01:52:40.187 | INFO     | __main__:<module>:160 - Step57250, Loss: 3.64119291305542, Grad L2 Norm: 0.024607835337519646
2025-11-24 01:52:41.905 | INFO     | __main__:<module>:160 - Step57260, Loss: 3.65388822555542, Grad L2 Norm: 0.022658677771687508
2025-11-24 01:52:43.620 | INFO     | __main__:<module>:160 - Step57270, Loss: 3.476125955581665, Grad L2 Norm: 0.02212749980390072
2025-11-24 01:52:45.348 | INFO     | __main__:<module>:160 - Step57280, Loss: 3.4742720127105713, Grad L2 Norm: 0.022000478580594063
2025-11-24 01:52:47.062 | INFO     | __main__:<module>:160 - Step57290, Loss: 3.564800262451172, Grad L2 Norm: 0.02500816434621811
2025-11-24 01:52:48.784 | INFO     | __main__:<module>:160 - Step57300, Loss: 3.6526453495025635, Grad L2 Norm: 0.02502264268696308
2025-11-24 01:52:50.514 | INFO     | __main__:<module>:160 - Step57310, Loss: 3.6377933025360107, Grad L2 Norm: 0.023620083928108215
2025-11-24 01:52:52.231 | INFO     | __main__:<module>:160 - Step57320, Loss: 3.6034300327301025, Grad L2 Norm: 0.024385975673794746
2025-11-24 01:52:53.956 | INFO     | __main__:<module>:160 - Step57330, Loss: 3.492802143096924, Grad L2 Norm: 0.021931732073426247
2025-11-24 01:52:55.670 | INFO     | __main__:<module>:160 - Step57340, Loss: 3.5782506465911865, Grad L2 Norm: 0.02401667833328247
2025-11-24 01:52:57.397 | INFO     | __main__:<module>:160 - Step57350, Loss: 3.56992769241333, Grad L2 Norm: 0.023968134075403214
2025-11-24 01:52:59.123 | INFO     | __main__:<module>:160 - Step57360, Loss: 3.5023701190948486, Grad L2 Norm: 0.02209707349538803
2025-11-24 01:53:00.851 | INFO     | __main__:<module>:160 - Step57370, Loss: 3.4698283672332764, Grad L2 Norm: 0.023351307958364487
2025-11-24 01:53:02.565 | INFO     | __main__:<module>:160 - Step57380, Loss: 3.477689743041992, Grad L2 Norm: 0.02207200601696968
2025-11-24 01:53:04.281 | INFO     | __main__:<module>:160 - Step57390, Loss: 3.601196765899658, Grad L2 Norm: 0.021600976586341858
2025-11-24 01:53:06.018 | INFO     | __main__:<module>:160 - Step57400, Loss: 3.5370230674743652, Grad L2 Norm: 0.023250775411725044
2025-11-24 01:53:07.734 | INFO     | __main__:<module>:160 - Step57410, Loss: 3.521301746368408, Grad L2 Norm: 0.023231366649270058
2025-11-24 01:53:09.457 | INFO     | __main__:<module>:160 - Step57420, Loss: 3.55029296875, Grad L2 Norm: 0.02257419377565384
2025-11-24 01:53:11.173 | INFO     | __main__:<module>:160 - Step57430, Loss: 3.614351749420166, Grad L2 Norm: 0.021557610481977463
2025-11-24 01:53:12.901 | INFO     | __main__:<module>:160 - Step57440, Loss: 3.48740816116333, Grad L2 Norm: 0.02379496954381466
2025-11-24 01:53:14.625 | INFO     | __main__:<module>:160 - Step57450, Loss: 3.5674924850463867, Grad L2 Norm: 0.022939244285225868
2025-11-24 01:53:16.342 | INFO     | __main__:<module>:160 - Step57460, Loss: 3.616586208343506, Grad L2 Norm: 0.02239043638110161
2025-11-24 01:53:18.064 | INFO     | __main__:<module>:160 - Step57470, Loss: 3.5635762214660645, Grad L2 Norm: 0.022004064172506332
2025-11-24 01:53:19.784 | INFO     | __main__:<module>:160 - Step57480, Loss: 3.744232177734375, Grad L2 Norm: 0.022990411147475243
2025-11-24 01:53:21.508 | INFO     | __main__:<module>:160 - Step57490, Loss: 3.5185964107513428, Grad L2 Norm: 0.022392887622117996
2025-11-24 01:53:23.237 | INFO     | __main__:<module>:160 - Step57500, Loss: 3.634685516357422, Grad L2 Norm: 0.023328814655542374
2025-11-24 01:53:24.950 | INFO     | __main__:<module>:160 - Step57510, Loss: 3.542515277862549, Grad L2 Norm: 0.02241482026875019
2025-11-24 01:53:26.673 | INFO     | __main__:<module>:160 - Step57520, Loss: 3.645691156387329, Grad L2 Norm: 0.022724134847521782
2025-11-24 01:53:28.401 | INFO     | __main__:<module>:160 - Step57530, Loss: 3.506617784500122, Grad L2 Norm: 0.0242750383913517
2025-11-24 01:53:30.118 | INFO     | __main__:<module>:160 - Step57540, Loss: 3.5469894409179688, Grad L2 Norm: 0.02394859865307808
2025-11-24 01:53:31.845 | INFO     | __main__:<module>:160 - Step57550, Loss: 3.4841036796569824, Grad L2 Norm: 0.022183066233992577
2025-11-24 01:53:33.559 | INFO     | __main__:<module>:160 - Step57560, Loss: 3.520493984222412, Grad L2 Norm: 0.0227431058883667
2025-11-24 01:53:35.288 | INFO     | __main__:<module>:160 - Step57570, Loss: 3.6426002979278564, Grad L2 Norm: 0.022826705127954483
2025-11-24 01:53:37.012 | INFO     | __main__:<module>:160 - Step57580, Loss: 3.5702357292175293, Grad L2 Norm: 0.021722063422203064
2025-11-24 01:53:38.738 | INFO     | __main__:<module>:160 - Step57590, Loss: 3.582465171813965, Grad L2 Norm: 0.02256905660033226
2025-11-24 01:53:40.454 | INFO     | __main__:<module>:160 - Step57600, Loss: 3.5182244777679443, Grad L2 Norm: 0.023384995758533478
2025-11-24 01:53:40.454 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:53:41.472 | INFO     | __main__:<module>:181 - validation loss: 3.537336194515228
2025-11-24 01:53:43.189 | INFO     | __main__:<module>:160 - Step57610, Loss: 3.540652275085449, Grad L2 Norm: 0.022446725517511368
2025-11-24 01:53:44.911 | INFO     | __main__:<module>:160 - Step57620, Loss: 3.530219554901123, Grad L2 Norm: 0.022679371759295464
2025-11-24 01:53:46.628 | INFO     | __main__:<module>:160 - Step57630, Loss: 3.609330654144287, Grad L2 Norm: 0.024165259674191475
2025-11-24 01:53:48.342 | INFO     | __main__:<module>:160 - Step57640, Loss: 3.623277187347412, Grad L2 Norm: 0.022165508940815926
2025-11-24 01:53:50.070 | INFO     | __main__:<module>:160 - Step57650, Loss: 3.5461137294769287, Grad L2 Norm: 0.021642137318849564
2025-11-24 01:53:51.783 | INFO     | __main__:<module>:160 - Step57660, Loss: 3.6517350673675537, Grad L2 Norm: 0.021707389503717422
2025-11-24 01:53:53.504 | INFO     | __main__:<module>:160 - Step57670, Loss: 3.589087963104248, Grad L2 Norm: 0.02186373434960842
2025-11-24 01:53:55.222 | INFO     | __main__:<module>:160 - Step57680, Loss: 3.59920072555542, Grad L2 Norm: 0.02366376668214798
2025-11-24 01:53:56.937 | INFO     | __main__:<module>:160 - Step57690, Loss: 3.672403573989868, Grad L2 Norm: 0.022265993058681488
2025-11-24 01:53:58.664 | INFO     | __main__:<module>:160 - Step57700, Loss: 3.4934768676757812, Grad L2 Norm: 0.02210765704512596
2025-11-24 01:54:00.390 | INFO     | __main__:<module>:160 - Step57710, Loss: 3.580676555633545, Grad L2 Norm: 0.023014135658740997
2025-11-24 01:54:02.116 | INFO     | __main__:<module>:160 - Step57720, Loss: 3.477576732635498, Grad L2 Norm: 0.021977931261062622
2025-11-24 01:54:03.833 | INFO     | __main__:<module>:160 - Step57730, Loss: 3.553719997406006, Grad L2 Norm: 0.022676758468151093
2025-11-24 01:54:05.550 | INFO     | __main__:<module>:160 - Step57740, Loss: 3.6512646675109863, Grad L2 Norm: 0.02236761525273323
2025-11-24 01:54:07.287 | INFO     | __main__:<module>:160 - Step57750, Loss: 3.5283803939819336, Grad L2 Norm: 0.022555088624358177
2025-11-24 01:54:09.003 | INFO     | __main__:<module>:160 - Step57760, Loss: 3.5996267795562744, Grad L2 Norm: 0.023379040881991386
2025-11-24 01:54:10.726 | INFO     | __main__:<module>:160 - Step57770, Loss: 3.557163715362549, Grad L2 Norm: 0.023608095943927765
2025-11-24 01:54:12.440 | INFO     | __main__:<module>:160 - Step57780, Loss: 3.6548824310302734, Grad L2 Norm: 0.023289570584893227
2025-11-24 01:54:14.167 | INFO     | __main__:<module>:160 - Step57790, Loss: 3.498591423034668, Grad L2 Norm: 0.02306341379880905
2025-11-24 01:54:15.893 | INFO     | __main__:<module>:160 - Step57800, Loss: 3.576788902282715, Grad L2 Norm: 0.022686289623379707
2025-11-24 01:54:17.610 | INFO     | __main__:<module>:160 - Step57810, Loss: 3.55218505859375, Grad L2 Norm: 0.023704465478658676
2025-11-24 01:54:19.336 | INFO     | __main__:<module>:160 - Step57820, Loss: 3.4994664192199707, Grad L2 Norm: 0.021791432052850723
2025-11-24 01:54:21.049 | INFO     | __main__:<module>:160 - Step57830, Loss: 3.602221965789795, Grad L2 Norm: 0.022567100822925568
2025-11-24 01:54:22.783 | INFO     | __main__:<module>:160 - Step57840, Loss: 3.57625675201416, Grad L2 Norm: 0.022947706282138824
2025-11-24 01:54:24.502 | INFO     | __main__:<module>:160 - Step57850, Loss: 3.5771594047546387, Grad L2 Norm: 0.02342558279633522
2025-11-24 01:54:26.218 | INFO     | __main__:<module>:160 - Step57860, Loss: 3.618262529373169, Grad L2 Norm: 0.023760294541716576
2025-11-24 01:54:27.942 | INFO     | __main__:<module>:160 - Step57870, Loss: 3.6239027976989746, Grad L2 Norm: 0.023701820522546768
2025-11-24 01:54:29.670 | INFO     | __main__:<module>:160 - Step57880, Loss: 3.455871105194092, Grad L2 Norm: 0.023364806547760963
2025-11-24 01:54:31.392 | INFO     | __main__:<module>:160 - Step57890, Loss: 3.541320323944092, Grad L2 Norm: 0.023421069607138634
2025-11-24 01:54:33.112 | INFO     | __main__:<module>:160 - Step57900, Loss: 3.5429630279541016, Grad L2 Norm: 0.022062769159674644
2025-11-24 01:54:34.826 | INFO     | __main__:<module>:160 - Step57910, Loss: 3.6459178924560547, Grad L2 Norm: 0.023168740794062614
2025-11-24 01:54:36.552 | INFO     | __main__:<module>:160 - Step57920, Loss: 3.5726022720336914, Grad L2 Norm: 0.022785041481256485
2025-11-24 01:54:38.278 | INFO     | __main__:<module>:160 - Step57930, Loss: 3.64736270904541, Grad L2 Norm: 0.023295501247048378
2025-11-24 01:54:40.008 | INFO     | __main__:<module>:160 - Step57940, Loss: 3.504531145095825, Grad L2 Norm: 0.0220206156373024
2025-11-24 01:54:41.722 | INFO     | __main__:<module>:160 - Step57950, Loss: 3.5197134017944336, Grad L2 Norm: 0.022000765427947044
2025-11-24 01:54:43.436 | INFO     | __main__:<module>:160 - Step57960, Loss: 3.5328774452209473, Grad L2 Norm: 0.025054795667529106
2025-11-24 01:54:45.172 | INFO     | __main__:<module>:160 - Step57970, Loss: 3.4654810428619385, Grad L2 Norm: 0.023173978552222252
2025-11-24 01:54:46.888 | INFO     | __main__:<module>:160 - Step57980, Loss: 3.490199565887451, Grad L2 Norm: 0.021839285269379616
2025-11-24 01:54:48.614 | INFO     | __main__:<module>:160 - Step57990, Loss: 3.5722899436950684, Grad L2 Norm: 0.022310741245746613
2025-11-24 01:54:50.328 | INFO     | __main__:<module>:160 - Step58000, Loss: 3.594120502471924, Grad L2 Norm: 0.021812796592712402
2025-11-24 01:54:50.329 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:54:51.349 | INFO     | __main__:<module>:181 - validation loss: 3.555463767051697
2025-11-24 01:54:51.350 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_58000.pt
2025-11-24 01:54:53.105 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 01:54:54.749 | INFO     | __main__:<module>:160 - Step58010, Loss: 3.3929107189178467, Grad L2 Norm: 0.02268631011247635
2025-11-24 01:54:56.483 | INFO     | __main__:<module>:160 - Step58020, Loss: 3.5317296981811523, Grad L2 Norm: 0.024915872141718864
2025-11-24 01:54:58.214 | INFO     | __main__:<module>:160 - Step58030, Loss: 3.609793186187744, Grad L2 Norm: 0.022562647238373756
2025-11-24 01:54:59.940 | INFO     | __main__:<module>:160 - Step58040, Loss: 3.6605000495910645, Grad L2 Norm: 0.023376721888780594
2025-11-24 01:55:01.669 | INFO     | __main__:<module>:160 - Step58050, Loss: 3.5469462871551514, Grad L2 Norm: 0.023644834756851196
2025-11-24 01:55:03.396 | INFO     | __main__:<module>:160 - Step58060, Loss: 3.650949001312256, Grad L2 Norm: 0.02373475581407547
2025-11-24 01:55:05.125 | INFO     | __main__:<module>:160 - Step58070, Loss: 3.6028614044189453, Grad L2 Norm: 0.025008346885442734
2025-11-24 01:55:06.849 | INFO     | __main__:<module>:160 - Step58080, Loss: 3.596191644668579, Grad L2 Norm: 0.023661108687520027
2025-11-24 01:55:08.563 | INFO     | __main__:<module>:160 - Step58090, Loss: 3.55088472366333, Grad L2 Norm: 0.021854424849152565
2025-11-24 01:55:10.289 | INFO     | __main__:<module>:160 - Step58100, Loss: 3.585754632949829, Grad L2 Norm: 0.02495158091187477
2025-11-24 01:55:12.008 | INFO     | __main__:<module>:160 - Step58110, Loss: 3.550206184387207, Grad L2 Norm: 0.023597462102770805
2025-11-24 01:55:13.735 | INFO     | __main__:<module>:160 - Step58120, Loss: 3.672750473022461, Grad L2 Norm: 0.021712565794587135
2025-11-24 01:55:15.462 | INFO     | __main__:<module>:160 - Step58130, Loss: 3.4661407470703125, Grad L2 Norm: 0.02471676841378212
2025-11-24 01:55:17.173 | INFO     | __main__:<module>:160 - Step58140, Loss: 3.5244946479797363, Grad L2 Norm: 0.02328520640730858
2025-11-24 01:55:18.897 | INFO     | __main__:<module>:160 - Step58150, Loss: 3.52091383934021, Grad L2 Norm: 0.02239842899143696
2025-11-24 01:55:20.613 | INFO     | __main__:<module>:160 - Step58160, Loss: 3.6050448417663574, Grad L2 Norm: 0.02208966203033924
2025-11-24 01:55:22.330 | INFO     | __main__:<module>:160 - Step58170, Loss: 3.4898223876953125, Grad L2 Norm: 0.023173145949840546
2025-11-24 01:55:24.055 | INFO     | __main__:<module>:160 - Step58180, Loss: 3.4225332736968994, Grad L2 Norm: 0.02238626405596733
2025-11-24 01:55:25.771 | INFO     | __main__:<module>:160 - Step58190, Loss: 3.50551176071167, Grad L2 Norm: 0.023558879271149635
2025-11-24 01:55:27.493 | INFO     | __main__:<module>:160 - Step58200, Loss: 3.496600389480591, Grad L2 Norm: 0.020523615181446075
2025-11-24 01:55:29.208 | INFO     | __main__:<module>:160 - Step58210, Loss: 3.619715690612793, Grad L2 Norm: 0.02320897951722145
2025-11-24 01:55:30.935 | INFO     | __main__:<module>:160 - Step58220, Loss: 3.4866650104522705, Grad L2 Norm: 0.02288953959941864
2025-11-24 01:55:32.660 | INFO     | __main__:<module>:160 - Step58230, Loss: 3.6336617469787598, Grad L2 Norm: 0.023528888821601868
2025-11-24 01:55:34.376 | INFO     | __main__:<module>:160 - Step58240, Loss: 3.5381875038146973, Grad L2 Norm: 0.022846654057502747
2025-11-24 01:55:36.102 | INFO     | __main__:<module>:160 - Step58250, Loss: 3.6137783527374268, Grad L2 Norm: 0.02333531342446804
2025-11-24 01:55:37.820 | INFO     | __main__:<module>:160 - Step58260, Loss: 3.4447526931762695, Grad L2 Norm: 0.02246348187327385
2025-11-24 01:55:39.545 | INFO     | __main__:<module>:160 - Step58270, Loss: 3.62111234664917, Grad L2 Norm: 0.022831991314888
2025-11-24 01:55:41.272 | INFO     | __main__:<module>:160 - Step58280, Loss: 3.606480598449707, Grad L2 Norm: 0.02210145629942417
2025-11-24 01:55:42.987 | INFO     | __main__:<module>:160 - Step58290, Loss: 3.6617231369018555, Grad L2 Norm: 0.058181244879961014
2025-11-24 01:55:44.710 | INFO     | __main__:<module>:160 - Step58300, Loss: 3.6458232402801514, Grad L2 Norm: 0.024115703999996185
2025-11-24 01:55:46.442 | INFO     | __main__:<module>:160 - Step58310, Loss: 3.5146546363830566, Grad L2 Norm: 0.02198878675699234
2025-11-24 01:55:48.161 | INFO     | __main__:<module>:160 - Step58320, Loss: 3.569882392883301, Grad L2 Norm: 0.022517001256346703
2025-11-24 01:55:49.882 | INFO     | __main__:<module>:160 - Step58330, Loss: 3.5027735233306885, Grad L2 Norm: 0.021644333377480507
2025-11-24 01:55:51.596 | INFO     | __main__:<module>:160 - Step58340, Loss: 3.571638584136963, Grad L2 Norm: 0.026057815179228783
2025-11-24 01:55:53.324 | INFO     | __main__:<module>:160 - Step58350, Loss: 3.592060089111328, Grad L2 Norm: 0.021599657833576202
2025-11-24 01:55:55.047 | INFO     | __main__:<module>:160 - Step58360, Loss: 3.5411980152130127, Grad L2 Norm: 0.021921431645751
2025-11-24 01:55:56.772 | INFO     | __main__:<module>:160 - Step58370, Loss: 3.5543293952941895, Grad L2 Norm: 0.022100331261754036
2025-11-24 01:55:58.489 | INFO     | __main__:<module>:160 - Step58380, Loss: 3.6392288208007812, Grad L2 Norm: 0.02486288733780384
2025-11-24 01:56:00.206 | INFO     | __main__:<module>:160 - Step58390, Loss: 3.562764883041382, Grad L2 Norm: 0.02205524407327175
2025-11-24 01:56:01.940 | INFO     | __main__:<module>:160 - Step58400, Loss: 3.4711899757385254, Grad L2 Norm: 0.022641748189926147
2025-11-24 01:56:01.941 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:56:02.958 | INFO     | __main__:<module>:181 - validation loss: 3.510732853412628
2025-11-24 01:56:04.677 | INFO     | __main__:<module>:160 - Step58410, Loss: 3.492499351501465, Grad L2 Norm: 0.022253088653087616
2025-11-24 01:56:06.410 | INFO     | __main__:<module>:160 - Step58420, Loss: 3.599557876586914, Grad L2 Norm: 0.022192329168319702
2025-11-24 01:56:08.130 | INFO     | __main__:<module>:160 - Step58430, Loss: 3.65443754196167, Grad L2 Norm: 0.022338813170790672
2025-11-24 01:56:09.855 | INFO     | __main__:<module>:160 - Step58440, Loss: 3.7205541133880615, Grad L2 Norm: 0.02552831918001175
2025-11-24 01:56:11.584 | INFO     | __main__:<module>:160 - Step58450, Loss: 3.5966453552246094, Grad L2 Norm: 0.023713519796729088
2025-11-24 01:56:13.298 | INFO     | __main__:<module>:160 - Step58460, Loss: 3.5875768661499023, Grad L2 Norm: 0.022460224106907845
2025-11-24 01:56:15.020 | INFO     | __main__:<module>:160 - Step58470, Loss: 3.5900282859802246, Grad L2 Norm: 0.02515546791255474
2025-11-24 01:56:16.749 | INFO     | __main__:<module>:160 - Step58480, Loss: 3.447824478149414, Grad L2 Norm: 0.022487403824925423
2025-11-24 01:56:18.467 | INFO     | __main__:<module>:160 - Step58490, Loss: 3.6293599605560303, Grad L2 Norm: 0.022613611072301865
2025-11-24 01:56:20.193 | INFO     | __main__:<module>:160 - Step58500, Loss: 3.4683594703674316, Grad L2 Norm: 0.021889451891183853
2025-11-24 01:56:21.908 | INFO     | __main__:<module>:160 - Step58510, Loss: 3.4942774772644043, Grad L2 Norm: 0.023959742859005928
2025-11-24 01:56:23.634 | INFO     | __main__:<module>:160 - Step58520, Loss: 3.5471577644348145, Grad L2 Norm: 0.02331450767815113
2025-11-24 01:56:25.357 | INFO     | __main__:<module>:160 - Step58530, Loss: 3.653738021850586, Grad L2 Norm: 0.025088995695114136
2025-11-24 01:56:27.084 | INFO     | __main__:<module>:160 - Step58540, Loss: 3.5496315956115723, Grad L2 Norm: 0.023211563006043434
2025-11-24 01:56:28.801 | INFO     | __main__:<module>:160 - Step58550, Loss: 3.472769021987915, Grad L2 Norm: 0.024419112130999565
2025-11-24 01:56:30.519 | INFO     | __main__:<module>:160 - Step58560, Loss: 3.4467434883117676, Grad L2 Norm: 0.02129412442445755
2025-11-24 01:56:32.254 | INFO     | __main__:<module>:160 - Step58570, Loss: 3.562778949737549, Grad L2 Norm: 0.02371210791170597
2025-11-24 01:56:33.967 | INFO     | __main__:<module>:160 - Step58580, Loss: 3.4756407737731934, Grad L2 Norm: 0.023371729999780655
2025-11-24 01:56:35.692 | INFO     | __main__:<module>:160 - Step58590, Loss: 3.5888938903808594, Grad L2 Norm: 0.021820634603500366
2025-11-24 01:56:37.408 | INFO     | __main__:<module>:160 - Step58600, Loss: 3.539783477783203, Grad L2 Norm: 0.023388847708702087
2025-11-24 01:56:39.135 | INFO     | __main__:<module>:160 - Step58610, Loss: 3.444869041442871, Grad L2 Norm: 0.023936834186315536
2025-11-24 01:56:40.861 | INFO     | __main__:<module>:160 - Step58620, Loss: 3.637819766998291, Grad L2 Norm: 0.02368004620075226
2025-11-24 01:56:42.578 | INFO     | __main__:<module>:160 - Step58630, Loss: 3.6067252159118652, Grad L2 Norm: 0.02318008802831173
2025-11-24 01:56:44.301 | INFO     | __main__:<module>:160 - Step58640, Loss: 3.4861836433410645, Grad L2 Norm: 0.02131541259586811
2025-11-24 01:56:46.019 | INFO     | __main__:<module>:160 - Step58650, Loss: 3.547109842300415, Grad L2 Norm: 0.021965518593788147
2025-11-24 01:56:47.743 | INFO     | __main__:<module>:160 - Step58660, Loss: 3.665614128112793, Grad L2 Norm: 0.024156617000699043
2025-11-24 01:56:49.471 | INFO     | __main__:<module>:160 - Step58670, Loss: 3.5870490074157715, Grad L2 Norm: 0.022870754823088646
2025-11-24 01:56:51.188 | INFO     | __main__:<module>:160 - Step58680, Loss: 3.5209360122680664, Grad L2 Norm: 0.02234385348856449
2025-11-24 01:56:52.911 | INFO     | __main__:<module>:160 - Step58690, Loss: 3.4881300926208496, Grad L2 Norm: 0.02206181176006794
2025-11-24 01:56:54.642 | INFO     | __main__:<module>:160 - Step58700, Loss: 3.648974895477295, Grad L2 Norm: 0.024677643552422523
2025-11-24 01:56:56.357 | INFO     | __main__:<module>:160 - Step58710, Loss: 3.58488130569458, Grad L2 Norm: 0.02216624654829502
2025-11-24 01:56:58.080 | INFO     | __main__:<module>:160 - Step58720, Loss: 3.5775721073150635, Grad L2 Norm: 0.021768424659967422
2025-11-24 01:56:59.793 | INFO     | __main__:<module>:160 - Step58730, Loss: 3.6374239921569824, Grad L2 Norm: 0.022760575637221336
2025-11-24 01:57:01.518 | INFO     | __main__:<module>:160 - Step58740, Loss: 3.4701523780822754, Grad L2 Norm: 0.02148481272161007
2025-11-24 01:57:03.243 | INFO     | __main__:<module>:160 - Step58750, Loss: 3.53985595703125, Grad L2 Norm: 0.021455520763993263
2025-11-24 01:57:04.972 | INFO     | __main__:<module>:160 - Step58760, Loss: 3.4174699783325195, Grad L2 Norm: 0.02260987088084221
2025-11-24 01:57:06.688 | INFO     | __main__:<module>:160 - Step58770, Loss: 3.604356288909912, Grad L2 Norm: 0.02457449957728386
2025-11-24 01:57:08.403 | INFO     | __main__:<module>:160 - Step58780, Loss: 3.5300564765930176, Grad L2 Norm: 0.02308700606226921
2025-11-24 01:57:10.139 | INFO     | __main__:<module>:160 - Step58790, Loss: 3.481215476989746, Grad L2 Norm: 0.023808086290955544
2025-11-24 01:57:11.857 | INFO     | __main__:<module>:160 - Step58800, Loss: 3.5236728191375732, Grad L2 Norm: 0.023728162050247192
2025-11-24 01:57:11.858 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:57:12.877 | INFO     | __main__:<module>:181 - validation loss: 3.539771592617035
2025-11-24 01:57:14.610 | INFO     | __main__:<module>:160 - Step58810, Loss: 3.5647754669189453, Grad L2 Norm: 0.02152884006500244
2025-11-24 01:57:16.328 | INFO     | __main__:<module>:160 - Step58820, Loss: 3.4692296981811523, Grad L2 Norm: 0.02248757891356945
2025-11-24 01:57:18.054 | INFO     | __main__:<module>:160 - Step58830, Loss: 3.5746562480926514, Grad L2 Norm: 0.022722968831658363
2025-11-24 01:57:19.782 | INFO     | __main__:<module>:160 - Step58840, Loss: 3.5570240020751953, Grad L2 Norm: 0.0236220583319664
2025-11-24 01:57:21.495 | INFO     | __main__:<module>:160 - Step58850, Loss: 3.619541645050049, Grad L2 Norm: 0.024291357025504112
2025-11-24 01:57:23.218 | INFO     | __main__:<module>:160 - Step58860, Loss: 3.512509346008301, Grad L2 Norm: 0.025003455579280853
2025-11-24 01:57:24.947 | INFO     | __main__:<module>:160 - Step58870, Loss: 3.550288677215576, Grad L2 Norm: 0.02200544811785221
2025-11-24 01:57:26.666 | INFO     | __main__:<module>:160 - Step58880, Loss: 3.4434337615966797, Grad L2 Norm: 0.024121573194861412
2025-11-24 01:57:28.391 | INFO     | __main__:<module>:160 - Step58890, Loss: 3.630920886993408, Grad L2 Norm: 0.022461144253611565
2025-11-24 01:57:30.104 | INFO     | __main__:<module>:160 - Step58900, Loss: 3.81003999710083, Grad L2 Norm: 0.02400808595120907
2025-11-24 01:57:31.830 | INFO     | __main__:<module>:160 - Step58910, Loss: 3.5113306045532227, Grad L2 Norm: 0.02298518270254135
2025-11-24 01:57:33.555 | INFO     | __main__:<module>:160 - Step58920, Loss: 3.5490097999572754, Grad L2 Norm: 0.02238430082798004
2025-11-24 01:57:35.281 | INFO     | __main__:<module>:160 - Step58930, Loss: 3.664552688598633, Grad L2 Norm: 0.023680338636040688
2025-11-24 01:57:37.004 | INFO     | __main__:<module>:160 - Step58940, Loss: 3.6224865913391113, Grad L2 Norm: 0.021702557802200317
2025-11-24 01:57:38.715 | INFO     | __main__:<module>:160 - Step58950, Loss: 3.6496529579162598, Grad L2 Norm: 0.024890625849366188
2025-11-24 01:57:40.450 | INFO     | __main__:<module>:160 - Step58960, Loss: 3.5622825622558594, Grad L2 Norm: 0.022274259477853775
2025-11-24 01:57:42.166 | INFO     | __main__:<module>:160 - Step58970, Loss: 3.5310957431793213, Grad L2 Norm: 0.023912852630019188
2025-11-24 01:57:43.889 | INFO     | __main__:<module>:160 - Step58980, Loss: 3.5331056118011475, Grad L2 Norm: 0.022399969398975372
2025-11-24 01:57:45.607 | INFO     | __main__:<module>:160 - Step58990, Loss: 3.6438937187194824, Grad L2 Norm: 0.02260579727590084
2025-11-24 01:57:47.333 | INFO     | __main__:<module>:160 - Step59000, Loss: 3.475489616394043, Grad L2 Norm: 0.02226496860384941
2025-11-24 01:57:49.058 | INFO     | __main__:<module>:160 - Step59010, Loss: 3.591609477996826, Grad L2 Norm: 0.02056831680238247
2025-11-24 01:57:50.776 | INFO     | __main__:<module>:160 - Step59020, Loss: 3.5835793018341064, Grad L2 Norm: 0.02396995946764946
2025-11-24 01:57:52.499 | INFO     | __main__:<module>:160 - Step59030, Loss: 3.507392406463623, Grad L2 Norm: 0.02267453446984291
2025-11-24 01:57:54.216 | INFO     | __main__:<module>:160 - Step59040, Loss: 3.624748706817627, Grad L2 Norm: 0.021744148805737495
2025-11-24 01:57:55.942 | INFO     | __main__:<module>:160 - Step59050, Loss: 3.5553250312805176, Grad L2 Norm: 0.0226377472281456
2025-11-24 01:57:57.670 | INFO     | __main__:<module>:160 - Step59060, Loss: 3.4265964031219482, Grad L2 Norm: 0.021725265309214592
2025-11-24 01:57:59.387 | INFO     | __main__:<module>:160 - Step59070, Loss: 3.6565349102020264, Grad L2 Norm: 0.023811256512999535
2025-11-24 01:58:01.110 | INFO     | __main__:<module>:160 - Step59080, Loss: 3.5653553009033203, Grad L2 Norm: 0.02262049913406372
2025-11-24 01:58:02.837 | INFO     | __main__:<module>:160 - Step59090, Loss: 3.4232778549194336, Grad L2 Norm: 0.02158447727560997
2025-11-24 01:58:04.554 | INFO     | __main__:<module>:160 - Step59100, Loss: 3.3914175033569336, Grad L2 Norm: 0.0244592372328043
2025-11-24 01:58:06.277 | INFO     | __main__:<module>:160 - Step59110, Loss: 3.593902587890625, Grad L2 Norm: 0.023250192403793335
2025-11-24 01:58:07.992 | INFO     | __main__:<module>:160 - Step59120, Loss: 3.505131721496582, Grad L2 Norm: 0.024542849510908127
2025-11-24 01:58:09.723 | INFO     | __main__:<module>:160 - Step59130, Loss: 3.5821938514709473, Grad L2 Norm: 0.023872187361121178
2025-11-24 01:58:11.445 | INFO     | __main__:<module>:160 - Step59140, Loss: 3.5263261795043945, Grad L2 Norm: 0.024543646723031998
2025-11-24 01:58:13.170 | INFO     | __main__:<module>:160 - Step59150, Loss: 3.7259092330932617, Grad L2 Norm: 0.0250419732183218
2025-11-24 01:58:14.887 | INFO     | __main__:<module>:160 - Step59160, Loss: 3.546975612640381, Grad L2 Norm: 0.02280590869486332
2025-11-24 01:58:16.603 | INFO     | __main__:<module>:160 - Step59170, Loss: 3.5291171073913574, Grad L2 Norm: 0.023194801062345505
2025-11-24 01:58:18.338 | INFO     | __main__:<module>:160 - Step59180, Loss: 3.554629325866699, Grad L2 Norm: 0.024239182472229004
2025-11-24 01:58:20.054 | INFO     | __main__:<module>:160 - Step59190, Loss: 3.5219218730926514, Grad L2 Norm: 0.022373247891664505
2025-11-24 01:58:21.777 | INFO     | __main__:<module>:160 - Step59200, Loss: 3.703155517578125, Grad L2 Norm: 0.022744804620742798
2025-11-24 01:58:21.778 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:58:22.790 | INFO     | __main__:<module>:181 - validation loss: 3.5502815365791323
2025-11-24 01:58:24.513 | INFO     | __main__:<module>:160 - Step59210, Loss: 3.738097667694092, Grad L2 Norm: 0.025397442281246185
2025-11-24 01:58:26.227 | INFO     | __main__:<module>:160 - Step59220, Loss: 3.59428334236145, Grad L2 Norm: 0.025283874943852425
2025-11-24 01:58:27.955 | INFO     | __main__:<module>:160 - Step59230, Loss: 3.633190393447876, Grad L2 Norm: 0.024941733106970787
2025-11-24 01:58:29.669 | INFO     | __main__:<module>:160 - Step59240, Loss: 3.5288076400756836, Grad L2 Norm: 0.022576283663511276
2025-11-24 01:58:31.385 | INFO     | __main__:<module>:160 - Step59250, Loss: 3.500267744064331, Grad L2 Norm: 0.022300513461232185
2025-11-24 01:58:33.112 | INFO     | __main__:<module>:160 - Step59260, Loss: 3.71529483795166, Grad L2 Norm: 0.022871902212500572
2025-11-24 01:58:34.828 | INFO     | __main__:<module>:160 - Step59270, Loss: 3.560047149658203, Grad L2 Norm: 0.023531829938292503
2025-11-24 01:58:36.554 | INFO     | __main__:<module>:160 - Step59280, Loss: 3.505436420440674, Grad L2 Norm: 0.021917250007390976
2025-11-24 01:58:38.265 | INFO     | __main__:<module>:160 - Step59290, Loss: 3.647646427154541, Grad L2 Norm: 0.022737257182598114
2025-11-24 01:58:39.981 | INFO     | __main__:<module>:160 - Step59300, Loss: 3.5801401138305664, Grad L2 Norm: 0.0236493069678545
2025-11-24 01:58:41.717 | INFO     | __main__:<module>:160 - Step59310, Loss: 3.4494876861572266, Grad L2 Norm: 0.023512011393904686
2025-11-24 01:58:43.437 | INFO     | __main__:<module>:160 - Step59320, Loss: 3.4456706047058105, Grad L2 Norm: 0.022883059456944466
2025-11-24 01:58:45.160 | INFO     | __main__:<module>:160 - Step59330, Loss: 3.676356792449951, Grad L2 Norm: 0.022374600172042847
2025-11-24 01:58:46.873 | INFO     | __main__:<module>:160 - Step59340, Loss: 3.5648865699768066, Grad L2 Norm: 0.022937865927815437
2025-11-24 01:58:48.600 | INFO     | __main__:<module>:160 - Step59350, Loss: 3.4899163246154785, Grad L2 Norm: 0.024344388395547867
2025-11-24 01:58:50.325 | INFO     | __main__:<module>:160 - Step59360, Loss: 3.5355641841888428, Grad L2 Norm: 0.022767281159758568
2025-11-24 01:58:52.042 | INFO     | __main__:<module>:160 - Step59370, Loss: 3.420840263366699, Grad L2 Norm: 0.020787734538316727
2025-11-24 01:58:53.767 | INFO     | __main__:<module>:160 - Step59380, Loss: 3.6245508193969727, Grad L2 Norm: 0.023940587416291237
2025-11-24 01:58:55.483 | INFO     | __main__:<module>:160 - Step59390, Loss: 3.620576858520508, Grad L2 Norm: 0.023772479966282845
2025-11-24 01:58:57.217 | INFO     | __main__:<module>:160 - Step59400, Loss: 3.5752134323120117, Grad L2 Norm: 0.022572362795472145
2025-11-24 01:58:58.936 | INFO     | __main__:<module>:160 - Step59410, Loss: 3.5970382690429688, Grad L2 Norm: 0.024237127974629402
2025-11-24 01:59:00.652 | INFO     | __main__:<module>:160 - Step59420, Loss: 3.6252212524414062, Grad L2 Norm: 0.02279345877468586
2025-11-24 01:59:02.377 | INFO     | __main__:<module>:160 - Step59430, Loss: 3.7332730293273926, Grad L2 Norm: 0.023515574634075165
2025-11-24 01:59:04.105 | INFO     | __main__:<module>:160 - Step59440, Loss: 3.5392727851867676, Grad L2 Norm: 0.024924462661147118
2025-11-24 01:59:05.829 | INFO     | __main__:<module>:160 - Step59450, Loss: 3.6237471103668213, Grad L2 Norm: 0.022586628794670105
2025-11-24 01:59:07.546 | INFO     | __main__:<module>:160 - Step59460, Loss: 3.5357537269592285, Grad L2 Norm: 0.02419016696512699
2025-11-24 01:59:09.260 | INFO     | __main__:<module>:160 - Step59470, Loss: 3.5106310844421387, Grad L2 Norm: 0.02283412218093872
2025-11-24 01:59:10.988 | INFO     | __main__:<module>:160 - Step59480, Loss: 3.5110864639282227, Grad L2 Norm: 0.024764951318502426
2025-11-24 01:59:12.712 | INFO     | __main__:<module>:160 - Step59490, Loss: 3.5217785835266113, Grad L2 Norm: 0.023445308208465576
2025-11-24 01:59:14.440 | INFO     | __main__:<module>:160 - Step59500, Loss: 3.5035758018493652, Grad L2 Norm: 0.023624440655112267
2025-11-24 01:59:16.156 | INFO     | __main__:<module>:160 - Step59510, Loss: 3.5477957725524902, Grad L2 Norm: 0.022877419367432594
2025-11-24 01:59:17.871 | INFO     | __main__:<module>:160 - Step59520, Loss: 3.4768505096435547, Grad L2 Norm: 0.02369622327387333
2025-11-24 01:59:19.607 | INFO     | __main__:<module>:160 - Step59530, Loss: 3.5202770233154297, Grad L2 Norm: 0.0213936697691679
2025-11-24 01:59:21.322 | INFO     | __main__:<module>:160 - Step59540, Loss: 3.571331262588501, Grad L2 Norm: 0.024001525714993477
2025-11-24 01:59:23.047 | INFO     | __main__:<module>:160 - Step59550, Loss: 3.6085867881774902, Grad L2 Norm: 0.022872718051075935
2025-11-24 01:59:24.761 | INFO     | __main__:<module>:160 - Step59560, Loss: 3.46783447265625, Grad L2 Norm: 0.02366253174841404
2025-11-24 01:59:26.486 | INFO     | __main__:<module>:160 - Step59570, Loss: 3.4748120307922363, Grad L2 Norm: 0.022255735471844673
2025-11-24 01:59:28.214 | INFO     | __main__:<module>:160 - Step59580, Loss: 3.6919033527374268, Grad L2 Norm: 0.024319730699062347
2025-11-24 01:59:29.932 | INFO     | __main__:<module>:160 - Step59590, Loss: 3.6134650707244873, Grad L2 Norm: 0.02438361383974552
2025-11-24 01:59:31.657 | INFO     | __main__:<module>:160 - Step59600, Loss: 3.596846580505371, Grad L2 Norm: 0.022433290258049965
2025-11-24 01:59:31.657 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 01:59:32.674 | INFO     | __main__:<module>:181 - validation loss: 3.5322534322738646
2025-11-24 01:59:34.629 | INFO     | __main__:<module>:160 - Step59610, Loss: 3.5897977352142334, Grad L2 Norm: 0.02255466766655445
2025-11-24 01:59:36.671 | INFO     | __main__:<module>:160 - Step59620, Loss: 3.608664035797119, Grad L2 Norm: 0.023296840488910675
2025-11-24 01:59:38.706 | INFO     | __main__:<module>:160 - Step59630, Loss: 3.5945611000061035, Grad L2 Norm: 0.023185284808278084
2025-11-24 01:59:40.737 | INFO     | __main__:<module>:160 - Step59640, Loss: 3.54950213432312, Grad L2 Norm: 0.02331545017659664
2025-11-24 01:59:42.768 | INFO     | __main__:<module>:160 - Step59650, Loss: 3.7486324310302734, Grad L2 Norm: 0.02533360943198204
2025-11-24 01:59:44.800 | INFO     | __main__:<module>:160 - Step59660, Loss: 3.6106081008911133, Grad L2 Norm: 0.022432085126638412
2025-11-24 01:59:46.830 | INFO     | __main__:<module>:160 - Step59670, Loss: 3.480335235595703, Grad L2 Norm: 0.022932274267077446
2025-11-24 01:59:48.858 | INFO     | __main__:<module>:160 - Step59680, Loss: 3.568072557449341, Grad L2 Norm: 0.023001184687018394
2025-11-24 01:59:50.888 | INFO     | __main__:<module>:160 - Step59690, Loss: 3.529259204864502, Grad L2 Norm: 0.023628611117601395
2025-11-24 01:59:52.914 | INFO     | __main__:<module>:160 - Step59700, Loss: 3.6984801292419434, Grad L2 Norm: 0.023499397560954094
2025-11-24 01:59:54.937 | INFO     | __main__:<module>:160 - Step59710, Loss: 3.4989287853240967, Grad L2 Norm: 0.022847836837172508
2025-11-24 01:59:56.957 | INFO     | __main__:<module>:160 - Step59720, Loss: 3.651707172393799, Grad L2 Norm: 0.023099815472960472
2025-11-24 01:59:58.983 | INFO     | __main__:<module>:160 - Step59730, Loss: 3.4413323402404785, Grad L2 Norm: 0.023435400798916817
2025-11-24 02:00:01.004 | INFO     | __main__:<module>:160 - Step59740, Loss: 3.4504079818725586, Grad L2 Norm: 0.022368496283888817
2025-11-24 02:00:03.015 | INFO     | __main__:<module>:160 - Step59750, Loss: 3.5575544834136963, Grad L2 Norm: 0.02491873688995838
2025-11-24 02:00:05.031 | INFO     | __main__:<module>:160 - Step59760, Loss: 3.5103988647460938, Grad L2 Norm: 0.021825267001986504
2025-11-24 02:00:07.046 | INFO     | __main__:<module>:160 - Step59770, Loss: 3.6109962463378906, Grad L2 Norm: 0.021336598321795464
2025-11-24 02:00:09.055 | INFO     | __main__:<module>:160 - Step59780, Loss: 3.594977378845215, Grad L2 Norm: 0.023023072630167007
2025-11-24 02:00:11.065 | INFO     | __main__:<module>:160 - Step59790, Loss: 3.4467382431030273, Grad L2 Norm: 0.022600000724196434
2025-11-24 02:00:13.079 | INFO     | __main__:<module>:160 - Step59800, Loss: 3.5882315635681152, Grad L2 Norm: 0.022784460335969925
2025-11-24 02:00:15.085 | INFO     | __main__:<module>:160 - Step59810, Loss: 3.447220802307129, Grad L2 Norm: 0.024235576391220093
2025-11-24 02:00:17.088 | INFO     | __main__:<module>:160 - Step59820, Loss: 3.5619425773620605, Grad L2 Norm: 0.022751905024051666
2025-11-24 02:00:19.096 | INFO     | __main__:<module>:160 - Step59830, Loss: 3.497004985809326, Grad L2 Norm: 0.021254083141684532
2025-11-24 02:00:21.102 | INFO     | __main__:<module>:160 - Step59840, Loss: 3.746715784072876, Grad L2 Norm: 0.024943768978118896
2025-11-24 02:00:23.105 | INFO     | __main__:<module>:160 - Step59850, Loss: 3.633120536804199, Grad L2 Norm: 0.024050762876868248
2025-11-24 02:00:25.105 | INFO     | __main__:<module>:160 - Step59860, Loss: 3.5503945350646973, Grad L2 Norm: 0.024315671995282173
2025-11-24 02:00:27.100 | INFO     | __main__:<module>:160 - Step59870, Loss: 3.558138370513916, Grad L2 Norm: 0.023726850748062134
2025-11-24 02:00:29.096 | INFO     | __main__:<module>:160 - Step59880, Loss: 3.4772262573242188, Grad L2 Norm: 0.022314224392175674
2025-11-24 02:00:31.094 | INFO     | __main__:<module>:160 - Step59890, Loss: 3.574068546295166, Grad L2 Norm: 0.022382786497473717
2025-11-24 02:00:33.093 | INFO     | __main__:<module>:160 - Step59900, Loss: 3.5432279109954834, Grad L2 Norm: 0.022333452478051186
2025-11-24 02:00:35.095 | INFO     | __main__:<module>:160 - Step59910, Loss: 3.511915445327759, Grad L2 Norm: 0.02261786162853241
2025-11-24 02:00:37.093 | INFO     | __main__:<module>:160 - Step59920, Loss: 3.493091583251953, Grad L2 Norm: 0.021615346893668175
2025-11-24 02:00:39.093 | INFO     | __main__:<module>:160 - Step59930, Loss: 3.5433478355407715, Grad L2 Norm: 0.023376768454909325
2025-11-24 02:00:41.091 | INFO     | __main__:<module>:160 - Step59940, Loss: 3.6174159049987793, Grad L2 Norm: 0.024652307853102684
2025-11-24 02:00:43.091 | INFO     | __main__:<module>:160 - Step59950, Loss: 3.57472562789917, Grad L2 Norm: 0.026296252384781837
2025-11-24 02:00:45.090 | INFO     | __main__:<module>:160 - Step59960, Loss: 3.5669422149658203, Grad L2 Norm: 0.023237284272909164
2025-11-24 02:00:47.091 | INFO     | __main__:<module>:160 - Step59970, Loss: 3.6617531776428223, Grad L2 Norm: 0.02299950085580349
2025-11-24 02:00:49.089 | INFO     | __main__:<module>:160 - Step59980, Loss: 3.5134944915771484, Grad L2 Norm: 0.02276938408613205
2025-11-24 02:00:51.087 | INFO     | __main__:<module>:160 - Step59990, Loss: 3.6401162147521973, Grad L2 Norm: 0.024957403540611267
2025-11-24 02:00:53.086 | INFO     | __main__:<module>:160 - Step60000, Loss: 3.5081002712249756, Grad L2 Norm: 0.025578448548913002
2025-11-24 02:00:53.086 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:00:54.354 | INFO     | __main__:<module>:181 - validation loss: 3.5554558753967287
2025-11-24 02:00:54.355 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_60000.pt
2025-11-24 02:00:56.047 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 02:00:58.013 | INFO     | __main__:<module>:160 - Step60010, Loss: 3.5275192260742188, Grad L2 Norm: 0.023580627515912056
2025-11-24 02:01:00.000 | INFO     | __main__:<module>:160 - Step60020, Loss: 3.5412325859069824, Grad L2 Norm: 0.02208167314529419
2025-11-24 02:01:01.985 | INFO     | __main__:<module>:160 - Step60030, Loss: 3.5988874435424805, Grad L2 Norm: 0.022649623453617096
2025-11-24 02:01:03.968 | INFO     | __main__:<module>:160 - Step60040, Loss: 3.500471591949463, Grad L2 Norm: 0.022990632802248
2025-11-24 02:01:05.947 | INFO     | __main__:<module>:160 - Step60050, Loss: 3.6272621154785156, Grad L2 Norm: 0.024214688688516617
2025-11-24 02:01:07.933 | INFO     | __main__:<module>:160 - Step60060, Loss: 3.5010738372802734, Grad L2 Norm: 0.024158602580428123
2025-11-24 02:01:09.919 | INFO     | __main__:<module>:160 - Step60070, Loss: 3.6238534450531006, Grad L2 Norm: 0.022908015176653862
2025-11-24 02:01:11.902 | INFO     | __main__:<module>:160 - Step60080, Loss: 3.4047248363494873, Grad L2 Norm: 0.022208435460925102
2025-11-24 02:01:13.892 | INFO     | __main__:<module>:160 - Step60090, Loss: 3.521244764328003, Grad L2 Norm: 0.022674154490232468
2025-11-24 02:01:15.879 | INFO     | __main__:<module>:160 - Step60100, Loss: 3.503434896469116, Grad L2 Norm: 0.022246411070227623
2025-11-24 02:01:17.866 | INFO     | __main__:<module>:160 - Step60110, Loss: 3.634185791015625, Grad L2 Norm: 0.023977596312761307
2025-11-24 02:01:19.853 | INFO     | __main__:<module>:160 - Step60120, Loss: 3.496793270111084, Grad L2 Norm: 0.02271084301173687
2025-11-24 02:01:21.842 | INFO     | __main__:<module>:160 - Step60130, Loss: 3.607248544692993, Grad L2 Norm: 0.023164182901382446
2025-11-24 02:01:23.826 | INFO     | __main__:<module>:160 - Step60140, Loss: 3.627673625946045, Grad L2 Norm: 0.02276819385588169
2025-11-24 02:01:25.812 | INFO     | __main__:<module>:160 - Step60150, Loss: 3.5392091274261475, Grad L2 Norm: 0.024576226249337196
2025-11-24 02:01:27.801 | INFO     | __main__:<module>:160 - Step60160, Loss: 3.4532432556152344, Grad L2 Norm: 0.023047130554914474
2025-11-24 02:01:29.793 | INFO     | __main__:<module>:160 - Step60170, Loss: 3.5452442169189453, Grad L2 Norm: 0.02270795777440071
2025-11-24 02:01:31.785 | INFO     | __main__:<module>:160 - Step60180, Loss: 3.622357130050659, Grad L2 Norm: 0.02476034127175808
2025-11-24 02:01:33.772 | INFO     | __main__:<module>:160 - Step60190, Loss: 3.6757616996765137, Grad L2 Norm: 0.024989141151309013
2025-11-24 02:01:35.761 | INFO     | __main__:<module>:160 - Step60200, Loss: 3.4810855388641357, Grad L2 Norm: 0.02166736125946045
2025-11-24 02:01:37.752 | INFO     | __main__:<module>:160 - Step60210, Loss: 3.395339012145996, Grad L2 Norm: 0.023484384641051292
2025-11-24 02:01:39.738 | INFO     | __main__:<module>:160 - Step60220, Loss: 3.6890501976013184, Grad L2 Norm: 0.022138183936476707
2025-11-24 02:01:41.728 | INFO     | __main__:<module>:160 - Step60230, Loss: 3.5937795639038086, Grad L2 Norm: 0.021311230957508087
2025-11-24 02:01:43.713 | INFO     | __main__:<module>:160 - Step60240, Loss: 3.617197275161743, Grad L2 Norm: 0.02457638829946518
2025-11-24 02:01:45.701 | INFO     | __main__:<module>:160 - Step60250, Loss: 3.463907241821289, Grad L2 Norm: 0.023522499948740005
2025-11-24 02:01:47.689 | INFO     | __main__:<module>:160 - Step60260, Loss: 3.561997890472412, Grad L2 Norm: 0.021841736510396004
2025-11-24 02:01:49.682 | INFO     | __main__:<module>:160 - Step60270, Loss: 3.4646341800689697, Grad L2 Norm: 0.02359645999968052
2025-11-24 02:01:51.670 | INFO     | __main__:<module>:160 - Step60280, Loss: 3.6213834285736084, Grad L2 Norm: 0.023827360942959785
2025-11-24 02:01:53.664 | INFO     | __main__:<module>:160 - Step60290, Loss: 3.52522611618042, Grad L2 Norm: 0.02156318724155426
2025-11-24 02:01:55.656 | INFO     | __main__:<module>:160 - Step60300, Loss: 3.5886151790618896, Grad L2 Norm: 0.0218124371021986
2025-11-24 02:01:57.644 | INFO     | __main__:<module>:160 - Step60310, Loss: 3.5792887210845947, Grad L2 Norm: 0.02692708931863308
2025-11-24 02:01:59.639 | INFO     | __main__:<module>:160 - Step60320, Loss: 3.578427791595459, Grad L2 Norm: 0.022575857117772102
2025-11-24 02:02:01.630 | INFO     | __main__:<module>:160 - Step60330, Loss: 3.684361457824707, Grad L2 Norm: 0.023649808019399643
2025-11-24 02:02:03.623 | INFO     | __main__:<module>:160 - Step60340, Loss: 3.6717159748077393, Grad L2 Norm: 0.024149425327777863
2025-11-24 02:02:05.608 | INFO     | __main__:<module>:160 - Step60350, Loss: 3.4603307247161865, Grad L2 Norm: 0.021636269986629486
2025-11-24 02:02:07.594 | INFO     | __main__:<module>:160 - Step60360, Loss: 3.5863845348358154, Grad L2 Norm: 0.022846827283501625
2025-11-24 02:02:09.581 | INFO     | __main__:<module>:160 - Step60370, Loss: 3.7515430450439453, Grad L2 Norm: 0.026629161089658737
2025-11-24 02:02:11.561 | INFO     | __main__:<module>:160 - Step60380, Loss: 3.6070594787597656, Grad L2 Norm: 0.023931242525577545
2025-11-24 02:02:13.546 | INFO     | __main__:<module>:160 - Step60390, Loss: 3.651200771331787, Grad L2 Norm: 0.02392188459634781
2025-11-24 02:02:15.533 | INFO     | __main__:<module>:160 - Step60400, Loss: 3.618222713470459, Grad L2 Norm: 0.02339906059205532
2025-11-24 02:02:15.533 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:02:16.792 | INFO     | __main__:<module>:181 - validation loss: 3.5797140121459963
2025-11-24 02:02:18.793 | INFO     | __main__:<module>:160 - Step60410, Loss: 3.457979679107666, Grad L2 Norm: 0.02234734781086445
2025-11-24 02:02:20.777 | INFO     | __main__:<module>:160 - Step60420, Loss: 3.4515085220336914, Grad L2 Norm: 0.022522030398249626
2025-11-24 02:02:22.764 | INFO     | __main__:<module>:160 - Step60430, Loss: 3.5381765365600586, Grad L2 Norm: 0.021536992862820625
2025-11-24 02:02:24.751 | INFO     | __main__:<module>:160 - Step60440, Loss: 3.5063583850860596, Grad L2 Norm: 0.022565986961126328
2025-11-24 02:02:26.735 | INFO     | __main__:<module>:160 - Step60450, Loss: 3.538682460784912, Grad L2 Norm: 0.022939326241612434
2025-11-24 02:02:28.721 | INFO     | __main__:<module>:160 - Step60460, Loss: 3.58896541595459, Grad L2 Norm: 0.02414667047560215
2025-11-24 02:02:30.708 | INFO     | __main__:<module>:160 - Step60470, Loss: 3.5597102642059326, Grad L2 Norm: 0.02201920934021473
2025-11-24 02:02:32.693 | INFO     | __main__:<module>:160 - Step60480, Loss: 3.5910189151763916, Grad L2 Norm: 0.023447055369615555
2025-11-24 02:02:34.676 | INFO     | __main__:<module>:160 - Step60490, Loss: 3.7092161178588867, Grad L2 Norm: 0.02453860267996788
2025-11-24 02:02:36.666 | INFO     | __main__:<module>:160 - Step60500, Loss: 3.6504149436950684, Grad L2 Norm: 0.022050850093364716
2025-11-24 02:02:38.652 | INFO     | __main__:<module>:160 - Step60510, Loss: 3.5940487384796143, Grad L2 Norm: 0.02423792891204357
2025-11-24 02:02:40.640 | INFO     | __main__:<module>:160 - Step60520, Loss: 3.5494885444641113, Grad L2 Norm: 0.023970240727066994
2025-11-24 02:02:42.631 | INFO     | __main__:<module>:160 - Step60530, Loss: 3.5776288509368896, Grad L2 Norm: 0.02416227012872696
2025-11-24 02:02:44.630 | INFO     | __main__:<module>:160 - Step60540, Loss: 3.606130599975586, Grad L2 Norm: 0.022947141900658607
2025-11-24 02:02:46.620 | INFO     | __main__:<module>:160 - Step60550, Loss: 3.6522223949432373, Grad L2 Norm: 0.023092983290553093
2025-11-24 02:02:48.610 | INFO     | __main__:<module>:160 - Step60560, Loss: 3.5938169956207275, Grad L2 Norm: 0.023300087079405785
2025-11-24 02:02:50.594 | INFO     | __main__:<module>:160 - Step60570, Loss: 3.551238775253296, Grad L2 Norm: 0.022903060540556908
2025-11-24 02:02:52.582 | INFO     | __main__:<module>:160 - Step60580, Loss: 3.4507713317871094, Grad L2 Norm: 0.022813282907009125
2025-11-24 02:02:54.566 | INFO     | __main__:<module>:160 - Step60590, Loss: 3.5289969444274902, Grad L2 Norm: 0.023195456713438034
2025-11-24 02:02:56.547 | INFO     | __main__:<module>:160 - Step60600, Loss: 3.6917543411254883, Grad L2 Norm: 0.02534271590411663
2025-11-24 02:02:58.533 | INFO     | __main__:<module>:160 - Step60610, Loss: 3.5748941898345947, Grad L2 Norm: 0.02266141027212143
2025-11-24 02:03:00.523 | INFO     | __main__:<module>:160 - Step60620, Loss: 3.7090988159179688, Grad L2 Norm: 0.023159252479672432
2025-11-24 02:03:02.505 | INFO     | __main__:<module>:160 - Step60630, Loss: 3.611077308654785, Grad L2 Norm: 0.023267747834324837
2025-11-24 02:03:04.485 | INFO     | __main__:<module>:160 - Step60640, Loss: 3.4363410472869873, Grad L2 Norm: 0.022027138620615005
2025-11-24 02:03:06.465 | INFO     | __main__:<module>:160 - Step60650, Loss: 3.451809883117676, Grad L2 Norm: 0.02218892052769661
2025-11-24 02:03:08.444 | INFO     | __main__:<module>:160 - Step60660, Loss: 3.556015968322754, Grad L2 Norm: 0.021494979038834572
2025-11-24 02:03:10.428 | INFO     | __main__:<module>:160 - Step60670, Loss: 3.6195244789123535, Grad L2 Norm: 0.025355372577905655
2025-11-24 02:03:12.408 | INFO     | __main__:<module>:160 - Step60680, Loss: 3.591139793395996, Grad L2 Norm: 0.024198679253458977
2025-11-24 02:03:14.386 | INFO     | __main__:<module>:160 - Step60690, Loss: 3.534827709197998, Grad L2 Norm: 0.022360246628522873
2025-11-24 02:03:16.365 | INFO     | __main__:<module>:160 - Step60700, Loss: 3.6334574222564697, Grad L2 Norm: 0.022815681993961334
2025-11-24 02:03:18.337 | INFO     | __main__:<module>:160 - Step60710, Loss: 3.4277212619781494, Grad L2 Norm: 0.023038657382130623
2025-11-24 02:03:20.313 | INFO     | __main__:<module>:160 - Step60720, Loss: 3.495985507965088, Grad L2 Norm: 0.021534770727157593
2025-11-24 02:03:22.284 | INFO     | __main__:<module>:160 - Step60730, Loss: 3.459566831588745, Grad L2 Norm: 0.02256377600133419
2025-11-24 02:03:24.260 | INFO     | __main__:<module>:160 - Step60740, Loss: 3.4552106857299805, Grad L2 Norm: 0.021605487912893295
2025-11-24 02:03:26.238 | INFO     | __main__:<module>:160 - Step60750, Loss: 3.586984395980835, Grad L2 Norm: 0.023393187671899796
2025-11-24 02:03:28.215 | INFO     | __main__:<module>:160 - Step60760, Loss: 3.4316532611846924, Grad L2 Norm: 0.02417130209505558
2025-11-24 02:03:30.188 | INFO     | __main__:<module>:160 - Step60770, Loss: 3.6368799209594727, Grad L2 Norm: 0.02240859717130661
2025-11-24 02:03:32.157 | INFO     | __main__:<module>:160 - Step60780, Loss: 3.590625286102295, Grad L2 Norm: 0.022990429773926735
2025-11-24 02:03:34.135 | INFO     | __main__:<module>:160 - Step60790, Loss: 3.5854299068450928, Grad L2 Norm: 0.02217988856136799
2025-11-24 02:03:36.108 | INFO     | __main__:<module>:160 - Step60800, Loss: 3.5390548706054688, Grad L2 Norm: 0.022482462227344513
2025-11-24 02:03:36.108 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:03:37.363 | INFO     | __main__:<module>:181 - validation loss: 3.5664006233215333
2025-11-24 02:03:39.351 | INFO     | __main__:<module>:160 - Step60810, Loss: 3.350606918334961, Grad L2 Norm: 0.023917527869343758
2025-11-24 02:03:41.332 | INFO     | __main__:<module>:160 - Step60820, Loss: 3.5510830879211426, Grad L2 Norm: 0.022710159420967102
2025-11-24 02:03:43.313 | INFO     | __main__:<module>:160 - Step60830, Loss: 3.588906764984131, Grad L2 Norm: 0.0226394385099411
2025-11-24 02:03:45.300 | INFO     | __main__:<module>:160 - Step60840, Loss: 3.6107544898986816, Grad L2 Norm: 0.022842876613140106
2025-11-24 02:03:47.278 | INFO     | __main__:<module>:160 - Step60850, Loss: 3.6305150985717773, Grad L2 Norm: 0.02345995232462883
2025-11-24 02:03:49.267 | INFO     | __main__:<module>:160 - Step60860, Loss: 3.4950926303863525, Grad L2 Norm: 0.023909185081720352
2025-11-24 02:03:51.249 | INFO     | __main__:<module>:160 - Step60870, Loss: 3.453138828277588, Grad L2 Norm: 0.023270005360245705
2025-11-24 02:03:53.232 | INFO     | __main__:<module>:160 - Step60880, Loss: 3.478992223739624, Grad L2 Norm: 0.022116420790553093
2025-11-24 02:03:55.210 | INFO     | __main__:<module>:160 - Step60890, Loss: 3.651338577270508, Grad L2 Norm: 0.023189712315797806
2025-11-24 02:03:57.189 | INFO     | __main__:<module>:160 - Step60900, Loss: 3.5405826568603516, Grad L2 Norm: 0.025160936638712883
2025-11-24 02:03:59.168 | INFO     | __main__:<module>:160 - Step60910, Loss: 3.474148750305176, Grad L2 Norm: 0.02281920053064823
2025-11-24 02:04:01.147 | INFO     | __main__:<module>:160 - Step60920, Loss: 3.657635450363159, Grad L2 Norm: 0.026553811505436897
2025-11-24 02:04:03.131 | INFO     | __main__:<module>:160 - Step60930, Loss: 3.613438606262207, Grad L2 Norm: 0.022527148947119713
2025-11-24 02:04:05.114 | INFO     | __main__:<module>:160 - Step60940, Loss: 3.5727901458740234, Grad L2 Norm: 0.020733816549181938
2025-11-24 02:04:07.099 | INFO     | __main__:<module>:160 - Step60950, Loss: 3.485508441925049, Grad L2 Norm: 0.021836115047335625
2025-11-24 02:04:09.083 | INFO     | __main__:<module>:160 - Step60960, Loss: 3.531785011291504, Grad L2 Norm: 0.022888442501425743
2025-11-24 02:04:11.058 | INFO     | __main__:<module>:160 - Step60970, Loss: 3.5148086547851562, Grad L2 Norm: 0.02215714566409588
2025-11-24 02:04:13.040 | INFO     | __main__:<module>:160 - Step60980, Loss: 3.5512540340423584, Grad L2 Norm: 0.022530248388648033
2025-11-24 02:04:15.017 | INFO     | __main__:<module>:160 - Step60990, Loss: 3.4037222862243652, Grad L2 Norm: 0.023693036288022995
2025-11-24 02:04:16.993 | INFO     | __main__:<module>:160 - Step61000, Loss: 3.586027145385742, Grad L2 Norm: 0.021780943498015404
2025-11-24 02:04:18.964 | INFO     | __main__:<module>:160 - Step61010, Loss: 3.543766975402832, Grad L2 Norm: 0.02326982282102108
2025-11-24 02:04:20.941 | INFO     | __main__:<module>:160 - Step61020, Loss: 3.5369858741760254, Grad L2 Norm: 0.02637774497270584
2025-11-24 02:04:22.914 | INFO     | __main__:<module>:160 - Step61030, Loss: 3.6453676223754883, Grad L2 Norm: 0.027521388605237007
2025-11-24 02:04:24.891 | INFO     | __main__:<module>:160 - Step61040, Loss: 3.415040969848633, Grad L2 Norm: 0.021343011409044266
2025-11-24 02:04:26.866 | INFO     | __main__:<module>:160 - Step61050, Loss: 3.599119186401367, Grad L2 Norm: 0.02347862347960472
2025-11-24 02:04:28.847 | INFO     | __main__:<module>:160 - Step61060, Loss: 3.5411789417266846, Grad L2 Norm: 0.02141937054693699
2025-11-24 02:04:30.822 | INFO     | __main__:<module>:160 - Step61070, Loss: 3.5840811729431152, Grad L2 Norm: 0.023915382102131844
2025-11-24 02:04:32.799 | INFO     | __main__:<module>:160 - Step61080, Loss: 3.539168119430542, Grad L2 Norm: 0.023404564708471298
2025-11-24 02:04:34.777 | INFO     | __main__:<module>:160 - Step61090, Loss: 3.638205051422119, Grad L2 Norm: 0.02283116616308689
2025-11-24 02:04:36.755 | INFO     | __main__:<module>:160 - Step61100, Loss: 3.7034049034118652, Grad L2 Norm: 0.023476503789424896
2025-11-24 02:04:38.732 | INFO     | __main__:<module>:160 - Step61110, Loss: 3.623779773712158, Grad L2 Norm: 0.023849032819271088
2025-11-24 02:04:40.705 | INFO     | __main__:<module>:160 - Step61120, Loss: 3.5226316452026367, Grad L2 Norm: 0.0220134649425745
2025-11-24 02:04:42.679 | INFO     | __main__:<module>:160 - Step61130, Loss: 3.4254183769226074, Grad L2 Norm: 0.023376187309622765
2025-11-24 02:04:44.648 | INFO     | __main__:<module>:160 - Step61140, Loss: 3.5021157264709473, Grad L2 Norm: 0.023363405838608742
2025-11-24 02:04:46.616 | INFO     | __main__:<module>:160 - Step61150, Loss: 3.5412111282348633, Grad L2 Norm: 0.02313360944390297
2025-11-24 02:04:48.586 | INFO     | __main__:<module>:160 - Step61160, Loss: 3.715517282485962, Grad L2 Norm: 0.023034051060676575
2025-11-24 02:04:50.554 | INFO     | __main__:<module>:160 - Step61170, Loss: 3.5459609031677246, Grad L2 Norm: 0.02283211424946785
2025-11-24 02:04:52.524 | INFO     | __main__:<module>:160 - Step61180, Loss: 3.5633528232574463, Grad L2 Norm: 0.022244716063141823
2025-11-24 02:04:54.491 | INFO     | __main__:<module>:160 - Step61190, Loss: 3.561479091644287, Grad L2 Norm: 0.025681527331471443
2025-11-24 02:04:56.464 | INFO     | __main__:<module>:160 - Step61200, Loss: 3.5670571327209473, Grad L2 Norm: 0.022808585315942764
2025-11-24 02:04:56.465 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:04:57.714 | INFO     | __main__:<module>:181 - validation loss: 3.5654531598091124
2025-11-24 02:04:59.693 | INFO     | __main__:<module>:160 - Step61210, Loss: 3.5179195404052734, Grad L2 Norm: 0.023295510560274124
2025-11-24 02:05:01.667 | INFO     | __main__:<module>:160 - Step61220, Loss: 3.5437612533569336, Grad L2 Norm: 0.021914521232247353
2025-11-24 02:05:03.634 | INFO     | __main__:<module>:160 - Step61230, Loss: 3.429675340652466, Grad L2 Norm: 0.02215605042874813
2025-11-24 02:05:05.606 | INFO     | __main__:<module>:160 - Step61240, Loss: 3.6157326698303223, Grad L2 Norm: 0.02322535403072834
2025-11-24 02:05:07.573 | INFO     | __main__:<module>:160 - Step61250, Loss: 3.797734260559082, Grad L2 Norm: 0.02395557425916195
2025-11-24 02:05:09.543 | INFO     | __main__:<module>:160 - Step61260, Loss: 3.568572521209717, Grad L2 Norm: 0.021716173738241196
2025-11-24 02:05:11.508 | INFO     | __main__:<module>:160 - Step61270, Loss: 3.632061004638672, Grad L2 Norm: 0.025202784687280655
2025-11-24 02:05:13.478 | INFO     | __main__:<module>:160 - Step61280, Loss: 3.5282557010650635, Grad L2 Norm: 0.023624124005436897
2025-11-24 02:05:15.442 | INFO     | __main__:<module>:160 - Step61290, Loss: 3.5920982360839844, Grad L2 Norm: 0.022062502801418304
2025-11-24 02:05:17.404 | INFO     | __main__:<module>:160 - Step61300, Loss: 3.5290579795837402, Grad L2 Norm: 0.02307412400841713
2025-11-24 02:05:19.366 | INFO     | __main__:<module>:160 - Step61310, Loss: 3.5951077938079834, Grad L2 Norm: 0.02519633248448372
2025-11-24 02:05:21.333 | INFO     | __main__:<module>:160 - Step61320, Loss: 3.516556739807129, Grad L2 Norm: 0.021639641374349594
2025-11-24 02:05:23.300 | INFO     | __main__:<module>:160 - Step61330, Loss: 3.5586302280426025, Grad L2 Norm: 0.022897828370332718
2025-11-24 02:05:25.267 | INFO     | __main__:<module>:160 - Step61340, Loss: 3.4964847564697266, Grad L2 Norm: 0.02265699952840805
2025-11-24 02:05:27.241 | INFO     | __main__:<module>:160 - Step61350, Loss: 3.491392135620117, Grad L2 Norm: 0.021819623187184334
2025-11-24 02:05:29.216 | INFO     | __main__:<module>:160 - Step61360, Loss: 3.5826199054718018, Grad L2 Norm: 0.022462261840701103
2025-11-24 02:05:31.184 | INFO     | __main__:<module>:160 - Step61370, Loss: 3.4648518562316895, Grad L2 Norm: 0.022503862157464027
2025-11-24 02:05:33.152 | INFO     | __main__:<module>:160 - Step61380, Loss: 3.4451305866241455, Grad L2 Norm: 0.02248353883624077
2025-11-24 02:05:35.118 | INFO     | __main__:<module>:160 - Step61390, Loss: 3.5762221813201904, Grad L2 Norm: 0.023136679083108902
2025-11-24 02:05:37.091 | INFO     | __main__:<module>:160 - Step61400, Loss: 3.5136494636535645, Grad L2 Norm: 0.021717507392168045
2025-11-24 02:05:39.056 | INFO     | __main__:<module>:160 - Step61410, Loss: 3.4981470108032227, Grad L2 Norm: 0.02237023040652275
2025-11-24 02:05:41.022 | INFO     | __main__:<module>:160 - Step61420, Loss: 3.486264228820801, Grad L2 Norm: 0.02151424065232277
2025-11-24 02:05:42.993 | INFO     | __main__:<module>:160 - Step61430, Loss: 3.670795440673828, Grad L2 Norm: 0.02416285127401352
2025-11-24 02:05:44.956 | INFO     | __main__:<module>:160 - Step61440, Loss: 3.512725830078125, Grad L2 Norm: 0.024218512699007988
2025-11-24 02:05:46.925 | INFO     | __main__:<module>:160 - Step61450, Loss: 3.5600526332855225, Grad L2 Norm: 0.022861741483211517
2025-11-24 02:05:48.895 | INFO     | __main__:<module>:160 - Step61460, Loss: 3.7457237243652344, Grad L2 Norm: 0.025131437927484512
2025-11-24 02:05:50.866 | INFO     | __main__:<module>:160 - Step61470, Loss: 3.5841526985168457, Grad L2 Norm: 0.023906202986836433
2025-11-24 02:05:52.834 | INFO     | __main__:<module>:160 - Step61480, Loss: 3.5574989318847656, Grad L2 Norm: 0.02263292297720909
2025-11-24 02:05:54.805 | INFO     | __main__:<module>:160 - Step61490, Loss: 3.43632435798645, Grad L2 Norm: 0.02157089300453663
2025-11-24 02:05:56.774 | INFO     | __main__:<module>:160 - Step61500, Loss: 3.5638346672058105, Grad L2 Norm: 0.02280132658779621
2025-11-24 02:05:58.742 | INFO     | __main__:<module>:160 - Step61510, Loss: 3.688725471496582, Grad L2 Norm: 0.023859869688749313
2025-11-24 02:06:00.708 | INFO     | __main__:<module>:160 - Step61520, Loss: 3.5429229736328125, Grad L2 Norm: 0.022065868601202965
2025-11-24 02:06:02.675 | INFO     | __main__:<module>:160 - Step61530, Loss: 3.532174587249756, Grad L2 Norm: 0.022916598245501518
2025-11-24 02:06:04.642 | INFO     | __main__:<module>:160 - Step61540, Loss: 3.5342836380004883, Grad L2 Norm: 0.02319004200398922
2025-11-24 02:06:06.609 | INFO     | __main__:<module>:160 - Step61550, Loss: 3.5357165336608887, Grad L2 Norm: 0.022273030132055283
2025-11-24 02:06:08.576 | INFO     | __main__:<module>:160 - Step61560, Loss: 3.516401767730713, Grad L2 Norm: 0.022052424028515816
2025-11-24 02:06:10.544 | INFO     | __main__:<module>:160 - Step61570, Loss: 3.4180383682250977, Grad L2 Norm: 0.02422577142715454
2025-11-24 02:06:12.507 | INFO     | __main__:<module>:160 - Step61580, Loss: 3.512089252471924, Grad L2 Norm: 0.02344483695924282
2025-11-24 02:06:14.471 | INFO     | __main__:<module>:160 - Step61590, Loss: 3.5414159297943115, Grad L2 Norm: 0.02332635410130024
2025-11-24 02:06:16.442 | INFO     | __main__:<module>:160 - Step61600, Loss: 3.512211799621582, Grad L2 Norm: 0.023644421249628067
2025-11-24 02:06:16.442 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:06:17.690 | INFO     | __main__:<module>:181 - validation loss: 3.547378325462341
2025-11-24 02:06:19.670 | INFO     | __main__:<module>:160 - Step61610, Loss: 3.4787349700927734, Grad L2 Norm: 0.021767910569906235
2025-11-24 02:06:21.643 | INFO     | __main__:<module>:160 - Step61620, Loss: 3.526139497756958, Grad L2 Norm: 0.021910231560468674
2025-11-24 02:06:23.613 | INFO     | __main__:<module>:160 - Step61630, Loss: 3.47674298286438, Grad L2 Norm: 0.022535214200615883
2025-11-24 02:06:25.583 | INFO     | __main__:<module>:160 - Step61640, Loss: 3.523502826690674, Grad L2 Norm: 0.02268976718187332
2025-11-24 02:06:27.556 | INFO     | __main__:<module>:160 - Step61650, Loss: 3.465914249420166, Grad L2 Norm: 0.02340850979089737
2025-11-24 02:06:29.523 | INFO     | __main__:<module>:160 - Step61660, Loss: 3.501866340637207, Grad L2 Norm: 0.023433858528733253
2025-11-24 02:06:31.489 | INFO     | __main__:<module>:160 - Step61670, Loss: 3.361827850341797, Grad L2 Norm: 0.0239222664386034
2025-11-24 02:06:33.460 | INFO     | __main__:<module>:160 - Step61680, Loss: 3.584486722946167, Grad L2 Norm: 0.021758263930678368
2025-11-24 02:06:35.429 | INFO     | __main__:<module>:160 - Step61690, Loss: 3.6909260749816895, Grad L2 Norm: 0.023733381181955338
2025-11-24 02:06:37.396 | INFO     | __main__:<module>:160 - Step61700, Loss: 3.5233614444732666, Grad L2 Norm: 0.02205067314207554
2025-11-24 02:06:39.359 | INFO     | __main__:<module>:160 - Step61710, Loss: 3.5025792121887207, Grad L2 Norm: 0.022716617211699486
2025-11-24 02:06:41.326 | INFO     | __main__:<module>:160 - Step61720, Loss: 3.6474571228027344, Grad L2 Norm: 0.0226263627409935
2025-11-24 02:06:43.296 | INFO     | __main__:<module>:160 - Step61730, Loss: 3.4398248195648193, Grad L2 Norm: 0.024045070633292198
2025-11-24 02:06:45.268 | INFO     | __main__:<module>:160 - Step61740, Loss: 3.567910671234131, Grad L2 Norm: 0.02313569374382496
2025-11-24 02:06:47.238 | INFO     | __main__:<module>:160 - Step61750, Loss: 3.531602382659912, Grad L2 Norm: 0.02237461879849434
2025-11-24 02:06:49.213 | INFO     | __main__:<module>:160 - Step61760, Loss: 3.5604043006896973, Grad L2 Norm: 0.022891782224178314
2025-11-24 02:06:51.183 | INFO     | __main__:<module>:160 - Step61770, Loss: 3.6604628562927246, Grad L2 Norm: 0.023630807176232338
2025-11-24 02:06:53.158 | INFO     | __main__:<module>:160 - Step61780, Loss: 3.5375189781188965, Grad L2 Norm: 0.02267332747578621
2025-11-24 02:06:55.133 | INFO     | __main__:<module>:160 - Step61790, Loss: 3.5770649909973145, Grad L2 Norm: 0.022973988205194473
2025-11-24 02:06:57.105 | INFO     | __main__:<module>:160 - Step61800, Loss: 3.458855628967285, Grad L2 Norm: 0.022440830245614052
2025-11-24 02:06:59.075 | INFO     | __main__:<module>:160 - Step61810, Loss: 3.5558319091796875, Grad L2 Norm: 0.02205250784754753
2025-11-24 02:07:01.045 | INFO     | __main__:<module>:160 - Step61820, Loss: 3.52469801902771, Grad L2 Norm: 0.022454695776104927
2025-11-24 02:07:03.010 | INFO     | __main__:<module>:160 - Step61830, Loss: 3.505098342895508, Grad L2 Norm: 0.021352265030145645
2025-11-24 02:07:04.975 | INFO     | __main__:<module>:160 - Step61840, Loss: 3.6679396629333496, Grad L2 Norm: 0.023513220250606537
2025-11-24 02:07:06.947 | INFO     | __main__:<module>:160 - Step61850, Loss: 3.4958975315093994, Grad L2 Norm: 0.0224264245480299
2025-11-24 02:07:08.909 | INFO     | __main__:<module>:160 - Step61860, Loss: 3.5763370990753174, Grad L2 Norm: 0.02262083999812603
2025-11-24 02:07:10.883 | INFO     | __main__:<module>:160 - Step61870, Loss: 3.5038232803344727, Grad L2 Norm: 0.02269759215414524
2025-11-24 02:07:12.846 | INFO     | __main__:<module>:160 - Step61880, Loss: 3.7072227001190186, Grad L2 Norm: 0.02353464998304844
2025-11-24 02:07:14.806 | INFO     | __main__:<module>:160 - Step61890, Loss: 3.6035923957824707, Grad L2 Norm: 0.0228573065251112
2025-11-24 02:07:16.772 | INFO     | __main__:<module>:160 - Step61900, Loss: 3.5335237979888916, Grad L2 Norm: 0.02547299861907959
2025-11-24 02:07:18.735 | INFO     | __main__:<module>:160 - Step61910, Loss: 3.501915454864502, Grad L2 Norm: 0.02352564036846161
2025-11-24 02:07:20.700 | INFO     | __main__:<module>:160 - Step61920, Loss: 3.5547871589660645, Grad L2 Norm: 0.020512057468295097
2025-11-24 02:07:22.664 | INFO     | __main__:<module>:160 - Step61930, Loss: 3.491560459136963, Grad L2 Norm: 0.021917754784226418
2025-11-24 02:07:24.623 | INFO     | __main__:<module>:160 - Step61940, Loss: 3.5482804775238037, Grad L2 Norm: 0.022983258590102196
2025-11-24 02:07:26.595 | INFO     | __main__:<module>:160 - Step61950, Loss: 3.543929100036621, Grad L2 Norm: 0.02345896326005459
2025-11-24 02:07:28.563 | INFO     | __main__:<module>:160 - Step61960, Loss: 3.6794161796569824, Grad L2 Norm: 0.022699549794197083
2025-11-24 02:07:30.529 | INFO     | __main__:<module>:160 - Step61970, Loss: 3.513688325881958, Grad L2 Norm: 0.022902624681591988
2025-11-24 02:07:32.492 | INFO     | __main__:<module>:160 - Step61980, Loss: 3.5782790184020996, Grad L2 Norm: 0.0238882377743721
2025-11-24 02:07:34.457 | INFO     | __main__:<module>:160 - Step61990, Loss: 3.6794862747192383, Grad L2 Norm: 0.024897228926420212
2025-11-24 02:07:36.419 | INFO     | __main__:<module>:160 - Step62000, Loss: 3.476926565170288, Grad L2 Norm: 0.02478954941034317
2025-11-24 02:07:36.420 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:07:37.666 | INFO     | __main__:<module>:181 - validation loss: 3.55110958814621
2025-11-24 02:07:37.667 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_62000.pt
2025-11-24 02:07:39.387 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 02:07:41.333 | INFO     | __main__:<module>:160 - Step62010, Loss: 3.5378856658935547, Grad L2 Norm: 0.02209324762225151
2025-11-24 02:07:43.287 | INFO     | __main__:<module>:160 - Step62020, Loss: 3.4759058952331543, Grad L2 Norm: 0.022394992411136627
2025-11-24 02:07:45.251 | INFO     | __main__:<module>:160 - Step62030, Loss: 3.456533670425415, Grad L2 Norm: 0.021080462262034416
2025-11-24 02:07:47.207 | INFO     | __main__:<module>:160 - Step62040, Loss: 3.520808219909668, Grad L2 Norm: 0.024173520505428314
2025-11-24 02:07:49.163 | INFO     | __main__:<module>:160 - Step62050, Loss: 3.4654769897460938, Grad L2 Norm: 0.02235485427081585
2025-11-24 02:07:51.122 | INFO     | __main__:<module>:160 - Step62060, Loss: 3.5043983459472656, Grad L2 Norm: 0.022494858130812645
2025-11-24 02:07:53.081 | INFO     | __main__:<module>:160 - Step62070, Loss: 3.5560812950134277, Grad L2 Norm: 0.022386277094483376
2025-11-24 02:07:55.040 | INFO     | __main__:<module>:160 - Step62080, Loss: 3.3884053230285645, Grad L2 Norm: 0.022400598973035812
2025-11-24 02:07:57.008 | INFO     | __main__:<module>:160 - Step62090, Loss: 3.4905028343200684, Grad L2 Norm: 0.02252592332661152
2025-11-24 02:07:58.970 | INFO     | __main__:<module>:160 - Step62100, Loss: 3.541182041168213, Grad L2 Norm: 0.02276281639933586
2025-11-24 02:08:00.930 | INFO     | __main__:<module>:160 - Step62110, Loss: 3.5369362831115723, Grad L2 Norm: 0.02353537082672119
2025-11-24 02:08:02.891 | INFO     | __main__:<module>:160 - Step62120, Loss: 3.6712872982025146, Grad L2 Norm: 0.023241980001330376
2025-11-24 02:08:04.856 | INFO     | __main__:<module>:160 - Step62130, Loss: 3.6768722534179688, Grad L2 Norm: 0.024629024788737297
2025-11-24 02:08:06.820 | INFO     | __main__:<module>:160 - Step62140, Loss: 3.5448994636535645, Grad L2 Norm: 0.022085323929786682
2025-11-24 02:08:08.772 | INFO     | __main__:<module>:160 - Step62150, Loss: 3.5361437797546387, Grad L2 Norm: 0.022672859951853752
2025-11-24 02:08:10.728 | INFO     | __main__:<module>:160 - Step62160, Loss: 3.635733127593994, Grad L2 Norm: 0.023957854136824608
2025-11-24 02:08:12.688 | INFO     | __main__:<module>:160 - Step62170, Loss: 3.685063362121582, Grad L2 Norm: 0.02383601665496826
2025-11-24 02:08:14.647 | INFO     | __main__:<module>:160 - Step62180, Loss: 3.5892744064331055, Grad L2 Norm: 0.022902479395270348
2025-11-24 02:08:16.612 | INFO     | __main__:<module>:160 - Step62190, Loss: 3.545797109603882, Grad L2 Norm: 0.026085300371050835
2025-11-24 02:08:18.581 | INFO     | __main__:<module>:160 - Step62200, Loss: 3.4386448860168457, Grad L2 Norm: 0.021888593211770058
2025-11-24 02:08:20.546 | INFO     | __main__:<module>:160 - Step62210, Loss: 3.4823293685913086, Grad L2 Norm: 0.02316773682832718
2025-11-24 02:08:22.504 | INFO     | __main__:<module>:160 - Step62220, Loss: 3.5807080268859863, Grad L2 Norm: 0.02355514094233513
2025-11-24 02:08:24.463 | INFO     | __main__:<module>:160 - Step62230, Loss: 3.6572046279907227, Grad L2 Norm: 0.02479754015803337
2025-11-24 02:08:26.422 | INFO     | __main__:<module>:160 - Step62240, Loss: 3.514503002166748, Grad L2 Norm: 0.023004865273833275
2025-11-24 02:08:28.382 | INFO     | __main__:<module>:160 - Step62250, Loss: 3.4891040325164795, Grad L2 Norm: 0.022601669654250145
2025-11-24 02:08:30.340 | INFO     | __main__:<module>:160 - Step62260, Loss: 3.5867552757263184, Grad L2 Norm: 0.021049948409199715
2025-11-24 02:08:32.300 | INFO     | __main__:<module>:160 - Step62270, Loss: 3.476254940032959, Grad L2 Norm: 0.021611349657177925
2025-11-24 02:08:34.257 | INFO     | __main__:<module>:160 - Step62280, Loss: 3.6560208797454834, Grad L2 Norm: 0.022604594007134438
2025-11-24 02:08:36.219 | INFO     | __main__:<module>:160 - Step62290, Loss: 3.511669874191284, Grad L2 Norm: 0.021517623215913773
2025-11-24 02:08:38.180 | INFO     | __main__:<module>:160 - Step62300, Loss: 3.5121610164642334, Grad L2 Norm: 0.023775383830070496
2025-11-24 02:08:40.142 | INFO     | __main__:<module>:160 - Step62310, Loss: 3.5306742191314697, Grad L2 Norm: 0.021456528455018997
2025-11-24 02:08:42.109 | INFO     | __main__:<module>:160 - Step62320, Loss: 3.481858730316162, Grad L2 Norm: 0.025583982467651367
2025-11-24 02:08:44.066 | INFO     | __main__:<module>:160 - Step62330, Loss: 3.5922043323516846, Grad L2 Norm: 0.02324165403842926
2025-11-24 02:08:46.023 | INFO     | __main__:<module>:160 - Step62340, Loss: 3.499253273010254, Grad L2 Norm: 0.022047443315386772
2025-11-24 02:08:47.983 | INFO     | __main__:<module>:160 - Step62350, Loss: 3.5237956047058105, Grad L2 Norm: 0.024276098236441612
2025-11-24 02:08:49.949 | INFO     | __main__:<module>:160 - Step62360, Loss: 3.6165108680725098, Grad L2 Norm: 0.0230733472853899
2025-11-24 02:08:51.915 | INFO     | __main__:<module>:160 - Step62370, Loss: 3.4243063926696777, Grad L2 Norm: 0.022965146228671074
2025-11-24 02:08:53.876 | INFO     | __main__:<module>:160 - Step62380, Loss: 3.5897367000579834, Grad L2 Norm: 0.024753516539931297
2025-11-24 02:08:55.837 | INFO     | __main__:<module>:160 - Step62390, Loss: 3.4706592559814453, Grad L2 Norm: 0.02308320626616478
2025-11-24 02:08:57.801 | INFO     | __main__:<module>:160 - Step62400, Loss: 3.5729994773864746, Grad L2 Norm: 0.027090702205896378
2025-11-24 02:08:57.802 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:08:59.044 | INFO     | __main__:<module>:181 - validation loss: 3.5498526096343994
2025-11-24 02:09:01.018 | INFO     | __main__:<module>:160 - Step62410, Loss: 3.5434415340423584, Grad L2 Norm: 0.022763336077332497
2025-11-24 02:09:02.987 | INFO     | __main__:<module>:160 - Step62420, Loss: 3.6069064140319824, Grad L2 Norm: 0.02309388853609562
2025-11-24 02:09:04.952 | INFO     | __main__:<module>:160 - Step62430, Loss: 3.547821521759033, Grad L2 Norm: 0.022132588550448418
2025-11-24 02:09:06.921 | INFO     | __main__:<module>:160 - Step62440, Loss: 3.5123279094696045, Grad L2 Norm: 0.022577205672860146
2025-11-24 02:09:08.889 | INFO     | __main__:<module>:160 - Step62450, Loss: 3.568526268005371, Grad L2 Norm: 0.023180929943919182
2025-11-24 02:09:10.856 | INFO     | __main__:<module>:160 - Step62460, Loss: 3.5462043285369873, Grad L2 Norm: 0.02282281406223774
2025-11-24 02:09:12.828 | INFO     | __main__:<module>:160 - Step62470, Loss: 3.505366086959839, Grad L2 Norm: 0.02193574793636799
2025-11-24 02:09:14.794 | INFO     | __main__:<module>:160 - Step62480, Loss: 3.4831440448760986, Grad L2 Norm: 0.022135721519589424
2025-11-24 02:09:16.767 | INFO     | __main__:<module>:160 - Step62490, Loss: 3.476296901702881, Grad L2 Norm: 0.02252901904284954
2025-11-24 02:09:18.737 | INFO     | __main__:<module>:160 - Step62500, Loss: 3.5024566650390625, Grad L2 Norm: 0.021726476028561592
2025-11-24 02:09:20.707 | INFO     | __main__:<module>:160 - Step62510, Loss: 3.6300208568573, Grad L2 Norm: 0.022561917081475258
2025-11-24 02:09:22.675 | INFO     | __main__:<module>:160 - Step62520, Loss: 3.526397705078125, Grad L2 Norm: 0.022161830216646194
2025-11-24 02:09:24.646 | INFO     | __main__:<module>:160 - Step62530, Loss: 3.610591173171997, Grad L2 Norm: 0.022495482116937637
2025-11-24 02:09:26.620 | INFO     | __main__:<module>:160 - Step62540, Loss: 3.525106430053711, Grad L2 Norm: 0.022695394232869148
2025-11-24 02:09:28.587 | INFO     | __main__:<module>:160 - Step62550, Loss: 3.5652387142181396, Grad L2 Norm: 0.023905495181679726
2025-11-24 02:09:30.559 | INFO     | __main__:<module>:160 - Step62560, Loss: 3.598329544067383, Grad L2 Norm: 0.02546386979520321
2025-11-24 02:09:32.529 | INFO     | __main__:<module>:160 - Step62570, Loss: 3.5546767711639404, Grad L2 Norm: 0.023293044418096542
2025-11-24 02:09:34.502 | INFO     | __main__:<module>:160 - Step62580, Loss: 3.5480639934539795, Grad L2 Norm: 0.022451180964708328
2025-11-24 02:09:36.478 | INFO     | __main__:<module>:160 - Step62590, Loss: 3.426467180252075, Grad L2 Norm: 0.0227377787232399
2025-11-24 02:09:38.455 | INFO     | __main__:<module>:160 - Step62600, Loss: 3.534554958343506, Grad L2 Norm: 0.022796450182795525
2025-11-24 02:09:40.430 | INFO     | __main__:<module>:160 - Step62610, Loss: 3.5532257556915283, Grad L2 Norm: 0.022478273138403893
2025-11-24 02:09:42.407 | INFO     | __main__:<module>:160 - Step62620, Loss: 3.4281766414642334, Grad L2 Norm: 0.02262023463845253
2025-11-24 02:09:44.386 | INFO     | __main__:<module>:160 - Step62630, Loss: 3.6155824661254883, Grad L2 Norm: 0.024362843483686447
2025-11-24 02:09:46.361 | INFO     | __main__:<module>:160 - Step62640, Loss: 3.454087257385254, Grad L2 Norm: 0.023251637816429138
2025-11-24 02:09:48.336 | INFO     | __main__:<module>:160 - Step62650, Loss: 3.679299831390381, Grad L2 Norm: 0.02278236299753189
2025-11-24 02:09:50.310 | INFO     | __main__:<module>:160 - Step62660, Loss: 3.5741710662841797, Grad L2 Norm: 0.023512257263064384
2025-11-24 02:09:52.284 | INFO     | __main__:<module>:160 - Step62670, Loss: 3.634523868560791, Grad L2 Norm: 0.023200534284114838
2025-11-24 02:09:54.259 | INFO     | __main__:<module>:160 - Step62680, Loss: 3.5266594886779785, Grad L2 Norm: 0.023527704179286957
2025-11-24 02:09:56.235 | INFO     | __main__:<module>:160 - Step62690, Loss: 3.5262982845306396, Grad L2 Norm: 0.02155406028032303
2025-11-24 02:09:58.211 | INFO     | __main__:<module>:160 - Step62700, Loss: 3.5305631160736084, Grad L2 Norm: 0.02195756323635578
2025-11-24 02:10:00.184 | INFO     | __main__:<module>:160 - Step62710, Loss: 3.5121684074401855, Grad L2 Norm: 0.022645864635705948
2025-11-24 02:10:02.157 | INFO     | __main__:<module>:160 - Step62720, Loss: 3.516199827194214, Grad L2 Norm: 0.02318715676665306
2025-11-24 02:10:04.131 | INFO     | __main__:<module>:160 - Step62730, Loss: 3.446639060974121, Grad L2 Norm: 0.02098212204873562
2025-11-24 02:10:06.103 | INFO     | __main__:<module>:160 - Step62740, Loss: 3.4899210929870605, Grad L2 Norm: 0.022793153300881386
2025-11-24 02:10:08.074 | INFO     | __main__:<module>:160 - Step62750, Loss: 3.577699661254883, Grad L2 Norm: 0.022698726505041122
2025-11-24 02:10:10.042 | INFO     | __main__:<module>:160 - Step62760, Loss: 3.650120735168457, Grad L2 Norm: 0.023545334115624428
2025-11-24 02:10:12.015 | INFO     | __main__:<module>:160 - Step62770, Loss: 3.7222189903259277, Grad L2 Norm: 0.024411525577306747
2025-11-24 02:10:13.987 | INFO     | __main__:<module>:160 - Step62780, Loss: 3.5302734375, Grad L2 Norm: 0.023777008056640625
2025-11-24 02:10:15.959 | INFO     | __main__:<module>:160 - Step62790, Loss: 3.55277681350708, Grad L2 Norm: 0.022815531119704247
2025-11-24 02:10:17.930 | INFO     | __main__:<module>:160 - Step62800, Loss: 3.647721767425537, Grad L2 Norm: 0.022677669301629066
2025-11-24 02:10:17.931 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:10:19.180 | INFO     | __main__:<module>:181 - validation loss: 3.5449294328689573
2025-11-24 02:10:21.161 | INFO     | __main__:<module>:160 - Step62810, Loss: 3.515768527984619, Grad L2 Norm: 0.02241848036646843
2025-11-24 02:10:23.129 | INFO     | __main__:<module>:160 - Step62820, Loss: 3.683830499649048, Grad L2 Norm: 0.02292882651090622
2025-11-24 02:10:25.106 | INFO     | __main__:<module>:160 - Step62830, Loss: 3.5588886737823486, Grad L2 Norm: 0.023005712777376175
2025-11-24 02:10:27.079 | INFO     | __main__:<module>:160 - Step62840, Loss: 3.4809844493865967, Grad L2 Norm: 0.02399878390133381
2025-11-24 02:10:29.051 | INFO     | __main__:<module>:160 - Step62850, Loss: 3.5403709411621094, Grad L2 Norm: 0.0221185851842165
2025-11-24 02:10:31.025 | INFO     | __main__:<module>:160 - Step62860, Loss: 3.553286552429199, Grad L2 Norm: 0.0240437351167202
2025-11-24 02:10:32.998 | INFO     | __main__:<module>:160 - Step62870, Loss: 3.567692756652832, Grad L2 Norm: 0.02306823432445526
2025-11-24 02:10:34.969 | INFO     | __main__:<module>:160 - Step62880, Loss: 3.3978006839752197, Grad L2 Norm: 0.022747360169887543
2025-11-24 02:10:36.942 | INFO     | __main__:<module>:160 - Step62890, Loss: 3.499112606048584, Grad L2 Norm: 0.023920372128486633
2025-11-24 02:10:38.914 | INFO     | __main__:<module>:160 - Step62900, Loss: 3.5043234825134277, Grad L2 Norm: 0.02214021049439907
2025-11-24 02:10:40.884 | INFO     | __main__:<module>:160 - Step62910, Loss: 3.5392377376556396, Grad L2 Norm: 0.022918973118066788
2025-11-24 02:10:42.851 | INFO     | __main__:<module>:160 - Step62920, Loss: 3.5908684730529785, Grad L2 Norm: 0.02413538284599781
2025-11-24 02:10:44.823 | INFO     | __main__:<module>:160 - Step62930, Loss: 3.5830936431884766, Grad L2 Norm: 0.024100206792354584
2025-11-24 02:10:46.795 | INFO     | __main__:<module>:160 - Step62940, Loss: 3.66811203956604, Grad L2 Norm: 0.025944620370864868
2025-11-24 02:10:48.763 | INFO     | __main__:<module>:160 - Step62950, Loss: 3.4789257049560547, Grad L2 Norm: 0.02330259047448635
2025-11-24 02:10:50.729 | INFO     | __main__:<module>:160 - Step62960, Loss: 3.567474842071533, Grad L2 Norm: 0.021001046523451805
2025-11-24 02:10:52.697 | INFO     | __main__:<module>:160 - Step62970, Loss: 3.5922999382019043, Grad L2 Norm: 0.022360866889357567
2025-11-24 02:10:54.662 | INFO     | __main__:<module>:160 - Step62980, Loss: 3.401031017303467, Grad L2 Norm: 0.022176049649715424
2025-11-24 02:10:56.629 | INFO     | __main__:<module>:160 - Step62990, Loss: 3.5640292167663574, Grad L2 Norm: 0.020888037979602814
2025-11-24 02:10:58.598 | INFO     | __main__:<module>:160 - Step63000, Loss: 3.622818946838379, Grad L2 Norm: 0.022986359894275665
2025-11-24 02:11:00.562 | INFO     | __main__:<module>:160 - Step63010, Loss: 3.562563180923462, Grad L2 Norm: 0.02506852336227894
2025-11-24 02:11:02.531 | INFO     | __main__:<module>:160 - Step63020, Loss: 3.598294734954834, Grad L2 Norm: 0.024791531264781952
2025-11-24 02:11:04.496 | INFO     | __main__:<module>:160 - Step63030, Loss: 3.6832222938537598, Grad L2 Norm: 0.02528667449951172
2025-11-24 02:11:06.466 | INFO     | __main__:<module>:160 - Step63040, Loss: 3.5683765411376953, Grad L2 Norm: 0.025520095601677895
2025-11-24 02:11:08.434 | INFO     | __main__:<module>:160 - Step63050, Loss: 3.543374538421631, Grad L2 Norm: 0.022847741842269897
2025-11-24 02:11:10.396 | INFO     | __main__:<module>:160 - Step63060, Loss: 3.6147844791412354, Grad L2 Norm: 0.023503359407186508
2025-11-24 02:11:12.368 | INFO     | __main__:<module>:160 - Step63070, Loss: 3.572849750518799, Grad L2 Norm: 0.024170340970158577
2025-11-24 02:11:14.334 | INFO     | __main__:<module>:160 - Step63080, Loss: 3.62738037109375, Grad L2 Norm: 0.02753080241382122
2025-11-24 02:11:16.299 | INFO     | __main__:<module>:160 - Step63090, Loss: 3.4518063068389893, Grad L2 Norm: 0.02316110208630562
2025-11-24 02:11:18.271 | INFO     | __main__:<module>:160 - Step63100, Loss: 3.7218542098999023, Grad L2 Norm: 0.024824906140565872
2025-11-24 02:11:20.238 | INFO     | __main__:<module>:160 - Step63110, Loss: 3.464092254638672, Grad L2 Norm: 0.02169245108962059
2025-11-24 02:11:22.209 | INFO     | __main__:<module>:160 - Step63120, Loss: 3.420746326446533, Grad L2 Norm: 0.023328294977545738
2025-11-24 02:11:24.176 | INFO     | __main__:<module>:160 - Step63130, Loss: 3.5813798904418945, Grad L2 Norm: 0.021652381867170334
2025-11-24 02:11:26.147 | INFO     | __main__:<module>:160 - Step63140, Loss: 3.589414596557617, Grad L2 Norm: 0.02136967144906521
2025-11-24 02:11:28.118 | INFO     | __main__:<module>:160 - Step63150, Loss: 3.5559396743774414, Grad L2 Norm: 0.02227754145860672
2025-11-24 02:11:30.090 | INFO     | __main__:<module>:160 - Step63160, Loss: 3.562394142150879, Grad L2 Norm: 0.023303303867578506
2025-11-24 02:11:32.060 | INFO     | __main__:<module>:160 - Step63170, Loss: 3.5742368698120117, Grad L2 Norm: 0.021440796554088593
2025-11-24 02:11:34.027 | INFO     | __main__:<module>:160 - Step63180, Loss: 3.3838534355163574, Grad L2 Norm: 0.02185257524251938
2025-11-24 02:11:35.997 | INFO     | __main__:<module>:160 - Step63190, Loss: 3.508416175842285, Grad L2 Norm: 0.021947108209133148
2025-11-24 02:11:37.965 | INFO     | __main__:<module>:160 - Step63200, Loss: 3.6155495643615723, Grad L2 Norm: 0.02366618812084198
2025-11-24 02:11:37.966 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:11:39.215 | INFO     | __main__:<module>:181 - validation loss: 3.5387251138687135
2025-11-24 02:11:41.193 | INFO     | __main__:<module>:160 - Step63210, Loss: 3.51603627204895, Grad L2 Norm: 0.0242447592318058
2025-11-24 02:11:43.163 | INFO     | __main__:<module>:160 - Step63220, Loss: 3.4610743522644043, Grad L2 Norm: 0.02340436540544033
2025-11-24 02:11:45.128 | INFO     | __main__:<module>:160 - Step63230, Loss: 3.578580379486084, Grad L2 Norm: 0.024863701313734055
2025-11-24 02:11:47.097 | INFO     | __main__:<module>:160 - Step63240, Loss: 3.54207181930542, Grad L2 Norm: 0.02243899554014206
2025-11-24 02:11:49.060 | INFO     | __main__:<module>:160 - Step63250, Loss: 3.477904796600342, Grad L2 Norm: 0.022436320781707764
2025-11-24 02:11:51.020 | INFO     | __main__:<module>:160 - Step63260, Loss: 3.512866258621216, Grad L2 Norm: 0.022934189066290855
2025-11-24 02:11:52.988 | INFO     | __main__:<module>:160 - Step63270, Loss: 3.6341965198516846, Grad L2 Norm: 0.03104703314602375
2025-11-24 02:11:54.960 | INFO     | __main__:<module>:160 - Step63280, Loss: 3.474222183227539, Grad L2 Norm: 0.02268723025918007
2025-11-24 02:11:56.921 | INFO     | __main__:<module>:160 - Step63290, Loss: 3.4593257904052734, Grad L2 Norm: 0.022186966612935066
2025-11-24 02:11:58.887 | INFO     | __main__:<module>:160 - Step63300, Loss: 3.5838184356689453, Grad L2 Norm: 0.022786226123571396
2025-11-24 02:12:00.856 | INFO     | __main__:<module>:160 - Step63310, Loss: 3.5287463665008545, Grad L2 Norm: 0.022572685033082962
2025-11-24 02:12:02.820 | INFO     | __main__:<module>:160 - Step63320, Loss: 3.6397924423217773, Grad L2 Norm: 0.024582823738455772
2025-11-24 02:12:04.786 | INFO     | __main__:<module>:160 - Step63330, Loss: 3.4343621730804443, Grad L2 Norm: 0.021670641377568245
2025-11-24 02:12:06.757 | INFO     | __main__:<module>:160 - Step63340, Loss: 3.533681631088257, Grad L2 Norm: 0.024137509986758232
2025-11-24 02:12:08.728 | INFO     | __main__:<module>:160 - Step63350, Loss: 3.4766440391540527, Grad L2 Norm: 0.02223309315741062
2025-11-24 02:12:10.696 | INFO     | __main__:<module>:160 - Step63360, Loss: 3.4922165870666504, Grad L2 Norm: 0.02308935672044754
2025-11-24 02:12:12.673 | INFO     | __main__:<module>:160 - Step63370, Loss: 3.529822826385498, Grad L2 Norm: 0.022058870643377304
2025-11-24 02:12:14.645 | INFO     | __main__:<module>:160 - Step63380, Loss: 3.494724988937378, Grad L2 Norm: 0.026260117068886757
2025-11-24 02:12:16.617 | INFO     | __main__:<module>:160 - Step63390, Loss: 3.6519227027893066, Grad L2 Norm: 0.0227584857493639
2025-11-24 02:12:18.592 | INFO     | __main__:<module>:160 - Step63400, Loss: 3.607128143310547, Grad L2 Norm: 0.02263474464416504
2025-11-24 02:12:20.561 | INFO     | __main__:<module>:160 - Step63410, Loss: 3.696868658065796, Grad L2 Norm: 0.02437485381960869
2025-11-24 02:12:22.535 | INFO     | __main__:<module>:160 - Step63420, Loss: 3.5618667602539062, Grad L2 Norm: 0.022369634360074997
2025-11-24 02:12:24.510 | INFO     | __main__:<module>:160 - Step63430, Loss: 3.533153533935547, Grad L2 Norm: 0.022270379588007927
2025-11-24 02:12:26.481 | INFO     | __main__:<module>:160 - Step63440, Loss: 3.4737610816955566, Grad L2 Norm: 0.022032296285033226
2025-11-24 02:12:28.454 | INFO     | __main__:<module>:160 - Step63450, Loss: 3.572331190109253, Grad L2 Norm: 0.022884592413902283
2025-11-24 02:12:30.427 | INFO     | __main__:<module>:160 - Step63460, Loss: 3.6173830032348633, Grad L2 Norm: 0.023691412061452866
2025-11-24 02:12:32.394 | INFO     | __main__:<module>:160 - Step63470, Loss: 3.445870876312256, Grad L2 Norm: 0.022153722122311592
2025-11-24 02:12:34.368 | INFO     | __main__:<module>:160 - Step63480, Loss: 3.6274380683898926, Grad L2 Norm: 0.02374139055609703
2025-11-24 02:12:36.341 | INFO     | __main__:<module>:160 - Step63490, Loss: 3.651456117630005, Grad L2 Norm: 0.02270658314228058
2025-11-24 02:12:38.306 | INFO     | __main__:<module>:160 - Step63500, Loss: 3.6671645641326904, Grad L2 Norm: 0.023181073367595673
2025-11-24 02:12:40.271 | INFO     | __main__:<module>:160 - Step63510, Loss: 3.6044249534606934, Grad L2 Norm: 0.023218445479869843
2025-11-24 02:12:42.243 | INFO     | __main__:<module>:160 - Step63520, Loss: 3.581087112426758, Grad L2 Norm: 0.02210320718586445
2025-11-24 02:12:44.210 | INFO     | __main__:<module>:160 - Step63530, Loss: 3.5009074211120605, Grad L2 Norm: 0.02220921777188778
2025-11-24 02:12:46.181 | INFO     | __main__:<module>:160 - Step63540, Loss: 3.6815905570983887, Grad L2 Norm: 0.02555941417813301
2025-11-24 02:12:48.149 | INFO     | __main__:<module>:160 - Step63550, Loss: 3.6075782775878906, Grad L2 Norm: 0.025496801361441612
2025-11-24 02:12:50.123 | INFO     | __main__:<module>:160 - Step63560, Loss: 3.4628396034240723, Grad L2 Norm: 0.02158351056277752
2025-11-24 02:12:52.091 | INFO     | __main__:<module>:160 - Step63570, Loss: 3.6019697189331055, Grad L2 Norm: 0.022190038114786148
2025-11-24 02:12:54.061 | INFO     | __main__:<module>:160 - Step63580, Loss: 3.4467506408691406, Grad L2 Norm: 0.022935722023248672
2025-11-24 02:12:56.025 | INFO     | __main__:<module>:160 - Step63590, Loss: 3.4645767211914062, Grad L2 Norm: 0.0236374381929636
2025-11-24 02:12:57.997 | INFO     | __main__:<module>:160 - Step63600, Loss: 3.4627127647399902, Grad L2 Norm: 0.020930346101522446
2025-11-24 02:12:57.997 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:12:59.246 | INFO     | __main__:<module>:181 - validation loss: 3.5560169577598573
2025-11-24 02:13:01.223 | INFO     | __main__:<module>:160 - Step63610, Loss: 3.584137439727783, Grad L2 Norm: 0.02304355800151825
2025-11-24 02:13:03.199 | INFO     | __main__:<module>:160 - Step63620, Loss: 3.508978843688965, Grad L2 Norm: 0.023637576028704643
2025-11-24 02:13:05.171 | INFO     | __main__:<module>:160 - Step63630, Loss: 3.6713626384735107, Grad L2 Norm: 0.02262168563902378
2025-11-24 02:13:07.139 | INFO     | __main__:<module>:160 - Step63640, Loss: 3.5285592079162598, Grad L2 Norm: 0.022403132170438766
2025-11-24 02:13:09.112 | INFO     | __main__:<module>:160 - Step63650, Loss: 3.589214324951172, Grad L2 Norm: 0.022297730669379234
2025-11-24 02:13:11.082 | INFO     | __main__:<module>:160 - Step63660, Loss: 3.5888209342956543, Grad L2 Norm: 0.021986791864037514
2025-11-24 02:13:13.056 | INFO     | __main__:<module>:160 - Step63670, Loss: 3.5031228065490723, Grad L2 Norm: 0.024154989048838615
2025-11-24 02:13:15.029 | INFO     | __main__:<module>:160 - Step63680, Loss: 3.4072213172912598, Grad L2 Norm: 0.023591531440615654
2025-11-24 02:13:16.994 | INFO     | __main__:<module>:160 - Step63690, Loss: 3.4964566230773926, Grad L2 Norm: 0.021812554448843002
2025-11-24 02:13:18.958 | INFO     | __main__:<module>:160 - Step63700, Loss: 3.589275360107422, Grad L2 Norm: 0.022339705377817154
2025-11-24 02:13:20.928 | INFO     | __main__:<module>:160 - Step63710, Loss: 3.5152971744537354, Grad L2 Norm: 0.02270614169538021
2025-11-24 02:13:22.894 | INFO     | __main__:<module>:160 - Step63720, Loss: 3.5094094276428223, Grad L2 Norm: 0.023088879883289337
2025-11-24 02:13:24.862 | INFO     | __main__:<module>:160 - Step63730, Loss: 3.5625159740448, Grad L2 Norm: 0.022482477128505707
2025-11-24 02:13:26.832 | INFO     | __main__:<module>:160 - Step63740, Loss: 3.569556713104248, Grad L2 Norm: 0.022720113396644592
2025-11-24 02:13:28.794 | INFO     | __main__:<module>:160 - Step63750, Loss: 3.4683725833892822, Grad L2 Norm: 0.023108579218387604
2025-11-24 02:13:30.762 | INFO     | __main__:<module>:160 - Step63760, Loss: 3.5658020973205566, Grad L2 Norm: 0.023233450949192047
2025-11-24 02:13:32.730 | INFO     | __main__:<module>:160 - Step63770, Loss: 3.5540966987609863, Grad L2 Norm: 0.022002797573804855
2025-11-24 02:13:34.697 | INFO     | __main__:<module>:160 - Step63780, Loss: 3.560774326324463, Grad L2 Norm: 0.024441620334982872
2025-11-24 02:13:36.668 | INFO     | __main__:<module>:160 - Step63790, Loss: 3.6556429862976074, Grad L2 Norm: 0.022584879770874977
2025-11-24 02:13:38.639 | INFO     | __main__:<module>:160 - Step63800, Loss: 3.626936912536621, Grad L2 Norm: 0.022367771714925766
2025-11-24 02:13:40.609 | INFO     | __main__:<module>:160 - Step63810, Loss: 3.6836495399475098, Grad L2 Norm: 0.023321090266108513
2025-11-24 02:13:42.581 | INFO     | __main__:<module>:160 - Step63820, Loss: 3.414560317993164, Grad L2 Norm: 0.023620953783392906
2025-11-24 02:13:44.551 | INFO     | __main__:<module>:160 - Step63830, Loss: 3.558375358581543, Grad L2 Norm: 0.022791637107729912
2025-11-24 02:13:46.520 | INFO     | __main__:<module>:160 - Step63840, Loss: 3.4055418968200684, Grad L2 Norm: 0.02449651248753071
2025-11-24 02:13:48.486 | INFO     | __main__:<module>:160 - Step63850, Loss: 3.5909078121185303, Grad L2 Norm: 0.024898448958992958
2025-11-24 02:13:50.454 | INFO     | __main__:<module>:160 - Step63860, Loss: 3.7813353538513184, Grad L2 Norm: 0.025119580328464508
2025-11-24 02:13:52.423 | INFO     | __main__:<module>:160 - Step63870, Loss: 3.5625784397125244, Grad L2 Norm: 0.02193756029009819
2025-11-24 02:13:54.384 | INFO     | __main__:<module>:160 - Step63880, Loss: 3.54360294342041, Grad L2 Norm: 0.023158594965934753
2025-11-24 02:13:56.354 | INFO     | __main__:<module>:160 - Step63890, Loss: 3.547128200531006, Grad L2 Norm: 0.02276117354631424
2025-11-24 02:13:58.322 | INFO     | __main__:<module>:160 - Step63900, Loss: 3.5406689643859863, Grad L2 Norm: 0.02276831492781639
2025-11-24 02:14:00.294 | INFO     | __main__:<module>:160 - Step63910, Loss: 3.6116151809692383, Grad L2 Norm: 0.021946217864751816
2025-11-24 02:14:02.262 | INFO     | __main__:<module>:160 - Step63920, Loss: 3.581779718399048, Grad L2 Norm: 0.023375388234853745
2025-11-24 02:14:04.237 | INFO     | __main__:<module>:160 - Step63930, Loss: 3.64748477935791, Grad L2 Norm: 0.024710634723305702
2025-11-24 02:14:06.210 | INFO     | __main__:<module>:160 - Step63940, Loss: 3.5958669185638428, Grad L2 Norm: 0.023387596011161804
2025-11-24 02:14:08.180 | INFO     | __main__:<module>:160 - Step63950, Loss: 3.647036075592041, Grad L2 Norm: 0.02563881315290928
2025-11-24 02:14:10.152 | INFO     | __main__:<module>:160 - Step63960, Loss: 3.531825304031372, Grad L2 Norm: 0.02370597794651985
2025-11-24 02:14:12.120 | INFO     | __main__:<module>:160 - Step63970, Loss: 3.4996626377105713, Grad L2 Norm: 0.022137820720672607
2025-11-24 02:14:14.091 | INFO     | __main__:<module>:160 - Step63980, Loss: 3.482186794281006, Grad L2 Norm: 0.022896336391568184
2025-11-24 02:14:16.060 | INFO     | __main__:<module>:160 - Step63990, Loss: 3.6187243461608887, Grad L2 Norm: 0.023273548111319542
2025-11-24 02:14:18.032 | INFO     | __main__:<module>:160 - Step64000, Loss: 3.5955586433410645, Grad L2 Norm: 0.02390550635755062
2025-11-24 02:14:18.033 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:14:19.280 | INFO     | __main__:<module>:181 - validation loss: 3.574045407772064
2025-11-24 02:14:19.281 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_64000.pt
2025-11-24 02:14:20.989 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 02:14:22.937 | INFO     | __main__:<module>:160 - Step64010, Loss: 3.512331008911133, Grad L2 Norm: 0.02142488770186901
2025-11-24 02:14:24.902 | INFO     | __main__:<module>:160 - Step64020, Loss: 3.4688730239868164, Grad L2 Norm: 0.022932708263397217
2025-11-24 02:14:26.871 | INFO     | __main__:<module>:160 - Step64030, Loss: 3.6152145862579346, Grad L2 Norm: 0.02535710111260414
2025-11-24 02:14:28.836 | INFO     | __main__:<module>:160 - Step64040, Loss: 3.634763717651367, Grad L2 Norm: 0.02249561809003353
2025-11-24 02:14:30.810 | INFO     | __main__:<module>:160 - Step64050, Loss: 3.5265398025512695, Grad L2 Norm: 0.02189238928258419
2025-11-24 02:14:32.773 | INFO     | __main__:<module>:160 - Step64060, Loss: 3.6142923831939697, Grad L2 Norm: 0.025069480761885643
2025-11-24 02:14:34.743 | INFO     | __main__:<module>:160 - Step64070, Loss: 3.5985350608825684, Grad L2 Norm: 0.02233976311981678
2025-11-24 02:14:36.710 | INFO     | __main__:<module>:160 - Step64080, Loss: 3.4276437759399414, Grad L2 Norm: 0.023972954601049423
2025-11-24 02:14:38.674 | INFO     | __main__:<module>:160 - Step64090, Loss: 3.5729665756225586, Grad L2 Norm: 0.02809433452785015
2025-11-24 02:14:40.647 | INFO     | __main__:<module>:160 - Step64100, Loss: 3.566347599029541, Grad L2 Norm: 0.021770304068922997
2025-11-24 02:14:42.618 | INFO     | __main__:<module>:160 - Step64110, Loss: 3.546154737472534, Grad L2 Norm: 0.024604758247733116
2025-11-24 02:14:44.587 | INFO     | __main__:<module>:160 - Step64120, Loss: 3.622959613800049, Grad L2 Norm: 0.022173039615154266
2025-11-24 02:14:46.547 | INFO     | __main__:<module>:160 - Step64130, Loss: 3.5559659004211426, Grad L2 Norm: 0.022360827773809433
2025-11-24 02:14:48.516 | INFO     | __main__:<module>:160 - Step64140, Loss: 3.5452771186828613, Grad L2 Norm: 0.023521622642874718
2025-11-24 02:14:50.486 | INFO     | __main__:<module>:160 - Step64150, Loss: 3.504878520965576, Grad L2 Norm: 0.022425906732678413
2025-11-24 02:14:52.454 | INFO     | __main__:<module>:160 - Step64160, Loss: 3.5444772243499756, Grad L2 Norm: 0.02250422164797783
2025-11-24 02:14:54.424 | INFO     | __main__:<module>:160 - Step64170, Loss: 3.591660499572754, Grad L2 Norm: 0.0223850067704916
2025-11-24 02:14:56.389 | INFO     | __main__:<module>:160 - Step64180, Loss: 3.647150993347168, Grad L2 Norm: 0.021775033324956894
2025-11-24 02:14:58.360 | INFO     | __main__:<module>:160 - Step64190, Loss: 3.607722282409668, Grad L2 Norm: 0.021836617961525917
2025-11-24 02:15:00.326 | INFO     | __main__:<module>:160 - Step64200, Loss: 3.604616165161133, Grad L2 Norm: 0.020997973158955574
2025-11-24 02:15:02.293 | INFO     | __main__:<module>:160 - Step64210, Loss: 3.6222662925720215, Grad L2 Norm: 0.023094717413187027
2025-11-24 02:15:04.260 | INFO     | __main__:<module>:160 - Step64220, Loss: 3.6797080039978027, Grad L2 Norm: 0.02390827238559723
2025-11-24 02:15:06.227 | INFO     | __main__:<module>:160 - Step64230, Loss: 3.681978702545166, Grad L2 Norm: 0.023895684629678726
2025-11-24 02:15:08.197 | INFO     | __main__:<module>:160 - Step64240, Loss: 3.4631619453430176, Grad L2 Norm: 0.022095412015914917
2025-11-24 02:15:10.160 | INFO     | __main__:<module>:160 - Step64250, Loss: 3.530536651611328, Grad L2 Norm: 0.021423213183879852
2025-11-24 02:15:12.128 | INFO     | __main__:<module>:160 - Step64260, Loss: 3.524613618850708, Grad L2 Norm: 0.02260012924671173
2025-11-24 02:15:14.099 | INFO     | __main__:<module>:160 - Step64270, Loss: 3.405088424682617, Grad L2 Norm: 0.023532839491963387
2025-11-24 02:15:16.067 | INFO     | __main__:<module>:160 - Step64280, Loss: 3.5668530464172363, Grad L2 Norm: 0.02306225709617138
2025-11-24 02:15:18.037 | INFO     | __main__:<module>:160 - Step64290, Loss: 3.5532422065734863, Grad L2 Norm: 0.022500623017549515
2025-11-24 02:15:20.007 | INFO     | __main__:<module>:160 - Step64300, Loss: 3.518367290496826, Grad L2 Norm: 0.02222146838903427
2025-11-24 02:15:21.976 | INFO     | __main__:<module>:160 - Step64310, Loss: 3.4439496994018555, Grad L2 Norm: 0.022998519241809845
2025-11-24 02:15:23.943 | INFO     | __main__:<module>:160 - Step64320, Loss: 3.5954036712646484, Grad L2 Norm: 0.022929958999156952
2025-11-24 02:15:25.915 | INFO     | __main__:<module>:160 - Step64330, Loss: 3.568967342376709, Grad L2 Norm: 0.022924430668354034
2025-11-24 02:15:27.882 | INFO     | __main__:<module>:160 - Step64340, Loss: 3.5442843437194824, Grad L2 Norm: 0.023351114243268967
2025-11-24 02:15:29.854 | INFO     | __main__:<module>:160 - Step64350, Loss: 3.5861597061157227, Grad L2 Norm: 0.024818647652864456
2025-11-24 02:15:31.818 | INFO     | __main__:<module>:160 - Step64360, Loss: 3.6517174243927, Grad L2 Norm: 0.023065974935889244
2025-11-24 02:15:33.791 | INFO     | __main__:<module>:160 - Step64370, Loss: 3.5005269050598145, Grad L2 Norm: 0.02367999590933323
2025-11-24 02:15:35.757 | INFO     | __main__:<module>:160 - Step64380, Loss: 3.4922711849212646, Grad L2 Norm: 0.02173839509487152
2025-11-24 02:15:37.728 | INFO     | __main__:<module>:160 - Step64390, Loss: 3.6761972904205322, Grad L2 Norm: 0.02322641760110855
2025-11-24 02:15:39.695 | INFO     | __main__:<module>:160 - Step64400, Loss: 3.569455623626709, Grad L2 Norm: 0.023313242942094803
2025-11-24 02:15:39.696 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:15:40.942 | INFO     | __main__:<module>:181 - validation loss: 3.5555716037750242
2025-11-24 02:15:42.917 | INFO     | __main__:<module>:160 - Step64410, Loss: 3.5588035583496094, Grad L2 Norm: 0.023164577782154083
2025-11-24 02:15:44.889 | INFO     | __main__:<module>:160 - Step64420, Loss: 3.4638257026672363, Grad L2 Norm: 0.021914925426244736
2025-11-24 02:15:46.854 | INFO     | __main__:<module>:160 - Step64430, Loss: 3.4523496627807617, Grad L2 Norm: 0.022839920595288277
2025-11-24 02:15:48.823 | INFO     | __main__:<module>:160 - Step64440, Loss: 3.5633740425109863, Grad L2 Norm: 0.023072607815265656
2025-11-24 02:15:50.788 | INFO     | __main__:<module>:160 - Step64450, Loss: 3.4067845344543457, Grad L2 Norm: 0.023841742426156998
2025-11-24 02:15:52.755 | INFO     | __main__:<module>:160 - Step64460, Loss: 3.6001100540161133, Grad L2 Norm: 0.022650836035609245
2025-11-24 02:15:54.726 | INFO     | __main__:<module>:160 - Step64470, Loss: 3.4672160148620605, Grad L2 Norm: 0.02270020730793476
2025-11-24 02:15:56.688 | INFO     | __main__:<module>:160 - Step64480, Loss: 3.4306604862213135, Grad L2 Norm: 0.02200758270919323
2025-11-24 02:15:58.651 | INFO     | __main__:<module>:160 - Step64490, Loss: 3.6452274322509766, Grad L2 Norm: 0.023153038695454597
2025-11-24 02:16:00.622 | INFO     | __main__:<module>:160 - Step64500, Loss: 3.6192972660064697, Grad L2 Norm: 0.02238677442073822
2025-11-24 02:16:02.584 | INFO     | __main__:<module>:160 - Step64510, Loss: 3.598209857940674, Grad L2 Norm: 0.022226495668292046
2025-11-24 02:16:04.551 | INFO     | __main__:<module>:160 - Step64520, Loss: 3.6248531341552734, Grad L2 Norm: 0.023386556655168533
2025-11-24 02:16:06.520 | INFO     | __main__:<module>:160 - Step64530, Loss: 3.573143482208252, Grad L2 Norm: 0.021886397153139114
2025-11-24 02:16:08.483 | INFO     | __main__:<module>:160 - Step64540, Loss: 3.4922306537628174, Grad L2 Norm: 0.023020267486572266
2025-11-24 02:16:10.451 | INFO     | __main__:<module>:160 - Step64550, Loss: 3.4983930587768555, Grad L2 Norm: 0.021938178688287735
2025-11-24 02:16:12.422 | INFO     | __main__:<module>:160 - Step64560, Loss: 3.6614761352539062, Grad L2 Norm: 0.022425934672355652
2025-11-24 02:16:14.392 | INFO     | __main__:<module>:160 - Step64570, Loss: 3.5559654235839844, Grad L2 Norm: 0.025067396461963654
2025-11-24 02:16:16.359 | INFO     | __main__:<module>:160 - Step64580, Loss: 3.6485419273376465, Grad L2 Norm: 0.02304491400718689
2025-11-24 02:16:18.330 | INFO     | __main__:<module>:160 - Step64590, Loss: 3.603576183319092, Grad L2 Norm: 0.027661321684718132
2025-11-24 02:16:20.299 | INFO     | __main__:<module>:160 - Step64600, Loss: 3.5016722679138184, Grad L2 Norm: 0.022215666249394417
2025-11-24 02:16:22.277 | INFO     | __main__:<module>:160 - Step64610, Loss: 3.557727336883545, Grad L2 Norm: 0.02296733483672142
2025-11-24 02:16:24.243 | INFO     | __main__:<module>:160 - Step64620, Loss: 3.5052123069763184, Grad L2 Norm: 0.02282257005572319
2025-11-24 02:16:26.213 | INFO     | __main__:<module>:160 - Step64630, Loss: 3.6002535820007324, Grad L2 Norm: 0.02235894463956356
2025-11-24 02:16:28.177 | INFO     | __main__:<module>:160 - Step64640, Loss: 3.5451607704162598, Grad L2 Norm: 0.022444751113653183
2025-11-24 02:16:30.143 | INFO     | __main__:<module>:160 - Step64650, Loss: 3.533513307571411, Grad L2 Norm: 0.02316553331911564
2025-11-24 02:16:32.115 | INFO     | __main__:<module>:160 - Step64660, Loss: 3.5840396881103516, Grad L2 Norm: 0.023728178814053535
2025-11-24 02:16:34.090 | INFO     | __main__:<module>:160 - Step64670, Loss: 3.531428098678589, Grad L2 Norm: 0.02307635359466076
2025-11-24 02:16:36.055 | INFO     | __main__:<module>:160 - Step64680, Loss: 3.6358742713928223, Grad L2 Norm: 0.025646427646279335
2025-11-24 02:16:38.026 | INFO     | __main__:<module>:160 - Step64690, Loss: 3.560150146484375, Grad L2 Norm: 0.02274651825428009
2025-11-24 02:16:39.994 | INFO     | __main__:<module>:160 - Step64700, Loss: 3.622793197631836, Grad L2 Norm: 0.02503269538283348
2025-11-24 02:16:41.966 | INFO     | __main__:<module>:160 - Step64710, Loss: 3.5919864177703857, Grad L2 Norm: 0.023083096370100975
2025-11-24 02:16:43.934 | INFO     | __main__:<module>:160 - Step64720, Loss: 3.530299663543701, Grad L2 Norm: 0.02285429649055004
2025-11-24 02:16:45.902 | INFO     | __main__:<module>:160 - Step64730, Loss: 3.4482946395874023, Grad L2 Norm: 0.0241601150482893
2025-11-24 02:16:47.872 | INFO     | __main__:<module>:160 - Step64740, Loss: 3.53889536857605, Grad L2 Norm: 0.02178064174950123
2025-11-24 02:16:49.841 | INFO     | __main__:<module>:160 - Step64750, Loss: 3.5641183853149414, Grad L2 Norm: 0.022690773010253906
2025-11-24 02:16:51.806 | INFO     | __main__:<module>:160 - Step64760, Loss: 3.6749281883239746, Grad L2 Norm: 0.021967703476548195
2025-11-24 02:16:53.770 | INFO     | __main__:<module>:160 - Step64770, Loss: 3.60616397857666, Grad L2 Norm: 0.023990722373127937
2025-11-24 02:16:55.735 | INFO     | __main__:<module>:160 - Step64780, Loss: 3.6050050258636475, Grad L2 Norm: 0.024071985855698586
2025-11-24 02:16:57.704 | INFO     | __main__:<module>:160 - Step64790, Loss: 3.5075063705444336, Grad L2 Norm: 0.02266889438033104
2025-11-24 02:16:59.672 | INFO     | __main__:<module>:160 - Step64800, Loss: 3.539787530899048, Grad L2 Norm: 0.021024560555815697
2025-11-24 02:16:59.672 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:17:00.921 | INFO     | __main__:<module>:181 - validation loss: 3.5745865941047668
2025-11-24 02:17:02.901 | INFO     | __main__:<module>:160 - Step64810, Loss: 3.6208038330078125, Grad L2 Norm: 0.02423928678035736
2025-11-24 02:17:04.886 | INFO     | __main__:<module>:160 - Step64820, Loss: 3.3871583938598633, Grad L2 Norm: 0.024083007127046585
2025-11-24 02:17:06.863 | INFO     | __main__:<module>:160 - Step64830, Loss: 3.6663405895233154, Grad L2 Norm: 0.0222360510379076
2025-11-24 02:17:08.834 | INFO     | __main__:<module>:160 - Step64840, Loss: 3.5484867095947266, Grad L2 Norm: 0.022626811638474464
2025-11-24 02:17:10.805 | INFO     | __main__:<module>:160 - Step64850, Loss: 3.498147487640381, Grad L2 Norm: 0.021644223481416702
2025-11-24 02:17:12.781 | INFO     | __main__:<module>:160 - Step64860, Loss: 3.608543634414673, Grad L2 Norm: 0.02367575280368328
2025-11-24 02:17:14.754 | INFO     | __main__:<module>:160 - Step64870, Loss: 3.3948094844818115, Grad L2 Norm: 0.021446162834763527
2025-11-24 02:17:16.723 | INFO     | __main__:<module>:160 - Step64880, Loss: 3.5359766483306885, Grad L2 Norm: 0.022032352164387703
2025-11-24 02:17:18.697 | INFO     | __main__:<module>:160 - Step64890, Loss: 3.600769519805908, Grad L2 Norm: 0.022899895906448364
2025-11-24 02:17:20.666 | INFO     | __main__:<module>:160 - Step64900, Loss: 3.620518684387207, Grad L2 Norm: 0.02231064811348915
2025-11-24 02:17:22.637 | INFO     | __main__:<module>:160 - Step64910, Loss: 3.47004771232605, Grad L2 Norm: 0.021774042397737503
2025-11-24 02:17:24.599 | INFO     | __main__:<module>:160 - Step64920, Loss: 3.5634067058563232, Grad L2 Norm: 0.023261578753590584
2025-11-24 02:17:26.569 | INFO     | __main__:<module>:160 - Step64930, Loss: 3.4554591178894043, Grad L2 Norm: 0.02237122878432274
2025-11-24 02:17:28.536 | INFO     | __main__:<module>:160 - Step64940, Loss: 3.5504822731018066, Grad L2 Norm: 0.02264334447681904
2025-11-24 02:17:30.505 | INFO     | __main__:<module>:160 - Step64950, Loss: 3.6208009719848633, Grad L2 Norm: 0.02254839614033699
2025-11-24 02:17:32.474 | INFO     | __main__:<module>:160 - Step64960, Loss: 3.5142128467559814, Grad L2 Norm: 0.02327360026538372
2025-11-24 02:17:34.447 | INFO     | __main__:<module>:160 - Step64970, Loss: 3.690995693206787, Grad L2 Norm: 0.023918241262435913
2025-11-24 02:17:36.419 | INFO     | __main__:<module>:160 - Step64980, Loss: 3.6233620643615723, Grad L2 Norm: 0.02182711847126484
2025-11-24 02:17:38.392 | INFO     | __main__:<module>:160 - Step64990, Loss: 3.746433734893799, Grad L2 Norm: 0.02539270557463169
2025-11-24 02:17:40.372 | INFO     | __main__:<module>:160 - Step65000, Loss: 3.505103826522827, Grad L2 Norm: 0.025615014135837555
2025-11-24 02:17:42.345 | INFO     | __main__:<module>:160 - Step65010, Loss: 3.4994709491729736, Grad L2 Norm: 0.022261926904320717
2025-11-24 02:17:44.315 | INFO     | __main__:<module>:160 - Step65020, Loss: 3.4814648628234863, Grad L2 Norm: 0.022120395675301552
2025-11-24 02:17:46.288 | INFO     | __main__:<module>:160 - Step65030, Loss: 3.592874050140381, Grad L2 Norm: 0.025234760716557503
2025-11-24 02:17:48.259 | INFO     | __main__:<module>:160 - Step65040, Loss: 3.6056299209594727, Grad L2 Norm: 0.023670805618166924
2025-11-24 02:17:50.230 | INFO     | __main__:<module>:160 - Step65050, Loss: 3.4997713565826416, Grad L2 Norm: 0.023687006905674934
2025-11-24 02:17:52.202 | INFO     | __main__:<module>:160 - Step65060, Loss: 3.469290256500244, Grad L2 Norm: 0.022676218301057816
2025-11-24 02:17:54.172 | INFO     | __main__:<module>:160 - Step65070, Loss: 3.6157066822052, Grad L2 Norm: 0.023707976564764977
2025-11-24 02:17:56.144 | INFO     | __main__:<module>:160 - Step65080, Loss: 3.5143585205078125, Grad L2 Norm: 0.02429714985191822
2025-11-24 02:17:58.117 | INFO     | __main__:<module>:160 - Step65090, Loss: 3.4488935470581055, Grad L2 Norm: 0.02266530878841877
2025-11-24 02:18:00.088 | INFO     | __main__:<module>:160 - Step65100, Loss: 3.666719913482666, Grad L2 Norm: 0.024454455822706223
2025-11-24 02:18:02.061 | INFO     | __main__:<module>:160 - Step65110, Loss: 3.622840404510498, Grad L2 Norm: 0.023524845018982887
2025-11-24 02:18:04.030 | INFO     | __main__:<module>:160 - Step65120, Loss: 3.451251745223999, Grad L2 Norm: 0.02149251662194729
2025-11-24 02:18:06.000 | INFO     | __main__:<module>:160 - Step65130, Loss: 3.504901647567749, Grad L2 Norm: 0.02222675085067749
2025-11-24 02:18:07.966 | INFO     | __main__:<module>:160 - Step65140, Loss: 3.5415868759155273, Grad L2 Norm: 0.02535025216639042
2025-11-24 02:18:09.939 | INFO     | __main__:<module>:160 - Step65150, Loss: 3.475874900817871, Grad L2 Norm: 0.02284771390259266
2025-11-24 02:18:11.902 | INFO     | __main__:<module>:160 - Step65160, Loss: 3.569010019302368, Grad L2 Norm: 0.022484781220555305
2025-11-24 02:18:13.862 | INFO     | __main__:<module>:160 - Step65170, Loss: 3.638436794281006, Grad L2 Norm: 0.02421591617166996
2025-11-24 02:18:15.828 | INFO     | __main__:<module>:160 - Step65180, Loss: 3.5168838500976562, Grad L2 Norm: 0.02308797650039196
2025-11-24 02:18:17.798 | INFO     | __main__:<module>:160 - Step65190, Loss: 3.5384206771850586, Grad L2 Norm: 0.022069483995437622
2025-11-24 02:18:19.764 | INFO     | __main__:<module>:160 - Step65200, Loss: 3.559340238571167, Grad L2 Norm: 0.024154312908649445
2025-11-24 02:18:19.764 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:18:21.012 | INFO     | __main__:<module>:181 - validation loss: 3.572885012626648
2025-11-24 02:18:22.985 | INFO     | __main__:<module>:160 - Step65210, Loss: 3.4707350730895996, Grad L2 Norm: 0.02231302484869957
2025-11-24 02:18:24.956 | INFO     | __main__:<module>:160 - Step65220, Loss: 3.7309086322784424, Grad L2 Norm: 0.023499149829149246
2025-11-24 02:18:26.919 | INFO     | __main__:<module>:160 - Step65230, Loss: 3.5422112941741943, Grad L2 Norm: 0.022560279816389084
2025-11-24 02:18:28.884 | INFO     | __main__:<module>:160 - Step65240, Loss: 3.60640025138855, Grad L2 Norm: 0.024545254185795784
2025-11-24 02:18:30.855 | INFO     | __main__:<module>:160 - Step65250, Loss: 3.630993366241455, Grad L2 Norm: 0.025154823437333107
2025-11-24 02:18:32.825 | INFO     | __main__:<module>:160 - Step65260, Loss: 3.489675283432007, Grad L2 Norm: 0.022782720625400543
2025-11-24 02:18:34.794 | INFO     | __main__:<module>:160 - Step65270, Loss: 3.669053077697754, Grad L2 Norm: 0.02252546325325966
2025-11-24 02:18:36.761 | INFO     | __main__:<module>:160 - Step65280, Loss: 3.596569061279297, Grad L2 Norm: 0.022132493555545807
2025-11-24 02:18:38.730 | INFO     | __main__:<module>:160 - Step65290, Loss: 3.623539924621582, Grad L2 Norm: 0.025029456242918968
2025-11-24 02:18:40.695 | INFO     | __main__:<module>:160 - Step65300, Loss: 3.5650126934051514, Grad L2 Norm: 0.022606581449508667
2025-11-24 02:18:42.659 | INFO     | __main__:<module>:160 - Step65310, Loss: 3.6015305519104004, Grad L2 Norm: 0.024938086047768593
2025-11-24 02:18:44.633 | INFO     | __main__:<module>:160 - Step65320, Loss: 3.5510292053222656, Grad L2 Norm: 0.023800645023584366
2025-11-24 02:18:46.606 | INFO     | __main__:<module>:160 - Step65330, Loss: 3.547311782836914, Grad L2 Norm: 0.02349601686000824
2025-11-24 02:18:48.574 | INFO     | __main__:<module>:160 - Step65340, Loss: 3.5690159797668457, Grad L2 Norm: 0.023015230894088745
2025-11-24 02:18:50.550 | INFO     | __main__:<module>:160 - Step65350, Loss: 3.546239137649536, Grad L2 Norm: 0.0237276628613472
2025-11-24 02:18:52.525 | INFO     | __main__:<module>:160 - Step65360, Loss: 3.6018781661987305, Grad L2 Norm: 0.021621907129883766
2025-11-24 02:18:54.494 | INFO     | __main__:<module>:160 - Step65370, Loss: 3.525848627090454, Grad L2 Norm: 0.02319498546421528
2025-11-24 02:18:56.469 | INFO     | __main__:<module>:160 - Step65380, Loss: 3.4599575996398926, Grad L2 Norm: 0.022089185193181038
2025-11-24 02:18:58.437 | INFO     | __main__:<module>:160 - Step65390, Loss: 3.4280080795288086, Grad L2 Norm: 0.022231586277484894
2025-11-24 02:19:00.409 | INFO     | __main__:<module>:160 - Step65400, Loss: 3.4798011779785156, Grad L2 Norm: 0.021953443065285683
2025-11-24 02:19:02.373 | INFO     | __main__:<module>:160 - Step65410, Loss: 3.590419292449951, Grad L2 Norm: 0.025507746264338493
2025-11-24 02:19:04.342 | INFO     | __main__:<module>:160 - Step65420, Loss: 3.46496844291687, Grad L2 Norm: 0.02249022386968136
2025-11-24 02:19:06.315 | INFO     | __main__:<module>:160 - Step65430, Loss: 3.589926242828369, Grad L2 Norm: 0.0221187062561512
2025-11-24 02:19:08.290 | INFO     | __main__:<module>:160 - Step65440, Loss: 3.597428321838379, Grad L2 Norm: 0.022410515695810318
2025-11-24 02:19:10.263 | INFO     | __main__:<module>:160 - Step65450, Loss: 3.5626766681671143, Grad L2 Norm: 0.022400397807359695
2025-11-24 02:19:12.233 | INFO     | __main__:<module>:160 - Step65460, Loss: 3.484363079071045, Grad L2 Norm: 0.02214362844824791
2025-11-24 02:19:14.206 | INFO     | __main__:<module>:160 - Step65470, Loss: 3.561363935470581, Grad L2 Norm: 0.02193732000887394
2025-11-24 02:19:16.180 | INFO     | __main__:<module>:160 - Step65480, Loss: 3.626451253890991, Grad L2 Norm: 0.021721316501498222
2025-11-24 02:19:18.155 | INFO     | __main__:<module>:160 - Step65490, Loss: 3.5440568923950195, Grad L2 Norm: 0.023470988497138023
2025-11-24 02:19:20.128 | INFO     | __main__:<module>:160 - Step65500, Loss: 3.430116891860962, Grad L2 Norm: 0.022615090012550354
2025-11-24 02:19:22.104 | INFO     | __main__:<module>:160 - Step65510, Loss: 3.5029611587524414, Grad L2 Norm: 0.022099899128079414
2025-11-24 02:19:24.074 | INFO     | __main__:<module>:160 - Step65520, Loss: 3.5465354919433594, Grad L2 Norm: 0.02183685079216957
2025-11-24 02:19:26.041 | INFO     | __main__:<module>:160 - Step65530, Loss: 3.7649264335632324, Grad L2 Norm: 0.024601006880402565
2025-11-24 02:19:28.012 | INFO     | __main__:<module>:160 - Step65540, Loss: 3.729496955871582, Grad L2 Norm: 0.025838270783424377
2025-11-24 02:19:29.982 | INFO     | __main__:<module>:160 - Step65550, Loss: 3.545811176300049, Grad L2 Norm: 0.022438405081629753
2025-11-24 02:19:31.956 | INFO     | __main__:<module>:160 - Step65560, Loss: 3.580327033996582, Grad L2 Norm: 0.02548857033252716
2025-11-24 02:19:33.929 | INFO     | __main__:<module>:160 - Step65570, Loss: 3.5358471870422363, Grad L2 Norm: 0.022778013721108437
2025-11-24 02:19:35.902 | INFO     | __main__:<module>:160 - Step65580, Loss: 3.5750136375427246, Grad L2 Norm: 0.02246583253145218
2025-11-24 02:19:37.874 | INFO     | __main__:<module>:160 - Step65590, Loss: 3.5770039558410645, Grad L2 Norm: 0.02328706905245781
2025-11-24 02:19:39.840 | INFO     | __main__:<module>:160 - Step65600, Loss: 3.4984958171844482, Grad L2 Norm: 0.021614255383610725
2025-11-24 02:19:39.840 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:19:41.091 | INFO     | __main__:<module>:181 - validation loss: 3.5625141978263857
2025-11-24 02:19:43.073 | INFO     | __main__:<module>:160 - Step65610, Loss: 3.5421478748321533, Grad L2 Norm: 0.02372913435101509
2025-11-24 02:19:45.046 | INFO     | __main__:<module>:160 - Step65620, Loss: 3.5173163414001465, Grad L2 Norm: 0.02148059569299221
2025-11-24 02:19:47.014 | INFO     | __main__:<module>:160 - Step65630, Loss: 3.57625150680542, Grad L2 Norm: 0.02341841533780098
2025-11-24 02:19:48.985 | INFO     | __main__:<module>:160 - Step65640, Loss: 3.5963196754455566, Grad L2 Norm: 0.023526202887296677
2025-11-24 02:19:50.955 | INFO     | __main__:<module>:160 - Step65650, Loss: 3.6022679805755615, Grad L2 Norm: 0.02527862787246704
2025-11-24 02:19:52.932 | INFO     | __main__:<module>:160 - Step65660, Loss: 3.5055699348449707, Grad L2 Norm: 0.02221032790839672
2025-11-24 02:19:54.910 | INFO     | __main__:<module>:160 - Step65670, Loss: 3.635997772216797, Grad L2 Norm: 0.02408735267817974
2025-11-24 02:19:56.884 | INFO     | __main__:<module>:160 - Step65680, Loss: 3.5765538215637207, Grad L2 Norm: 0.02291487343609333
2025-11-24 02:19:58.850 | INFO     | __main__:<module>:160 - Step65690, Loss: 3.5505075454711914, Grad L2 Norm: 0.02192356251180172
2025-11-24 02:20:00.820 | INFO     | __main__:<module>:160 - Step65700, Loss: 3.4966495037078857, Grad L2 Norm: 0.02232205867767334
2025-11-24 02:20:02.789 | INFO     | __main__:<module>:160 - Step65710, Loss: 3.4594225883483887, Grad L2 Norm: 0.022774485871195793
2025-11-24 02:20:04.759 | INFO     | __main__:<module>:160 - Step65720, Loss: 3.532796859741211, Grad L2 Norm: 0.023206554353237152
2025-11-24 02:20:06.727 | INFO     | __main__:<module>:160 - Step65730, Loss: 3.562023162841797, Grad L2 Norm: 0.022982534021139145
2025-11-24 02:20:08.696 | INFO     | __main__:<module>:160 - Step65740, Loss: 3.693861961364746, Grad L2 Norm: 0.02609635703265667
2025-11-24 02:20:10.668 | INFO     | __main__:<module>:160 - Step65750, Loss: 3.5354843139648438, Grad L2 Norm: 0.02258933335542679
2025-11-24 02:20:12.644 | INFO     | __main__:<module>:160 - Step65760, Loss: 3.558001756668091, Grad L2 Norm: 0.022681821137666702
2025-11-24 02:20:14.611 | INFO     | __main__:<module>:160 - Step65770, Loss: 3.5658230781555176, Grad L2 Norm: 0.02290119230747223
2025-11-24 02:20:16.582 | INFO     | __main__:<module>:160 - Step65780, Loss: 3.6375529766082764, Grad L2 Norm: 0.022475188598036766
2025-11-24 02:20:18.547 | INFO     | __main__:<module>:160 - Step65790, Loss: 3.6837706565856934, Grad L2 Norm: 0.023020029067993164
2025-11-24 02:20:20.520 | INFO     | __main__:<module>:160 - Step65800, Loss: 3.452989101409912, Grad L2 Norm: 0.02375577762722969
2025-11-24 02:20:22.488 | INFO     | __main__:<module>:160 - Step65810, Loss: 3.5548741817474365, Grad L2 Norm: 0.021792978048324585
2025-11-24 02:20:24.463 | INFO     | __main__:<module>:160 - Step65820, Loss: 3.4886231422424316, Grad L2 Norm: 0.024265840649604797
2025-11-24 02:20:26.434 | INFO     | __main__:<module>:160 - Step65830, Loss: 3.5522541999816895, Grad L2 Norm: 0.023264432325959206
2025-11-24 02:20:28.403 | INFO     | __main__:<module>:160 - Step65840, Loss: 3.630648612976074, Grad L2 Norm: 0.023678753525018692
2025-11-24 02:20:30.366 | INFO     | __main__:<module>:160 - Step65850, Loss: 3.643402099609375, Grad L2 Norm: 0.022792337462306023
2025-11-24 02:20:32.332 | INFO     | __main__:<module>:160 - Step65860, Loss: 3.6599514484405518, Grad L2 Norm: 0.02319403924047947
2025-11-24 02:20:34.298 | INFO     | __main__:<module>:160 - Step65870, Loss: 3.4035580158233643, Grad L2 Norm: 0.021985070779919624
2025-11-24 02:20:36.265 | INFO     | __main__:<module>:160 - Step65880, Loss: 3.5262436866760254, Grad L2 Norm: 0.023408735170960426
2025-11-24 02:20:38.236 | INFO     | __main__:<module>:160 - Step65890, Loss: 3.6776537895202637, Grad L2 Norm: 0.023438723757863045
2025-11-24 02:20:40.202 | INFO     | __main__:<module>:160 - Step65900, Loss: 3.6900577545166016, Grad L2 Norm: 0.022457262501120567
2025-11-24 02:20:42.170 | INFO     | __main__:<module>:160 - Step65910, Loss: 3.60271954536438, Grad L2 Norm: 0.02324533835053444
2025-11-24 02:20:44.137 | INFO     | __main__:<module>:160 - Step65920, Loss: 3.535551071166992, Grad L2 Norm: 0.02329692430794239
2025-11-24 02:20:46.107 | INFO     | __main__:<module>:160 - Step65930, Loss: 3.6832151412963867, Grad L2 Norm: 0.023472797125577927
2025-11-24 02:20:48.078 | INFO     | __main__:<module>:160 - Step65940, Loss: 3.4999749660491943, Grad L2 Norm: 0.025579262524843216
2025-11-24 02:20:50.048 | INFO     | __main__:<module>:160 - Step65950, Loss: 3.5819568634033203, Grad L2 Norm: 0.023279596120119095
2025-11-24 02:20:52.014 | INFO     | __main__:<module>:160 - Step65960, Loss: 3.647930383682251, Grad L2 Norm: 0.022580843418836594
2025-11-24 02:20:53.986 | INFO     | __main__:<module>:160 - Step65970, Loss: 3.6053080558776855, Grad L2 Norm: 0.022365044802427292
2025-11-24 02:20:55.955 | INFO     | __main__:<module>:160 - Step65980, Loss: 3.605225086212158, Grad L2 Norm: 0.024002861231565475
2025-11-24 02:20:57.927 | INFO     | __main__:<module>:160 - Step65990, Loss: 3.4947752952575684, Grad L2 Norm: 0.022925514727830887
2025-11-24 02:20:59.894 | INFO     | __main__:<module>:160 - Step66000, Loss: 3.558476686477661, Grad L2 Norm: 0.025143520906567574
2025-11-24 02:20:59.895 | INFO     | __main__:<module>:172 - Evaluating on validation dataset
2025-11-24 02:21:01.144 | INFO     | __main__:<module>:181 - validation loss: 3.5903352737426757
2025-11-24 02:21:01.145 | INFO     | __main__:<module>:187 - Saving model checkpoint to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/checkpoint_v0_66000.pt
2025-11-24 02:21:02.852 | INFO     | __main__:<module>:194 - Model checkpoint saved successfully
2025-11-24 02:21:04.797 | INFO     | __main__:<module>:160 - Step66010, Loss: 3.5564351081848145, Grad L2 Norm: 0.022644992917776108
2025-11-24 02:21:06.766 | INFO     | __main__:<module>:160 - Step66020, Loss: 3.727078437805176, Grad L2 Norm: 0.02409503236413002
2025-11-24 02:21:08.731 | INFO     | __main__:<module>:160 - Step66030, Loss: 3.588700771331787, Grad L2 Norm: 0.024213535711169243
2025-11-24 02:21:10.697 | INFO     | __main__:<module>:160 - Step66040, Loss: 3.524320363998413, Grad L2 Norm: 0.021721169352531433
2025-11-24 02:21:12.665 | INFO     | __main__:<module>:160 - Step66050, Loss: 3.588456392288208, Grad L2 Norm: 0.02307847887277603
2025-11-24 02:21:14.630 | INFO     | __main__:<module>:160 - Step66060, Loss: 3.578531265258789, Grad L2 Norm: 0.022213757038116455
2025-11-24 02:21:15.413 | INFO     | __main__:<module>:197 - Model training completed
2025-11-24 02:21:15.413 | INFO     | __main__:<module>:200 - Saving the final model to: /media/yizhouli/1TB 970 Evo Plus/code/cs336/data/model/final_model_v0.pt
2025-11-24 02:21:17.110 | INFO     | __main__:<module>:209 - Final model saved
